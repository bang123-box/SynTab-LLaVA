[2024-11-03 18:11:26,660] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-03 18:11:28,495] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-11-03 18:11:28,495] [INFO] [runner.py:568:main] cmd = /opt/conda/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=20056 --enable_each_rank_log=None llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed ./scripts/zero3.json --model_name_or_path /home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d --version v1 --data_path sft.jsonl --image_folder none --highres_vision_tower /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 --lowres_vision_tower /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1 --pretrain_mm_mlp_adapter ./pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir ./checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava --num_train_epochs 1 --per_device_train_batch_size 10 --per_device_eval_batch_size 4 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 6000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2560 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none
[2024-11-03 18:11:30,687] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-03 18:11:32,493] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
[2024-11-03 18:11:32,493] [INFO] [launch.py:139:main] 0 NCCL_P2P_DISABLE=1
[2024-11-03 18:11:32,493] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 3, 4, 5, 6, 7]}
[2024-11-03 18:11:32,493] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=7, node_rank=0
[2024-11-03 18:11:32,493] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6]})
[2024-11-03 18:11:32,493] [INFO] [launch.py:164:main] dist_world_size=7
[2024-11-03 18:11:32,493] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,3,4,5,6,7
[2024-11-03 18:11:32,494] [INFO] [launch.py:256:main] process 4447 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:32,494] [INFO] [launch.py:256:main] process 4448 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=1', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:32,494] [INFO] [launch.py:256:main] process 4449 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=2', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:32,495] [INFO] [launch.py:256:main] process 4450 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=3', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:32,495] [INFO] [launch.py:256:main] process 4451 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=4', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:32,496] [INFO] [launch.py:256:main] process 4452 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=5', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:32,496] [INFO] [launch.py:256:main] process 4453 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=6', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'v1', '--data_path', 'sft.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--pretrain_mm_mlp_adapter', './pretrained_mm_projector/Pre_MP_7b_Conv_Clip/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/lr2e5_Pre_MP_7b_Sftlora_MS_Conv_Clip_llava', '--num_train_epochs', '1', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-03 18:11:36,844] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-11-03 18:11:36,966] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 18:11:36,972] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 18:11:37,000] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 18:11:37,023] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 18:11:37,052] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 18:11:37,072] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-03 18:11:38,381] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 18:11:38,517] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 18:11:38,536] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 18:11:38,545] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 18:11:38,575] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 18:11:38,586] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 18:11:38,587] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 18:11:38,628] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-11-03 18:11:42,350] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.45s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.44s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.44s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.44s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.44s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.43s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:24<00:24, 24.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.30s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 11.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.50s/it]
Adding LoRA adapters...
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
[2024-11-03 18:12:33,510] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 691, num_elems = 7.41B
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
[2024-11-03 18:12:36,005] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 1082, num_elems = 7.71B
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Formatting inputs...Skip in lazy mode
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Parameter Offload: Total persistent parameters: 2136768 in 615 params
  0%|          | 0/1663 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3988 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2781 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2980 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (11237 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5665 > 2560). Running this sequence through the model will result in indexing errors
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (3000 > 2560). Running this sequence through the model will result in indexing errors
  0%|          | 1/1663 [00:59<27:22:50, 59.31s/it]                                                   {'loss': 1.1094, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.0}
  0%|          | 1/1663 [00:59<27:22:50, 59.31s/it]  0%|          | 2/1663 [01:30<19:51:02, 43.02s/it]                                                   {'loss': 0.8279, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.0}
  0%|          | 2/1663 [01:30<19:51:02, 43.02s/it]  0%|          | 3/1663 [02:01<17:15:20, 37.42s/it]                                                   {'loss': 0.964, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.0}
  0%|          | 3/1663 [02:01<17:15:20, 37.42s/it]  0%|          | 4/1663 [02:32<16:03:21, 34.84s/it]                                                   {'loss': 1.0487, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.0}
  0%|          | 4/1663 [02:32<16:03:21, 34.84s/it]  0%|          | 5/1663 [03:03<15:22:52, 33.40s/it]                                                   {'loss': 1.0149, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 5/1663 [03:03<15:22:52, 33.40s/it]  0%|          | 6/1663 [03:34<15:05:18, 32.78s/it]                                                   {'loss': 0.8227, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.0}
  0%|          | 6/1663 [03:34<15:05:18, 32.78s/it]  0%|          | 7/1663 [04:06<14:54:02, 32.39s/it]                                                   {'loss': 0.9865, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.0}
  0%|          | 7/1663 [04:06<14:54:02, 32.39s/it]  0%|          | 8/1663 [04:37<14:44:40, 32.07s/it]                                                   {'loss': 0.9286, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.0}
  0%|          | 8/1663 [04:37<14:44:40, 32.07s/it]  1%|          | 9/1663 [05:09<14:43:15, 32.04s/it]                                                   {'loss': 1.0173, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.01}
  1%|          | 9/1663 [05:09<14:43:15, 32.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2681 > 2560). Running this sequence through the model will result in indexing errors
  1%|          | 10/1663 [05:42<14:50:33, 32.32s/it]                                                    {'loss': 0.954, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 10/1663 [05:42<14:50:33, 32.32s/it]  1%|          | 11/1663 [06:13<14:34:26, 31.76s/it]                                                    {'loss': 0.8683, 'learning_rate': 4.4e-06, 'epoch': 0.01}
  1%|          | 11/1663 [06:13<14:34:26, 31.76s/it]  1%|          | 12/1663 [06:43<14:17:09, 31.15s/it]                                                    {'loss': 0.9104, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.01}
  1%|          | 12/1663 [06:43<14:17:09, 31.15s/it]  1%|          | 13/1663 [07:15<14:27:57, 31.56s/it]                                                    {'loss': 1.0007, 'learning_rate': 5.2e-06, 'epoch': 0.01}
  1%|          | 13/1663 [07:15<14:27:57, 31.56s/it]  1%|          | 14/1663 [07:45<14:17:02, 31.18s/it]                                                    {'loss': 1.0002, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.01}
  1%|          | 14/1663 [07:45<14:17:02, 31.18s/it]  1%|          | 15/1663 [08:17<14:20:39, 31.33s/it]                                                    {'loss': 0.9041, 'learning_rate': 6e-06, 'epoch': 0.01}
  1%|          | 15/1663 [08:17<14:20:39, 31.33s/it]  1%|          | 16/1663 [08:47<14:09:11, 30.94s/it]                                                    {'loss': 1.0127, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.01}
  1%|          | 16/1663 [08:47<14:09:11, 30.94s/it]  1%|          | 17/1663 [09:18<14:11:03, 31.02s/it]                                                    {'loss': 0.9889, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.01}
  1%|          | 17/1663 [09:18<14:11:03, 31.02s/it]  1%|          | 18/1663 [09:51<14:26:51, 31.62s/it]                                                    {'loss': 0.8112, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.01}
  1%|          | 18/1663 [09:51<14:26:51, 31.62s/it]  1%|          | 19/1663 [10:22<14:20:20, 31.40s/it]                                                    {'loss': 0.9072, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.01}
  1%|          | 19/1663 [10:22<14:20:20, 31.40s/it]  1%|          | 20/1663 [10:55<14:29:55, 31.77s/it]                                                    {'loss': 0.9516, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  1%|          | 20/1663 [10:55<14:29:55, 31.77s/it]  1%|▏         | 21/1663 [11:29<14:47:31, 32.43s/it]                                                    {'loss': 0.8805, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.01}
  1%|▏         | 21/1663 [11:29<14:47:31, 32.43s/it]  1%|▏         | 22/1663 [11:56<14:03:28, 30.84s/it]                                                    {'loss': 0.9671, 'learning_rate': 8.8e-06, 'epoch': 0.01}
  1%|▏         | 22/1663 [11:56<14:03:28, 30.84s/it]  1%|▏         | 23/1663 [12:28<14:09:03, 31.06s/it]                                                    {'loss': 0.8842, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.01}
  1%|▏         | 23/1663 [12:28<14:09:03, 31.06s/it]  1%|▏         | 24/1663 [12:59<14:12:10, 31.20s/it]                                                    {'loss': 0.8281, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.01}
  1%|▏         | 24/1663 [12:59<14:12:10, 31.20s/it]  2%|▏         | 25/1663 [13:29<13:59:56, 30.77s/it]                                                    {'loss': 0.9684, 'learning_rate': 1e-05, 'epoch': 0.02}
  2%|▏         | 25/1663 [13:29<13:59:56, 30.77s/it]  2%|▏         | 26/1663 [13:59<13:56:18, 30.65s/it]                                                    {'loss': 0.8141, 'learning_rate': 1.04e-05, 'epoch': 0.02}
  2%|▏         | 26/1663 [13:59<13:56:18, 30.65s/it]  2%|▏         | 27/1663 [14:30<13:58:04, 30.74s/it]                                                    {'loss': 0.8345, 'learning_rate': 1.0800000000000002e-05, 'epoch': 0.02}
  2%|▏         | 27/1663 [14:30<13:58:04, 30.74s/it]  2%|▏         | 28/1663 [15:03<14:17:06, 31.45s/it]                                                    {'loss': 0.7647, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.02}
  2%|▏         | 28/1663 [15:03<14:17:06, 31.45s/it]  2%|▏         | 29/1663 [15:37<14:34:49, 32.12s/it]                                                    {'loss': 0.7079, 'learning_rate': 1.16e-05, 'epoch': 0.02}
  2%|▏         | 29/1663 [15:37<14:34:49, 32.12s/it]  2%|▏         | 30/1663 [16:09<14:37:14, 32.23s/it]                                                    {'loss': 0.7326, 'learning_rate': 1.2e-05, 'epoch': 0.02}
  2%|▏         | 30/1663 [16:09<14:37:14, 32.23s/it]  2%|▏         | 31/1663 [16:39<14:16:35, 31.49s/it]                                                    {'loss': 0.8098, 'learning_rate': 1.2400000000000002e-05, 'epoch': 0.02}
  2%|▏         | 31/1663 [16:39<14:16:35, 31.49s/it]  2%|▏         | 32/1663 [17:10<14:11:25, 31.32s/it]                                                    {'loss': 0.8297, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.02}
  2%|▏         | 32/1663 [17:10<14:11:25, 31.32s/it]  2%|▏         | 33/1663 [17:40<14:00:58, 30.96s/it]                                                    {'loss': 0.7534, 'learning_rate': 1.3200000000000002e-05, 'epoch': 0.02}
  2%|▏         | 33/1663 [17:40<14:00:58, 30.96s/it]  2%|▏         | 34/1663 [18:11<13:56:34, 30.81s/it]                                                    {'loss': 0.7743, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.02}
  2%|▏         | 34/1663 [18:11<13:56:34, 30.81s/it]  2%|▏         | 35/1663 [18:41<13:49:09, 30.56s/it]                                                    {'loss': 0.7847, 'learning_rate': 1.4e-05, 'epoch': 0.02}
  2%|▏         | 35/1663 [18:41<13:49:09, 30.56s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2652 > 2560). Running this sequence through the model will result in indexing errors
  2%|▏         | 36/1663 [19:12<13:57:40, 30.89s/it]                                                    {'loss': 0.7405, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.02}
  2%|▏         | 36/1663 [19:12<13:57:40, 30.89s/it]  2%|▏         | 37/1663 [19:44<14:05:11, 31.19s/it]                                                    {'loss': 0.6752, 'learning_rate': 1.48e-05, 'epoch': 0.02}
  2%|▏         | 37/1663 [19:44<14:05:11, 31.19s/it]  2%|▏         | 38/1663 [20:19<14:32:15, 32.21s/it]                                                    {'loss': 0.7304, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.02}
  2%|▏         | 38/1663 [20:19<14:32:15, 32.21s/it]  2%|▏         | 39/1663 [20:52<14:38:01, 32.44s/it]                                                    {'loss': 0.7175, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.02}
  2%|▏         | 39/1663 [20:52<14:38:01, 32.44s/it]  2%|▏         | 40/1663 [21:22<14:16:57, 31.68s/it]                                                    {'loss': 0.7349, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.02}
  2%|▏         | 40/1663 [21:22<14:16:57, 31.68s/it]  2%|▏         | 41/1663 [21:53<14:14:41, 31.62s/it]                                                    {'loss': 0.6839, 'learning_rate': 1.64e-05, 'epoch': 0.02}
  2%|▏         | 41/1663 [21:53<14:14:41, 31.62s/it]  3%|▎         | 42/1663 [22:23<13:57:37, 31.00s/it]                                                    {'loss': 0.7177, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.03}
  3%|▎         | 42/1663 [22:23<13:57:37, 31.00s/it]  3%|▎         | 43/1663 [22:51<13:35:41, 30.21s/it]                                                    {'loss': 0.8061, 'learning_rate': 1.72e-05, 'epoch': 0.03}
  3%|▎         | 43/1663 [22:51<13:35:41, 30.21s/it]  3%|▎         | 44/1663 [23:22<13:44:00, 30.54s/it]                                                    {'loss': 0.6766, 'learning_rate': 1.76e-05, 'epoch': 0.03}
  3%|▎         | 44/1663 [23:22<13:44:00, 30.54s/it]  3%|▎         | 45/1663 [23:54<13:52:39, 30.88s/it]                                                    {'loss': 0.7579, 'learning_rate': 1.8e-05, 'epoch': 0.03}
  3%|▎         | 45/1663 [23:54<13:52:39, 30.88s/it]  3%|▎         | 46/1663 [24:23<13:39:44, 30.42s/it]                                                    {'loss': 0.669, 'learning_rate': 1.8400000000000003e-05, 'epoch': 0.03}
  3%|▎         | 46/1663 [24:23<13:39:44, 30.42s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2791 > 2560). Running this sequence through the model will result in indexing errors
  3%|▎         | 47/1663 [24:55<13:45:38, 30.66s/it]                                                    {'loss': 0.6835, 'learning_rate': 1.88e-05, 'epoch': 0.03}
  3%|▎         | 47/1663 [24:55<13:45:38, 30.66s/it]  3%|▎         | 48/1663 [25:27<13:56:23, 31.07s/it]                                                    {'loss': 0.737, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.03}
  3%|▎         | 48/1663 [25:27<13:56:23, 31.07s/it]  3%|▎         | 49/1663 [25:58<14:01:11, 31.27s/it]                                                    {'loss': 0.7489, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.03}
  3%|▎         | 49/1663 [25:58<14:01:11, 31.27s/it]  3%|▎         | 50/1663 [26:29<13:58:06, 31.18s/it]                                                    {'loss': 0.6213, 'learning_rate': 2e-05, 'epoch': 0.03}
  3%|▎         | 50/1663 [26:29<13:58:06, 31.18s/it]  3%|▎         | 51/1663 [27:01<13:59:14, 31.24s/it]                                                    {'loss': 0.6817, 'learning_rate': 1.999998103290246e-05, 'epoch': 0.03}
  3%|▎         | 51/1663 [27:01<13:59:14, 31.24s/it]  3%|▎         | 52/1663 [27:34<14:12:26, 31.75s/it]                                                    {'loss': 0.6463, 'learning_rate': 1.9999924131681782e-05, 'epoch': 0.03}
  3%|▎         | 52/1663 [27:34<14:12:26, 31.75s/it]  3%|▎         | 53/1663 [28:05<14:05:03, 31.49s/it]                                                    {'loss': 0.6282, 'learning_rate': 1.999982929655382e-05, 'epoch': 0.03}
  3%|▎         | 53/1663 [28:05<14:05:03, 31.49s/it]  3%|▎         | 54/1663 [28:36<14:04:15, 31.48s/it]                                                    {'loss': 0.6773, 'learning_rate': 1.9999696527878326e-05, 'epoch': 0.03}
  3%|▎         | 54/1663 [28:36<14:04:15, 31.48s/it]  3%|▎         | 55/1663 [29:08<14:07:58, 31.64s/it]                                                    {'loss': 0.6543, 'learning_rate': 1.9999525826158944e-05, 'epoch': 0.03}
  3%|▎         | 55/1663 [29:08<14:07:58, 31.64s/it]  3%|▎         | 56/1663 [29:41<14:18:05, 32.04s/it]                                                    {'loss': 0.5827, 'learning_rate': 1.9999317192043213e-05, 'epoch': 0.03}
  3%|▎         | 56/1663 [29:41<14:18:05, 32.04s/it]  3%|▎         | 57/1663 [30:12<14:12:10, 31.84s/it]                                                    {'loss': 0.6346, 'learning_rate': 1.9999070626322576e-05, 'epoch': 0.03}
  3%|▎         | 57/1663 [30:12<14:12:10, 31.84s/it]  3%|▎         | 58/1663 [30:46<14:21:44, 32.21s/it]                                                    {'loss': 0.6003, 'learning_rate': 1.999878612993236e-05, 'epoch': 0.03}
  3%|▎         | 58/1663 [30:46<14:21:44, 32.21s/it]  4%|▎         | 59/1663 [31:16<14:07:15, 31.69s/it]                                                    {'loss': 0.6004, 'learning_rate': 1.999846370395178e-05, 'epoch': 0.04}
  4%|▎         | 59/1663 [31:16<14:07:15, 31.69s/it]  4%|▎         | 60/1663 [31:46<13:56:52, 31.32s/it]                                                    {'loss': 0.6151, 'learning_rate': 1.9998103349603927e-05, 'epoch': 0.04}
  4%|▎         | 60/1663 [31:46<13:56:52, 31.32s/it]  4%|▎         | 61/1663 [32:19<14:06:23, 31.70s/it]                                                    {'loss': 0.6742, 'learning_rate': 1.9997705068255782e-05, 'epoch': 0.04}
  4%|▎         | 61/1663 [32:19<14:06:23, 31.70s/it]  4%|▎         | 62/1663 [32:50<14:01:22, 31.53s/it]                                                    {'loss': 0.6642, 'learning_rate': 1.999726886141819e-05, 'epoch': 0.04}
  4%|▎         | 62/1663 [32:50<14:01:22, 31.53s/it]  4%|▍         | 63/1663 [33:17<13:23:11, 30.12s/it]                                                    {'loss': 0.6548, 'learning_rate': 1.999679473074587e-05, 'epoch': 0.04}
  4%|▍         | 63/1663 [33:17<13:23:11, 30.12s/it]  4%|▍         | 64/1663 [33:49<13:39:03, 30.73s/it]                                                    {'loss': 0.6312, 'learning_rate': 1.9996282678037393e-05, 'epoch': 0.04}
  4%|▍         | 64/1663 [33:49<13:39:03, 30.73s/it]  4%|▍         | 65/1663 [34:20<13:40:23, 30.80s/it]                                                    {'loss': 0.5771, 'learning_rate': 1.9995732705235193e-05, 'epoch': 0.04}
  4%|▍         | 65/1663 [34:20<13:40:23, 30.80s/it]  4%|▍         | 66/1663 [34:53<13:58:22, 31.50s/it]                                                    {'loss': 0.5408, 'learning_rate': 1.9995144814425548e-05, 'epoch': 0.04}
  4%|▍         | 66/1663 [34:53<13:58:22, 31.50s/it]  4%|▍         | 67/1663 [35:24<13:55:02, 31.39s/it]                                                    {'loss': 0.6984, 'learning_rate': 1.9994519007838577e-05, 'epoch': 0.04}
  4%|▍         | 67/1663 [35:24<13:55:02, 31.39s/it]  4%|▍         | 68/1663 [35:57<14:03:57, 31.75s/it]                                                    {'loss': 0.6192, 'learning_rate': 1.999385528784822e-05, 'epoch': 0.04}
  4%|▍         | 68/1663 [35:57<14:03:57, 31.75s/it]  4%|▍         | 69/1663 [36:27<13:47:43, 31.16s/it]                                                    {'loss': 0.5548, 'learning_rate': 1.9993153656972254e-05, 'epoch': 0.04}
  4%|▍         | 69/1663 [36:27<13:47:43, 31.16s/it]  4%|▍         | 70/1663 [36:57<13:41:29, 30.94s/it]                                                    {'loss': 0.4403, 'learning_rate': 1.999241411787225e-05, 'epoch': 0.04}
  4%|▍         | 70/1663 [36:57<13:41:29, 30.94s/it]  4%|▍         | 71/1663 [37:27<13:29:40, 30.52s/it]                                                    {'loss': 0.5124, 'learning_rate': 1.9991636673353597e-05, 'epoch': 0.04}
  4%|▍         | 71/1663 [37:27<13:29:40, 30.52s/it]  4%|▍         | 72/1663 [37:56<13:21:23, 30.22s/it]                                                    {'loss': 0.5483, 'learning_rate': 1.9990821326365463e-05, 'epoch': 0.04}
  4%|▍         | 72/1663 [37:56<13:21:23, 30.22s/it]  4%|▍         | 73/1663 [38:27<13:21:13, 30.24s/it]                                                    {'loss': 0.497, 'learning_rate': 1.9989968080000808e-05, 'epoch': 0.04}
  4%|▍         | 73/1663 [38:27<13:21:13, 30.24s/it]  4%|▍         | 74/1663 [38:59<13:36:49, 30.84s/it]                                                    {'loss': 0.5997, 'learning_rate': 1.9989076937496346e-05, 'epoch': 0.04}
  4%|▍         | 74/1663 [38:59<13:36:49, 30.84s/it]  5%|▍         | 75/1663 [39:30<13:36:10, 30.84s/it]                                                    {'loss': 0.5807, 'learning_rate': 1.998814790223256e-05, 'epoch': 0.05}
  5%|▍         | 75/1663 [39:30<13:36:10, 30.84s/it]  5%|▍         | 76/1663 [40:00<13:36:00, 30.85s/it]                                                    {'loss': 0.5223, 'learning_rate': 1.9987180977733668e-05, 'epoch': 0.05}
  5%|▍         | 76/1663 [40:00<13:36:00, 30.85s/it]  5%|▍         | 77/1663 [40:33<13:50:06, 31.40s/it]                                                    {'loss': 0.6333, 'learning_rate': 1.9986176167667617e-05, 'epoch': 0.05}
  5%|▍         | 77/1663 [40:33<13:50:06, 31.40s/it]  5%|▍         | 78/1663 [41:04<13:47:11, 31.31s/it]                                                    {'loss': 0.5947, 'learning_rate': 1.998513347584608e-05, 'epoch': 0.05}
  5%|▍         | 78/1663 [41:04<13:47:11, 31.31s/it]  5%|▍         | 79/1663 [41:34<13:33:58, 30.83s/it]                                                    {'loss': 0.5478, 'learning_rate': 1.9984052906224422e-05, 'epoch': 0.05}
  5%|▍         | 79/1663 [41:34<13:33:58, 30.83s/it]  5%|▍         | 80/1663 [42:05<13:36:48, 30.96s/it]                                                    {'loss': 0.6523, 'learning_rate': 1.9982934462901694e-05, 'epoch': 0.05}
  5%|▍         | 80/1663 [42:05<13:36:48, 30.96s/it]  5%|▍         | 81/1663 [42:36<13:33:40, 30.86s/it]                                                    {'loss': 0.5267, 'learning_rate': 1.998177815012062e-05, 'epoch': 0.05}
  5%|▍         | 81/1663 [42:36<13:33:40, 30.86s/it]  5%|▍         | 82/1663 [43:05<13:20:02, 30.36s/it]                                                    {'loss': 0.5826, 'learning_rate': 1.9980583972267585e-05, 'epoch': 0.05}
  5%|▍         | 82/1663 [43:05<13:20:02, 30.36s/it]  5%|▍         | 83/1663 [43:39<13:50:14, 31.53s/it]                                                    {'loss': 0.4402, 'learning_rate': 1.9979351933872605e-05, 'epoch': 0.05}
  5%|▍         | 83/1663 [43:39<13:50:14, 31.53s/it]  5%|▌         | 84/1663 [44:12<13:56:05, 31.77s/it]                                                    {'loss': 0.5564, 'learning_rate': 1.9978082039609316e-05, 'epoch': 0.05}
  5%|▌         | 84/1663 [44:12<13:56:05, 31.77s/it]  5%|▌         | 85/1663 [44:43<13:55:52, 31.78s/it]                                                    {'loss': 0.5072, 'learning_rate': 1.997677429429496e-05, 'epoch': 0.05}
  5%|▌         | 85/1663 [44:43<13:55:52, 31.78s/it]  5%|▌         | 86/1663 [45:17<14:07:42, 32.25s/it]                                                    {'loss': 0.4428, 'learning_rate': 1.9975428702890368e-05, 'epoch': 0.05}
  5%|▌         | 86/1663 [45:17<14:07:42, 32.25s/it]  5%|▌         | 87/1663 [45:47<13:47:07, 31.49s/it]                                                    {'loss': 0.5382, 'learning_rate': 1.9974045270499923e-05, 'epoch': 0.05}
  5%|▌         | 87/1663 [45:47<13:47:07, 31.49s/it]  5%|▌         | 88/1663 [46:19<13:58:16, 31.93s/it]                                                    {'loss': 0.5767, 'learning_rate': 1.9972624002371575e-05, 'epoch': 0.05}
  5%|▌         | 88/1663 [46:20<13:58:16, 31.93s/it]  5%|▌         | 89/1663 [46:52<14:01:36, 32.08s/it]                                                    {'loss': 0.5132, 'learning_rate': 1.9971164903896784e-05, 'epoch': 0.05}
  5%|▌         | 89/1663 [46:52<14:01:36, 32.08s/it]  5%|▌         | 90/1663 [47:24<14:02:07, 32.12s/it]                                                    {'loss': 0.5375, 'learning_rate': 1.9969667980610527e-05, 'epoch': 0.05}
  5%|▌         | 90/1663 [47:24<14:02:07, 32.12s/it]  5%|▌         | 91/1663 [47:55<13:54:37, 31.86s/it]                                                    {'loss': 0.6062, 'learning_rate': 1.9968133238191258e-05, 'epoch': 0.05}
  5%|▌         | 91/1663 [47:55<13:54:37, 31.86s/it]  6%|▌         | 92/1663 [48:25<13:34:05, 31.09s/it]                                                    {'loss': 0.4727, 'learning_rate': 1.99665606824609e-05, 'epoch': 0.06}
  6%|▌         | 92/1663 [48:25<13:34:05, 31.09s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3095 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (3512 > 2560). Running this sequence through the model will result in indexing errors
  6%|▌         | 93/1663 [48:54<13:16:05, 30.42s/it]                                                    {'loss': 0.5202, 'learning_rate': 1.9964950319384814e-05, 'epoch': 0.06}
  6%|▌         | 93/1663 [48:54<13:16:05, 30.42s/it]  6%|▌         | 94/1663 [49:25<13:26:06, 30.83s/it]                                                    {'loss': 0.3916, 'learning_rate': 1.9963302155071788e-05, 'epoch': 0.06}
  6%|▌         | 94/1663 [49:25<13:26:06, 30.83s/it]  6%|▌         | 95/1663 [49:56<13:24:43, 30.79s/it]                                                    {'loss': 0.4758, 'learning_rate': 1.9961616195774e-05, 'epoch': 0.06}
  6%|▌         | 95/1663 [49:56<13:24:43, 30.79s/it]  6%|▌         | 96/1663 [50:28<13:32:13, 31.10s/it]                                                    {'loss': 0.4124, 'learning_rate': 1.9959892447886997e-05, 'epoch': 0.06}
  6%|▌         | 96/1663 [50:28<13:32:13, 31.10s/it]  6%|▌         | 97/1663 [50:58<13:23:51, 30.80s/it]                                                    {'loss': 0.4845, 'learning_rate': 1.995813091794968e-05, 'epoch': 0.06}
  6%|▌         | 97/1663 [50:58<13:23:51, 30.80s/it]  6%|▌         | 98/1663 [51:34<14:04:58, 32.40s/it]                                                    {'loss': 0.6754, 'learning_rate': 1.995633161264427e-05, 'epoch': 0.06}
  6%|▌         | 98/1663 [51:34<14:04:58, 32.40s/it]  6%|▌         | 99/1663 [52:03<13:39:19, 31.43s/it]                                                    {'loss': 0.5282, 'learning_rate': 1.995449453879629e-05, 'epoch': 0.06}
  6%|▌         | 99/1663 [52:03<13:39:19, 31.43s/it]  6%|▌         | 100/1663 [52:33<13:25:53, 30.94s/it]                                                     {'loss': 0.4498, 'learning_rate': 1.995261970337453e-05, 'epoch': 0.06}
  6%|▌         | 100/1663 [52:33<13:25:53, 30.94s/it]  6%|▌         | 101/1663 [53:04<13:26:59, 31.00s/it]                                                     {'loss': 0.4836, 'learning_rate': 1.9950707113491025e-05, 'epoch': 0.06}
  6%|▌         | 101/1663 [53:04<13:26:59, 31.00s/it]  6%|▌         | 102/1663 [53:37<13:43:51, 31.67s/it]                                                     {'loss': 0.4659, 'learning_rate': 1.9948756776401032e-05, 'epoch': 0.06}
  6%|▌         | 102/1663 [53:37<13:43:51, 31.67s/it]  6%|▌         | 103/1663 [54:08<13:33:14, 31.28s/it]                                                     {'loss': 0.4884, 'learning_rate': 1.9946768699503002e-05, 'epoch': 0.06}
  6%|▌         | 103/1663 [54:08<13:33:14, 31.28s/it]  6%|▋         | 104/1663 [54:44<14:08:27, 32.65s/it]                                                     {'loss': 0.5029, 'learning_rate': 1.9944742890338537e-05, 'epoch': 0.06}
  6%|▋         | 104/1663 [54:44<14:08:27, 32.65s/it]  6%|▋         | 105/1663 [55:15<13:54:39, 32.14s/it]                                                     {'loss': 0.532, 'learning_rate': 1.994267935659239e-05, 'epoch': 0.06}
  6%|▋         | 105/1663 [55:15<13:54:39, 32.14s/it]  6%|▋         | 106/1663 [55:44<13:33:35, 31.35s/it]                                                     {'loss': 0.4959, 'learning_rate': 1.99405781060924e-05, 'epoch': 0.06}
  6%|▋         | 106/1663 [55:44<13:33:35, 31.35s/it]  6%|▋         | 107/1663 [56:18<13:49:55, 32.00s/it]                                                     {'loss': 0.4431, 'learning_rate': 1.9938439146809497e-05, 'epoch': 0.06}
  6%|▋         | 107/1663 [56:18<13:49:55, 32.00s/it]  6%|▋         | 108/1663 [56:51<13:57:36, 32.32s/it]                                                     {'loss': 0.5131, 'learning_rate': 1.9936262486857655e-05, 'epoch': 0.06}
  6%|▋         | 108/1663 [56:51<13:57:36, 32.32s/it]  7%|▋         | 109/1663 [57:20<13:36:27, 31.52s/it]                                                     {'loss': 0.491, 'learning_rate': 1.9934048134493854e-05, 'epoch': 0.07}
  7%|▋         | 109/1663 [57:20<13:36:27, 31.52s/it]  7%|▋         | 110/1663 [57:50<13:22:57, 31.02s/it]                                                     {'loss': 0.5264, 'learning_rate': 1.9931796098118057e-05, 'epoch': 0.07}
  7%|▋         | 110/1663 [57:50<13:22:57, 31.02s/it]  7%|▋         | 111/1663 [58:22<13:25:21, 31.14s/it]                                                     {'loss': 0.4861, 'learning_rate': 1.992950638627319e-05, 'epoch': 0.07}
  7%|▋         | 111/1663 [58:22<13:25:21, 31.14s/it]  7%|▋         | 112/1663 [58:50<13:05:56, 30.40s/it]                                                     {'loss': 0.5131, 'learning_rate': 1.9927179007645086e-05, 'epoch': 0.07}
  7%|▋         | 112/1663 [58:50<13:05:56, 30.40s/it]  7%|▋         | 113/1663 [59:22<13:19:24, 30.94s/it]                                                     {'loss': 0.4546, 'learning_rate': 1.9924813971062472e-05, 'epoch': 0.07}
  7%|▋         | 113/1663 [59:22<13:19:24, 30.94s/it]  7%|▋         | 114/1663 [59:54<13:25:36, 31.21s/it]                                                     {'loss': 0.5691, 'learning_rate': 1.9922411285496925e-05, 'epoch': 0.07}
  7%|▋         | 114/1663 [59:54<13:25:36, 31.21s/it]  7%|▋         | 115/1663 [1:00:28<13:43:28, 31.92s/it]                                                       {'loss': 0.4642, 'learning_rate': 1.991997096006283e-05, 'epoch': 0.07}
  7%|▋         | 115/1663 [1:00:28<13:43:28, 31.92s/it]  7%|▋         | 116/1663 [1:01:00<13:42:21, 31.90s/it]                                                       {'loss': 0.4751, 'learning_rate': 1.991749300401738e-05, 'epoch': 0.07}
  7%|▋         | 116/1663 [1:01:00<13:42:21, 31.90s/it]  7%|▋         | 117/1663 [1:01:31<13:34:21, 31.60s/it]                                                       {'loss': 0.5244, 'learning_rate': 1.9914977426760486e-05, 'epoch': 0.07}
  7%|▋         | 117/1663 [1:01:31<13:34:21, 31.60s/it]  7%|▋         | 118/1663 [1:02:01<13:25:12, 31.27s/it]                                                       {'loss': 0.5288, 'learning_rate': 1.9912424237834798e-05, 'epoch': 0.07}
  7%|▋         | 118/1663 [1:02:01<13:25:12, 31.27s/it]  7%|▋         | 119/1663 [1:02:36<13:50:58, 32.29s/it]                                                       {'loss': 0.518, 'learning_rate': 1.990983344692563e-05, 'epoch': 0.07}
  7%|▋         | 119/1663 [1:02:36<13:50:58, 32.29s/it]  7%|▋         | 120/1663 [1:03:07<13:44:48, 32.07s/it]                                                       {'loss': 0.3962, 'learning_rate': 1.990720506386094e-05, 'epoch': 0.07}
  7%|▋         | 120/1663 [1:03:07<13:44:48, 32.07s/it]  7%|▋         | 121/1663 [1:03:38<13:30:25, 31.53s/it]                                                       {'loss': 0.4772, 'learning_rate': 1.9904539098611283e-05, 'epoch': 0.07}
  7%|▋         | 121/1663 [1:03:38<13:30:25, 31.53s/it]  7%|▋         | 122/1663 [1:04:08<13:19:24, 31.13s/it]                                                       {'loss': 0.4641, 'learning_rate': 1.990183556128979e-05, 'epoch': 0.07}
  7%|▋         | 122/1663 [1:04:08<13:19:24, 31.13s/it]  7%|▋         | 123/1663 [1:04:40<13:24:40, 31.35s/it]                                                       {'loss': 0.4482, 'learning_rate': 1.989909446215211e-05, 'epoch': 0.07}
  7%|▋         | 123/1663 [1:04:40<13:24:40, 31.35s/it]  7%|▋         | 124/1663 [1:05:11<13:27:32, 31.48s/it]                                                       {'loss': 0.4947, 'learning_rate': 1.9896315811596378e-05, 'epoch': 0.07}
  7%|▋         | 124/1663 [1:05:12<13:27:32, 31.48s/it]  8%|▊         | 125/1663 [1:05:40<13:05:39, 30.65s/it]                                                       {'loss': 0.4152, 'learning_rate': 1.9893499620163184e-05, 'epoch': 0.08}
  8%|▊         | 125/1663 [1:05:40<13:05:39, 30.65s/it]  8%|▊         | 126/1663 [1:06:09<12:54:43, 30.24s/it]                                                       {'loss': 0.5488, 'learning_rate': 1.9890645898535527e-05, 'epoch': 0.08}
  8%|▊         | 126/1663 [1:06:10<12:54:43, 30.24s/it]  8%|▊         | 127/1663 [1:06:37<12:33:19, 29.43s/it]                                                       {'loss': 0.5404, 'learning_rate': 1.988775465753877e-05, 'epoch': 0.08}
  8%|▊         | 127/1663 [1:06:37<12:33:19, 29.43s/it]  8%|▊         | 128/1663 [1:07:09<12:48:59, 30.06s/it]                                                       {'loss': 0.5402, 'learning_rate': 1.9884825908140596e-05, 'epoch': 0.08}
  8%|▊         | 128/1663 [1:07:09<12:48:59, 30.06s/it]  8%|▊         | 129/1663 [1:07:41<13:05:36, 30.73s/it]                                                       {'loss': 0.4911, 'learning_rate': 1.988185966145098e-05, 'epoch': 0.08}
  8%|▊         | 129/1663 [1:07:41<13:05:36, 30.73s/it]  8%|▊         | 130/1663 [1:08:10<12:55:41, 30.36s/it]                                                       {'loss': 0.489, 'learning_rate': 1.987885592872215e-05, 'epoch': 0.08}
  8%|▊         | 130/1663 [1:08:10<12:55:41, 30.36s/it]  8%|▊         | 131/1663 [1:08:38<12:35:54, 29.60s/it]                                                       {'loss': 0.5757, 'learning_rate': 1.987581472134852e-05, 'epoch': 0.08}
  8%|▊         | 131/1663 [1:08:38<12:35:54, 29.60s/it]  8%|▊         | 132/1663 [1:09:09<12:43:43, 29.93s/it]                                                       {'loss': 0.4985, 'learning_rate': 1.9872736050866658e-05, 'epoch': 0.08}
  8%|▊         | 132/1663 [1:09:09<12:43:43, 29.93s/it]  8%|▊         | 133/1663 [1:09:39<12:46:52, 30.07s/it]                                                       {'loss': 0.5405, 'learning_rate': 1.9869619928955262e-05, 'epoch': 0.08}
  8%|▊         | 133/1663 [1:09:39<12:46:52, 30.07s/it]  8%|▊         | 134/1663 [1:10:12<13:10:02, 31.00s/it]                                                       {'loss': 0.4333, 'learning_rate': 1.9866466367435087e-05, 'epoch': 0.08}
  8%|▊         | 134/1663 [1:10:12<13:10:02, 31.00s/it]  8%|▊         | 135/1663 [1:10:42<12:58:49, 30.58s/it]                                                       {'loss': 0.4332, 'learning_rate': 1.9863275378268914e-05, 'epoch': 0.08}
  8%|▊         | 135/1663 [1:10:42<12:58:49, 30.58s/it]  8%|▊         | 136/1663 [1:11:14<13:12:18, 31.13s/it]                                                       {'loss': 0.4889, 'learning_rate': 1.98600469735615e-05, 'epoch': 0.08}
  8%|▊         | 136/1663 [1:11:14<13:12:18, 31.13s/it]  8%|▊         | 137/1663 [1:11:46<13:16:49, 31.33s/it]                                                       {'loss': 0.4326, 'learning_rate': 1.985678116555955e-05, 'epoch': 0.08}
  8%|▊         | 137/1663 [1:11:46<13:16:49, 31.33s/it]  8%|▊         | 138/1663 [1:12:16<13:01:24, 30.74s/it]                                                       {'loss': 0.4809, 'learning_rate': 1.9853477966651627e-05, 'epoch': 0.08}
  8%|▊         | 138/1663 [1:12:16<13:01:24, 30.74s/it]  8%|▊         | 139/1663 [1:12:51<13:35:58, 32.13s/it]                                                       {'loss': 0.4735, 'learning_rate': 1.9850137389368164e-05, 'epoch': 0.08}
  8%|▊         | 139/1663 [1:12:51<13:35:58, 32.13s/it]  8%|▊         | 140/1663 [1:13:24<13:39:04, 32.27s/it]                                                       {'loss': 0.4553, 'learning_rate': 1.9846759446381365e-05, 'epoch': 0.08}
  8%|▊         | 140/1663 [1:13:24<13:39:04, 32.27s/it]  8%|▊         | 141/1663 [1:13:54<13:23:06, 31.66s/it]                                                       {'loss': 0.4856, 'learning_rate': 1.9843344150505192e-05, 'epoch': 0.08}
  8%|▊         | 141/1663 [1:13:54<13:23:06, 31.66s/it]  9%|▊         | 142/1663 [1:14:24<13:07:41, 31.07s/it]                                                       {'loss': 0.4412, 'learning_rate': 1.9839891514695283e-05, 'epoch': 0.09}
  9%|▊         | 142/1663 [1:14:24<13:07:41, 31.07s/it]  9%|▊         | 143/1663 [1:14:54<13:03:33, 30.93s/it]                                                       {'loss': 0.465, 'learning_rate': 1.9836401552048944e-05, 'epoch': 0.09}
  9%|▊         | 143/1663 [1:14:54<13:03:33, 30.93s/it]  9%|▊         | 144/1663 [1:15:24<12:53:11, 30.54s/it]                                                       {'loss': 0.5935, 'learning_rate': 1.9832874275805064e-05, 'epoch': 0.09}
  9%|▊         | 144/1663 [1:15:24<12:53:11, 30.54s/it]  9%|▊         | 145/1663 [1:15:56<13:02:17, 30.92s/it]                                                       {'loss': 0.4719, 'learning_rate': 1.982930969934408e-05, 'epoch': 0.09}
  9%|▊         | 145/1663 [1:15:56<13:02:17, 30.92s/it]  9%|▉         | 146/1663 [1:16:27<13:06:12, 31.10s/it]                                                       {'loss': 0.4385, 'learning_rate': 1.9825707836187932e-05, 'epoch': 0.09}
  9%|▉         | 146/1663 [1:16:27<13:06:12, 31.10s/it]  9%|▉         | 147/1663 [1:16:59<13:08:22, 31.20s/it]                                                       {'loss': 0.4844, 'learning_rate': 1.982206869999999e-05, 'epoch': 0.09}
  9%|▉         | 147/1663 [1:16:59<13:08:22, 31.20s/it]  9%|▉         | 148/1663 [1:17:29<13:05:10, 31.10s/it]                                                       {'loss': 0.5586, 'learning_rate': 1.981839230458503e-05, 'epoch': 0.09}
  9%|▉         | 148/1663 [1:17:29<13:05:10, 31.10s/it]  9%|▉         | 149/1663 [1:18:00<13:04:51, 31.10s/it]                                                       {'loss': 0.5085, 'learning_rate': 1.9814678663889162e-05, 'epoch': 0.09}
  9%|▉         | 149/1663 [1:18:01<13:04:51, 31.10s/it]  9%|▉         | 150/1663 [1:18:31<13:02:27, 31.03s/it]                                                       {'loss': 0.611, 'learning_rate': 1.9810927791999778e-05, 'epoch': 0.09}
  9%|▉         | 150/1663 [1:18:31<13:02:27, 31.03s/it]  9%|▉         | 151/1663 [1:19:03<13:10:21, 31.36s/it]                                                       {'loss': 0.4809, 'learning_rate': 1.980713970314551e-05, 'epoch': 0.09}
  9%|▉         | 151/1663 [1:19:03<13:10:21, 31.36s/it]  9%|▉         | 152/1663 [1:19:36<13:16:47, 31.64s/it]                                                       {'loss': 0.5025, 'learning_rate': 1.9803314411696175e-05, 'epoch': 0.09}
  9%|▉         | 152/1663 [1:19:36<13:16:47, 31.64s/it]  9%|▉         | 153/1663 [1:20:07<13:12:56, 31.51s/it]                                                       {'loss': 0.5503, 'learning_rate': 1.9799451932162698e-05, 'epoch': 0.09}
  9%|▉         | 153/1663 [1:20:07<13:12:56, 31.51s/it]  9%|▉         | 154/1663 [1:20:38<13:07:08, 31.30s/it]                                                       {'loss': 0.5954, 'learning_rate': 1.9795552279197092e-05, 'epoch': 0.09}
  9%|▉         | 154/1663 [1:20:38<13:07:08, 31.30s/it]  9%|▉         | 155/1663 [1:21:08<12:55:21, 30.85s/it]                                                       {'loss': 0.5679, 'learning_rate': 1.9791615467592375e-05, 'epoch': 0.09}
  9%|▉         | 155/1663 [1:21:08<12:55:21, 30.85s/it]  9%|▉         | 156/1663 [1:21:37<12:46:14, 30.51s/it]                                                       {'loss': 0.5105, 'learning_rate': 1.978764151228252e-05, 'epoch': 0.09}
  9%|▉         | 156/1663 [1:21:37<12:46:14, 30.51s/it]  9%|▉         | 157/1663 [1:22:07<12:42:15, 30.37s/it]                                                       {'loss': 0.4654, 'learning_rate': 1.9783630428342414e-05, 'epoch': 0.09}
  9%|▉         | 157/1663 [1:22:07<12:42:15, 30.37s/it] 10%|▉         | 158/1663 [1:22:42<13:15:46, 31.73s/it]                                                       {'loss': 0.493, 'learning_rate': 1.9779582230987776e-05, 'epoch': 0.09}
 10%|▉         | 158/1663 [1:22:42<13:15:46, 31.73s/it] 10%|▉         | 159/1663 [1:23:11<12:54:52, 30.91s/it]                                                       {'loss': 0.3958, 'learning_rate': 1.9775496935575117e-05, 'epoch': 0.1}
 10%|▉         | 159/1663 [1:23:11<12:54:52, 30.91s/it] 10%|▉         | 160/1663 [1:23:45<13:17:22, 31.83s/it]                                                       {'loss': 0.5316, 'learning_rate': 1.9771374557601678e-05, 'epoch': 0.1}
 10%|▉         | 160/1663 [1:23:45<13:17:22, 31.83s/it] 10%|▉         | 161/1663 [1:24:15<13:04:05, 31.32s/it]                                                       {'loss': 0.417, 'learning_rate': 1.9767215112705368e-05, 'epoch': 0.1}
 10%|▉         | 161/1663 [1:24:15<13:04:05, 31.32s/it] 10%|▉         | 162/1663 [1:24:46<13:01:01, 31.22s/it]                                                       {'loss': 0.3955, 'learning_rate': 1.9763018616664705e-05, 'epoch': 0.1}
 10%|▉         | 162/1663 [1:24:46<13:01:01, 31.22s/it] 10%|▉         | 163/1663 [1:25:17<12:56:44, 31.07s/it]                                                       {'loss': 0.5345, 'learning_rate': 1.9758785085398763e-05, 'epoch': 0.1}
 10%|▉         | 163/1663 [1:25:17<12:56:44, 31.07s/it] 10%|▉         | 164/1663 [1:25:46<12:43:34, 30.56s/it]                                                       {'loss': 0.436, 'learning_rate': 1.9754514534967097e-05, 'epoch': 0.1}
 10%|▉         | 164/1663 [1:25:46<12:43:34, 30.56s/it] 10%|▉         | 165/1663 [1:26:17<12:43:59, 30.60s/it]                                                       {'loss': 0.4656, 'learning_rate': 1.97502069815697e-05, 'epoch': 0.1}
 10%|▉         | 165/1663 [1:26:17<12:43:59, 30.60s/it] 10%|▉         | 166/1663 [1:26:48<12:42:36, 30.57s/it]                                                       {'loss': 0.5995, 'learning_rate': 1.9745862441546928e-05, 'epoch': 0.1}
 10%|▉         | 166/1663 [1:26:48<12:42:36, 30.57s/it] 10%|█         | 167/1663 [1:27:17<12:30:34, 30.10s/it]                                                       {'loss': 0.4709, 'learning_rate': 1.974148093137944e-05, 'epoch': 0.1}
 10%|█         | 167/1663 [1:27:17<12:30:34, 30.10s/it] 10%|█         | 168/1663 [1:27:48<12:36:36, 30.37s/it]                                                       {'loss': 0.4524, 'learning_rate': 1.9737062467688148e-05, 'epoch': 0.1}
 10%|█         | 168/1663 [1:27:48<12:36:36, 30.37s/it] 10%|█         | 169/1663 [1:28:18<12:39:23, 30.50s/it]                                                       {'loss': 0.4834, 'learning_rate': 1.9732607067234135e-05, 'epoch': 0.1}
 10%|█         | 169/1663 [1:28:18<12:39:23, 30.50s/it] 10%|█         | 170/1663 [1:28:50<12:44:45, 30.73s/it]                                                       {'loss': 0.4302, 'learning_rate': 1.9728114746918606e-05, 'epoch': 0.1}
 10%|█         | 170/1663 [1:28:50<12:44:45, 30.73s/it] 10%|█         | 171/1663 [1:29:20<12:43:22, 30.70s/it]                                                       {'loss': 0.524, 'learning_rate': 1.9723585523782814e-05, 'epoch': 0.1}
 10%|█         | 171/1663 [1:29:20<12:43:22, 30.70s/it] 10%|█         | 172/1663 [1:29:53<12:57:24, 31.28s/it]                                                       {'loss': 0.4335, 'learning_rate': 1.9719019415008005e-05, 'epoch': 0.1}
 10%|█         | 172/1663 [1:29:53<12:57:24, 31.28s/it] 10%|█         | 173/1663 [1:30:25<13:05:10, 31.62s/it]                                                       {'loss': 0.5844, 'learning_rate': 1.9714416437915345e-05, 'epoch': 0.1}
 10%|█         | 173/1663 [1:30:25<13:05:10, 31.62s/it] 10%|█         | 174/1663 [1:30:56<12:59:16, 31.40s/it]                                                       {'loss': 0.5657, 'learning_rate': 1.9709776609965857e-05, 'epoch': 0.1}
 10%|█         | 174/1663 [1:30:56<12:59:16, 31.40s/it] 11%|█         | 175/1663 [1:31:26<12:47:01, 30.93s/it]                                                       {'loss': 0.3787, 'learning_rate': 1.970509994876035e-05, 'epoch': 0.11}
 11%|█         | 175/1663 [1:31:26<12:47:01, 30.93s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2673 > 2560). Running this sequence through the model will result in indexing errors
 11%|█         | 176/1663 [1:31:57<12:43:17, 30.80s/it]                                                       {'loss': 0.493, 'learning_rate': 1.9700386472039366e-05, 'epoch': 0.11}
 11%|█         | 176/1663 [1:31:57<12:43:17, 30.80s/it] 11%|█         | 177/1663 [1:32:28<12:48:30, 31.03s/it]                                                       {'loss': 0.3486, 'learning_rate': 1.96956361976831e-05, 'epoch': 0.11}
 11%|█         | 177/1663 [1:32:28<12:48:30, 31.03s/it] 11%|█         | 178/1663 [1:33:00<12:56:34, 31.38s/it]                                                       {'loss': 0.4413, 'learning_rate': 1.9690849143711335e-05, 'epoch': 0.11}
 11%|█         | 178/1663 [1:33:00<12:56:34, 31.38s/it] 11%|█         | 179/1663 [1:33:32<12:57:48, 31.45s/it]                                                       {'loss': 0.4702, 'learning_rate': 1.9686025328283376e-05, 'epoch': 0.11}
 11%|█         | 179/1663 [1:33:32<12:57:48, 31.45s/it] 11%|█         | 180/1663 [1:34:08<13:29:35, 32.75s/it]                                                       {'loss': 0.4322, 'learning_rate': 1.9681164769697977e-05, 'epoch': 0.11}
 11%|█         | 180/1663 [1:34:08<13:29:35, 32.75s/it] 11%|█         | 181/1663 [1:34:41<13:29:33, 32.78s/it]                                                       {'loss': 0.401, 'learning_rate': 1.9676267486393274e-05, 'epoch': 0.11}
 11%|█         | 181/1663 [1:34:41<13:29:33, 32.78s/it] 11%|█         | 182/1663 [1:35:13<13:26:19, 32.67s/it]                                                       {'loss': 0.4028, 'learning_rate': 1.967133349694672e-05, 'epoch': 0.11}
 11%|█         | 182/1663 [1:35:13<13:26:19, 32.67s/it] 11%|█         | 183/1663 [1:35:44<13:13:12, 32.16s/it]                                                       {'loss': 0.4171, 'learning_rate': 1.9666362820075004e-05, 'epoch': 0.11}
 11%|█         | 183/1663 [1:35:44<13:13:12, 32.16s/it] 11%|█         | 184/1663 [1:36:13<12:46:32, 31.10s/it]                                                       {'loss': 0.408, 'learning_rate': 1.9661355474633992e-05, 'epoch': 0.11}
 11%|█         | 184/1663 [1:36:13<12:46:32, 31.10s/it] 11%|█         | 185/1663 [1:36:44<12:47:00, 31.14s/it]                                                       {'loss': 0.4048, 'learning_rate': 1.9656311479618647e-05, 'epoch': 0.11}
 11%|█         | 185/1663 [1:36:44<12:47:00, 31.14s/it] 11%|█         | 186/1663 [1:37:19<13:14:06, 32.26s/it]                                                       {'loss': 0.5111, 'learning_rate': 1.9651230854162953e-05, 'epoch': 0.11}
 11%|█         | 186/1663 [1:37:19<13:14:06, 32.26s/it] 11%|█         | 187/1663 [1:37:51<13:12:33, 32.22s/it]                                                       {'loss': 0.371, 'learning_rate': 1.9646113617539853e-05, 'epoch': 0.11}
 11%|█         | 187/1663 [1:37:51<13:12:33, 32.22s/it] 11%|█▏        | 188/1663 [1:38:24<13:18:33, 32.48s/it]                                                       {'loss': 0.4448, 'learning_rate': 1.964095978916118e-05, 'epoch': 0.11}
 11%|█▏        | 188/1663 [1:38:24<13:18:33, 32.48s/it] 11%|█▏        | 189/1663 [1:38:55<13:08:11, 32.08s/it]                                                       {'loss': 0.4141, 'learning_rate': 1.963576938857756e-05, 'epoch': 0.11}
 11%|█▏        | 189/1663 [1:38:55<13:08:11, 32.08s/it] 11%|█▏        | 190/1663 [1:39:25<12:51:58, 31.44s/it]                                                       {'loss': 0.4265, 'learning_rate': 1.9630542435478364e-05, 'epoch': 0.11}
 11%|█▏        | 190/1663 [1:39:25<12:51:58, 31.44s/it] 11%|█▏        | 191/1663 [1:39:58<13:00:57, 31.83s/it]                                                       {'loss': 0.5294, 'learning_rate': 1.9625278949691612e-05, 'epoch': 0.11}
 11%|█▏        | 191/1663 [1:39:58<13:00:57, 31.83s/it] 12%|█▏        | 192/1663 [1:40:28<12:49:53, 31.40s/it]                                                       {'loss': 0.4955, 'learning_rate': 1.9619978951183924e-05, 'epoch': 0.12}
 12%|█▏        | 192/1663 [1:40:28<12:49:53, 31.40s/it] 12%|█▏        | 193/1663 [1:40:59<12:44:32, 31.21s/it]                                                       {'loss': 0.5508, 'learning_rate': 1.9614642460060407e-05, 'epoch': 0.12}
 12%|█▏        | 193/1663 [1:40:59<12:44:32, 31.21s/it] 12%|█▏        | 194/1663 [1:41:29<12:39:13, 31.01s/it]                                                       {'loss': 0.6024, 'learning_rate': 1.960926949656462e-05, 'epoch': 0.12}
 12%|█▏        | 194/1663 [1:41:29<12:39:13, 31.01s/it] 12%|█▏        | 195/1663 [1:41:59<12:30:56, 30.69s/it]                                                       {'loss': 0.5307, 'learning_rate': 1.9603860081078456e-05, 'epoch': 0.12}
 12%|█▏        | 195/1663 [1:41:59<12:30:56, 30.69s/it] 12%|█▏        | 196/1663 [1:42:29<12:21:50, 30.34s/it]                                                       {'loss': 0.5294, 'learning_rate': 1.9598414234122106e-05, 'epoch': 0.12}
 12%|█▏        | 196/1663 [1:42:29<12:21:50, 30.34s/it] 12%|█▏        | 197/1663 [1:42:59<12:20:41, 30.31s/it]                                                       {'loss': 0.4789, 'learning_rate': 1.959293197635395e-05, 'epoch': 0.12}
 12%|█▏        | 197/1663 [1:42:59<12:20:41, 30.31s/it] 12%|█▏        | 198/1663 [1:43:30<12:27:25, 30.61s/it]                                                       {'loss': 0.555, 'learning_rate': 1.9587413328570494e-05, 'epoch': 0.12}
 12%|█▏        | 198/1663 [1:43:30<12:27:25, 30.61s/it] 12%|█▏        | 199/1663 [1:44:04<12:45:33, 31.38s/it]                                                       {'loss': 0.5981, 'learning_rate': 1.958185831170628e-05, 'epoch': 0.12}
 12%|█▏        | 199/1663 [1:44:04<12:45:33, 31.38s/it] 12%|█▏        | 200/1663 [1:44:33<12:30:42, 30.79s/it]                                                       {'loss': 0.4231, 'learning_rate': 1.957626694683382e-05, 'epoch': 0.12}
 12%|█▏        | 200/1663 [1:44:33<12:30:42, 30.79s/it] 12%|█▏        | 201/1663 [1:45:02<12:15:37, 30.19s/it]                                                       {'loss': 0.4544, 'learning_rate': 1.9570639255163504e-05, 'epoch': 0.12}
 12%|█▏        | 201/1663 [1:45:02<12:15:37, 30.19s/it] 12%|█▏        | 202/1663 [1:45:32<12:16:08, 30.23s/it]                                                       {'loss': 0.5159, 'learning_rate': 1.9564975258043527e-05, 'epoch': 0.12}
 12%|█▏        | 202/1663 [1:45:32<12:16:08, 30.23s/it] 12%|█▏        | 203/1663 [1:46:06<12:41:15, 31.28s/it]                                                       {'loss': 0.4359, 'learning_rate': 1.9559274976959812e-05, 'epoch': 0.12}
 12%|█▏        | 203/1663 [1:46:06<12:41:15, 31.28s/it] 12%|█▏        | 204/1663 [1:46:36<12:28:58, 30.80s/it]                                                       {'loss': 0.42, 'learning_rate': 1.9553538433535914e-05, 'epoch': 0.12}
 12%|█▏        | 204/1663 [1:46:36<12:28:58, 30.80s/it] 12%|█▏        | 205/1663 [1:47:10<12:53:15, 31.82s/it]                                                       {'loss': 0.4, 'learning_rate': 1.9547765649532945e-05, 'epoch': 0.12}
 12%|█▏        | 205/1663 [1:47:10<12:53:15, 31.82s/it] 12%|█▏        | 206/1663 [1:47:42<12:52:15, 31.80s/it]                                                       {'loss': 0.4964, 'learning_rate': 1.9541956646849497e-05, 'epoch': 0.12}
 12%|█▏        | 206/1663 [1:47:42<12:52:15, 31.80s/it] 12%|█▏        | 207/1663 [1:48:08<12:13:34, 30.23s/it]                                                       {'loss': 0.5215, 'learning_rate': 1.9536111447521554e-05, 'epoch': 0.12}
 12%|█▏        | 207/1663 [1:48:08<12:13:34, 30.23s/it] 13%|█▎        | 208/1663 [1:48:38<12:08:23, 30.04s/it]                                                       {'loss': 0.3547, 'learning_rate': 1.9530230073722417e-05, 'epoch': 0.13}
 13%|█▎        | 208/1663 [1:48:38<12:08:23, 30.04s/it] 13%|█▎        | 209/1663 [1:49:07<12:05:35, 29.94s/it]                                                       {'loss': 0.5025, 'learning_rate': 1.9524312547762595e-05, 'epoch': 0.13}
 13%|█▎        | 209/1663 [1:49:07<12:05:35, 29.94s/it] 13%|█▎        | 210/1663 [1:49:37<12:04:52, 29.93s/it]                                                       {'loss': 0.3317, 'learning_rate': 1.951835889208975e-05, 'epoch': 0.13}
 13%|█▎        | 210/1663 [1:49:37<12:04:52, 29.93s/it] 13%|█▎        | 211/1663 [1:50:07<12:01:45, 29.82s/it]                                                       {'loss': 0.3841, 'learning_rate': 1.9512369129288597e-05, 'epoch': 0.13}
 13%|█▎        | 211/1663 [1:50:07<12:01:45, 29.82s/it] 13%|█▎        | 212/1663 [1:50:39<12:19:36, 30.58s/it]                                                       {'loss': 0.4962, 'learning_rate': 1.9506343282080814e-05, 'epoch': 0.13}
 13%|█▎        | 212/1663 [1:50:39<12:19:36, 30.58s/it] 13%|█▎        | 213/1663 [1:51:14<12:45:51, 31.69s/it]                                                       {'loss': 0.3951, 'learning_rate': 1.9500281373324972e-05, 'epoch': 0.13}
 13%|█▎        | 213/1663 [1:51:14<12:45:51, 31.69s/it] 13%|█▎        | 214/1663 [1:51:46<12:51:10, 31.93s/it]                                                       {'loss': 0.4809, 'learning_rate': 1.949418342601643e-05, 'epoch': 0.13}
 13%|█▎        | 214/1663 [1:51:46<12:51:10, 31.93s/it] 13%|█▎        | 215/1663 [1:52:14<12:22:20, 30.76s/it]                                                       {'loss': 0.47, 'learning_rate': 1.9488049463287267e-05, 'epoch': 0.13}
 13%|█▎        | 215/1663 [1:52:14<12:22:20, 30.76s/it] 13%|█▎        | 216/1663 [1:52:44<12:12:37, 30.38s/it]                                                       {'loss': 0.4036, 'learning_rate': 1.948187950840617e-05, 'epoch': 0.13}
 13%|█▎        | 216/1663 [1:52:44<12:12:37, 30.38s/it] 13%|█▎        | 217/1663 [1:53:18<12:41:58, 31.62s/it]                                                       {'loss': 0.3677, 'learning_rate': 1.947567358477837e-05, 'epoch': 0.13}
 13%|█▎        | 217/1663 [1:53:18<12:41:58, 31.62s/it] 13%|█▎        | 218/1663 [1:53:50<12:46:46, 31.84s/it]                                                       {'loss': 0.4281, 'learning_rate': 1.9469431715945537e-05, 'epoch': 0.13}
 13%|█▎        | 218/1663 [1:53:50<12:46:46, 31.84s/it] 13%|█▎        | 219/1663 [1:54:22<12:45:51, 31.82s/it]                                                       {'loss': 0.4789, 'learning_rate': 1.94631539255857e-05, 'epoch': 0.13}
 13%|█▎        | 219/1663 [1:54:22<12:45:51, 31.82s/it] 13%|█▎        | 220/1663 [1:54:53<12:36:16, 31.45s/it]                                                       {'loss': 0.479, 'learning_rate': 1.9456840237513147e-05, 'epoch': 0.13}
 13%|█▎        | 220/1663 [1:54:53<12:36:16, 31.45s/it] 13%|█▎        | 221/1663 [1:55:22<12:17:02, 30.67s/it]                                                       {'loss': 0.534, 'learning_rate': 1.945049067567835e-05, 'epoch': 0.13}
 13%|█▎        | 221/1663 [1:55:22<12:17:02, 30.67s/it] 13%|█▎        | 222/1663 [1:55:52<12:14:48, 30.60s/it]                                                       {'loss': 0.4058, 'learning_rate': 1.9444105264167864e-05, 'epoch': 0.13}
 13%|█▎        | 222/1663 [1:55:52<12:14:48, 30.60s/it] 13%|█▎        | 223/1663 [1:56:26<12:37:14, 31.55s/it]                                                       {'loss': 0.5846, 'learning_rate': 1.9437684027204223e-05, 'epoch': 0.13}
 13%|█▎        | 223/1663 [1:56:26<12:37:14, 31.55s/it] 13%|█▎        | 224/1663 [1:56:57<12:31:36, 31.34s/it]                                                       {'loss': 0.4955, 'learning_rate': 1.9431226989145878e-05, 'epoch': 0.13}
 13%|█▎        | 224/1663 [1:56:57<12:31:36, 31.34s/it] 14%|█▎        | 225/1663 [1:57:28<12:29:36, 31.28s/it]                                                       {'loss': 0.4771, 'learning_rate': 1.9424734174487087e-05, 'epoch': 0.14}
 14%|█▎        | 225/1663 [1:57:28<12:29:36, 31.28s/it] 14%|█▎        | 226/1663 [1:57:58<12:24:31, 31.09s/it]                                                       {'loss': 0.4467, 'learning_rate': 1.9418205607857816e-05, 'epoch': 0.14}
 14%|█▎        | 226/1663 [1:57:58<12:24:31, 31.09s/it] 14%|█▎        | 227/1663 [1:58:30<12:30:41, 31.37s/it]                                                       {'loss': 0.5219, 'learning_rate': 1.9411641314023656e-05, 'epoch': 0.14}
 14%|█▎        | 227/1663 [1:58:30<12:30:41, 31.37s/it] 14%|█▎        | 228/1663 [1:59:01<12:21:06, 30.99s/it]                                                       {'loss': 0.4059, 'learning_rate': 1.940504131788573e-05, 'epoch': 0.14}
 14%|█▎        | 228/1663 [1:59:01<12:21:06, 30.99s/it] 14%|█▍        | 229/1663 [1:59:30<12:08:16, 30.47s/it]                                                       {'loss': 0.4172, 'learning_rate': 1.939840564448059e-05, 'epoch': 0.14}
 14%|█▍        | 229/1663 [1:59:30<12:08:16, 30.47s/it] 14%|█▍        | 230/1663 [2:00:01<12:12:26, 30.67s/it]                                                       {'loss': 0.4178, 'learning_rate': 1.939173431898013e-05, 'epoch': 0.14}
 14%|█▍        | 230/1663 [2:00:01<12:12:26, 30.67s/it] 14%|█▍        | 231/1663 [2:00:32<12:15:24, 30.81s/it]                                                       {'loss': 0.5211, 'learning_rate': 1.938502736669149e-05, 'epoch': 0.14}
 14%|█▍        | 231/1663 [2:00:32<12:15:24, 30.81s/it] 14%|█▍        | 232/1663 [2:01:03<12:15:41, 30.85s/it]                                                       {'loss': 0.5108, 'learning_rate': 1.937828481305694e-05, 'epoch': 0.14}
 14%|█▍        | 232/1663 [2:01:03<12:15:41, 30.85s/it] 14%|█▍        | 233/1663 [2:01:31<11:55:52, 30.04s/it]                                                       {'loss': 0.5313, 'learning_rate': 1.9371506683653833e-05, 'epoch': 0.14}
 14%|█▍        | 233/1663 [2:01:31<11:55:52, 30.04s/it] 14%|█▍        | 234/1663 [2:01:59<11:42:44, 29.51s/it]                                                       {'loss': 0.459, 'learning_rate': 1.9364693004194445e-05, 'epoch': 0.14}
 14%|█▍        | 234/1663 [2:01:59<11:42:44, 29.51s/it] 14%|█▍        | 235/1663 [2:02:32<12:04:37, 30.45s/it]                                                       {'loss': 0.3535, 'learning_rate': 1.9357843800525923e-05, 'epoch': 0.14}
 14%|█▍        | 235/1663 [2:02:32<12:04:37, 30.45s/it] 14%|█▍        | 236/1663 [2:03:03<12:05:04, 30.49s/it]                                                       {'loss': 0.4209, 'learning_rate': 1.9350959098630173e-05, 'epoch': 0.14}
 14%|█▍        | 236/1663 [2:03:03<12:05:04, 30.49s/it] 14%|█▍        | 237/1663 [2:03:33<12:01:21, 30.35s/it]                                                       {'loss': 0.4246, 'learning_rate': 1.9344038924623754e-05, 'epoch': 0.14}
 14%|█▍        | 237/1663 [2:03:33<12:01:21, 30.35s/it] 14%|█▍        | 238/1663 [2:04:04<12:04:13, 30.49s/it]                                                       {'loss': 0.419, 'learning_rate': 1.933708330475779e-05, 'epoch': 0.14}
 14%|█▍        | 238/1663 [2:04:04<12:04:13, 30.49s/it] 14%|█▍        | 239/1663 [2:04:38<12:30:02, 31.60s/it]                                                       {'loss': 0.4579, 'learning_rate': 1.9330092265417867e-05, 'epoch': 0.14}
 14%|█▍        | 239/1663 [2:04:38<12:30:02, 31.60s/it] 14%|█▍        | 240/1663 [2:05:09<12:30:08, 31.63s/it]                                                       {'loss': 0.4162, 'learning_rate': 1.932306583312393e-05, 'epoch': 0.14}
 14%|█▍        | 240/1663 [2:05:09<12:30:08, 31.63s/it] 14%|█▍        | 241/1663 [2:05:35<11:49:03, 29.92s/it]                                                       {'loss': 0.375, 'learning_rate': 1.931600403453018e-05, 'epoch': 0.14}
 14%|█▍        | 241/1663 [2:05:35<11:49:03, 29.92s/it] 15%|█▍        | 242/1663 [2:06:06<11:53:25, 30.12s/it]                                                       {'loss': 0.392, 'learning_rate': 1.9308906896424987e-05, 'epoch': 0.15}
 15%|█▍        | 242/1663 [2:06:06<11:53:25, 30.12s/it] 15%|█▍        | 243/1663 [2:06:37<12:01:52, 30.50s/it]                                                       {'loss': 0.5285, 'learning_rate': 1.9301774445730767e-05, 'epoch': 0.15}
 15%|█▍        | 243/1663 [2:06:37<12:01:52, 30.50s/it] 15%|█▍        | 244/1663 [2:07:08<11:59:18, 30.41s/it]                                                       {'loss': 0.5221, 'learning_rate': 1.9294606709503904e-05, 'epoch': 0.15}
 15%|█▍        | 244/1663 [2:07:08<11:59:18, 30.41s/it] 15%|█▍        | 245/1663 [2:07:41<12:16:51, 31.18s/it]                                                       {'loss': 0.4742, 'learning_rate': 1.928740371493462e-05, 'epoch': 0.15}
 15%|█▍        | 245/1663 [2:07:41<12:16:51, 31.18s/it] 15%|█▍        | 246/1663 [2:08:11<12:08:19, 30.84s/it]                                                       {'loss': 0.4551, 'learning_rate': 1.928016548934691e-05, 'epoch': 0.15}
 15%|█▍        | 246/1663 [2:08:11<12:08:19, 30.84s/it] 15%|█▍        | 247/1663 [2:08:38<11:46:53, 29.95s/it]                                                       {'loss': 0.4993, 'learning_rate': 1.9272892060198385e-05, 'epoch': 0.15}
 15%|█▍        | 247/1663 [2:08:38<11:46:53, 29.95s/it] 15%|█▍        | 248/1663 [2:09:10<11:55:17, 30.33s/it]                                                       {'loss': 0.4747, 'learning_rate': 1.9265583455080222e-05, 'epoch': 0.15}
 15%|█▍        | 248/1663 [2:09:10<11:55:17, 30.33s/it] 15%|█▍        | 249/1663 [2:09:39<11:48:34, 30.07s/it]                                                       {'loss': 0.4421, 'learning_rate': 1.925823970171702e-05, 'epoch': 0.15}
 15%|█▍        | 249/1663 [2:09:39<11:48:34, 30.07s/it] 15%|█▌        | 250/1663 [2:10:10<11:55:26, 30.38s/it]                                                       {'loss': 0.4674, 'learning_rate': 1.9250860827966723e-05, 'epoch': 0.15}
 15%|█▌        | 250/1663 [2:10:10<11:55:26, 30.38s/it] 15%|█▌        | 251/1663 [2:10:42<12:03:41, 30.75s/it]                                                       {'loss': 0.4337, 'learning_rate': 1.9243446861820488e-05, 'epoch': 0.15}
 15%|█▌        | 251/1663 [2:10:42<12:03:41, 30.75s/it] 15%|█▌        | 252/1663 [2:11:14<12:10:15, 31.05s/it]                                                       {'loss': 0.4144, 'learning_rate': 1.9235997831402603e-05, 'epoch': 0.15}
 15%|█▌        | 252/1663 [2:11:14<12:10:15, 31.05s/it] 15%|█▌        | 253/1663 [2:11:42<11:53:18, 30.35s/it]                                                       {'loss': 0.5505, 'learning_rate': 1.9228513764970365e-05, 'epoch': 0.15}
 15%|█▌        | 253/1663 [2:11:42<11:53:18, 30.35s/it] 15%|█▌        | 254/1663 [2:12:14<12:04:29, 30.85s/it]                                                       {'loss': 0.4608, 'learning_rate': 1.9220994690913975e-05, 'epoch': 0.15}
 15%|█▌        | 254/1663 [2:12:14<12:04:29, 30.85s/it] 15%|█▌        | 255/1663 [2:12:46<12:11:19, 31.16s/it]                                                       {'loss': 0.4631, 'learning_rate': 1.921344063775644e-05, 'epoch': 0.15}
 15%|█▌        | 255/1663 [2:12:46<12:11:19, 31.16s/it] 15%|█▌        | 256/1663 [2:13:17<12:07:25, 31.02s/it]                                                       {'loss': 0.5633, 'learning_rate': 1.9205851634153447e-05, 'epoch': 0.15}
 15%|█▌        | 256/1663 [2:13:17<12:07:25, 31.02s/it] 15%|█▌        | 257/1663 [2:13:48<12:04:25, 30.91s/it]                                                       {'loss': 0.5329, 'learning_rate': 1.9198227708893274e-05, 'epoch': 0.15}
 15%|█▌        | 257/1663 [2:13:48<12:04:25, 30.91s/it] 16%|█▌        | 258/1663 [2:14:22<12:27:57, 31.94s/it]                                                       {'loss': 0.3592, 'learning_rate': 1.9190568890896665e-05, 'epoch': 0.16}
 16%|█▌        | 258/1663 [2:14:22<12:27:57, 31.94s/it] 16%|█▌        | 259/1663 [2:14:56<12:42:20, 32.58s/it]                                                       {'loss': 0.4814, 'learning_rate': 1.9182875209216732e-05, 'epoch': 0.16}
 16%|█▌        | 259/1663 [2:14:56<12:42:20, 32.58s/it] 16%|█▌        | 260/1663 [2:15:26<12:23:02, 31.78s/it]                                                       {'loss': 0.5229, 'learning_rate': 1.917514669303884e-05, 'epoch': 0.16}
 16%|█▌        | 260/1663 [2:15:26<12:23:02, 31.78s/it] 16%|█▌        | 261/1663 [2:15:59<12:30:48, 32.13s/it]                                                       {'loss': 0.534, 'learning_rate': 1.9167383371680482e-05, 'epoch': 0.16}
 16%|█▌        | 261/1663 [2:15:59<12:30:48, 32.13s/it] 16%|█▌        | 262/1663 [2:16:33<12:42:38, 32.66s/it]                                                       {'loss': 0.4943, 'learning_rate': 1.915958527459121e-05, 'epoch': 0.16}
 16%|█▌        | 262/1663 [2:16:33<12:42:38, 32.66s/it] 16%|█▌        | 263/1663 [2:17:03<12:24:03, 31.89s/it]                                                       {'loss': 0.3617, 'learning_rate': 1.915175243135246e-05, 'epoch': 0.16}
 16%|█▌        | 263/1663 [2:17:03<12:24:03, 31.89s/it] 16%|█▌        | 264/1663 [2:17:34<12:19:45, 31.73s/it]                                                       {'loss': 0.4823, 'learning_rate': 1.9143884871677504e-05, 'epoch': 0.16}
 16%|█▌        | 264/1663 [2:17:34<12:19:45, 31.73s/it] 16%|█▌        | 265/1663 [2:18:05<12:10:56, 31.37s/it]                                                       {'loss': 0.4296, 'learning_rate': 1.9135982625411295e-05, 'epoch': 0.16}
 16%|█▌        | 265/1663 [2:18:05<12:10:56, 31.37s/it] 16%|█▌        | 266/1663 [2:18:35<12:01:05, 30.97s/it]                                                       {'loss': 0.5645, 'learning_rate': 1.912804572253036e-05, 'epoch': 0.16}
 16%|█▌        | 266/1663 [2:18:35<12:01:05, 30.97s/it] 16%|█▌        | 267/1663 [2:19:06<12:00:59, 30.99s/it]                                                       {'loss': 0.4067, 'learning_rate': 1.912007419314271e-05, 'epoch': 0.16}
 16%|█▌        | 267/1663 [2:19:06<12:00:59, 30.99s/it] 16%|█▌        | 268/1663 [2:19:36<11:56:24, 30.81s/it]                                                       {'loss': 0.4925, 'learning_rate': 1.9112068067487698e-05, 'epoch': 0.16}
 16%|█▌        | 268/1663 [2:19:36<11:56:24, 30.81s/it] 16%|█▌        | 269/1663 [2:20:05<11:45:13, 30.35s/it]                                                       {'loss': 0.4871, 'learning_rate': 1.910402737593591e-05, 'epoch': 0.16}
 16%|█▌        | 269/1663 [2:20:05<11:45:13, 30.35s/it] 16%|█▌        | 270/1663 [2:20:38<12:02:47, 31.13s/it]                                                       {'loss': 0.3657, 'learning_rate': 1.9095952148989077e-05, 'epoch': 0.16}
 16%|█▌        | 270/1663 [2:20:38<12:02:47, 31.13s/it] 16%|█▋        | 271/1663 [2:21:09<12:00:01, 31.04s/it]                                                       {'loss': 0.4044, 'learning_rate': 1.9087842417279908e-05, 'epoch': 0.16}
 16%|█▋        | 271/1663 [2:21:09<12:00:01, 31.04s/it] 16%|█▋        | 272/1663 [2:21:37<11:38:24, 30.13s/it]                                                       {'loss': 0.4224, 'learning_rate': 1.907969821157203e-05, 'epoch': 0.16}
 16%|█▋        | 272/1663 [2:21:37<11:38:24, 30.13s/it] 16%|█▋        | 273/1663 [2:22:08<11:41:40, 30.29s/it]                                                       {'loss': 0.4872, 'learning_rate': 1.907151956275982e-05, 'epoch': 0.16}
 16%|█▋        | 273/1663 [2:22:08<11:41:40, 30.29s/it] 16%|█▋        | 274/1663 [2:22:44<12:20:41, 32.00s/it]                                                       {'loss': 0.5034, 'learning_rate': 1.906330650186833e-05, 'epoch': 0.16}
 16%|█▋        | 274/1663 [2:22:44<12:20:41, 32.00s/it] 17%|█▋        | 275/1663 [2:23:14<12:10:11, 31.56s/it]                                                       {'loss': 0.4276, 'learning_rate': 1.9055059060053143e-05, 'epoch': 0.17}
 17%|█▋        | 275/1663 [2:23:14<12:10:11, 31.56s/it] 17%|█▋        | 276/1663 [2:23:46<12:09:58, 31.58s/it]                                                       {'loss': 0.4825, 'learning_rate': 1.904677726860027e-05, 'epoch': 0.17}
 17%|█▋        | 276/1663 [2:23:46<12:09:58, 31.58s/it] 17%|█▋        | 277/1663 [2:24:16<11:59:03, 31.13s/it]                                                       {'loss': 0.4432, 'learning_rate': 1.9038461158926014e-05, 'epoch': 0.17}
 17%|█▋        | 277/1663 [2:24:16<11:59:03, 31.13s/it] 17%|█▋        | 278/1663 [2:24:46<11:46:54, 30.62s/it]                                                       {'loss': 0.5593, 'learning_rate': 1.9030110762576878e-05, 'epoch': 0.17}
 17%|█▋        | 278/1663 [2:24:46<11:46:54, 30.62s/it] 17%|█▋        | 279/1663 [2:25:19<12:05:53, 31.47s/it]                                                       {'loss': 0.5271, 'learning_rate': 1.9021726111229404e-05, 'epoch': 0.17}
 17%|█▋        | 279/1663 [2:25:19<12:05:53, 31.47s/it] 17%|█▋        | 280/1663 [2:25:51<12:08:02, 31.59s/it]                                                       {'loss': 0.422, 'learning_rate': 1.9013307236690105e-05, 'epoch': 0.17}
 17%|█▋        | 280/1663 [2:25:51<12:08:02, 31.59s/it] 17%|█▋        | 281/1663 [2:26:20<11:51:35, 30.89s/it]                                                       {'loss': 0.4173, 'learning_rate': 1.9004854170895296e-05, 'epoch': 0.17}
 17%|█▋        | 281/1663 [2:26:20<11:51:35, 30.89s/it] 17%|█▋        | 282/1663 [2:26:50<11:41:00, 30.46s/it]                                                       {'loss': 0.57, 'learning_rate': 1.8996366945911003e-05, 'epoch': 0.17}
 17%|█▋        | 282/1663 [2:26:50<11:41:00, 30.46s/it] 17%|█▋        | 283/1663 [2:27:21<11:49:18, 30.84s/it]                                                       {'loss': 0.3471, 'learning_rate': 1.8987845593932836e-05, 'epoch': 0.17}
 17%|█▋        | 283/1663 [2:27:21<11:49:18, 30.84s/it] 17%|█▋        | 284/1663 [2:27:53<11:55:32, 31.13s/it]                                                       {'loss': 0.4507, 'learning_rate': 1.8979290147285852e-05, 'epoch': 0.17}
 17%|█▋        | 284/1663 [2:27:53<11:55:32, 31.13s/it] 17%|█▋        | 285/1663 [2:28:26<12:04:56, 31.57s/it]                                                       {'loss': 0.515, 'learning_rate': 1.897070063842445e-05, 'epoch': 0.17}
 17%|█▋        | 285/1663 [2:28:26<12:04:56, 31.57s/it] 17%|█▋        | 286/1663 [2:28:56<11:57:44, 31.27s/it]                                                       {'loss': 0.3565, 'learning_rate': 1.8962077099932242e-05, 'epoch': 0.17}
 17%|█▋        | 286/1663 [2:28:56<11:57:44, 31.27s/it] 17%|█▋        | 287/1663 [2:29:27<11:50:59, 31.00s/it]                                                       {'loss': 0.4695, 'learning_rate': 1.8953419564521926e-05, 'epoch': 0.17}
 17%|█▋        | 287/1663 [2:29:27<11:50:59, 31.00s/it] 17%|█▋        | 288/1663 [2:29:58<11:54:28, 31.18s/it]                                                       {'loss': 0.4363, 'learning_rate': 1.894472806503517e-05, 'epoch': 0.17}
 17%|█▋        | 288/1663 [2:29:58<11:54:28, 31.18s/it] 17%|█▋        | 289/1663 [2:30:32<12:11:03, 31.92s/it]                                                       {'loss': 0.375, 'learning_rate': 1.893600263444247e-05, 'epoch': 0.17}
 17%|█▋        | 289/1663 [2:30:32<12:11:03, 31.92s/it] 17%|█▋        | 290/1663 [2:31:05<12:17:45, 32.24s/it]                                                       {'loss': 0.4478, 'learning_rate': 1.892724330584305e-05, 'epoch': 0.17}
 17%|█▋        | 290/1663 [2:31:05<12:17:45, 32.24s/it] 17%|█▋        | 291/1663 [2:31:36<12:10:43, 31.96s/it]                                                       {'loss': 0.4648, 'learning_rate': 1.891845011246472e-05, 'epoch': 0.17}
 17%|█▋        | 291/1663 [2:31:36<12:10:43, 31.96s/it] 18%|█▊        | 292/1663 [2:32:11<12:30:37, 32.85s/it]                                                       {'loss': 0.5734, 'learning_rate': 1.8909623087663745e-05, 'epoch': 0.18}
 18%|█▊        | 292/1663 [2:32:11<12:30:37, 32.85s/it] 18%|█▊        | 293/1663 [2:32:41<12:08:48, 31.92s/it]                                                       {'loss': 0.3627, 'learning_rate': 1.8900762264924736e-05, 'epoch': 0.18}
 18%|█▊        | 293/1663 [2:32:41<12:08:48, 31.92s/it] 18%|█▊        | 294/1663 [2:33:13<12:09:26, 31.97s/it]                                                       {'loss': 0.5111, 'learning_rate': 1.889186767786051e-05, 'epoch': 0.18}
 18%|█▊        | 294/1663 [2:33:13<12:09:26, 31.97s/it] 18%|█▊        | 295/1663 [2:33:46<12:14:19, 32.21s/it]                                                       {'loss': 0.3721, 'learning_rate': 1.888293936021197e-05, 'epoch': 0.18}
 18%|█▊        | 295/1663 [2:33:46<12:14:19, 32.21s/it] 18%|█▊        | 296/1663 [2:34:17<12:06:33, 31.89s/it]                                                       {'loss': 0.4246, 'learning_rate': 1.8873977345847967e-05, 'epoch': 0.18}
 18%|█▊        | 296/1663 [2:34:17<12:06:33, 31.89s/it] 18%|█▊        | 297/1663 [2:34:48<12:03:31, 31.78s/it]                                                       {'loss': 0.4059, 'learning_rate': 1.8864981668765185e-05, 'epoch': 0.18}
 18%|█▊        | 297/1663 [2:34:48<12:03:31, 31.78s/it] 18%|█▊        | 298/1663 [2:35:21<12:10:54, 32.13s/it]                                                       {'loss': 0.4506, 'learning_rate': 1.8855952363087997e-05, 'epoch': 0.18}
 18%|█▊        | 298/1663 [2:35:21<12:10:54, 32.13s/it] 18%|█▊        | 299/1663 [2:35:49<11:41:58, 30.88s/it]                                                       {'loss': 0.4201, 'learning_rate': 1.884688946306835e-05, 'epoch': 0.18}
 18%|█▊        | 299/1663 [2:35:49<11:41:58, 30.88s/it] 18%|█▊        | 300/1663 [2:36:19<11:34:27, 30.57s/it]                                                       {'loss': 0.5635, 'learning_rate': 1.883779300308562e-05, 'epoch': 0.18}
 18%|█▊        | 300/1663 [2:36:19<11:34:27, 30.57s/it] 18%|█▊        | 301/1663 [2:36:50<11:38:57, 30.79s/it]                                                       {'loss': 0.4729, 'learning_rate': 1.8828663017646505e-05, 'epoch': 0.18}
 18%|█▊        | 301/1663 [2:36:50<11:38:57, 30.79s/it] 18%|█▊        | 302/1663 [2:37:22<11:45:59, 31.12s/it]                                                       {'loss': 0.5212, 'learning_rate': 1.881949954138486e-05, 'epoch': 0.18}
 18%|█▊        | 302/1663 [2:37:22<11:45:59, 31.12s/it] 18%|█▊        | 303/1663 [2:37:52<11:38:31, 30.82s/it]                                                       {'loss': 0.4007, 'learning_rate': 1.881030260906161e-05, 'epoch': 0.18}
 18%|█▊        | 303/1663 [2:37:52<11:38:31, 30.82s/it] 18%|█▊        | 304/1663 [2:38:23<11:36:39, 30.76s/it]                                                       {'loss': 0.5092, 'learning_rate': 1.880107225556456e-05, 'epoch': 0.18}
 18%|█▊        | 304/1663 [2:38:23<11:36:39, 30.76s/it] 18%|█▊        | 305/1663 [2:38:52<11:26:29, 30.33s/it]                                                       {'loss': 0.5049, 'learning_rate': 1.879180851590832e-05, 'epoch': 0.18}
 18%|█▊        | 305/1663 [2:38:52<11:26:29, 30.33s/it] 18%|█▊        | 306/1663 [2:39:23<11:24:36, 30.27s/it]                                                       {'loss': 0.6059, 'learning_rate': 1.8782511425234143e-05, 'epoch': 0.18}
 18%|█▊        | 306/1663 [2:39:23<11:24:36, 30.27s/it] 18%|█▊        | 307/1663 [2:39:52<11:17:35, 29.98s/it]                                                       {'loss': 0.5651, 'learning_rate': 1.8773181018809793e-05, 'epoch': 0.18}
 18%|█▊        | 307/1663 [2:39:52<11:17:35, 29.98s/it] 19%|█▊        | 308/1663 [2:40:23<11:22:07, 30.20s/it]                                                       {'loss': 0.3865, 'learning_rate': 1.8763817332029412e-05, 'epoch': 0.19}
 19%|█▊        | 308/1663 [2:40:23<11:22:07, 30.20s/it] 19%|█▊        | 309/1663 [2:40:52<11:19:13, 30.10s/it]                                                       {'loss': 0.3135, 'learning_rate': 1.8754420400413392e-05, 'epoch': 0.19}
 19%|█▊        | 309/1663 [2:40:52<11:19:13, 30.10s/it] 19%|█▊        | 310/1663 [2:41:21<11:09:50, 29.70s/it]                                                       {'loss': 0.5938, 'learning_rate': 1.874499025960825e-05, 'epoch': 0.19}
 19%|█▊        | 310/1663 [2:41:21<11:09:50, 29.70s/it] 19%|█▊        | 311/1663 [2:41:53<11:21:00, 30.22s/it]                                                       {'loss': 0.4227, 'learning_rate': 1.8735526945386447e-05, 'epoch': 0.19}
 19%|█▊        | 311/1663 [2:41:53<11:21:00, 30.22s/it] 19%|█▉        | 312/1663 [2:42:24<11:28:09, 30.56s/it]                                                       {'loss': 0.5066, 'learning_rate': 1.8726030493646314e-05, 'epoch': 0.19}
 19%|█▉        | 312/1663 [2:42:24<11:28:09, 30.56s/it] 19%|█▉        | 313/1663 [2:42:53<11:17:34, 30.11s/it]                                                       {'loss': 0.3779, 'learning_rate': 1.8716500940411878e-05, 'epoch': 0.19}
 19%|█▉        | 313/1663 [2:42:53<11:17:34, 30.11s/it] 19%|█▉        | 314/1663 [2:43:23<11:17:21, 30.13s/it]                                                       {'loss': 0.47, 'learning_rate': 1.870693832183273e-05, 'epoch': 0.19}
 19%|█▉        | 314/1663 [2:43:23<11:17:21, 30.13s/it] 19%|█▉        | 315/1663 [2:43:55<11:26:05, 30.54s/it]                                                       {'loss': 0.5264, 'learning_rate': 1.869734267418389e-05, 'epoch': 0.19}
 19%|█▉        | 315/1663 [2:43:55<11:26:05, 30.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2603 > 2560). Running this sequence through the model will result in indexing errors
 19%|█▉        | 316/1663 [2:44:27<11:34:38, 30.94s/it]                                                       {'loss': 0.4317, 'learning_rate': 1.8687714033865677e-05, 'epoch': 0.19}
 19%|█▉        | 316/1663 [2:44:27<11:34:38, 30.94s/it] 19%|█▉        | 317/1663 [2:44:56<11:24:40, 30.52s/it]                                                       {'loss': 0.5237, 'learning_rate': 1.8678052437403567e-05, 'epoch': 0.19}
 19%|█▉        | 317/1663 [2:44:56<11:24:40, 30.52s/it] 19%|█▉        | 318/1663 [2:45:30<11:45:38, 31.48s/it]                                                       {'loss': 0.4512, 'learning_rate': 1.8668357921448042e-05, 'epoch': 0.19}
 19%|█▉        | 318/1663 [2:45:30<11:45:38, 31.48s/it] 19%|█▉        | 319/1663 [2:45:57<11:15:19, 30.15s/it]                                                       {'loss': 0.4745, 'learning_rate': 1.8658630522774474e-05, 'epoch': 0.19}
 19%|█▉        | 319/1663 [2:45:57<11:15:19, 30.15s/it] 19%|█▉        | 320/1663 [2:46:28<11:18:17, 30.30s/it]                                                       {'loss': 0.5578, 'learning_rate': 1.8648870278282963e-05, 'epoch': 0.19}
 19%|█▉        | 320/1663 [2:46:28<11:18:17, 30.30s/it] 19%|█▉        | 321/1663 [2:47:01<11:41:39, 31.37s/it]                                                       {'loss': 0.3709, 'learning_rate': 1.8639077224998212e-05, 'epoch': 0.19}
 19%|█▉        | 321/1663 [2:47:01<11:41:39, 31.37s/it] 19%|█▉        | 322/1663 [2:47:32<11:33:14, 31.02s/it]                                                       {'loss': 0.4159, 'learning_rate': 1.8629251400069383e-05, 'epoch': 0.19}
 19%|█▉        | 322/1663 [2:47:32<11:33:14, 31.02s/it] 19%|█▉        | 323/1663 [2:48:04<11:43:22, 31.49s/it]                                                       {'loss': 0.4248, 'learning_rate': 1.8619392840769946e-05, 'epoch': 0.19}
 19%|█▉        | 323/1663 [2:48:04<11:43:22, 31.49s/it] 19%|█▉        | 324/1663 [2:48:35<11:34:57, 31.14s/it]                                                       {'loss': 0.4026, 'learning_rate': 1.860950158449756e-05, 'epoch': 0.19}
 19%|█▉        | 324/1663 [2:48:35<11:34:57, 31.14s/it] 20%|█▉        | 325/1663 [2:49:05<11:32:29, 31.05s/it]                                                       {'loss': 0.4183, 'learning_rate': 1.8599577668773902e-05, 'epoch': 0.2}
 20%|█▉        | 325/1663 [2:49:05<11:32:29, 31.05s/it] 20%|█▉        | 326/1663 [2:49:35<11:25:28, 30.76s/it]                                                       {'loss': 0.4641, 'learning_rate': 1.858962113124455e-05, 'epoch': 0.2}
 20%|█▉        | 326/1663 [2:49:35<11:25:28, 30.76s/it] 20%|█▉        | 327/1663 [2:50:10<11:47:04, 31.75s/it]                                                       {'loss': 0.4414, 'learning_rate': 1.857963200967883e-05, 'epoch': 0.2}
 20%|█▉        | 327/1663 [2:50:10<11:47:04, 31.75s/it] 20%|█▉        | 328/1663 [2:50:38<11:24:27, 30.76s/it]                                                       {'loss': 0.365, 'learning_rate': 1.8569610341969667e-05, 'epoch': 0.2}
 20%|█▉        | 328/1663 [2:50:38<11:24:27, 30.76s/it] 20%|█▉        | 329/1663 [2:51:09<11:27:46, 30.93s/it]                                                       {'loss': 0.482, 'learning_rate': 1.8559556166133458e-05, 'epoch': 0.2}
 20%|█▉        | 329/1663 [2:51:09<11:27:46, 30.93s/it] 20%|█▉        | 330/1663 [2:51:40<11:24:38, 30.82s/it]                                                       {'loss': 0.4459, 'learning_rate': 1.85494695203099e-05, 'epoch': 0.2}
 20%|█▉        | 330/1663 [2:51:40<11:24:38, 30.82s/it] 20%|█▉        | 331/1663 [2:52:11<11:25:16, 30.87s/it]                                                       {'loss': 0.4011, 'learning_rate': 1.8539350442761876e-05, 'epoch': 0.2}
 20%|█▉        | 331/1663 [2:52:11<11:25:16, 30.87s/it] 20%|█▉        | 332/1663 [2:52:45<11:45:14, 31.79s/it]                                                       {'loss': 0.5058, 'learning_rate': 1.8529198971875297e-05, 'epoch': 0.2}
 20%|█▉        | 332/1663 [2:52:45<11:45:14, 31.79s/it] 20%|██        | 333/1663 [2:53:16<11:37:42, 31.48s/it]                                                       {'loss': 0.5664, 'learning_rate': 1.851901514615894e-05, 'epoch': 0.2}
 20%|██        | 333/1663 [2:53:16<11:37:42, 31.48s/it] 20%|██        | 334/1663 [2:53:46<11:30:31, 31.17s/it]                                                       {'loss': 0.4661, 'learning_rate': 1.8508799004244342e-05, 'epoch': 0.2}
 20%|██        | 334/1663 [2:53:46<11:30:31, 31.17s/it] 20%|██        | 335/1663 [2:54:19<11:42:13, 31.73s/it]                                                       {'loss': 0.4145, 'learning_rate': 1.8498550584885604e-05, 'epoch': 0.2}
 20%|██        | 335/1663 [2:54:19<11:42:13, 31.73s/it] 20%|██        | 336/1663 [2:54:50<11:38:51, 31.60s/it]                                                       {'loss': 0.4102, 'learning_rate': 1.8488269926959283e-05, 'epoch': 0.2}
 20%|██        | 336/1663 [2:54:50<11:38:51, 31.60s/it] 20%|██        | 337/1663 [2:55:22<11:38:31, 31.61s/it]                                                       {'loss': 0.3623, 'learning_rate': 1.847795706946423e-05, 'epoch': 0.2}
 20%|██        | 337/1663 [2:55:22<11:38:31, 31.61s/it] 20%|██        | 338/1663 [2:55:53<11:35:02, 31.47s/it]                                                       {'loss': 0.4687, 'learning_rate': 1.846761205152144e-05, 'epoch': 0.2}
 20%|██        | 338/1663 [2:55:53<11:35:02, 31.47s/it] 20%|██        | 339/1663 [2:56:22<11:17:23, 30.70s/it]                                                       {'loss': 0.3371, 'learning_rate': 1.8457234912373895e-05, 'epoch': 0.2}
 20%|██        | 339/1663 [2:56:22<11:17:23, 30.70s/it] 20%|██        | 340/1663 [2:56:51<11:04:14, 30.12s/it]                                                       {'loss': 0.4857, 'learning_rate': 1.844682569138645e-05, 'epoch': 0.2}
 20%|██        | 340/1663 [2:56:51<11:04:14, 30.12s/it] 21%|██        | 341/1663 [2:57:21<11:05:31, 30.21s/it]                                                       {'loss': 0.4328, 'learning_rate': 1.8436384428045645e-05, 'epoch': 0.2}
 21%|██        | 341/1663 [2:57:21<11:05:31, 30.21s/it] 21%|██        | 342/1663 [2:57:54<11:19:37, 30.87s/it]                                                       {'loss': 0.5515, 'learning_rate': 1.842591116195957e-05, 'epoch': 0.21}
 21%|██        | 342/1663 [2:57:54<11:19:37, 30.87s/it] 21%|██        | 343/1663 [2:58:23<11:12:14, 30.56s/it]                                                       {'loss': 0.3503, 'learning_rate': 1.8415405932857714e-05, 'epoch': 0.21}
 21%|██        | 343/1663 [2:58:23<11:12:14, 30.56s/it] 21%|██        | 344/1663 [2:58:53<11:06:20, 30.31s/it]                                                       {'loss': 0.381, 'learning_rate': 1.8404868780590822e-05, 'epoch': 0.21}
 21%|██        | 344/1663 [2:58:53<11:06:20, 30.31s/it] 21%|██        | 345/1663 [2:59:24<11:11:57, 30.59s/it]                                                       {'loss': 0.4217, 'learning_rate': 1.839429974513073e-05, 'epoch': 0.21}
 21%|██        | 345/1663 [2:59:24<11:11:57, 30.59s/it] 21%|██        | 346/1663 [2:59:59<11:35:08, 31.67s/it]                                                       {'loss': 0.5228, 'learning_rate': 1.838369886657023e-05, 'epoch': 0.21}
 21%|██        | 346/1663 [2:59:59<11:35:08, 31.67s/it] 21%|██        | 347/1663 [3:00:32<11:46:54, 32.23s/it]                                                       {'loss': 0.536, 'learning_rate': 1.837306618512289e-05, 'epoch': 0.21}
 21%|██        | 347/1663 [3:00:32<11:46:54, 32.23s/it] 21%|██        | 348/1663 [3:01:02<11:30:25, 31.50s/it]                                                       {'loss': 0.4337, 'learning_rate': 1.836240174112294e-05, 'epoch': 0.21}
 21%|██        | 348/1663 [3:01:02<11:30:25, 31.50s/it] 21%|██        | 349/1663 [3:01:35<11:41:58, 32.05s/it]                                                       {'loss': 0.3909, 'learning_rate': 1.8351705575025084e-05, 'epoch': 0.21}
 21%|██        | 349/1663 [3:01:35<11:41:58, 32.05s/it] 21%|██        | 350/1663 [3:02:04<11:19:13, 31.04s/it]                                                       {'loss': 0.5391, 'learning_rate': 1.8340977727404377e-05, 'epoch': 0.21}
 21%|██        | 350/1663 [3:02:04<11:19:13, 31.04s/it] 21%|██        | 351/1663 [3:02:35<11:21:39, 31.17s/it]                                                       {'loss': 0.358, 'learning_rate': 1.8330218238956037e-05, 'epoch': 0.21}
 21%|██        | 351/1663 [3:02:35<11:21:39, 31.17s/it] 21%|██        | 352/1663 [3:03:07<11:21:00, 31.17s/it]                                                       {'loss': 0.4484, 'learning_rate': 1.831942715049532e-05, 'epoch': 0.21}
 21%|██        | 352/1663 [3:03:07<11:21:00, 31.17s/it] 21%|██        | 353/1663 [3:03:40<11:34:51, 31.83s/it]                                                       {'loss': 0.4234, 'learning_rate': 1.8308604502957346e-05, 'epoch': 0.21}
 21%|██        | 353/1663 [3:03:40<11:34:51, 31.83s/it] 21%|██▏       | 354/1663 [3:04:11<11:28:47, 31.57s/it]                                                       {'loss': 0.5003, 'learning_rate': 1.829775033739697e-05, 'epoch': 0.21}
 21%|██▏       | 354/1663 [3:04:11<11:28:47, 31.57s/it] 21%|██▏       | 355/1663 [3:04:42<11:23:22, 31.35s/it]                                                       {'loss': 0.4415, 'learning_rate': 1.8286864694988583e-05, 'epoch': 0.21}
 21%|██▏       | 355/1663 [3:04:42<11:23:22, 31.35s/it] 21%|██▏       | 356/1663 [3:05:14<11:30:52, 31.72s/it]                                                       {'loss': 0.4042, 'learning_rate': 1.8275947617026e-05, 'epoch': 0.21}
 21%|██▏       | 356/1663 [3:05:14<11:30:52, 31.72s/it] 21%|██▏       | 357/1663 [3:05:48<11:41:50, 32.24s/it]                                                       {'loss': 0.3836, 'learning_rate': 1.8264999144922275e-05, 'epoch': 0.21}
 21%|██▏       | 357/1663 [3:05:48<11:41:50, 32.24s/it] 22%|██▏       | 358/1663 [3:06:21<11:49:36, 32.63s/it]                                                       {'loss': 0.4462, 'learning_rate': 1.8254019320209554e-05, 'epoch': 0.22}
 22%|██▏       | 358/1663 [3:06:21<11:49:36, 32.63s/it] 22%|██▏       | 359/1663 [3:06:55<11:56:20, 32.96s/it]                                                       {'loss': 0.46, 'learning_rate': 1.8243008184538924e-05, 'epoch': 0.22}
 22%|██▏       | 359/1663 [3:06:55<11:56:20, 32.96s/it] 22%|██▏       | 360/1663 [3:07:26<11:41:21, 32.30s/it]                                                       {'loss': 0.5056, 'learning_rate': 1.8231965779680237e-05, 'epoch': 0.22}
 22%|██▏       | 360/1663 [3:07:26<11:41:21, 32.30s/it] 22%|██▏       | 361/1663 [3:07:56<11:26:54, 31.65s/it]                                                       {'loss': 0.5084, 'learning_rate': 1.8220892147521967e-05, 'epoch': 0.22}
 22%|██▏       | 361/1663 [3:07:56<11:26:54, 31.65s/it] 22%|██▏       | 362/1663 [3:08:27<11:21:55, 31.45s/it]                                                       {'loss': 0.467, 'learning_rate': 1.820978733007105e-05, 'epoch': 0.22}
 22%|██▏       | 362/1663 [3:08:27<11:21:55, 31.45s/it] 22%|██▏       | 363/1663 [3:08:59<11:25:11, 31.62s/it]                                                       {'loss': 0.4282, 'learning_rate': 1.8198651369452714e-05, 'epoch': 0.22}
 22%|██▏       | 363/1663 [3:08:59<11:25:11, 31.62s/it] 22%|██▏       | 364/1663 [3:09:29<11:11:50, 31.03s/it]                                                       {'loss': 0.542, 'learning_rate': 1.8187484307910325e-05, 'epoch': 0.22}
 22%|██▏       | 364/1663 [3:09:29<11:11:50, 31.03s/it] 22%|██▏       | 365/1663 [3:09:56<10:45:40, 29.85s/it]                                                       {'loss': 0.4786, 'learning_rate': 1.8176286187805242e-05, 'epoch': 0.22}
 22%|██▏       | 365/1663 [3:09:56<10:45:40, 29.85s/it] 22%|██▏       | 366/1663 [3:10:27<10:53:27, 30.23s/it]                                                       {'loss': 0.4644, 'learning_rate': 1.8165057051616628e-05, 'epoch': 0.22}
 22%|██▏       | 366/1663 [3:10:27<10:53:27, 30.23s/it] 22%|██▏       | 367/1663 [3:10:56<10:49:19, 30.06s/it]                                                       {'loss': 0.4125, 'learning_rate': 1.8153796941941306e-05, 'epoch': 0.22}
 22%|██▏       | 367/1663 [3:10:56<10:49:19, 30.06s/it] 22%|██▏       | 368/1663 [3:11:29<11:03:53, 30.76s/it]                                                       {'loss': 0.5197, 'learning_rate': 1.8142505901493596e-05, 'epoch': 0.22}
 22%|██▏       | 368/1663 [3:11:29<11:03:53, 30.76s/it] 22%|██▏       | 369/1663 [3:11:59<10:58:57, 30.55s/it]                                                       {'loss': 0.5038, 'learning_rate': 1.8131183973105152e-05, 'epoch': 0.22}
 22%|██▏       | 369/1663 [3:11:59<10:58:57, 30.55s/it] 22%|██▏       | 370/1663 [3:12:31<11:08:20, 31.01s/it]                                                       {'loss': 0.4401, 'learning_rate': 1.8119831199724796e-05, 'epoch': 0.22}
 22%|██▏       | 370/1663 [3:12:31<11:08:20, 31.01s/it] 22%|██▏       | 371/1663 [3:13:04<11:22:45, 31.71s/it]                                                       {'loss': 0.367, 'learning_rate': 1.8108447624418363e-05, 'epoch': 0.22}
 22%|██▏       | 371/1663 [3:13:04<11:22:45, 31.71s/it] 22%|██▏       | 372/1663 [3:13:37<11:26:34, 31.91s/it]                                                       {'loss': 0.4325, 'learning_rate': 1.8097033290368525e-05, 'epoch': 0.22}
 22%|██▏       | 372/1663 [3:13:37<11:26:34, 31.91s/it] 22%|██▏       | 373/1663 [3:14:05<11:02:43, 30.82s/it]                                                       {'loss': 0.469, 'learning_rate': 1.8085588240874648e-05, 'epoch': 0.22}
 22%|██▏       | 373/1663 [3:14:05<11:02:43, 30.82s/it] 22%|██▏       | 374/1663 [3:14:41<11:34:34, 32.33s/it]                                                       {'loss': 0.35, 'learning_rate': 1.8074112519352597e-05, 'epoch': 0.22}
 22%|██▏       | 374/1663 [3:14:41<11:34:34, 32.33s/it] 23%|██▎       | 375/1663 [3:15:11<11:22:55, 31.81s/it]                                                       {'loss': 0.3927, 'learning_rate': 1.80626061693346e-05, 'epoch': 0.23}
 23%|██▎       | 375/1663 [3:15:12<11:22:55, 31.81s/it] 23%|██▎       | 376/1663 [3:15:44<11:26:28, 32.00s/it]                                                       {'loss': 0.5504, 'learning_rate': 1.8051069234469073e-05, 'epoch': 0.23}
 23%|██▎       | 376/1663 [3:15:44<11:26:28, 32.00s/it] 23%|██▎       | 377/1663 [3:16:17<11:35:47, 32.46s/it]                                                       {'loss': 0.4341, 'learning_rate': 1.803950175852045e-05, 'epoch': 0.23}
 23%|██▎       | 377/1663 [3:16:17<11:35:47, 32.46s/it] 23%|██▎       | 378/1663 [3:16:44<10:57:32, 30.70s/it]                                                       {'loss': 0.4774, 'learning_rate': 1.8027903785369015e-05, 'epoch': 0.23}
 23%|██▎       | 378/1663 [3:16:44<10:57:32, 30.70s/it] 23%|██▎       | 379/1663 [3:17:17<11:08:33, 31.24s/it]                                                       {'loss': 0.408, 'learning_rate': 1.801627535901075e-05, 'epoch': 0.23}
 23%|██▎       | 379/1663 [3:17:17<11:08:33, 31.24s/it] 23%|██▎       | 380/1663 [3:17:47<11:02:46, 30.99s/it]                                                       {'loss': 0.335, 'learning_rate': 1.8004616523557154e-05, 'epoch': 0.23}
 23%|██▎       | 380/1663 [3:17:47<11:02:46, 30.99s/it] 23%|██▎       | 381/1663 [3:18:16<10:50:48, 30.46s/it]                                                       {'loss': 0.4332, 'learning_rate': 1.7992927323235076e-05, 'epoch': 0.23}
 23%|██▎       | 381/1663 [3:18:16<10:50:48, 30.46s/it] 23%|██▎       | 382/1663 [3:18:49<11:04:29, 31.12s/it]                                                       {'loss': 0.4082, 'learning_rate': 1.7981207802386565e-05, 'epoch': 0.23}
 23%|██▎       | 382/1663 [3:18:49<11:04:29, 31.12s/it] 23%|██▎       | 383/1663 [3:19:21<11:11:37, 31.48s/it]                                                       {'loss': 0.4661, 'learning_rate': 1.796945800546867e-05, 'epoch': 0.23}
 23%|██▎       | 383/1663 [3:19:21<11:11:37, 31.48s/it] 23%|██▎       | 384/1663 [3:19:54<11:17:57, 31.80s/it]                                                       {'loss': 0.5656, 'learning_rate': 1.795767797705331e-05, 'epoch': 0.23}
 23%|██▎       | 384/1663 [3:19:54<11:17:57, 31.80s/it] 23%|██▎       | 385/1663 [3:20:25<11:16:38, 31.77s/it]                                                       {'loss': 0.5158, 'learning_rate': 1.7945867761827064e-05, 'epoch': 0.23}
 23%|██▎       | 385/1663 [3:20:25<11:16:38, 31.77s/it] 23%|██▎       | 386/1663 [3:20:56<11:05:53, 31.29s/it]                                                       {'loss': 0.4136, 'learning_rate': 1.7934027404591042e-05, 'epoch': 0.23}
 23%|██▎       | 386/1663 [3:20:56<11:05:53, 31.29s/it] 23%|██▎       | 387/1663 [3:21:25<10:54:59, 30.80s/it]                                                       {'loss': 0.5037, 'learning_rate': 1.7922156950260685e-05, 'epoch': 0.23}
 23%|██▎       | 387/1663 [3:21:25<10:54:59, 30.80s/it] 23%|██▎       | 388/1663 [3:21:58<11:07:36, 31.42s/it]                                                       {'loss': 0.4121, 'learning_rate': 1.79102564438656e-05, 'epoch': 0.23}
 23%|██▎       | 388/1663 [3:21:58<11:07:36, 31.42s/it] 23%|██▎       | 389/1663 [3:22:25<10:41:19, 30.20s/it]                                                       {'loss': 0.4029, 'learning_rate': 1.789832593054941e-05, 'epoch': 0.23}
 23%|██▎       | 389/1663 [3:22:25<10:41:19, 30.20s/it] 23%|██▎       | 390/1663 [3:22:56<10:42:31, 30.28s/it]                                                       {'loss': 0.4782, 'learning_rate': 1.788636545556954e-05, 'epoch': 0.23}
 23%|██▎       | 390/1663 [3:22:56<10:42:31, 30.28s/it] 24%|██▎       | 391/1663 [3:23:28<10:50:42, 30.69s/it]                                                       {'loss': 0.4144, 'learning_rate': 1.787437506429711e-05, 'epoch': 0.24}
 24%|██▎       | 391/1663 [3:23:28<10:50:42, 30.69s/it] 24%|██▎       | 392/1663 [3:23:56<10:33:21, 29.90s/it]                                                       {'loss': 0.4425, 'learning_rate': 1.7862354802216693e-05, 'epoch': 0.24}
 24%|██▎       | 392/1663 [3:23:56<10:33:21, 29.90s/it] 24%|██▎       | 393/1663 [3:24:27<10:45:03, 30.48s/it]                                                       {'loss': 0.3623, 'learning_rate': 1.7850304714926184e-05, 'epoch': 0.24}
 24%|██▎       | 393/1663 [3:24:27<10:45:03, 30.48s/it] 24%|██▎       | 394/1663 [3:25:02<11:07:48, 31.57s/it]                                                       {'loss': 0.4588, 'learning_rate': 1.783822484813662e-05, 'epoch': 0.24}
 24%|██▎       | 394/1663 [3:25:02<11:07:48, 31.57s/it] 24%|██▍       | 395/1663 [3:25:32<10:59:03, 31.19s/it]                                                       {'loss': 0.4756, 'learning_rate': 1.7826115247672007e-05, 'epoch': 0.24}
 24%|██▍       | 395/1663 [3:25:32<10:59:03, 31.19s/it] 24%|██▍       | 396/1663 [3:26:03<10:57:19, 31.13s/it]                                                       {'loss': 0.4623, 'learning_rate': 1.7813975959469138e-05, 'epoch': 0.24}
 24%|██▍       | 396/1663 [3:26:03<10:57:19, 31.13s/it] 24%|██▍       | 397/1663 [3:26:33<10:50:15, 30.82s/it]                                                       {'loss': 0.425, 'learning_rate': 1.7801807029577427e-05, 'epoch': 0.24}
 24%|██▍       | 397/1663 [3:26:33<10:50:15, 30.82s/it] 24%|██▍       | 398/1663 [3:27:08<11:18:28, 32.18s/it]                                                       {'loss': 0.4349, 'learning_rate': 1.7789608504158728e-05, 'epoch': 0.24}
 24%|██▍       | 398/1663 [3:27:08<11:18:28, 32.18s/it] 24%|██▍       | 399/1663 [3:27:39<11:05:16, 31.58s/it]                                                       {'loss': 0.4401, 'learning_rate': 1.7777380429487167e-05, 'epoch': 0.24}
 24%|██▍       | 399/1663 [3:27:39<11:05:16, 31.58s/it] 24%|██▍       | 400/1663 [3:28:12<11:15:22, 32.08s/it]                                                       {'loss': 0.4691, 'learning_rate': 1.7765122851948958e-05, 'epoch': 0.24}
 24%|██▍       | 400/1663 [3:28:12<11:15:22, 32.08s/it] 24%|██▍       | 401/1663 [3:28:43<11:10:42, 31.89s/it]                                                       {'loss': 0.4399, 'learning_rate': 1.7752835818042238e-05, 'epoch': 0.24}
 24%|██▍       | 401/1663 [3:28:43<11:10:42, 31.89s/it] 24%|██▍       | 402/1663 [3:29:17<11:21:53, 32.45s/it]                                                       {'loss': 0.4703, 'learning_rate': 1.774051937437688e-05, 'epoch': 0.24}
 24%|██▍       | 402/1663 [3:29:17<11:21:53, 32.45s/it] 24%|██▍       | 403/1663 [3:29:48<11:13:05, 32.05s/it]                                                       {'loss': 0.3826, 'learning_rate': 1.772817356767432e-05, 'epoch': 0.24}
 24%|██▍       | 403/1663 [3:29:48<11:13:05, 32.05s/it] 24%|██▍       | 404/1663 [3:30:21<11:19:45, 32.39s/it]                                                       {'loss': 0.543, 'learning_rate': 1.7715798444767384e-05, 'epoch': 0.24}
 24%|██▍       | 404/1663 [3:30:21<11:19:45, 32.39s/it] 24%|██▍       | 405/1663 [3:30:53<11:13:49, 32.14s/it]                                                       {'loss': 0.4774, 'learning_rate': 1.7703394052600103e-05, 'epoch': 0.24}
 24%|██▍       | 405/1663 [3:30:53<11:13:49, 32.14s/it] 24%|██▍       | 406/1663 [3:31:25<11:13:51, 32.17s/it]                                                       {'loss': 0.3898, 'learning_rate': 1.7690960438227543e-05, 'epoch': 0.24}
 24%|██▍       | 406/1663 [3:31:25<11:13:51, 32.17s/it] 24%|██▍       | 407/1663 [3:31:59<11:21:34, 32.56s/it]                                                       {'loss': 0.4653, 'learning_rate': 1.7678497648815622e-05, 'epoch': 0.24}
 24%|██▍       | 407/1663 [3:31:59<11:21:34, 32.56s/it] 25%|██▍       | 408/1663 [3:32:31<11:20:28, 32.53s/it]                                                       {'loss': 0.4608, 'learning_rate': 1.7666005731640917e-05, 'epoch': 0.25}
 25%|██▍       | 408/1663 [3:32:31<11:20:28, 32.53s/it] 25%|██▍       | 409/1663 [3:33:00<10:56:45, 31.42s/it]                                                       {'loss': 0.4382, 'learning_rate': 1.7653484734090522e-05, 'epoch': 0.25}
 25%|██▍       | 409/1663 [3:33:00<10:56:45, 31.42s/it] 25%|██▍       | 410/1663 [3:33:31<10:52:10, 31.23s/it]                                                       {'loss': 0.5045, 'learning_rate': 1.764093470366183e-05, 'epoch': 0.25}
 25%|██▍       | 410/1663 [3:33:31<10:52:10, 31.23s/it] 25%|██▍       | 411/1663 [3:34:03<10:58:45, 31.57s/it]                                                       {'loss': 0.5278, 'learning_rate': 1.7628355687962368e-05, 'epoch': 0.25}
 25%|██▍       | 411/1663 [3:34:03<10:58:45, 31.57s/it] 25%|██▍       | 412/1663 [3:34:33<10:50:31, 31.20s/it]                                                       {'loss': 0.4044, 'learning_rate': 1.761574773470962e-05, 'epoch': 0.25}
 25%|██▍       | 412/1663 [3:34:33<10:50:31, 31.20s/it] 25%|██▍       | 413/1663 [3:35:04<10:44:48, 30.95s/it]                                                       {'loss': 0.4061, 'learning_rate': 1.7603110891730847e-05, 'epoch': 0.25}
 25%|██▍       | 413/1663 [3:35:04<10:44:48, 30.95s/it] 25%|██▍       | 414/1663 [3:35:36<10:49:50, 31.22s/it]                                                       {'loss': 0.4399, 'learning_rate': 1.759044520696289e-05, 'epoch': 0.25}
 25%|██▍       | 414/1663 [3:35:36<10:49:50, 31.22s/it] 25%|██▍       | 415/1663 [3:36:06<10:45:19, 31.03s/it]                                                       {'loss': 0.4525, 'learning_rate': 1.7577750728452007e-05, 'epoch': 0.25}
 25%|██▍       | 415/1663 [3:36:06<10:45:19, 31.03s/it] 25%|██▌       | 416/1663 [3:36:38<10:50:56, 31.32s/it]                                                       {'loss': 0.3833, 'learning_rate': 1.756502750435368e-05, 'epoch': 0.25}
 25%|██▌       | 416/1663 [3:36:38<10:50:56, 31.32s/it] 25%|██▌       | 417/1663 [3:37:08<10:42:52, 30.96s/it]                                                       {'loss': 0.4113, 'learning_rate': 1.7552275582932438e-05, 'epoch': 0.25}
 25%|██▌       | 417/1663 [3:37:08<10:42:52, 30.96s/it] 25%|██▌       | 418/1663 [3:37:42<10:59:10, 31.77s/it]                                                       {'loss': 0.4399, 'learning_rate': 1.7539495012561665e-05, 'epoch': 0.25}
 25%|██▌       | 418/1663 [3:37:42<10:59:10, 31.77s/it] 25%|██▌       | 419/1663 [3:38:14<11:01:09, 31.89s/it]                                                       {'loss': 0.3648, 'learning_rate': 1.7526685841723428e-05, 'epoch': 0.25}
 25%|██▌       | 419/1663 [3:38:14<11:01:09, 31.89s/it] 25%|██▌       | 420/1663 [3:38:46<11:02:23, 31.97s/it]                                                       {'loss': 0.4892, 'learning_rate': 1.7513848119008285e-05, 'epoch': 0.25}
 25%|██▌       | 420/1663 [3:38:46<11:02:23, 31.97s/it] 25%|██▌       | 421/1663 [3:39:17<10:51:51, 31.49s/it]                                                       {'loss': 0.3937, 'learning_rate': 1.7500981893115103e-05, 'epoch': 0.25}
 25%|██▌       | 421/1663 [3:39:17<10:51:51, 31.49s/it] 25%|██▌       | 422/1663 [3:39:47<10:44:21, 31.15s/it]                                                       {'loss': 0.5349, 'learning_rate': 1.7488087212850873e-05, 'epoch': 0.25}
 25%|██▌       | 422/1663 [3:39:47<10:44:21, 31.15s/it] 25%|██▌       | 423/1663 [3:40:20<10:52:36, 31.58s/it]                                                       {'loss': 0.4686, 'learning_rate': 1.747516412713053e-05, 'epoch': 0.25}
 25%|██▌       | 423/1663 [3:40:20<10:52:36, 31.58s/it] 25%|██▌       | 424/1663 [3:40:51<10:53:26, 31.64s/it]                                                       {'loss': 0.5215, 'learning_rate': 1.746221268497676e-05, 'epoch': 0.25}
 25%|██▌       | 424/1663 [3:40:51<10:53:26, 31.64s/it] 26%|██▌       | 425/1663 [3:41:24<10:56:33, 31.82s/it]                                                       {'loss': 0.5241, 'learning_rate': 1.7449232935519816e-05, 'epoch': 0.26}
 26%|██▌       | 425/1663 [3:41:24<10:56:33, 31.82s/it] 26%|██▌       | 426/1663 [3:41:57<11:06:35, 32.33s/it]                                                       {'loss': 0.5325, 'learning_rate': 1.7436224927997327e-05, 'epoch': 0.26}
 26%|██▌       | 426/1663 [3:41:57<11:06:35, 32.33s/it] 26%|██▌       | 427/1663 [3:42:31<11:16:27, 32.84s/it]                                                       {'loss': 0.3871, 'learning_rate': 1.742318871175413e-05, 'epoch': 0.26}
 26%|██▌       | 427/1663 [3:42:31<11:16:27, 32.84s/it] 26%|██▌       | 428/1663 [3:43:01<11:00:58, 32.11s/it]                                                       {'loss': 0.3792, 'learning_rate': 1.7410124336242055e-05, 'epoch': 0.26}
 26%|██▌       | 428/1663 [3:43:02<11:00:58, 32.11s/it] 26%|██▌       | 429/1663 [3:43:35<11:09:09, 32.54s/it]                                                       {'loss': 0.6107, 'learning_rate': 1.7397031851019766e-05, 'epoch': 0.26}
 26%|██▌       | 429/1663 [3:43:35<11:09:09, 32.54s/it] 26%|██▌       | 430/1663 [3:44:05<10:49:49, 31.62s/it]                                                       {'loss': 0.4491, 'learning_rate': 1.738391130575255e-05, 'epoch': 0.26}
 26%|██▌       | 430/1663 [3:44:05<10:49:49, 31.62s/it] 26%|██▌       | 431/1663 [3:44:36<10:51:07, 31.71s/it]                                                       {'loss': 0.3012, 'learning_rate': 1.7370762750212134e-05, 'epoch': 0.26}
 26%|██▌       | 431/1663 [3:44:36<10:51:07, 31.71s/it] 26%|██▌       | 432/1663 [3:45:07<10:44:58, 31.44s/it]                                                       {'loss': 0.4356, 'learning_rate': 1.7357586234276513e-05, 'epoch': 0.26}
 26%|██▌       | 432/1663 [3:45:07<10:44:58, 31.44s/it] 26%|██▌       | 433/1663 [3:45:37<10:34:26, 30.95s/it]                                                       {'loss': 0.3509, 'learning_rate': 1.734438180792973e-05, 'epoch': 0.26}
 26%|██▌       | 433/1663 [3:45:37<10:34:26, 30.95s/it] 26%|██▌       | 434/1663 [3:46:09<10:39:29, 31.22s/it]                                                       {'loss': 0.458, 'learning_rate': 1.7331149521261723e-05, 'epoch': 0.26}
 26%|██▌       | 434/1663 [3:46:09<10:39:29, 31.22s/it] 26%|██▌       | 435/1663 [3:46:40<10:38:43, 31.21s/it]                                                       {'loss': 0.4381, 'learning_rate': 1.73178894244681e-05, 'epoch': 0.26}
 26%|██▌       | 435/1663 [3:46:40<10:38:43, 31.21s/it] 26%|██▌       | 436/1663 [3:47:12<10:45:01, 31.54s/it]                                                       {'loss': 0.4484, 'learning_rate': 1.730460156784998e-05, 'epoch': 0.26}
 26%|██▌       | 436/1663 [3:47:12<10:45:01, 31.54s/it] 26%|██▋       | 437/1663 [3:47:44<10:44:46, 31.56s/it]                                                       {'loss': 0.4869, 'learning_rate': 1.7291286001813765e-05, 'epoch': 0.26}
 26%|██▋       | 437/1663 [3:47:44<10:44:46, 31.56s/it] 26%|██▋       | 438/1663 [3:48:15<10:41:18, 31.41s/it]                                                       {'loss': 0.4655, 'learning_rate': 1.727794277687099e-05, 'epoch': 0.26}
 26%|██▋       | 438/1663 [3:48:15<10:41:18, 31.41s/it] 26%|██▋       | 439/1663 [3:48:48<10:50:03, 31.87s/it]                                                       {'loss': 0.3994, 'learning_rate': 1.7264571943638103e-05, 'epoch': 0.26}
 26%|██▋       | 439/1663 [3:48:48<10:50:03, 31.87s/it] 26%|██▋       | 440/1663 [3:49:20<10:48:50, 31.83s/it]                                                       {'loss': 0.4242, 'learning_rate': 1.7251173552836285e-05, 'epoch': 0.26}
 26%|██▋       | 440/1663 [3:49:20<10:48:50, 31.83s/it] 27%|██▋       | 441/1663 [3:49:51<10:47:10, 31.78s/it]                                                       {'loss': 0.3397, 'learning_rate': 1.7237747655291252e-05, 'epoch': 0.27}
 27%|██▋       | 441/1663 [3:49:51<10:47:10, 31.78s/it] 27%|██▋       | 442/1663 [3:50:22<10:37:51, 31.34s/it]                                                       {'loss': 0.5076, 'learning_rate': 1.722429430193307e-05, 'epoch': 0.27}
 27%|██▋       | 442/1663 [3:50:22<10:37:51, 31.34s/it] 27%|██▋       | 443/1663 [3:50:54<10:43:53, 31.67s/it]                                                       {'loss': 0.4904, 'learning_rate': 1.7210813543795942e-05, 'epoch': 0.27}
 27%|██▋       | 443/1663 [3:50:54<10:43:53, 31.67s/it] 27%|██▋       | 444/1663 [3:51:24<10:34:38, 31.24s/it]                                                       {'loss': 0.4417, 'learning_rate': 1.7197305432018048e-05, 'epoch': 0.27}
 27%|██▋       | 444/1663 [3:51:24<10:34:38, 31.24s/it] 27%|██▋       | 445/1663 [3:51:57<10:43:07, 31.68s/it]                                                       {'loss': 0.4381, 'learning_rate': 1.718377001784132e-05, 'epoch': 0.27}
 27%|██▋       | 445/1663 [3:51:57<10:43:07, 31.68s/it] 27%|██▋       | 446/1663 [3:52:27<10:32:55, 31.20s/it]                                                       {'loss': 0.414, 'learning_rate': 1.717020735261126e-05, 'epoch': 0.27}
 27%|██▋       | 446/1663 [3:52:27<10:32:55, 31.20s/it] 27%|██▋       | 447/1663 [3:53:00<10:42:13, 31.69s/it]                                                       {'loss': 0.4168, 'learning_rate': 1.715661748777675e-05, 'epoch': 0.27}
 27%|██▋       | 447/1663 [3:53:00<10:42:13, 31.69s/it] 27%|██▋       | 448/1663 [3:53:30<10:31:33, 31.19s/it]                                                       {'loss': 0.457, 'learning_rate': 1.714300047488985e-05, 'epoch': 0.27}
 27%|██▋       | 448/1663 [3:53:30<10:31:33, 31.19s/it] 27%|██▋       | 449/1663 [3:53:58<10:13:23, 30.32s/it]                                                       {'loss': 0.3597, 'learning_rate': 1.71293563656056e-05, 'epoch': 0.27}
 27%|██▋       | 449/1663 [3:53:58<10:13:23, 30.32s/it] 27%|██▋       | 450/1663 [3:54:30<10:21:29, 30.74s/it]                                                       {'loss': 0.3568, 'learning_rate': 1.7115685211681826e-05, 'epoch': 0.27}
 27%|██▋       | 450/1663 [3:54:30<10:21:29, 30.74s/it] 27%|██▋       | 451/1663 [3:55:05<10:45:12, 31.94s/it]                                                       {'loss': 0.4524, 'learning_rate': 1.7101987064978955e-05, 'epoch': 0.27}
 27%|██▋       | 451/1663 [3:55:05<10:45:12, 31.94s/it] 27%|██▋       | 452/1663 [3:55:37<10:48:45, 32.14s/it]                                                       {'loss': 0.4949, 'learning_rate': 1.7088261977459802e-05, 'epoch': 0.27}
 27%|██▋       | 452/1663 [3:55:37<10:48:45, 32.14s/it] 27%|██▋       | 453/1663 [3:56:07<10:33:11, 31.40s/it]                                                       {'loss': 0.4312, 'learning_rate': 1.707451000118938e-05, 'epoch': 0.27}
 27%|██▋       | 453/1663 [3:56:07<10:33:11, 31.40s/it] 27%|██▋       | 454/1663 [3:56:37<10:25:31, 31.04s/it]                                                       {'loss': 0.54, 'learning_rate': 1.7060731188334715e-05, 'epoch': 0.27}
 27%|██▋       | 454/1663 [3:56:37<10:25:31, 31.04s/it] 27%|██▋       | 455/1663 [3:57:10<10:32:57, 31.44s/it]                                                       {'loss': 0.3876, 'learning_rate': 1.704692559116461e-05, 'epoch': 0.27}
 27%|██▋       | 455/1663 [3:57:10<10:32:57, 31.44s/it] 27%|██▋       | 456/1663 [3:57:41<10:31:26, 31.39s/it]                                                       {'loss': 0.4523, 'learning_rate': 1.7033093262049492e-05, 'epoch': 0.27}
 27%|██▋       | 456/1663 [3:57:41<10:31:26, 31.39s/it] 27%|██▋       | 457/1663 [3:58:16<10:52:26, 32.46s/it]                                                       {'loss': 0.4126, 'learning_rate': 1.7019234253461193e-05, 'epoch': 0.27}
 27%|██▋       | 457/1663 [3:58:16<10:52:26, 32.46s/it] 28%|██▊       | 458/1663 [3:58:47<10:41:57, 31.96s/it]                                                       {'loss': 0.4711, 'learning_rate': 1.700534861797274e-05, 'epoch': 0.28}
 28%|██▊       | 458/1663 [3:58:47<10:41:57, 31.96s/it] 28%|██▊       | 459/1663 [3:59:19<10:43:12, 32.05s/it]                                                       {'loss': 0.4299, 'learning_rate': 1.6991436408258178e-05, 'epoch': 0.28}
 28%|██▊       | 459/1663 [3:59:19<10:43:12, 32.05s/it] 28%|██▊       | 460/1663 [3:59:50<10:39:38, 31.90s/it]                                                       {'loss': 0.4412, 'learning_rate': 1.697749767709235e-05, 'epoch': 0.28}
 28%|██▊       | 460/1663 [3:59:50<10:39:38, 31.90s/it] 28%|██▊       | 461/1663 [4:00:22<10:34:00, 31.65s/it]                                                       {'loss': 0.4223, 'learning_rate': 1.6963532477350715e-05, 'epoch': 0.28}
 28%|██▊       | 461/1663 [4:00:22<10:34:00, 31.65s/it] 28%|██▊       | 462/1663 [4:00:52<10:23:34, 31.15s/it]                                                       {'loss': 0.3616, 'learning_rate': 1.694954086200913e-05, 'epoch': 0.28}
 28%|██▊       | 462/1663 [4:00:52<10:23:34, 31.15s/it] 28%|██▊       | 463/1663 [4:01:21<10:15:43, 30.79s/it]                                                       {'loss': 0.3649, 'learning_rate': 1.6935522884143667e-05, 'epoch': 0.28}
 28%|██▊       | 463/1663 [4:01:21<10:15:43, 30.79s/it] 28%|██▊       | 464/1663 [4:01:53<10:20:21, 31.04s/it]                                                       {'loss': 0.4657, 'learning_rate': 1.6921478596930393e-05, 'epoch': 0.28}
 28%|██▊       | 464/1663 [4:01:53<10:20:21, 31.04s/it] 28%|██▊       | 465/1663 [4:02:23<10:11:11, 30.61s/it]                                                       {'loss': 0.408, 'learning_rate': 1.6907408053645184e-05, 'epoch': 0.28}
 28%|██▊       | 465/1663 [4:02:23<10:11:11, 30.61s/it] 28%|██▊       | 466/1663 [4:02:56<10:28:25, 31.50s/it]                                                       {'loss': 0.3691, 'learning_rate': 1.6893311307663508e-05, 'epoch': 0.28}
 28%|██▊       | 466/1663 [4:02:56<10:28:25, 31.50s/it] 28%|██▊       | 467/1663 [4:03:27<10:21:41, 31.19s/it]                                                       {'loss': 0.4001, 'learning_rate': 1.687918841246024e-05, 'epoch': 0.28}
 28%|██▊       | 467/1663 [4:03:27<10:21:41, 31.19s/it] 28%|██▊       | 468/1663 [4:04:00<10:34:37, 31.86s/it]                                                       {'loss': 0.4159, 'learning_rate': 1.6865039421609445e-05, 'epoch': 0.28}
 28%|██▊       | 468/1663 [4:04:00<10:34:37, 31.86s/it] 28%|██▊       | 469/1663 [4:04:31<10:27:57, 31.56s/it]                                                       {'loss': 0.4219, 'learning_rate': 1.6850864388784186e-05, 'epoch': 0.28}
 28%|██▊       | 469/1663 [4:04:31<10:27:57, 31.56s/it] 28%|██▊       | 470/1663 [4:04:59<10:07:29, 30.55s/it]                                                       {'loss': 0.421, 'learning_rate': 1.68366633677563e-05, 'epoch': 0.28}
 28%|██▊       | 470/1663 [4:04:59<10:07:29, 30.55s/it] 28%|██▊       | 471/1663 [4:05:29<10:00:16, 30.22s/it]                                                       {'loss': 0.453, 'learning_rate': 1.6822436412396227e-05, 'epoch': 0.28}
 28%|██▊       | 471/1663 [4:05:29<10:00:16, 30.22s/it] 28%|██▊       | 472/1663 [4:06:00<10:07:53, 30.62s/it]                                                       {'loss': 0.4623, 'learning_rate': 1.6808183576672766e-05, 'epoch': 0.28}
 28%|██▊       | 472/1663 [4:06:00<10:07:53, 30.62s/it] 28%|██▊       | 473/1663 [4:06:32<10:16:01, 31.06s/it]                                                       {'loss': 0.4692, 'learning_rate': 1.679390491465291e-05, 'epoch': 0.28}
 28%|██▊       | 473/1663 [4:06:32<10:16:01, 31.06s/it] 29%|██▊       | 474/1663 [4:07:05<10:24:45, 31.53s/it]                                                       {'loss': 0.3673, 'learning_rate': 1.6779600480501616e-05, 'epoch': 0.28}
 29%|██▊       | 474/1663 [4:07:05<10:24:45, 31.53s/it] 29%|██▊       | 475/1663 [4:07:36<10:18:50, 31.25s/it]                                                       {'loss': 0.5596, 'learning_rate': 1.6765270328481594e-05, 'epoch': 0.29}
 29%|██▊       | 475/1663 [4:07:36<10:18:50, 31.25s/it] 29%|██▊       | 476/1663 [4:08:06<10:13:39, 31.02s/it]                                                       {'loss': 0.4527, 'learning_rate': 1.675091451295313e-05, 'epoch': 0.29}
 29%|██▊       | 476/1663 [4:08:06<10:13:39, 31.02s/it] 29%|██▊       | 477/1663 [4:08:41<10:37:56, 32.27s/it]                                                       {'loss': 0.3867, 'learning_rate': 1.6736533088373853e-05, 'epoch': 0.29}
 29%|██▊       | 477/1663 [4:08:41<10:37:56, 32.27s/it] 29%|██▊       | 478/1663 [4:09:13<10:34:02, 32.10s/it]                                                       {'loss': 0.4508, 'learning_rate': 1.672212610929854e-05, 'epoch': 0.29}
 29%|██▊       | 478/1663 [4:09:13<10:34:02, 32.10s/it] 29%|██▉       | 479/1663 [4:09:44<10:27:32, 31.80s/it]                                                       {'loss': 0.3368, 'learning_rate': 1.6707693630378904e-05, 'epoch': 0.29}
 29%|██▉       | 479/1663 [4:09:44<10:27:32, 31.80s/it] 29%|██▉       | 480/1663 [4:10:14<10:16:29, 31.27s/it]                                                       {'loss': 0.448, 'learning_rate': 1.6693235706363394e-05, 'epoch': 0.29}
 29%|██▉       | 480/1663 [4:10:14<10:16:29, 31.27s/it] 29%|██▉       | 481/1663 [4:10:46<10:18:48, 31.41s/it]                                                       {'loss': 0.3826, 'learning_rate': 1.6678752392096985e-05, 'epoch': 0.29}
 29%|██▉       | 481/1663 [4:10:46<10:18:48, 31.41s/it] 29%|██▉       | 482/1663 [4:11:14<9:59:38, 30.46s/it]                                                       {'loss': 0.5228, 'learning_rate': 1.6664243742520953e-05, 'epoch': 0.29}
 29%|██▉       | 482/1663 [4:11:14<9:59:38, 30.46s/it] 29%|██▉       | 483/1663 [4:11:45<10:00:03, 30.51s/it]                                                       {'loss': 0.4296, 'learning_rate': 1.6649709812672702e-05, 'epoch': 0.29}
 29%|██▉       | 483/1663 [4:11:45<10:00:03, 30.51s/it] 29%|██▉       | 484/1663 [4:12:16<10:06:44, 30.88s/it]                                                       {'loss': 0.4383, 'learning_rate': 1.6635150657685525e-05, 'epoch': 0.29}
 29%|██▉       | 484/1663 [4:12:16<10:06:44, 30.88s/it] 29%|██▉       | 485/1663 [4:12:43<9:41:48, 29.63s/it]                                                       {'loss': 0.5302, 'learning_rate': 1.6620566332788395e-05, 'epoch': 0.29}
 29%|██▉       | 485/1663 [4:12:43<9:41:48, 29.63s/it] 29%|██▉       | 486/1663 [4:13:14<9:49:10, 30.03s/it]                                                      {'loss': 0.3802, 'learning_rate': 1.6605956893305784e-05, 'epoch': 0.29}
 29%|██▉       | 486/1663 [4:13:14<9:49:10, 30.03s/it] 29%|██▉       | 487/1663 [4:13:45<9:50:59, 30.15s/it]                                                      {'loss': 0.4513, 'learning_rate': 1.6591322394657426e-05, 'epoch': 0.29}
 29%|██▉       | 487/1663 [4:13:45<9:50:59, 30.15s/it] 29%|██▉       | 488/1663 [4:14:15<9:52:28, 30.25s/it]                                                      {'loss': 0.4239, 'learning_rate': 1.6576662892358103e-05, 'epoch': 0.29}
 29%|██▉       | 488/1663 [4:14:15<9:52:28, 30.25s/it] 29%|██▉       | 489/1663 [4:14:46<9:55:13, 30.42s/it]                                                      {'loss': 0.4279, 'learning_rate': 1.6561978442017467e-05, 'epoch': 0.29}
 29%|██▉       | 489/1663 [4:14:46<9:55:13, 30.42s/it] 29%|██▉       | 490/1663 [4:15:19<10:08:08, 31.11s/it]                                                       {'loss': 0.4261, 'learning_rate': 1.6547269099339796e-05, 'epoch': 0.29}
 29%|██▉       | 490/1663 [4:15:19<10:08:08, 31.11s/it] 30%|██▉       | 491/1663 [4:15:53<10:28:48, 32.19s/it]                                                       {'loss': 0.5208, 'learning_rate': 1.6532534920123794e-05, 'epoch': 0.3}
 30%|██▉       | 491/1663 [4:15:53<10:28:48, 32.19s/it] 30%|██▉       | 492/1663 [4:16:25<10:23:30, 31.95s/it]                                                       {'loss': 0.4346, 'learning_rate': 1.6517775960262385e-05, 'epoch': 0.3}
 30%|██▉       | 492/1663 [4:16:25<10:23:30, 31.95s/it] 30%|██▉       | 493/1663 [4:16:54<10:05:56, 31.07s/it]                                                       {'loss': 0.4914, 'learning_rate': 1.65029922757425e-05, 'epoch': 0.3}
 30%|██▉       | 493/1663 [4:16:54<10:05:56, 31.07s/it] 30%|██▉       | 494/1663 [4:17:28<10:23:42, 32.01s/it]                                                       {'loss': 0.4104, 'learning_rate': 1.648818392264485e-05, 'epoch': 0.3}
 30%|██▉       | 494/1663 [4:17:28<10:23:42, 32.01s/it] 30%|██▉       | 495/1663 [4:18:01<10:31:04, 32.42s/it]                                                       {'loss': 0.453, 'learning_rate': 1.6473350957143734e-05, 'epoch': 0.3}
 30%|██▉       | 495/1663 [4:18:01<10:31:04, 32.42s/it] 30%|██▉       | 496/1663 [4:18:34<10:30:04, 32.39s/it]                                                       {'loss': 0.4252, 'learning_rate': 1.6458493435506814e-05, 'epoch': 0.3}
 30%|██▉       | 496/1663 [4:18:34<10:30:04, 32.39s/it] 30%|██▉       | 497/1663 [4:19:03<10:11:08, 31.45s/it]                                                       {'loss': 0.4385, 'learning_rate': 1.64436114140949e-05, 'epoch': 0.3}
 30%|██▉       | 497/1663 [4:19:03<10:11:08, 31.45s/it] 30%|██▉       | 498/1663 [4:19:33<10:00:55, 30.95s/it]                                                       {'loss': 0.3697, 'learning_rate': 1.642870494936174e-05, 'epoch': 0.3}
 30%|██▉       | 498/1663 [4:19:33<10:00:55, 30.95s/it] 30%|███       | 499/1663 [4:20:06<10:12:30, 31.57s/it]                                                       {'loss': 0.4148, 'learning_rate': 1.641377409785381e-05, 'epoch': 0.3}
 30%|███       | 499/1663 [4:20:06<10:12:30, 31.57s/it] 30%|███       | 500/1663 [4:20:34<9:52:49, 30.58s/it]                                                       {'loss': 0.5242, 'learning_rate': 1.63988189162101e-05, 'epoch': 0.3}
 30%|███       | 500/1663 [4:20:34<9:52:49, 30.58s/it] 30%|███       | 501/1663 [4:21:05<9:56:29, 30.80s/it]                                                      {'loss': 0.3368, 'learning_rate': 1.6383839461161878e-05, 'epoch': 0.3}
 30%|███       | 501/1663 [4:21:05<9:56:29, 30.80s/it] 30%|███       | 502/1663 [4:21:40<10:18:51, 31.98s/it]                                                       {'loss': 0.3572, 'learning_rate': 1.6368835789532506e-05, 'epoch': 0.3}
 30%|███       | 502/1663 [4:21:40<10:18:51, 31.98s/it] 30%|███       | 503/1663 [4:22:10<10:06:09, 31.35s/it]                                                       {'loss': 0.5101, 'learning_rate': 1.63538079582372e-05, 'epoch': 0.3}
 30%|███       | 503/1663 [4:22:10<10:06:09, 31.35s/it] 30%|███       | 504/1663 [4:22:42<10:09:09, 31.54s/it]                                                       {'loss': 0.424, 'learning_rate': 1.633875602428284e-05, 'epoch': 0.3}
 30%|███       | 504/1663 [4:22:42<10:09:09, 31.54s/it] 30%|███       | 505/1663 [4:23:13<10:08:08, 31.51s/it]                                                       {'loss': 0.4373, 'learning_rate': 1.632368004476771e-05, 'epoch': 0.3}
 30%|███       | 505/1663 [4:23:13<10:08:08, 31.51s/it] 30%|███       | 506/1663 [4:23:43<9:57:32, 30.99s/it]                                                       {'loss': 0.6268, 'learning_rate': 1.630858007688134e-05, 'epoch': 0.3}
 30%|███       | 506/1663 [4:23:43<9:57:32, 30.99s/it] 30%|███       | 507/1663 [4:24:14<9:57:32, 31.01s/it]                                                      {'loss': 0.4028, 'learning_rate': 1.6293456177904233e-05, 'epoch': 0.3}
 30%|███       | 507/1663 [4:24:14<9:57:32, 31.01s/it] 31%|███       | 508/1663 [4:24:46<10:00:55, 31.22s/it]                                                       {'loss': 0.4937, 'learning_rate': 1.6278308405207682e-05, 'epoch': 0.31}
 31%|███       | 508/1663 [4:24:46<10:00:55, 31.22s/it] 31%|███       | 509/1663 [4:25:16<9:55:38, 30.97s/it]                                                       {'loss': 0.4251, 'learning_rate': 1.626313681625355e-05, 'epoch': 0.31}
 31%|███       | 509/1663 [4:25:16<9:55:38, 30.97s/it] 31%|███       | 510/1663 [4:25:48<9:59:18, 31.19s/it]                                                      {'loss': 0.4443, 'learning_rate': 1.6247941468594035e-05, 'epoch': 0.31}
 31%|███       | 510/1663 [4:25:48<9:59:18, 31.19s/it] 31%|███       | 511/1663 [4:26:18<9:52:44, 30.87s/it]                                                      {'loss': 0.5137, 'learning_rate': 1.6232722419871465e-05, 'epoch': 0.31}
 31%|███       | 511/1663 [4:26:18<9:52:44, 30.87s/it] 31%|███       | 512/1663 [4:26:48<9:46:44, 30.59s/it]                                                      {'loss': 0.454, 'learning_rate': 1.6217479727818075e-05, 'epoch': 0.31}
 31%|███       | 512/1663 [4:26:48<9:46:44, 30.59s/it] 31%|███       | 513/1663 [4:27:16<9:31:35, 29.82s/it]                                                      {'loss': 0.3092, 'learning_rate': 1.6202213450255794e-05, 'epoch': 0.31}
 31%|███       | 513/1663 [4:27:16<9:31:35, 29.82s/it] 31%|███       | 514/1663 [4:27:52<10:08:05, 31.75s/it]                                                       {'loss': 0.3397, 'learning_rate': 1.6186923645096012e-05, 'epoch': 0.31}
 31%|███       | 514/1663 [4:27:52<10:08:05, 31.75s/it] 31%|███       | 515/1663 [4:28:25<10:15:13, 32.15s/it]                                                       {'loss': 0.431, 'learning_rate': 1.6171610370339383e-05, 'epoch': 0.31}
 31%|███       | 515/1663 [4:28:25<10:15:13, 32.15s/it] 31%|███       | 516/1663 [4:28:55<10:03:12, 31.55s/it]                                                       {'loss': 0.4116, 'learning_rate': 1.615627368407557e-05, 'epoch': 0.31}
 31%|███       | 516/1663 [4:28:55<10:03:12, 31.55s/it] 31%|███       | 517/1663 [4:29:30<10:22:22, 32.59s/it]                                                       {'loss': 0.3581, 'learning_rate': 1.614091364448307e-05, 'epoch': 0.31}
 31%|███       | 517/1663 [4:29:30<10:22:22, 32.59s/it] 31%|███       | 518/1663 [4:30:01<10:07:45, 31.85s/it]                                                       {'loss': 0.4092, 'learning_rate': 1.6125530309828947e-05, 'epoch': 0.31}
 31%|███       | 518/1663 [4:30:01<10:07:45, 31.85s/it] 31%|███       | 519/1663 [4:30:30<9:51:23, 31.02s/it]                                                       {'loss': 0.4588, 'learning_rate': 1.611012373846865e-05, 'epoch': 0.31}
 31%|███       | 519/1663 [4:30:30<9:51:23, 31.02s/it] 31%|███▏      | 520/1663 [4:31:03<10:04:47, 31.75s/it]                                                       {'loss': 0.4145, 'learning_rate': 1.609469398884576e-05, 'epoch': 0.31}
 31%|███▏      | 520/1663 [4:31:03<10:04:47, 31.75s/it] 31%|███▏      | 521/1663 [4:31:37<10:16:17, 32.38s/it]                                                       {'loss': 0.422, 'learning_rate': 1.6079241119491797e-05, 'epoch': 0.31}
 31%|███▏      | 521/1663 [4:31:37<10:16:17, 32.38s/it] 31%|███▏      | 522/1663 [4:32:07<10:00:04, 31.56s/it]                                                       {'loss': 0.5295, 'learning_rate': 1.6063765189025974e-05, 'epoch': 0.31}
 31%|███▏      | 522/1663 [4:32:07<10:00:04, 31.56s/it] 31%|███▏      | 523/1663 [4:32:39<10:01:32, 31.66s/it]                                                       {'loss': 0.4584, 'learning_rate': 1.604826625615499e-05, 'epoch': 0.31}
 31%|███▏      | 523/1663 [4:32:39<10:01:32, 31.66s/it] 32%|███▏      | 524/1663 [4:33:08<9:51:23, 31.15s/it]                                                       {'loss': 0.4318, 'learning_rate': 1.6032744379672798e-05, 'epoch': 0.31}
 32%|███▏      | 524/1663 [4:33:08<9:51:23, 31.15s/it] 32%|███▏      | 525/1663 [4:33:39<9:49:09, 31.06s/it]                                                      {'loss': 0.3841, 'learning_rate': 1.6017199618460385e-05, 'epoch': 0.32}
 32%|███▏      | 525/1663 [4:33:39<9:49:09, 31.06s/it] 32%|███▏      | 526/1663 [4:34:12<9:55:01, 31.40s/it]                                                      {'loss': 0.3562, 'learning_rate': 1.6001632031485553e-05, 'epoch': 0.32}
 32%|███▏      | 526/1663 [4:34:12<9:55:01, 31.40s/it] 32%|███▏      | 527/1663 [4:34:41<9:45:07, 30.90s/it]                                                      {'loss': 0.4303, 'learning_rate': 1.5986041677802688e-05, 'epoch': 0.32}
 32%|███▏      | 527/1663 [4:34:41<9:45:07, 30.90s/it] 32%|███▏      | 528/1663 [4:35:13<9:48:40, 31.12s/it]                                                      {'loss': 0.4437, 'learning_rate': 1.597042861655255e-05, 'epoch': 0.32}
 32%|███▏      | 528/1663 [4:35:13<9:48:40, 31.12s/it] 32%|███▏      | 529/1663 [4:35:45<9:52:02, 31.33s/it]                                                      {'loss': 0.4547, 'learning_rate': 1.595479290696202e-05, 'epoch': 0.32}
 32%|███▏      | 529/1663 [4:35:45<9:52:02, 31.33s/it] 32%|███▏      | 530/1663 [4:36:14<9:39:50, 30.71s/it]                                                      {'loss': 0.4541, 'learning_rate': 1.5939134608343905e-05, 'epoch': 0.32}
 32%|███▏      | 530/1663 [4:36:14<9:39:50, 30.71s/it] 32%|███▏      | 531/1663 [4:36:41<9:20:35, 29.71s/it]                                                      {'loss': 0.3911, 'learning_rate': 1.5923453780096706e-05, 'epoch': 0.32}
 32%|███▏      | 531/1663 [4:36:41<9:20:35, 29.71s/it] 32%|███▏      | 532/1663 [4:37:16<9:47:24, 31.16s/it]                                                      {'loss': 0.4898, 'learning_rate': 1.590775048170438e-05, 'epoch': 0.32}
 32%|███▏      | 532/1663 [4:37:16<9:47:24, 31.16s/it] 32%|███▏      | 533/1663 [4:37:48<9:54:26, 31.56s/it]                                                      {'loss': 0.4625, 'learning_rate': 1.589202477273613e-05, 'epoch': 0.32}
 32%|███▏      | 533/1663 [4:37:48<9:54:26, 31.56s/it] 32%|███▏      | 534/1663 [4:38:20<9:55:15, 31.63s/it]                                                      {'loss': 0.4046, 'learning_rate': 1.5876276712846157e-05, 'epoch': 0.32}
 32%|███▏      | 534/1663 [4:38:20<9:55:15, 31.63s/it] 32%|███▏      | 535/1663 [4:38:51<9:52:35, 31.52s/it]                                                      {'loss': 0.4658, 'learning_rate': 1.5860506361773465e-05, 'epoch': 0.32}
 32%|███▏      | 535/1663 [4:38:51<9:52:35, 31.52s/it] 32%|███▏      | 536/1663 [4:39:24<9:56:49, 31.77s/it]                                                      {'loss': 0.4567, 'learning_rate': 1.584471377934161e-05, 'epoch': 0.32}
 32%|███▏      | 536/1663 [4:39:24<9:56:49, 31.77s/it] 32%|███▏      | 537/1663 [4:39:57<10:05:13, 32.25s/it]                                                       {'loss': 0.3733, 'learning_rate': 1.5828899025458487e-05, 'epoch': 0.32}
 32%|███▏      | 537/1663 [4:39:57<10:05:13, 32.25s/it] 32%|███▏      | 538/1663 [4:40:26<9:44:25, 31.17s/it]                                                       {'loss': 0.4998, 'learning_rate': 1.5813062160116087e-05, 'epoch': 0.32}
 32%|███▏      | 538/1663 [4:40:26<9:44:25, 31.17s/it] 32%|███▏      | 539/1663 [4:40:58<9:50:38, 31.53s/it]                                                      {'loss': 0.4165, 'learning_rate': 1.5797203243390282e-05, 'epoch': 0.32}
 32%|███▏      | 539/1663 [4:40:58<9:50:38, 31.53s/it] 32%|███▏      | 540/1663 [4:41:33<10:09:01, 32.54s/it]                                                       {'loss': 0.4078, 'learning_rate': 1.57813223354406e-05, 'epoch': 0.32}
 32%|███▏      | 540/1663 [4:41:33<10:09:01, 32.54s/it] 33%|███▎      | 541/1663 [4:42:04<9:59:12, 32.04s/it]                                                       {'loss': 0.3884, 'learning_rate': 1.5765419496509987e-05, 'epoch': 0.33}
 33%|███▎      | 541/1663 [4:42:04<9:59:12, 32.04s/it] 33%|███▎      | 542/1663 [4:42:38<10:11:41, 32.74s/it]                                                       {'loss': 0.3973, 'learning_rate': 1.574949478692458e-05, 'epoch': 0.33}
 33%|███▎      | 542/1663 [4:42:38<10:11:41, 32.74s/it] 33%|███▎      | 543/1663 [4:43:09<10:01:58, 32.25s/it]                                                       {'loss': 0.3878, 'learning_rate': 1.573354826709349e-05, 'epoch': 0.33}
 33%|███▎      | 543/1663 [4:43:09<10:01:58, 32.25s/it] 33%|███▎      | 544/1663 [4:43:40<9:50:26, 31.66s/it]                                                       {'loss': 0.4604, 'learning_rate': 1.5717579997508546e-05, 'epoch': 0.33}
 33%|███▎      | 544/1663 [4:43:40<9:50:26, 31.66s/it] 33%|███▎      | 545/1663 [4:44:10<9:44:35, 31.37s/it]                                                      {'loss': 0.5317, 'learning_rate': 1.57015900387441e-05, 'epoch': 0.33}
 33%|███▎      | 545/1663 [4:44:10<9:44:35, 31.37s/it] 33%|███▎      | 546/1663 [4:44:40<9:33:08, 30.79s/it]                                                      {'loss': 0.4072, 'learning_rate': 1.5685578451456768e-05, 'epoch': 0.33}
 33%|███▎      | 546/1663 [4:44:40<9:33:08, 30.79s/it] 33%|███▎      | 547/1663 [4:45:12<9:41:44, 31.28s/it]                                                      {'loss': 0.4519, 'learning_rate': 1.5669545296385223e-05, 'epoch': 0.33}
 33%|███▎      | 547/1663 [4:45:12<9:41:44, 31.28s/it] 33%|███▎      | 548/1663 [4:45:46<9:52:36, 31.89s/it]                                                      {'loss': 0.4212, 'learning_rate': 1.5653490634349945e-05, 'epoch': 0.33}
 33%|███▎      | 548/1663 [4:45:46<9:52:36, 31.89s/it] 33%|███▎      | 549/1663 [4:46:17<9:51:27, 31.86s/it]                                                      {'loss': 0.5333, 'learning_rate': 1.5637414526253007e-05, 'epoch': 0.33}
 33%|███▎      | 549/1663 [4:46:17<9:51:27, 31.86s/it] 33%|███▎      | 550/1663 [4:46:52<10:04:17, 32.58s/it]                                                       {'loss': 0.4465, 'learning_rate': 1.5621317033077828e-05, 'epoch': 0.33}
 33%|███▎      | 550/1663 [4:46:52<10:04:17, 32.58s/it] 33%|███▎      | 551/1663 [4:47:24<10:02:09, 32.49s/it]                                                       {'loss': 0.3657, 'learning_rate': 1.560519821588895e-05, 'epoch': 0.33}
 33%|███▎      | 551/1663 [4:47:24<10:02:09, 32.49s/it] 33%|███▎      | 552/1663 [4:47:54<9:47:13, 31.71s/it]                                                       {'loss': 0.4233, 'learning_rate': 1.5589058135831814e-05, 'epoch': 0.33}
 33%|███▎      | 552/1663 [4:47:54<9:47:13, 31.71s/it] 33%|███▎      | 553/1663 [4:48:25<9:41:10, 31.41s/it]                                                      {'loss': 0.4143, 'learning_rate': 1.557289685413251e-05, 'epoch': 0.33}
 33%|███▎      | 553/1663 [4:48:25<9:41:10, 31.41s/it] 33%|███▎      | 554/1663 [4:48:54<9:31:06, 30.90s/it]                                                      {'loss': 0.4675, 'learning_rate': 1.555671443209756e-05, 'epoch': 0.33}
 33%|███▎      | 554/1663 [4:48:54<9:31:06, 30.90s/it] 33%|███▎      | 555/1663 [4:49:26<9:35:35, 31.17s/it]                                                      {'loss': 0.4087, 'learning_rate': 1.554051093111368e-05, 'epoch': 0.33}
 33%|███▎      | 555/1663 [4:49:26<9:35:35, 31.17s/it] 33%|███▎      | 556/1663 [4:49:57<9:34:19, 31.13s/it]                                                      {'loss': 0.4042, 'learning_rate': 1.5524286412647548e-05, 'epoch': 0.33}
 33%|███▎      | 556/1663 [4:49:57<9:34:19, 31.13s/it] 33%|███▎      | 557/1663 [4:50:30<9:43:07, 31.63s/it]                                                      {'loss': 0.5666, 'learning_rate': 1.550804093824557e-05, 'epoch': 0.33}
 33%|███▎      | 557/1663 [4:50:30<9:43:07, 31.63s/it] 34%|███▎      | 558/1663 [4:51:00<9:32:35, 31.09s/it]                                                      {'loss': 0.4546, 'learning_rate': 1.549177456953364e-05, 'epoch': 0.34}
 34%|███▎      | 558/1663 [4:51:00<9:32:35, 31.09s/it] 34%|███▎      | 559/1663 [4:51:33<9:43:22, 31.71s/it]                                                      {'loss': 0.4406, 'learning_rate': 1.5475487368216924e-05, 'epoch': 0.34}
 34%|███▎      | 559/1663 [4:51:33<9:43:22, 31.71s/it] 34%|███▎      | 560/1663 [4:52:04<9:39:16, 31.51s/it]                                                      {'loss': 0.3972, 'learning_rate': 1.5459179396079608e-05, 'epoch': 0.34}
 34%|███▎      | 560/1663 [4:52:04<9:39:16, 31.51s/it] 34%|███▎      | 561/1663 [4:52:39<9:56:12, 32.46s/it]                                                      {'loss': 0.4976, 'learning_rate': 1.544285071498467e-05, 'epoch': 0.34}
 34%|███▎      | 561/1663 [4:52:39<9:56:12, 32.46s/it] 34%|███▍      | 562/1663 [4:53:09<9:42:39, 31.75s/it]                                                      {'loss': 0.4439, 'learning_rate': 1.5426501386873644e-05, 'epoch': 0.34}
 34%|███▍      | 562/1663 [4:53:09<9:42:39, 31.75s/it] 34%|███▍      | 563/1663 [4:53:41<9:46:14, 31.98s/it]                                                      {'loss': 0.3692, 'learning_rate': 1.54101314737664e-05, 'epoch': 0.34}
 34%|███▍      | 563/1663 [4:53:41<9:46:14, 31.98s/it] 34%|███▍      | 564/1663 [4:54:12<9:40:03, 31.67s/it]                                                      {'loss': 0.5159, 'learning_rate': 1.5393741037760875e-05, 'epoch': 0.34}
 34%|███▍      | 564/1663 [4:54:12<9:40:03, 31.67s/it] 34%|███▍      | 565/1663 [4:54:43<9:36:23, 31.50s/it]                                                      {'loss': 0.452, 'learning_rate': 1.5377330141032874e-05, 'epoch': 0.34}
 34%|███▍      | 565/1663 [4:54:43<9:36:23, 31.50s/it] 34%|███▍      | 566/1663 [4:55:12<9:22:03, 30.74s/it]                                                      {'loss': 0.535, 'learning_rate': 1.5360898845835817e-05, 'epoch': 0.34}
 34%|███▍      | 566/1663 [4:55:12<9:22:03, 30.74s/it] 34%|███▍      | 567/1663 [4:55:43<9:24:33, 30.91s/it]                                                      {'loss': 0.5166, 'learning_rate': 1.534444721450049e-05, 'epoch': 0.34}
 34%|███▍      | 567/1663 [4:55:43<9:24:33, 30.91s/it] 34%|███▍      | 568/1663 [4:56:14<9:22:16, 30.81s/it]                                                      {'loss': 0.507, 'learning_rate': 1.5327975309434842e-05, 'epoch': 0.34}
 34%|███▍      | 568/1663 [4:56:14<9:22:16, 30.81s/it] 34%|███▍      | 569/1663 [4:56:44<9:18:09, 30.61s/it]                                                      {'loss': 0.3029, 'learning_rate': 1.5311483193123713e-05, 'epoch': 0.34}
 34%|███▍      | 569/1663 [4:56:44<9:18:09, 30.61s/it] 34%|███▍      | 570/1663 [4:57:20<9:44:10, 32.07s/it]                                                      {'loss': 0.467, 'learning_rate': 1.529497092812862e-05, 'epoch': 0.34}
 34%|███▍      | 570/1663 [4:57:20<9:44:10, 32.07s/it] 34%|███▍      | 571/1663 [4:57:51<9:40:48, 31.91s/it]                                                      {'loss': 0.4249, 'learning_rate': 1.527843857708751e-05, 'epoch': 0.34}
 34%|███▍      | 571/1663 [4:57:51<9:40:48, 31.91s/it] 34%|███▍      | 572/1663 [4:58:22<9:32:59, 31.51s/it]                                                      {'loss': 0.4666, 'learning_rate': 1.5261886202714533e-05, 'epoch': 0.34}
 34%|███▍      | 572/1663 [4:58:22<9:32:59, 31.51s/it] 34%|███▍      | 573/1663 [4:58:51<9:21:21, 30.90s/it]                                                      {'loss': 0.3768, 'learning_rate': 1.5245313867799776e-05, 'epoch': 0.34}
 34%|███▍      | 573/1663 [4:58:51<9:21:21, 30.90s/it] 35%|███▍      | 574/1663 [4:59:26<9:39:25, 31.92s/it]                                                      {'loss': 0.3656, 'learning_rate': 1.522872163520907e-05, 'epoch': 0.35}
 35%|███▍      | 574/1663 [4:59:26<9:39:25, 31.92s/it] 35%|███▍      | 575/1663 [4:59:56<9:32:50, 31.59s/it]                                                      {'loss': 0.3882, 'learning_rate': 1.5212109567883706e-05, 'epoch': 0.35}
 35%|███▍      | 575/1663 [4:59:56<9:32:50, 31.59s/it] 35%|███▍      | 576/1663 [5:00:26<9:23:21, 31.10s/it]                                                      {'loss': 0.4349, 'learning_rate': 1.5195477728840229e-05, 'epoch': 0.35}
 35%|███▍      | 576/1663 [5:00:26<9:23:21, 31.10s/it] 35%|███▍      | 577/1663 [5:00:55<9:07:18, 30.24s/it]                                                      {'loss': 0.6345, 'learning_rate': 1.5178826181170178e-05, 'epoch': 0.35}
 35%|███▍      | 577/1663 [5:00:55<9:07:18, 30.24s/it] 35%|███▍      | 578/1663 [5:01:26<9:14:53, 30.68s/it]                                                      {'loss': 0.4726, 'learning_rate': 1.5162154988039861e-05, 'epoch': 0.35}
 35%|███▍      | 578/1663 [5:01:26<9:14:53, 30.68s/it] 35%|███▍      | 579/1663 [5:01:58<9:18:48, 30.93s/it]                                                      {'loss': 0.5045, 'learning_rate': 1.5145464212690106e-05, 'epoch': 0.35}
 35%|███▍      | 579/1663 [5:01:58<9:18:48, 30.93s/it] 35%|███▍      | 580/1663 [5:02:29<9:21:44, 31.12s/it]                                                      {'loss': 0.4431, 'learning_rate': 1.5128753918436027e-05, 'epoch': 0.35}
 35%|███▍      | 580/1663 [5:02:29<9:21:44, 31.12s/it] 35%|███▍      | 581/1663 [5:03:02<9:26:51, 31.43s/it]                                                      {'loss': 0.3462, 'learning_rate': 1.5112024168666782e-05, 'epoch': 0.35}
 35%|███▍      | 581/1663 [5:03:02<9:26:51, 31.43s/it] 35%|███▍      | 582/1663 [5:03:33<9:24:19, 31.32s/it]                                                      {'loss': 0.4356, 'learning_rate': 1.5095275026845324e-05, 'epoch': 0.35}
 35%|███▍      | 582/1663 [5:03:33<9:24:19, 31.32s/it] 35%|███▌      | 583/1663 [5:04:08<9:46:43, 32.60s/it]                                                      {'loss': 0.4456, 'learning_rate': 1.507850655650818e-05, 'epoch': 0.35}
 35%|███▌      | 583/1663 [5:04:08<9:46:43, 32.60s/it] 35%|███▌      | 584/1663 [5:04:38<9:29:19, 31.66s/it]                                                      {'loss': 0.4411, 'learning_rate': 1.506171882126519e-05, 'epoch': 0.35}
 35%|███▌      | 584/1663 [5:04:38<9:29:19, 31.66s/it] 35%|███▌      | 585/1663 [5:05:11<9:39:47, 32.27s/it]                                                      {'loss': 0.5192, 'learning_rate': 1.5044911884799276e-05, 'epoch': 0.35}
 35%|███▌      | 585/1663 [5:05:11<9:39:47, 32.27s/it] 35%|███▌      | 586/1663 [5:05:42<9:32:13, 31.88s/it]                                                      {'loss': 0.435, 'learning_rate': 1.5028085810866202e-05, 'epoch': 0.35}
 35%|███▌      | 586/1663 [5:05:42<9:32:13, 31.88s/it] 35%|███▌      | 587/1663 [5:06:12<9:22:24, 31.36s/it]                                                      {'loss': 0.4717, 'learning_rate': 1.5011240663294322e-05, 'epoch': 0.35}
 35%|███▌      | 587/1663 [5:06:12<9:22:24, 31.36s/it] 35%|███▌      | 588/1663 [5:06:42<9:12:50, 30.86s/it]                                                      {'loss': 0.4219, 'learning_rate': 1.4994376505984348e-05, 'epoch': 0.35}
 35%|███▌      | 588/1663 [5:06:42<9:12:50, 30.86s/it] 35%|███▌      | 589/1663 [5:07:11<9:04:14, 30.40s/it]                                                      {'loss': 0.3961, 'learning_rate': 1.4977493402909105e-05, 'epoch': 0.35}
 35%|███▌      | 589/1663 [5:07:12<9:04:14, 30.40s/it] 35%|███▌      | 590/1663 [5:07:43<9:07:46, 30.63s/it]                                                      {'loss': 0.5096, 'learning_rate': 1.4960591418113282e-05, 'epoch': 0.35}
 35%|███▌      | 590/1663 [5:07:43<9:07:46, 30.63s/it] 36%|███▌      | 591/1663 [5:08:13<9:04:57, 30.50s/it]                                                      {'loss': 0.3514, 'learning_rate': 1.49436706157132e-05, 'epoch': 0.36}
 36%|███▌      | 591/1663 [5:08:13<9:04:57, 30.50s/it] 36%|███▌      | 592/1663 [5:08:44<9:09:43, 30.80s/it]                                                      {'loss': 0.4178, 'learning_rate': 1.4926731059896561e-05, 'epoch': 0.36}
 36%|███▌      | 592/1663 [5:08:44<9:09:43, 30.80s/it] 36%|███▌      | 593/1663 [5:09:15<9:11:02, 30.90s/it]                                                      {'loss': 0.4923, 'learning_rate': 1.4909772814922207e-05, 'epoch': 0.36}
 36%|███▌      | 593/1663 [5:09:15<9:11:02, 30.90s/it] 36%|███▌      | 594/1663 [5:09:45<9:05:40, 30.63s/it]                                                      {'loss': 0.5075, 'learning_rate': 1.4892795945119876e-05, 'epoch': 0.36}
 36%|███▌      | 594/1663 [5:09:45<9:05:40, 30.63s/it] 36%|███▌      | 595/1663 [5:10:17<9:08:54, 30.84s/it]                                                      {'loss': 0.3392, 'learning_rate': 1.4875800514889955e-05, 'epoch': 0.36}
 36%|███▌      | 595/1663 [5:10:17<9:08:54, 30.84s/it] 36%|███▌      | 596/1663 [5:10:49<9:14:45, 31.20s/it]                                                      {'loss': 0.4637, 'learning_rate': 1.485878658870324e-05, 'epoch': 0.36}
 36%|███▌      | 596/1663 [5:10:49<9:14:45, 31.20s/it] 36%|███▌      | 597/1663 [5:11:19<9:06:58, 30.79s/it]                                                      {'loss': 0.4116, 'learning_rate': 1.4841754231100693e-05, 'epoch': 0.36}
 36%|███▌      | 597/1663 [5:11:19<9:06:58, 30.79s/it] 36%|███▌      | 598/1663 [5:11:53<9:25:59, 31.89s/it]                                                      {'loss': 0.4477, 'learning_rate': 1.4824703506693192e-05, 'epoch': 0.36}
 36%|███▌      | 598/1663 [5:11:53<9:25:59, 31.89s/it] 36%|███▌      | 599/1663 [5:12:27<9:38:14, 32.61s/it]                                                      {'loss': 0.4468, 'learning_rate': 1.4807634480161284e-05, 'epoch': 0.36}
 36%|███▌      | 599/1663 [5:12:27<9:38:14, 32.61s/it] 36%|███▌      | 600/1663 [5:12:57<9:23:02, 31.78s/it]                                                      {'loss': 0.4635, 'learning_rate': 1.4790547216254952e-05, 'epoch': 0.36}
 36%|███▌      | 600/1663 [5:12:57<9:23:02, 31.78s/it] 36%|███▌      | 601/1663 [5:13:32<9:40:41, 32.81s/it]                                                      {'loss': 0.4705, 'learning_rate': 1.477344177979335e-05, 'epoch': 0.36}
 36%|███▌      | 601/1663 [5:13:32<9:40:41, 32.81s/it] 36%|███▌      | 602/1663 [5:14:04<9:31:52, 32.34s/it]                                                      {'loss': 0.3572, 'learning_rate': 1.475631823566458e-05, 'epoch': 0.36}
 36%|███▌      | 602/1663 [5:14:04<9:31:52, 32.34s/it] 36%|███▋      | 603/1663 [5:14:36<9:28:28, 32.18s/it]                                                      {'loss': 0.4706, 'learning_rate': 1.4739176648825425e-05, 'epoch': 0.36}
 36%|███▋      | 603/1663 [5:14:36<9:28:28, 32.18s/it] 36%|███▋      | 604/1663 [5:15:05<9:13:08, 31.34s/it]                                                      {'loss': 0.4518, 'learning_rate': 1.4722017084301117e-05, 'epoch': 0.36}
 36%|███▋      | 604/1663 [5:15:05<9:13:08, 31.34s/it] 36%|███▋      | 605/1663 [5:15:35<9:08:33, 31.11s/it]                                                      {'loss': 0.4609, 'learning_rate': 1.4704839607185084e-05, 'epoch': 0.36}
 36%|███▋      | 605/1663 [5:15:35<9:08:33, 31.11s/it] 36%|███▋      | 606/1663 [5:16:06<9:04:00, 30.88s/it]                                                      {'loss': 0.4616, 'learning_rate': 1.4687644282638698e-05, 'epoch': 0.36}
 36%|███▋      | 606/1663 [5:16:06<9:04:00, 30.88s/it] 37%|███▋      | 607/1663 [5:16:37<9:04:17, 30.93s/it]                                                      {'loss': 0.5036, 'learning_rate': 1.4670431175891043e-05, 'epoch': 0.36}
 37%|███▋      | 607/1663 [5:16:37<9:04:17, 30.93s/it] 37%|███▋      | 608/1663 [5:17:10<9:13:33, 31.48s/it]                                                      {'loss': 0.462, 'learning_rate': 1.4653200352238652e-05, 'epoch': 0.37}
 37%|███▋      | 608/1663 [5:17:10<9:13:33, 31.48s/it] 37%|███▋      | 609/1663 [5:17:43<9:23:29, 32.08s/it]                                                      {'loss': 0.3556, 'learning_rate': 1.4635951877045269e-05, 'epoch': 0.37}
 37%|███▋      | 609/1663 [5:17:43<9:23:29, 32.08s/it] 37%|███▋      | 610/1663 [5:18:13<9:12:25, 31.48s/it]                                                      {'loss': 0.3549, 'learning_rate': 1.4618685815741595e-05, 'epoch': 0.37}
 37%|███▋      | 610/1663 [5:18:13<9:12:25, 31.48s/it] 37%|███▋      | 611/1663 [5:18:44<9:09:04, 31.32s/it]                                                      {'loss': 0.3875, 'learning_rate': 1.4601402233825042e-05, 'epoch': 0.37}
 37%|███▋      | 611/1663 [5:18:44<9:09:04, 31.32s/it] 37%|███▋      | 612/1663 [5:19:15<9:04:47, 31.10s/it]                                                      {'loss': 0.3881, 'learning_rate': 1.458410119685949e-05, 'epoch': 0.37}
 37%|███▋      | 612/1663 [5:19:15<9:04:47, 31.10s/it] 37%|███▋      | 613/1663 [5:19:45<8:57:58, 30.74s/it]                                                      {'loss': 0.4961, 'learning_rate': 1.456678277047503e-05, 'epoch': 0.37}
 37%|███▋      | 613/1663 [5:19:45<8:57:58, 30.74s/it] 37%|███▋      | 614/1663 [5:20:17<9:07:42, 31.33s/it]                                                      {'loss': 0.4494, 'learning_rate': 1.4549447020367717e-05, 'epoch': 0.37}
 37%|███▋      | 614/1663 [5:20:17<9:07:42, 31.33s/it] 37%|███▋      | 615/1663 [5:20:50<9:16:14, 31.85s/it]                                                      {'loss': 0.386, 'learning_rate': 1.4532094012299325e-05, 'epoch': 0.37}
 37%|███▋      | 615/1663 [5:20:50<9:16:14, 31.85s/it] 37%|███▋      | 616/1663 [5:21:21<9:07:16, 31.36s/it]                                                      {'loss': 0.485, 'learning_rate': 1.4514723812097092e-05, 'epoch': 0.37}
 37%|███▋      | 616/1663 [5:21:21<9:07:16, 31.36s/it] 37%|███▋      | 617/1663 [5:21:54<9:16:16, 31.91s/it]                                                      {'loss': 0.4525, 'learning_rate': 1.4497336485653473e-05, 'epoch': 0.37}
 37%|███▋      | 617/1663 [5:21:54<9:16:16, 31.91s/it] 37%|███▋      | 618/1663 [5:22:27<9:22:08, 32.28s/it]                                                      {'loss': 0.4355, 'learning_rate': 1.4479932098925895e-05, 'epoch': 0.37}
 37%|███▋      | 618/1663 [5:22:27<9:22:08, 32.28s/it] 37%|███▋      | 619/1663 [5:22:56<9:03:35, 31.24s/it]                                                      {'loss': 0.403, 'learning_rate': 1.4462510717936495e-05, 'epoch': 0.37}
 37%|███▋      | 619/1663 [5:22:56<9:03:35, 31.24s/it] 37%|███▋      | 620/1663 [5:23:27<9:03:47, 31.28s/it]                                                      {'loss': 0.4292, 'learning_rate': 1.4445072408771883e-05, 'epoch': 0.37}
 37%|███▋      | 620/1663 [5:23:27<9:03:47, 31.28s/it] 37%|███▋      | 621/1663 [5:23:54<8:40:24, 29.97s/it]                                                      {'loss': 0.4413, 'learning_rate': 1.4427617237582878e-05, 'epoch': 0.37}
 37%|███▋      | 621/1663 [5:23:54<8:40:24, 29.97s/it] 37%|███▋      | 622/1663 [5:24:25<8:44:34, 30.24s/it]                                                      {'loss': 0.4887, 'learning_rate': 1.4410145270584268e-05, 'epoch': 0.37}
 37%|███▋      | 622/1663 [5:24:25<8:44:34, 30.24s/it] 37%|███▋      | 623/1663 [5:24:55<8:45:31, 30.32s/it]                                                      {'loss': 0.3891, 'learning_rate': 1.4392656574054554e-05, 'epoch': 0.37}
 37%|███▋      | 623/1663 [5:24:55<8:45:31, 30.32s/it] 38%|███▊      | 624/1663 [5:25:29<9:03:02, 31.36s/it]                                                      {'loss': 0.4686, 'learning_rate': 1.4375151214335696e-05, 'epoch': 0.38}
 38%|███▊      | 624/1663 [5:25:29<9:03:02, 31.36s/it] 38%|███▊      | 625/1663 [5:26:00<9:01:33, 31.30s/it]                                                      {'loss': 0.4216, 'learning_rate': 1.435762925783287e-05, 'epoch': 0.38}
 38%|███▊      | 625/1663 [5:26:00<9:01:33, 31.30s/it] 38%|███▊      | 626/1663 [5:26:34<9:13:06, 32.00s/it]                                                      {'loss': 0.4452, 'learning_rate': 1.4340090771014208e-05, 'epoch': 0.38}
 38%|███▊      | 626/1663 [5:26:34<9:13:06, 32.00s/it] 38%|███▊      | 627/1663 [5:27:05<9:04:58, 31.56s/it]                                                      {'loss': 0.3927, 'learning_rate': 1.4322535820410545e-05, 'epoch': 0.38}
 38%|███▊      | 627/1663 [5:27:05<9:04:58, 31.56s/it] 38%|███▊      | 628/1663 [5:27:33<8:46:31, 30.52s/it]                                                      {'loss': 0.4947, 'learning_rate': 1.4304964472615176e-05, 'epoch': 0.38}
 38%|███▊      | 628/1663 [5:27:33<8:46:31, 30.52s/it] 38%|███▊      | 629/1663 [5:28:01<8:36:19, 29.96s/it]                                                      {'loss': 0.4189, 'learning_rate': 1.4287376794283594e-05, 'epoch': 0.38}
 38%|███▊      | 629/1663 [5:28:01<8:36:19, 29.96s/it] 38%|███▊      | 630/1663 [5:28:33<8:42:46, 30.36s/it]                                                      {'loss': 0.3885, 'learning_rate': 1.426977285213324e-05, 'epoch': 0.38}
 38%|███▊      | 630/1663 [5:28:33<8:42:46, 30.36s/it] 38%|███▊      | 631/1663 [5:29:03<8:42:39, 30.39s/it]                                                      {'loss': 0.5195, 'learning_rate': 1.425215271294325e-05, 'epoch': 0.38}
 38%|███▊      | 631/1663 [5:29:03<8:42:39, 30.39s/it] 38%|███▊      | 632/1663 [5:29:33<8:41:30, 30.35s/it]                                                      {'loss': 0.319, 'learning_rate': 1.4234516443554206e-05, 'epoch': 0.38}
 38%|███▊      | 632/1663 [5:29:33<8:41:30, 30.35s/it] 38%|███▊      | 633/1663 [5:30:08<9:05:32, 31.78s/it]                                                      {'loss': 0.4086, 'learning_rate': 1.4216864110867879e-05, 'epoch': 0.38}
 38%|███▊      | 633/1663 [5:30:08<9:05:32, 31.78s/it] 38%|███▊      | 634/1663 [5:30:40<9:03:10, 31.67s/it]                                                      {'loss': 0.3485, 'learning_rate': 1.4199195781846966e-05, 'epoch': 0.38}
 38%|███▊      | 634/1663 [5:30:40<9:03:10, 31.67s/it] 38%|███▊      | 635/1663 [5:31:10<8:56:33, 31.32s/it]                                                      {'loss': 0.4919, 'learning_rate': 1.4181511523514857e-05, 'epoch': 0.38}
 38%|███▊      | 635/1663 [5:31:10<8:56:33, 31.32s/it] 38%|███▊      | 636/1663 [5:31:43<9:03:42, 31.77s/it]                                                      {'loss': 0.4559, 'learning_rate': 1.4163811402955357e-05, 'epoch': 0.38}
 38%|███▊      | 636/1663 [5:31:43<9:03:42, 31.77s/it] 38%|███▊      | 637/1663 [5:32:14<9:00:42, 31.62s/it]                                                      {'loss': 0.4671, 'learning_rate': 1.4146095487312454e-05, 'epoch': 0.38}
 38%|███▊      | 637/1663 [5:32:14<9:00:42, 31.62s/it] 38%|███▊      | 638/1663 [5:32:45<8:56:24, 31.40s/it]                                                      {'loss': 0.4716, 'learning_rate': 1.4128363843790043e-05, 'epoch': 0.38}
 38%|███▊      | 638/1663 [5:32:45<8:56:24, 31.40s/it] 38%|███▊      | 639/1663 [5:33:17<8:56:22, 31.43s/it]                                                      {'loss': 0.3845, 'learning_rate': 1.4110616539651691e-05, 'epoch': 0.38}
 38%|███▊      | 639/1663 [5:33:17<8:56:22, 31.43s/it] 38%|███▊      | 640/1663 [5:33:52<9:15:15, 32.57s/it]                                                      {'loss': 0.3784, 'learning_rate': 1.4092853642220365e-05, 'epoch': 0.38}
 38%|███▊      | 640/1663 [5:33:52<9:15:15, 32.57s/it] 39%|███▊      | 641/1663 [5:34:23<9:04:32, 31.97s/it]                                                      {'loss': 0.4893, 'learning_rate': 1.4075075218878187e-05, 'epoch': 0.39}
 39%|███▊      | 641/1663 [5:34:23<9:04:32, 31.97s/it] 39%|███▊      | 642/1663 [5:34:54<9:01:55, 31.85s/it]                                                      {'loss': 0.3524, 'learning_rate': 1.4057281337066175e-05, 'epoch': 0.39}
 39%|███▊      | 642/1663 [5:34:54<9:01:55, 31.85s/it] 39%|███▊      | 643/1663 [5:35:25<8:55:37, 31.51s/it]                                                      {'loss': 0.5265, 'learning_rate': 1.403947206428399e-05, 'epoch': 0.39}
 39%|███▊      | 643/1663 [5:35:25<8:55:37, 31.51s/it] 39%|███▊      | 644/1663 [5:35:58<9:01:16, 31.87s/it]                                                      {'loss': 0.4052, 'learning_rate': 1.402164746808967e-05, 'epoch': 0.39}
 39%|███▊      | 644/1663 [5:35:58<9:01:16, 31.87s/it] 39%|███▉      | 645/1663 [5:36:30<9:05:40, 32.16s/it]                                                      {'loss': 0.4515, 'learning_rate': 1.400380761609939e-05, 'epoch': 0.39}
 39%|███▉      | 645/1663 [5:36:30<9:05:40, 32.16s/it] 39%|███▉      | 646/1663 [5:37:01<8:56:24, 31.65s/it]                                                      {'loss': 0.4178, 'learning_rate': 1.3985952575987186e-05, 'epoch': 0.39}
 39%|███▉      | 646/1663 [5:37:01<8:56:24, 31.65s/it] 39%|███▉      | 647/1663 [5:37:32<8:51:56, 31.41s/it]                                                      {'loss': 0.3609, 'learning_rate': 1.3968082415484728e-05, 'epoch': 0.39}
 39%|███▉      | 647/1663 [5:37:32<8:51:56, 31.41s/it] 39%|███▉      | 648/1663 [5:38:03<8:51:13, 31.40s/it]                                                      {'loss': 0.4471, 'learning_rate': 1.3950197202381019e-05, 'epoch': 0.39}
 39%|███▉      | 648/1663 [5:38:03<8:51:13, 31.40s/it] 39%|███▉      | 649/1663 [5:38:33<8:42:05, 30.89s/it]                                                      {'loss': 0.4833, 'learning_rate': 1.3932297004522182e-05, 'epoch': 0.39}
 39%|███▉      | 649/1663 [5:38:33<8:42:05, 30.89s/it] 39%|███▉      | 650/1663 [5:39:04<8:42:26, 30.94s/it]                                                      {'loss': 0.3797, 'learning_rate': 1.3914381889811172e-05, 'epoch': 0.39}
 39%|███▉      | 650/1663 [5:39:04<8:42:26, 30.94s/it] 39%|███▉      | 651/1663 [5:39:31<8:23:57, 29.88s/it]                                                      {'loss': 0.394, 'learning_rate': 1.3896451926207542e-05, 'epoch': 0.39}
 39%|███▉      | 651/1663 [5:39:31<8:23:57, 29.88s/it] 39%|███▉      | 652/1663 [5:40:02<8:29:26, 30.23s/it]                                                      {'loss': 0.4363, 'learning_rate': 1.3878507181727158e-05, 'epoch': 0.39}
 39%|███▉      | 652/1663 [5:40:02<8:29:26, 30.23s/it] 39%|███▉      | 653/1663 [5:40:35<8:42:53, 31.06s/it]                                                      {'loss': 0.4474, 'learning_rate': 1.3860547724441968e-05, 'epoch': 0.39}
 39%|███▉      | 653/1663 [5:40:35<8:42:53, 31.06s/it] 39%|███▉      | 654/1663 [5:41:07<8:43:27, 31.13s/it]                                                      {'loss': 0.4427, 'learning_rate': 1.3842573622479729e-05, 'epoch': 0.39}
 39%|███▉      | 654/1663 [5:41:07<8:43:27, 31.13s/it] 39%|███▉      | 655/1663 [5:41:38<8:45:46, 31.30s/it]                                                      {'loss': 0.3805, 'learning_rate': 1.3824584944023742e-05, 'epoch': 0.39}
 39%|███▉      | 655/1663 [5:41:38<8:45:46, 31.30s/it] 39%|███▉      | 656/1663 [5:42:10<8:44:58, 31.28s/it]                                                      {'loss': 0.467, 'learning_rate': 1.3806581757312621e-05, 'epoch': 0.39}
 39%|███▉      | 656/1663 [5:42:10<8:44:58, 31.28s/it] 40%|███▉      | 657/1663 [5:42:42<8:50:25, 31.64s/it]                                                      {'loss': 0.4529, 'learning_rate': 1.378856413064e-05, 'epoch': 0.39}
 40%|███▉      | 657/1663 [5:42:42<8:50:25, 31.64s/it] 40%|███▉      | 658/1663 [5:43:15<8:55:31, 31.97s/it]                                                      {'loss': 0.3386, 'learning_rate': 1.37705321323543e-05, 'epoch': 0.4}
 40%|███▉      | 658/1663 [5:43:15<8:55:31, 31.97s/it] 40%|███▉      | 659/1663 [5:43:50<9:09:24, 32.83s/it]                                                      {'loss': 0.3022, 'learning_rate': 1.3752485830858446e-05, 'epoch': 0.4}
 40%|███▉      | 659/1663 [5:43:50<9:09:24, 32.83s/it] 40%|███▉      | 660/1663 [5:44:22<9:05:57, 32.66s/it]                                                      {'loss': 0.4822, 'learning_rate': 1.3734425294609642e-05, 'epoch': 0.4}
 40%|███▉      | 660/1663 [5:44:22<9:05:57, 32.66s/it] 40%|███▉      | 661/1663 [5:44:57<9:20:09, 33.54s/it]                                                      {'loss': 0.4608, 'learning_rate': 1.3716350592119067e-05, 'epoch': 0.4}
 40%|███▉      | 661/1663 [5:44:57<9:20:09, 33.54s/it] 40%|███▉      | 662/1663 [5:45:28<9:03:14, 32.56s/it]                                                      {'loss': 0.3902, 'learning_rate': 1.3698261791951659e-05, 'epoch': 0.4}
 40%|███▉      | 662/1663 [5:45:28<9:03:14, 32.56s/it] 40%|███▉      | 663/1663 [5:45:59<8:55:39, 32.14s/it]                                                      {'loss': 0.4115, 'learning_rate': 1.3680158962725823e-05, 'epoch': 0.4}
 40%|███▉      | 663/1663 [5:45:59<8:55:39, 32.14s/it] 40%|███▉      | 664/1663 [5:46:31<8:56:18, 32.21s/it]                                                      {'loss': 0.4607, 'learning_rate': 1.366204217311318e-05, 'epoch': 0.4}
 40%|███▉      | 664/1663 [5:46:31<8:56:18, 32.21s/it] 40%|███▉      | 665/1663 [5:47:01<8:43:52, 31.50s/it]                                                      {'loss': 0.4476, 'learning_rate': 1.364391149183832e-05, 'epoch': 0.4}
 40%|███▉      | 665/1663 [5:47:01<8:43:52, 31.50s/it] 40%|████      | 666/1663 [5:47:33<8:45:15, 31.61s/it]                                                      {'loss': 0.4783, 'learning_rate': 1.3625766987678517e-05, 'epoch': 0.4}
 40%|████      | 666/1663 [5:47:33<8:45:15, 31.61s/it] 40%|████      | 667/1663 [5:48:05<8:48:03, 31.81s/it]                                                      {'loss': 0.3077, 'learning_rate': 1.360760872946349e-05, 'epoch': 0.4}
 40%|████      | 667/1663 [5:48:05<8:48:03, 31.81s/it] 40%|████      | 668/1663 [5:48:36<8:40:12, 31.37s/it]                                                      {'loss': 0.4541, 'learning_rate': 1.3589436786075133e-05, 'epoch': 0.4}
 40%|████      | 668/1663 [5:48:36<8:40:12, 31.37s/it] 40%|████      | 669/1663 [5:49:04<8:26:50, 30.59s/it]                                                      {'loss': 0.4249, 'learning_rate': 1.3571251226447244e-05, 'epoch': 0.4}
 40%|████      | 669/1663 [5:49:04<8:26:50, 30.59s/it] 40%|████      | 670/1663 [5:49:34<8:21:50, 30.32s/it]                                                      {'loss': 0.4452, 'learning_rate': 1.3553052119565285e-05, 'epoch': 0.4}
 40%|████      | 670/1663 [5:49:34<8:21:50, 30.32s/it] 40%|████      | 671/1663 [5:50:05<8:23:49, 30.47s/it]                                                      {'loss': 0.4741, 'learning_rate': 1.35348395344661e-05, 'epoch': 0.4}
 40%|████      | 671/1663 [5:50:05<8:23:49, 30.47s/it] 40%|████      | 672/1663 [5:50:36<8:28:04, 30.76s/it]                                                      {'loss': 0.4631, 'learning_rate': 1.3516613540237664e-05, 'epoch': 0.4}
 40%|████      | 672/1663 [5:50:36<8:28:04, 30.76s/it] 40%|████      | 673/1663 [5:51:08<8:32:41, 31.07s/it]                                                      {'loss': 0.3556, 'learning_rate': 1.3498374206018823e-05, 'epoch': 0.4}
 40%|████      | 673/1663 [5:51:08<8:32:41, 31.07s/it] 41%|████      | 674/1663 [5:51:38<8:27:26, 30.79s/it]                                                      {'loss': 0.3143, 'learning_rate': 1.3480121600999021e-05, 'epoch': 0.41}
 41%|████      | 674/1663 [5:51:38<8:27:26, 30.79s/it] 41%|████      | 675/1663 [5:52:09<8:24:58, 30.67s/it]                                                      {'loss': 0.3731, 'learning_rate': 1.3461855794418043e-05, 'epoch': 0.41}
 41%|████      | 675/1663 [5:52:09<8:24:58, 30.67s/it] 41%|████      | 676/1663 [5:52:35<8:04:52, 29.48s/it]                                                      {'loss': 0.4761, 'learning_rate': 1.3443576855565763e-05, 'epoch': 0.41}
 41%|████      | 676/1663 [5:52:35<8:04:52, 29.48s/it] 41%|████      | 677/1663 [5:53:06<8:11:06, 29.88s/it]                                                      {'loss': 0.5972, 'learning_rate': 1.342528485378186e-05, 'epoch': 0.41}
 41%|████      | 677/1663 [5:53:06<8:11:06, 29.88s/it] 41%|████      | 678/1663 [5:53:35<8:06:39, 29.64s/it]                                                      {'loss': 0.3743, 'learning_rate': 1.3406979858455566e-05, 'epoch': 0.41}
 41%|████      | 678/1663 [5:53:35<8:06:39, 29.64s/it] 41%|████      | 679/1663 [5:54:07<8:14:33, 30.16s/it]                                                      {'loss': 0.4784, 'learning_rate': 1.3388661939025416e-05, 'epoch': 0.41}
 41%|████      | 679/1663 [5:54:07<8:14:33, 30.16s/it] 41%|████      | 680/1663 [5:54:37<8:15:22, 30.24s/it]                                                      {'loss': 0.3997, 'learning_rate': 1.3370331164978958e-05, 'epoch': 0.41}
 41%|████      | 680/1663 [5:54:37<8:15:22, 30.24s/it] 41%|████      | 681/1663 [5:55:04<7:57:02, 29.15s/it]                                                      {'loss': 0.3885, 'learning_rate': 1.3351987605852507e-05, 'epoch': 0.41}
 41%|████      | 681/1663 [5:55:04<7:57:02, 29.15s/it] 41%|████      | 682/1663 [5:55:35<8:08:54, 29.90s/it]                                                      {'loss': 0.4199, 'learning_rate': 1.3333631331230883e-05, 'epoch': 0.41}
 41%|████      | 682/1663 [5:55:35<8:08:54, 29.90s/it] 41%|████      | 683/1663 [5:56:10<8:30:16, 31.24s/it]                                                      {'loss': 0.3841, 'learning_rate': 1.3315262410747132e-05, 'epoch': 0.41}
 41%|████      | 683/1663 [5:56:10<8:30:16, 31.24s/it] 41%|████      | 684/1663 [5:56:42<8:37:24, 31.71s/it]                                                      {'loss': 0.4694, 'learning_rate': 1.3296880914082275e-05, 'epoch': 0.41}
 41%|████      | 684/1663 [5:56:42<8:37:24, 31.71s/it] 41%|████      | 685/1663 [5:57:17<8:48:59, 32.45s/it]                                                      {'loss': 0.5455, 'learning_rate': 1.3278486910965043e-05, 'epoch': 0.41}
 41%|████      | 685/1663 [5:57:17<8:48:59, 32.45s/it] 41%|████▏     | 686/1663 [5:57:47<8:36:56, 31.75s/it]                                                      {'loss': 0.457, 'learning_rate': 1.3260080471171603e-05, 'epoch': 0.41}
 41%|████▏     | 686/1663 [5:57:47<8:36:56, 31.75s/it] 41%|████▏     | 687/1663 [5:58:15<8:18:57, 30.67s/it]                                                      {'loss': 0.4414, 'learning_rate': 1.3241661664525305e-05, 'epoch': 0.41}
 41%|████▏     | 687/1663 [5:58:15<8:18:57, 30.67s/it] 41%|████▏     | 688/1663 [5:58:49<8:33:05, 31.57s/it]                                                      {'loss': 0.4032, 'learning_rate': 1.322323056089641e-05, 'epoch': 0.41}
 41%|████▏     | 688/1663 [5:58:49<8:33:05, 31.57s/it] 41%|████▏     | 689/1663 [5:59:16<8:12:58, 30.37s/it]                                                      {'loss': 0.4023, 'learning_rate': 1.3204787230201826e-05, 'epoch': 0.41}
 41%|████▏     | 689/1663 [5:59:16<8:12:58, 30.37s/it] 41%|████▏     | 690/1663 [5:59:46<8:07:36, 30.07s/it]                                                      {'loss': 0.3645, 'learning_rate': 1.3186331742404842e-05, 'epoch': 0.41}
 41%|████▏     | 690/1663 [5:59:46<8:07:36, 30.07s/it] 42%|████▏     | 691/1663 [6:00:19<8:21:46, 30.97s/it]                                                      {'loss': 0.428, 'learning_rate': 1.3167864167514863e-05, 'epoch': 0.42}
 42%|████▏     | 691/1663 [6:00:19<8:21:46, 30.97s/it] 42%|████▏     | 692/1663 [6:00:47<8:10:48, 30.33s/it]                                                      {'loss': 0.4721, 'learning_rate': 1.3149384575587153e-05, 'epoch': 0.42}
 42%|████▏     | 692/1663 [6:00:47<8:10:48, 30.33s/it] 42%|████▏     | 693/1663 [6:01:18<8:11:46, 30.42s/it]                                                      {'loss': 0.5213, 'learning_rate': 1.3130893036722553e-05, 'epoch': 0.42}
 42%|████▏     | 693/1663 [6:01:18<8:11:46, 30.42s/it] 42%|████▏     | 694/1663 [6:01:50<8:17:05, 30.78s/it]                                                      {'loss': 0.4298, 'learning_rate': 1.311238962106723e-05, 'epoch': 0.42}
 42%|████▏     | 694/1663 [6:01:50<8:17:05, 30.78s/it] 42%|████▏     | 695/1663 [6:02:20<8:12:29, 30.53s/it]                                                      {'loss': 0.4707, 'learning_rate': 1.30938743988124e-05, 'epoch': 0.42}
 42%|████▏     | 695/1663 [6:02:20<8:12:29, 30.53s/it] 42%|████▏     | 696/1663 [6:02:51<8:16:11, 30.79s/it]                                                      {'loss': 0.4611, 'learning_rate': 1.3075347440194066e-05, 'epoch': 0.42}
 42%|████▏     | 696/1663 [6:02:51<8:16:11, 30.79s/it] 42%|████▏     | 697/1663 [6:03:22<8:18:46, 30.98s/it]                                                      {'loss': 0.384, 'learning_rate': 1.3056808815492761e-05, 'epoch': 0.42}
 42%|████▏     | 697/1663 [6:03:22<8:18:46, 30.98s/it] 42%|████▏     | 698/1663 [6:03:56<8:29:41, 31.69s/it]                                                      {'loss': 0.3932, 'learning_rate': 1.303825859503326e-05, 'epoch': 0.42}
 42%|████▏     | 698/1663 [6:03:56<8:29:41, 31.69s/it] 42%|████▏     | 699/1663 [6:04:28<8:29:45, 31.73s/it]                                                      {'loss': 0.4375, 'learning_rate': 1.3019696849184334e-05, 'epoch': 0.42}
 42%|████▏     | 699/1663 [6:04:28<8:29:45, 31.73s/it] 42%|████▏     | 700/1663 [6:04:58<8:23:00, 31.34s/it]                                                      {'loss': 0.3848, 'learning_rate': 1.3001123648358469e-05, 'epoch': 0.42}
 42%|████▏     | 700/1663 [6:04:58<8:23:00, 31.34s/it] 42%|████▏     | 701/1663 [6:05:28<8:15:16, 30.89s/it]                                                      {'loss': 0.3919, 'learning_rate': 1.298253906301161e-05, 'epoch': 0.42}
 42%|████▏     | 701/1663 [6:05:28<8:15:16, 30.89s/it] 42%|████▏     | 702/1663 [6:05:59<8:15:52, 30.96s/it]                                                      {'loss': 0.4316, 'learning_rate': 1.2963943163642885e-05, 'epoch': 0.42}
 42%|████▏     | 702/1663 [6:05:59<8:15:52, 30.96s/it] 42%|████▏     | 703/1663 [6:06:30<8:17:51, 31.12s/it]                                                      {'loss': 0.4327, 'learning_rate': 1.2945336020794338e-05, 'epoch': 0.42}
 42%|████▏     | 703/1663 [6:06:30<8:17:51, 31.12s/it] 42%|████▏     | 704/1663 [6:07:00<8:11:03, 30.72s/it]                                                      {'loss': 0.4513, 'learning_rate': 1.2926717705050675e-05, 'epoch': 0.42}
 42%|████▏     | 704/1663 [6:07:00<8:11:03, 30.72s/it] 42%|████▏     | 705/1663 [6:07:31<8:09:40, 30.67s/it]                                                      {'loss': 0.3969, 'learning_rate': 1.2908088287038974e-05, 'epoch': 0.42}
 42%|████▏     | 705/1663 [6:07:31<8:09:40, 30.67s/it] 42%|████▏     | 706/1663 [6:08:03<8:15:24, 31.06s/it]                                                      {'loss': 0.3782, 'learning_rate': 1.288944783742843e-05, 'epoch': 0.42}
 42%|████▏     | 706/1663 [6:08:03<8:15:24, 31.06s/it] 43%|████▎     | 707/1663 [6:08:33<8:11:10, 30.83s/it]                                                      {'loss': 0.4436, 'learning_rate': 1.287079642693009e-05, 'epoch': 0.43}
 43%|████▎     | 707/1663 [6:08:33<8:11:10, 30.83s/it] 43%|████▎     | 708/1663 [6:09:03<8:07:41, 30.64s/it]                                                      {'loss': 0.5231, 'learning_rate': 1.2852134126296583e-05, 'epoch': 0.43}
 43%|████▎     | 708/1663 [6:09:03<8:07:41, 30.64s/it] 43%|████▎     | 709/1663 [6:09:35<8:12:04, 30.95s/it]                                                      {'loss': 0.4695, 'learning_rate': 1.2833461006321837e-05, 'epoch': 0.43}
 43%|████▎     | 709/1663 [6:09:35<8:12:04, 30.95s/it] 43%|████▎     | 710/1663 [6:10:05<8:09:29, 30.82s/it]                                                      {'loss': 0.4363, 'learning_rate': 1.2814777137840834e-05, 'epoch': 0.43}
 43%|████▎     | 710/1663 [6:10:05<8:09:29, 30.82s/it] 43%|████▎     | 711/1663 [6:10:36<8:06:52, 30.69s/it]                                                      {'loss': 0.484, 'learning_rate': 1.2796082591729326e-05, 'epoch': 0.43}
 43%|████▎     | 711/1663 [6:10:36<8:06:52, 30.69s/it] 43%|████▎     | 712/1663 [6:11:09<8:19:59, 31.54s/it]                                                      {'loss': 0.427, 'learning_rate': 1.2777377438903567e-05, 'epoch': 0.43}
 43%|████▎     | 712/1663 [6:11:09<8:19:59, 31.54s/it] 43%|████▎     | 713/1663 [6:11:40<8:16:30, 31.36s/it]                                                      {'loss': 0.4838, 'learning_rate': 1.2758661750320047e-05, 'epoch': 0.43}
 43%|████▎     | 713/1663 [6:11:40<8:16:30, 31.36s/it] 43%|████▎     | 714/1663 [6:12:10<8:07:28, 30.82s/it]                                                      {'loss': 0.4811, 'learning_rate': 1.2739935596975225e-05, 'epoch': 0.43}
 43%|████▎     | 714/1663 [6:12:10<8:07:28, 30.82s/it] 43%|████▎     | 715/1663 [6:12:44<8:20:43, 31.69s/it]                                                      {'loss': 0.3948, 'learning_rate': 1.2721199049905262e-05, 'epoch': 0.43}
 43%|████▎     | 715/1663 [6:12:44<8:20:43, 31.69s/it] 43%|████▎     | 716/1663 [6:13:19<8:35:41, 32.67s/it]                                                      {'loss': 0.3863, 'learning_rate': 1.2702452180185734e-05, 'epoch': 0.43}
 43%|████▎     | 716/1663 [6:13:19<8:35:41, 32.67s/it] 43%|████▎     | 717/1663 [6:13:50<8:30:50, 32.40s/it]                                                      {'loss': 0.4485, 'learning_rate': 1.2683695058931384e-05, 'epoch': 0.43}
 43%|████▎     | 717/1663 [6:13:50<8:30:50, 32.40s/it] 43%|████▎     | 718/1663 [6:14:19<8:11:12, 31.19s/it]                                                      {'loss': 0.483, 'learning_rate': 1.2664927757295844e-05, 'epoch': 0.43}
 43%|████▎     | 718/1663 [6:14:19<8:11:12, 31.19s/it] 43%|████▎     | 719/1663 [6:14:50<8:11:14, 31.22s/it]                                                      {'loss': 0.4332, 'learning_rate': 1.2646150346471362e-05, 'epoch': 0.43}
 43%|████▎     | 719/1663 [6:14:50<8:11:14, 31.22s/it] 43%|████▎     | 720/1663 [6:15:23<8:17:19, 31.64s/it]                                                      {'loss': 0.3822, 'learning_rate': 1.2627362897688531e-05, 'epoch': 0.43}
 43%|████▎     | 720/1663 [6:15:23<8:17:19, 31.64s/it] 43%|████▎     | 721/1663 [6:15:54<8:14:00, 31.47s/it]                                                      {'loss': 0.4793, 'learning_rate': 1.2608565482216029e-05, 'epoch': 0.43}
 43%|████▎     | 721/1663 [6:15:54<8:14:00, 31.47s/it] 43%|████▎     | 722/1663 [6:16:25<8:15:06, 31.57s/it]                                                      {'loss': 0.3801, 'learning_rate': 1.2589758171360338e-05, 'epoch': 0.43}
 43%|████▎     | 722/1663 [6:16:25<8:15:06, 31.57s/it] 43%|████▎     | 723/1663 [6:16:59<8:24:16, 32.19s/it]                                                      {'loss': 0.3237, 'learning_rate': 1.2570941036465479e-05, 'epoch': 0.43}
 43%|████▎     | 723/1663 [6:16:59<8:24:16, 32.19s/it] 44%|████▎     | 724/1663 [6:17:28<8:07:47, 31.17s/it]                                                      {'loss': 0.4973, 'learning_rate': 1.2552114148912735e-05, 'epoch': 0.44}
 44%|████▎     | 724/1663 [6:17:28<8:07:47, 31.17s/it] 44%|████▎     | 725/1663 [6:17:58<8:02:56, 30.89s/it]                                                      {'loss': 0.4714, 'learning_rate': 1.2533277580120392e-05, 'epoch': 0.44}
 44%|████▎     | 725/1663 [6:17:58<8:02:56, 30.89s/it] 44%|████▎     | 726/1663 [6:18:29<8:00:23, 30.76s/it]                                                      {'loss': 0.392, 'learning_rate': 1.2514431401543455e-05, 'epoch': 0.44}
 44%|████▎     | 726/1663 [6:18:29<8:00:23, 30.76s/it] 44%|████▎     | 727/1663 [6:18:59<7:58:31, 30.68s/it]                                                      {'loss': 0.4458, 'learning_rate': 1.2495575684673385e-05, 'epoch': 0.44}
 44%|████▎     | 727/1663 [6:18:59<7:58:31, 30.68s/it] 44%|████▍     | 728/1663 [6:19:30<7:59:28, 30.77s/it]                                                      {'loss': 0.3527, 'learning_rate': 1.247671050103783e-05, 'epoch': 0.44}
 44%|████▍     | 728/1663 [6:19:30<7:59:28, 30.77s/it] 44%|████▍     | 729/1663 [6:20:01<7:57:26, 30.67s/it]                                                      {'loss': 0.4393, 'learning_rate': 1.2457835922200344e-05, 'epoch': 0.44}
 44%|████▍     | 729/1663 [6:20:01<7:57:26, 30.67s/it] 44%|████▍     | 730/1663 [6:20:31<7:57:59, 30.74s/it]                                                      {'loss': 0.4205, 'learning_rate': 1.2438952019760123e-05, 'epoch': 0.44}
 44%|████▍     | 730/1663 [6:20:31<7:57:59, 30.74s/it] 44%|████▍     | 731/1663 [6:21:03<8:01:05, 30.97s/it]                                                      {'loss': 0.4152, 'learning_rate': 1.2420058865351727e-05, 'epoch': 0.44}
 44%|████▍     | 731/1663 [6:21:03<8:01:05, 30.97s/it] 44%|████▍     | 732/1663 [6:21:34<8:00:36, 30.97s/it]                                                      {'loss': 0.3598, 'learning_rate': 1.2401156530644822e-05, 'epoch': 0.44}
 44%|████▍     | 732/1663 [6:21:34<8:00:36, 30.97s/it] 44%|████▍     | 733/1663 [6:22:08<8:12:48, 31.79s/it]                                                      {'loss': 0.3528, 'learning_rate': 1.2382245087343889e-05, 'epoch': 0.44}
 44%|████▍     | 733/1663 [6:22:08<8:12:48, 31.79s/it] 44%|████▍     | 734/1663 [6:22:39<8:08:20, 31.54s/it]                                                      {'loss': 0.4963, 'learning_rate': 1.236332460718797e-05, 'epoch': 0.44}
 44%|████▍     | 734/1663 [6:22:39<8:08:20, 31.54s/it] 44%|████▍     | 735/1663 [6:23:10<8:08:21, 31.57s/it]                                                      {'loss': 0.3439, 'learning_rate': 1.234439516195038e-05, 'epoch': 0.44}
 44%|████▍     | 735/1663 [6:23:10<8:08:21, 31.57s/it] 44%|████▍     | 736/1663 [6:23:39<7:56:13, 30.82s/it]                                                      {'loss': 0.4326, 'learning_rate': 1.2325456823438447e-05, 'epoch': 0.44}
 44%|████▍     | 736/1663 [6:23:39<7:56:13, 30.82s/it] 44%|████▍     | 737/1663 [6:24:09<7:49:20, 30.41s/it]                                                      {'loss': 0.4992, 'learning_rate': 1.2306509663493233e-05, 'epoch': 0.44}
 44%|████▍     | 737/1663 [6:24:09<7:49:20, 30.41s/it] 44%|████▍     | 738/1663 [6:24:39<7:47:33, 30.33s/it]                                                      {'loss': 0.3588, 'learning_rate': 1.2287553753989265e-05, 'epoch': 0.44}
 44%|████▍     | 738/1663 [6:24:39<7:47:33, 30.33s/it] 44%|████▍     | 739/1663 [6:25:09<7:48:10, 30.40s/it]                                                      {'loss': 0.5385, 'learning_rate': 1.2268589166834262e-05, 'epoch': 0.44}
 44%|████▍     | 739/1663 [6:25:09<7:48:10, 30.40s/it] 44%|████▍     | 740/1663 [6:25:40<7:48:56, 30.48s/it]                                                      {'loss': 0.3088, 'learning_rate': 1.2249615973968856e-05, 'epoch': 0.44}
 44%|████▍     | 740/1663 [6:25:40<7:48:56, 30.48s/it] 45%|████▍     | 741/1663 [6:26:14<8:04:53, 31.55s/it]                                                      {'loss': 0.3561, 'learning_rate': 1.2230634247366327e-05, 'epoch': 0.45}
 45%|████▍     | 741/1663 [6:26:14<8:04:53, 31.55s/it] 45%|████▍     | 742/1663 [6:26:49<8:21:05, 32.64s/it]                                                      {'loss': 0.4807, 'learning_rate': 1.2211644059032329e-05, 'epoch': 0.45}
 45%|████▍     | 742/1663 [6:26:49<8:21:05, 32.64s/it] 45%|████▍     | 743/1663 [6:27:20<8:12:22, 32.11s/it]                                                      {'loss': 0.3997, 'learning_rate': 1.219264548100461e-05, 'epoch': 0.45}
 45%|████▍     | 743/1663 [6:27:20<8:12:22, 32.11s/it] 45%|████▍     | 744/1663 [6:27:52<8:11:51, 32.11s/it]                                                      {'loss': 0.5214, 'learning_rate': 1.2173638585352749e-05, 'epoch': 0.45}
 45%|████▍     | 744/1663 [6:27:52<8:11:51, 32.11s/it] 45%|████▍     | 745/1663 [6:28:24<8:08:17, 31.91s/it]                                                      {'loss': 0.3498, 'learning_rate': 1.2154623444177874e-05, 'epoch': 0.45}
 45%|████▍     | 745/1663 [6:28:24<8:08:17, 31.91s/it] 45%|████▍     | 746/1663 [6:28:58<8:18:54, 32.64s/it]                                                      {'loss': 0.3072, 'learning_rate': 1.2135600129612393e-05, 'epoch': 0.45}
 45%|████▍     | 746/1663 [6:28:58<8:18:54, 32.64s/it] 45%|████▍     | 747/1663 [6:29:28<8:06:44, 31.88s/it]                                                      {'loss': 0.4051, 'learning_rate': 1.2116568713819716e-05, 'epoch': 0.45}
 45%|████▍     | 747/1663 [6:29:28<8:06:44, 31.88s/it] 45%|████▍     | 748/1663 [6:30:00<8:07:22, 31.96s/it]                                                      {'loss': 0.4186, 'learning_rate': 1.2097529268993993e-05, 'epoch': 0.45}
 45%|████▍     | 748/1663 [6:30:00<8:07:22, 31.96s/it] 45%|████▌     | 749/1663 [6:30:32<8:04:21, 31.80s/it]                                                      {'loss': 0.5225, 'learning_rate': 1.2078481867359816e-05, 'epoch': 0.45}
 45%|████▌     | 749/1663 [6:30:32<8:04:21, 31.80s/it] 45%|████▌     | 750/1663 [6:31:03<8:02:48, 31.73s/it]                                                      {'loss': 0.2974, 'learning_rate': 1.205942658117198e-05, 'epoch': 0.45}
 45%|████▌     | 750/1663 [6:31:03<8:02:48, 31.73s/it] 45%|████▌     | 751/1663 [6:31:35<7:59:53, 31.57s/it]                                                      {'loss': 0.4946, 'learning_rate': 1.2040363482715174e-05, 'epoch': 0.45}
 45%|████▌     | 751/1663 [6:31:35<7:59:53, 31.57s/it] 45%|████▌     | 752/1663 [6:32:05<7:53:12, 31.17s/it]                                                      {'loss': 0.4007, 'learning_rate': 1.2021292644303725e-05, 'epoch': 0.45}
 45%|████▌     | 752/1663 [6:32:05<7:53:12, 31.17s/it] 45%|████▌     | 753/1663 [6:32:35<7:48:00, 30.86s/it]                                                      {'loss': 0.4302, 'learning_rate': 1.2002214138281332e-05, 'epoch': 0.45}
 45%|████▌     | 753/1663 [6:32:35<7:48:00, 30.86s/it] 45%|████▌     | 754/1663 [6:33:07<7:51:51, 31.15s/it]                                                      {'loss': 0.421, 'learning_rate': 1.1983128037020763e-05, 'epoch': 0.45}
 45%|████▌     | 754/1663 [6:33:07<7:51:51, 31.15s/it] 45%|████▌     | 755/1663 [6:33:39<7:54:44, 31.37s/it]                                                      {'loss': 0.3898, 'learning_rate': 1.196403441292361e-05, 'epoch': 0.45}
 45%|████▌     | 755/1663 [6:33:39<7:54:44, 31.37s/it] 45%|████▌     | 756/1663 [6:34:10<7:56:13, 31.50s/it]                                                      {'loss': 0.3395, 'learning_rate': 1.1944933338420001e-05, 'epoch': 0.45}
 45%|████▌     | 756/1663 [6:34:10<7:56:13, 31.50s/it] 46%|████▌     | 757/1663 [6:34:42<7:56:32, 31.56s/it]                                                      {'loss': 0.4716, 'learning_rate': 1.1925824885968325e-05, 'epoch': 0.46}
 46%|████▌     | 757/1663 [6:34:42<7:56:32, 31.56s/it] 46%|████▌     | 758/1663 [6:35:12<7:49:45, 31.14s/it]                                                      {'loss': 0.4299, 'learning_rate': 1.1906709128054956e-05, 'epoch': 0.46}
 46%|████▌     | 758/1663 [6:35:12<7:49:45, 31.14s/it] 46%|████▌     | 759/1663 [6:35:41<7:37:34, 30.37s/it]                                                      {'loss': 0.4182, 'learning_rate': 1.1887586137193982e-05, 'epoch': 0.46}
 46%|████▌     | 759/1663 [6:35:41<7:37:34, 30.37s/it] 46%|████▌     | 760/1663 [6:36:11<7:36:24, 30.33s/it]                                                      {'loss': 0.3984, 'learning_rate': 1.186845598592693e-05, 'epoch': 0.46}
 46%|████▌     | 760/1663 [6:36:11<7:36:24, 30.33s/it] 46%|████▌     | 761/1663 [6:36:44<7:46:23, 31.02s/it]                                                      {'loss': 0.4802, 'learning_rate': 1.1849318746822491e-05, 'epoch': 0.46}
 46%|████▌     | 761/1663 [6:36:44<7:46:23, 31.02s/it] 46%|████▌     | 762/1663 [6:37:15<7:46:40, 31.08s/it]                                                      {'loss': 0.4456, 'learning_rate': 1.1830174492476243e-05, 'epoch': 0.46}
 46%|████▌     | 762/1663 [6:37:15<7:46:40, 31.08s/it] 46%|████▌     | 763/1663 [6:37:42<7:27:29, 29.83s/it]                                                      {'loss': 0.4502, 'learning_rate': 1.1811023295510372e-05, 'epoch': 0.46}
 46%|████▌     | 763/1663 [6:37:42<7:27:29, 29.83s/it] 46%|████▌     | 764/1663 [6:38:13<7:33:27, 30.26s/it]                                                      {'loss': 0.3942, 'learning_rate': 1.1791865228573398e-05, 'epoch': 0.46}
 46%|████▌     | 764/1663 [6:38:13<7:33:27, 30.26s/it] 46%|████▌     | 765/1663 [6:38:42<7:25:47, 29.79s/it]                                                      {'loss': 0.3846, 'learning_rate': 1.1772700364339911e-05, 'epoch': 0.46}
 46%|████▌     | 765/1663 [6:38:42<7:25:47, 29.79s/it] 46%|████▌     | 766/1663 [6:39:16<7:43:42, 31.02s/it]                                                      {'loss': 0.4692, 'learning_rate': 1.1753528775510278e-05, 'epoch': 0.46}
 46%|████▌     | 766/1663 [6:39:16<7:43:42, 31.02s/it] 46%|████▌     | 767/1663 [6:39:48<7:50:06, 31.48s/it]                                                      {'loss': 0.4783, 'learning_rate': 1.1734350534810381e-05, 'epoch': 0.46}
 46%|████▌     | 767/1663 [6:39:48<7:50:06, 31.48s/it] 46%|████▌     | 768/1663 [6:40:19<7:46:50, 31.30s/it]                                                      {'loss': 0.4624, 'learning_rate': 1.1715165714991333e-05, 'epoch': 0.46}
 46%|████▌     | 768/1663 [6:40:19<7:46:50, 31.30s/it] 46%|████▌     | 769/1663 [6:40:51<7:47:48, 31.40s/it]                                                      {'loss': 0.4097, 'learning_rate': 1.1695974388829197e-05, 'epoch': 0.46}
 46%|████▌     | 769/1663 [6:40:51<7:47:48, 31.40s/it] 46%|████▋     | 770/1663 [6:41:21<7:42:50, 31.10s/it]                                                      {'loss': 0.4008, 'learning_rate': 1.167677662912473e-05, 'epoch': 0.46}
 46%|████▋     | 770/1663 [6:41:21<7:42:50, 31.10s/it] 46%|████▋     | 771/1663 [6:41:50<7:34:01, 30.54s/it]                                                      {'loss': 0.4242, 'learning_rate': 1.1657572508703087e-05, 'epoch': 0.46}
 46%|████▋     | 771/1663 [6:41:50<7:34:01, 30.54s/it] 46%|████▋     | 772/1663 [6:42:20<7:30:55, 30.37s/it]                                                      {'loss': 0.3772, 'learning_rate': 1.1638362100413553e-05, 'epoch': 0.46}
 46%|████▋     | 772/1663 [6:42:20<7:30:55, 30.37s/it] 46%|████▋     | 773/1663 [6:42:48<7:19:51, 29.65s/it]                                                      {'loss': 0.3844, 'learning_rate': 1.1619145477129265e-05, 'epoch': 0.46}
 46%|████▋     | 773/1663 [6:42:48<7:19:51, 29.65s/it] 47%|████▋     | 774/1663 [6:43:16<7:11:38, 29.13s/it]                                                      {'loss': 0.5488, 'learning_rate': 1.1599922711746938e-05, 'epoch': 0.47}
 47%|████▋     | 774/1663 [6:43:16<7:11:38, 29.13s/it] 47%|████▋     | 775/1663 [6:43:45<7:07:42, 28.90s/it]                                                      {'loss': 0.4632, 'learning_rate': 1.1580693877186583e-05, 'epoch': 0.47}
 47%|████▋     | 775/1663 [6:43:45<7:07:42, 28.90s/it] 47%|████▋     | 776/1663 [6:44:18<7:27:49, 30.29s/it]                                                      {'loss': 0.3739, 'learning_rate': 1.156145904639124e-05, 'epoch': 0.47}
 47%|████▋     | 776/1663 [6:44:18<7:27:49, 30.29s/it] 47%|████▋     | 777/1663 [6:44:50<7:31:55, 30.60s/it]                                                      {'loss': 0.373, 'learning_rate': 1.1542218292326686e-05, 'epoch': 0.47}
 47%|████▋     | 777/1663 [6:44:50<7:31:55, 30.60s/it] 47%|████▋     | 778/1663 [6:45:22<7:38:56, 31.11s/it]                                                      {'loss': 0.4322, 'learning_rate': 1.1522971687981175e-05, 'epoch': 0.47}
 47%|████▋     | 778/1663 [6:45:22<7:38:56, 31.11s/it] 47%|████▋     | 779/1663 [6:45:53<7:38:02, 31.09s/it]                                                      {'loss': 0.473, 'learning_rate': 1.1503719306365153e-05, 'epoch': 0.47}
 47%|████▋     | 779/1663 [6:45:53<7:38:02, 31.09s/it] 47%|████▋     | 780/1663 [6:46:24<7:35:40, 30.96s/it]                                                      {'loss': 0.493, 'learning_rate': 1.148446122051098e-05, 'epoch': 0.47}
 47%|████▋     | 780/1663 [6:46:24<7:35:40, 30.96s/it] 47%|████▋     | 781/1663 [6:46:58<7:51:18, 32.06s/it]                                                      {'loss': 0.4605, 'learning_rate': 1.1465197503472654e-05, 'epoch': 0.47}
 47%|████▋     | 781/1663 [6:46:58<7:51:18, 32.06s/it] 47%|████▋     | 782/1663 [6:47:30<7:48:17, 31.89s/it]                                                      {'loss': 0.4221, 'learning_rate': 1.1445928228325532e-05, 'epoch': 0.47}
 47%|████▋     | 782/1663 [6:47:30<7:48:17, 31.89s/it] 47%|████▋     | 783/1663 [6:48:03<7:54:40, 32.36s/it]                                                      {'loss': 0.296, 'learning_rate': 1.1426653468166062e-05, 'epoch': 0.47}
 47%|████▋     | 783/1663 [6:48:03<7:54:40, 32.36s/it] 47%|████▋     | 784/1663 [6:48:37<7:59:23, 32.72s/it]                                                      {'loss': 0.4019, 'learning_rate': 1.1407373296111495e-05, 'epoch': 0.47}
 47%|████▋     | 784/1663 [6:48:37<7:59:23, 32.72s/it] 47%|████▋     | 785/1663 [6:49:09<7:56:50, 32.59s/it]                                                      {'loss': 0.4558, 'learning_rate': 1.1388087785299609e-05, 'epoch': 0.47}
 47%|████▋     | 785/1663 [6:49:09<7:56:50, 32.59s/it] 47%|████▋     | 786/1663 [6:49:39<7:43:07, 31.68s/it]                                                      {'loss': 0.3939, 'learning_rate': 1.1368797008888439e-05, 'epoch': 0.47}
 47%|████▋     | 786/1663 [6:49:39<7:43:07, 31.68s/it] 47%|████▋     | 787/1663 [6:50:09<7:35:26, 31.19s/it]                                                      {'loss': 0.4027, 'learning_rate': 1.1349501040055995e-05, 'epoch': 0.47}
 47%|████▋     | 787/1663 [6:50:09<7:35:26, 31.19s/it] 47%|████▋     | 788/1663 [6:50:42<7:44:32, 31.85s/it]                                                      {'loss': 0.3724, 'learning_rate': 1.1330199951999976e-05, 'epoch': 0.47}
 47%|████▋     | 788/1663 [6:50:42<7:44:32, 31.85s/it] 47%|████▋     | 789/1663 [6:51:14<7:43:12, 31.80s/it]                                                      {'loss': 0.3754, 'learning_rate': 1.1310893817937509e-05, 'epoch': 0.47}
 47%|████▋     | 789/1663 [6:51:14<7:43:12, 31.80s/it] 48%|████▊     | 790/1663 [6:51:45<7:41:37, 31.73s/it]                                                      {'loss': 0.3977, 'learning_rate': 1.1291582711104862e-05, 'epoch': 0.47}
 48%|████▊     | 790/1663 [6:51:45<7:41:37, 31.73s/it] 48%|████▊     | 791/1663 [6:52:15<7:34:38, 31.28s/it]                                                      {'loss': 0.3968, 'learning_rate': 1.127226670475716e-05, 'epoch': 0.48}
 48%|████▊     | 791/1663 [6:52:15<7:34:38, 31.28s/it] 48%|████▊     | 792/1663 [6:52:45<7:28:08, 30.87s/it]                                                      {'loss': 0.4392, 'learning_rate': 1.125294587216812e-05, 'epoch': 0.48}
 48%|████▊     | 792/1663 [6:52:45<7:28:08, 30.87s/it] 48%|████▊     | 793/1663 [6:53:16<7:27:11, 30.84s/it]                                                      {'loss': 0.4478, 'learning_rate': 1.1233620286629768e-05, 'epoch': 0.48}
 48%|████▊     | 793/1663 [6:53:16<7:27:11, 30.84s/it] 48%|████▊     | 794/1663 [6:53:49<7:34:26, 31.38s/it]                                                      {'loss': 0.4366, 'learning_rate': 1.1214290021452153e-05, 'epoch': 0.48}
 48%|████▊     | 794/1663 [6:53:49<7:34:26, 31.38s/it] 48%|████▊     | 795/1663 [6:54:19<7:29:57, 31.10s/it]                                                      {'loss': 0.4974, 'learning_rate': 1.1194955149963081e-05, 'epoch': 0.48}
 48%|████▊     | 795/1663 [6:54:19<7:29:57, 31.10s/it] 48%|████▊     | 796/1663 [6:54:50<7:30:12, 31.16s/it]                                                      {'loss': 0.4016, 'learning_rate': 1.117561574550783e-05, 'epoch': 0.48}
 48%|████▊     | 796/1663 [6:54:50<7:30:12, 31.16s/it] 48%|████▊     | 797/1663 [6:55:22<7:31:39, 31.29s/it]                                                      {'loss': 0.4858, 'learning_rate': 1.1156271881448878e-05, 'epoch': 0.48}
 48%|████▊     | 797/1663 [6:55:22<7:31:39, 31.29s/it] 48%|████▊     | 798/1663 [6:55:52<7:27:16, 31.02s/it]                                                      {'loss': 0.3537, 'learning_rate': 1.1136923631165613e-05, 'epoch': 0.48}
 48%|████▊     | 798/1663 [6:55:52<7:27:16, 31.02s/it] 48%|████▊     | 799/1663 [6:56:23<7:24:00, 30.83s/it]                                                      {'loss': 0.3421, 'learning_rate': 1.1117571068054067e-05, 'epoch': 0.48}
 48%|████▊     | 799/1663 [6:56:23<7:24:00, 30.83s/it] 48%|████▊     | 800/1663 [6:56:58<7:42:26, 32.15s/it]                                                      {'loss': 0.4138, 'learning_rate': 1.1098214265526628e-05, 'epoch': 0.48}
 48%|████▊     | 800/1663 [6:56:58<7:42:26, 32.15s/it] 48%|████▊     | 801/1663 [6:57:26<7:24:44, 30.96s/it]                                                      {'loss': 0.4424, 'learning_rate': 1.1078853297011769e-05, 'epoch': 0.48}
 48%|████▊     | 801/1663 [6:57:26<7:24:44, 30.96s/it] 48%|████▊     | 802/1663 [6:57:58<7:27:46, 31.20s/it]                                                      {'loss': 0.4618, 'learning_rate': 1.1059488235953769e-05, 'epoch': 0.48}
 48%|████▊     | 802/1663 [6:57:58<7:27:46, 31.20s/it] 48%|████▊     | 803/1663 [6:58:27<7:16:20, 30.44s/it]                                                      {'loss': 0.4695, 'learning_rate': 1.1040119155812424e-05, 'epoch': 0.48}
 48%|████▊     | 803/1663 [6:58:27<7:16:20, 30.44s/it] 48%|████▊     | 804/1663 [6:58:59<7:25:23, 31.11s/it]                                                      {'loss': 0.3868, 'learning_rate': 1.102074613006278e-05, 'epoch': 0.48}
 48%|████▊     | 804/1663 [6:58:59<7:25:23, 31.11s/it] 48%|████▊     | 805/1663 [6:59:30<7:21:12, 30.85s/it]                                                      {'loss': 0.3279, 'learning_rate': 1.1001369232194856e-05, 'epoch': 0.48}
 48%|████▊     | 805/1663 [6:59:30<7:21:12, 30.85s/it] 48%|████▊     | 806/1663 [7:00:01<7:24:14, 31.10s/it]                                                      {'loss': 0.4272, 'learning_rate': 1.098198853571335e-05, 'epoch': 0.48}
 48%|████▊     | 806/1663 [7:00:01<7:24:14, 31.10s/it] 49%|████▊     | 807/1663 [7:00:37<7:44:18, 32.54s/it]                                                      {'loss': 0.3812, 'learning_rate': 1.0962604114137378e-05, 'epoch': 0.49}
 49%|████▊     | 807/1663 [7:00:37<7:44:18, 32.54s/it] 49%|████▊     | 808/1663 [7:01:10<7:43:43, 32.54s/it]                                                      {'loss': 0.377, 'learning_rate': 1.0943216041000177e-05, 'epoch': 0.49}
 49%|████▊     | 808/1663 [7:01:10<7:43:43, 32.54s/it] 49%|████▊     | 809/1663 [7:01:39<7:30:56, 31.68s/it]                                                      {'loss': 0.4516, 'learning_rate': 1.092382438984885e-05, 'epoch': 0.49}
 49%|████▊     | 809/1663 [7:01:39<7:30:56, 31.68s/it] 49%|████▊     | 810/1663 [7:02:13<7:39:00, 32.29s/it]                                                      {'loss': 0.4151, 'learning_rate': 1.0904429234244056e-05, 'epoch': 0.49}
 49%|████▊     | 810/1663 [7:02:13<7:39:00, 32.29s/it] 49%|████▉     | 811/1663 [7:02:44<7:33:54, 31.97s/it]                                                      {'loss': 0.5005, 'learning_rate': 1.0885030647759763e-05, 'epoch': 0.49}
 49%|████▉     | 811/1663 [7:02:44<7:33:54, 31.97s/it] 49%|████▉     | 812/1663 [7:03:18<7:39:12, 32.38s/it]                                                      {'loss': 0.4233, 'learning_rate': 1.0865628703982945e-05, 'epoch': 0.49}
 49%|████▉     | 812/1663 [7:03:18<7:39:12, 32.38s/it] 49%|████▉     | 813/1663 [7:03:49<7:34:13, 32.06s/it]                                                      {'loss': 0.3621, 'learning_rate': 1.0846223476513312e-05, 'epoch': 0.49}
 49%|████▉     | 813/1663 [7:03:49<7:34:13, 32.06s/it] 49%|████▉     | 814/1663 [7:04:19<7:22:46, 31.29s/it]                                                      {'loss': 0.3622, 'learning_rate': 1.0826815038963037e-05, 'epoch': 0.49}
 49%|████▉     | 814/1663 [7:04:19<7:22:46, 31.29s/it] 49%|████▉     | 815/1663 [7:04:46<7:05:09, 30.08s/it]                                                      {'loss': 0.4176, 'learning_rate': 1.080740346495646e-05, 'epoch': 0.49}
 49%|████▉     | 815/1663 [7:04:46<7:05:09, 30.08s/it] 49%|████▉     | 816/1663 [7:05:18<7:12:03, 30.61s/it]                                                      {'loss': 0.4814, 'learning_rate': 1.0787988828129831e-05, 'epoch': 0.49}
 49%|████▉     | 816/1663 [7:05:18<7:12:03, 30.61s/it] 49%|████▉     | 817/1663 [7:05:51<7:22:12, 31.36s/it]                                                      {'loss': 0.3651, 'learning_rate': 1.0768571202131009e-05, 'epoch': 0.49}
 49%|████▉     | 817/1663 [7:05:51<7:22:12, 31.36s/it] 49%|████▉     | 818/1663 [7:06:25<7:33:47, 32.22s/it]                                                      {'loss': 0.4117, 'learning_rate': 1.0749150660619193e-05, 'epoch': 0.49}
 49%|████▉     | 818/1663 [7:06:25<7:33:47, 32.22s/it] 49%|████▉     | 819/1663 [7:06:56<7:28:22, 31.88s/it]                                                      {'loss': 0.356, 'learning_rate': 1.072972727726465e-05, 'epoch': 0.49}
 49%|████▉     | 819/1663 [7:06:56<7:28:22, 31.88s/it] 49%|████▉     | 820/1663 [7:07:28<7:27:49, 31.87s/it]                                                      {'loss': 0.3779, 'learning_rate': 1.0710301125748415e-05, 'epoch': 0.49}
 49%|████▉     | 820/1663 [7:07:28<7:27:49, 31.87s/it] 49%|████▉     | 821/1663 [7:08:01<7:32:20, 32.23s/it]                                                      {'loss': 0.4572, 'learning_rate': 1.0690872279762033e-05, 'epoch': 0.49}
 49%|████▉     | 821/1663 [7:08:01<7:32:20, 32.23s/it] 49%|████▉     | 822/1663 [7:08:33<7:31:03, 32.18s/it]                                                      {'loss': 0.5007, 'learning_rate': 1.0671440813007265e-05, 'epoch': 0.49}
 49%|████▉     | 822/1663 [7:08:33<7:31:03, 32.18s/it] 49%|████▉     | 823/1663 [7:09:04<7:26:20, 31.88s/it]                                                      {'loss': 0.4598, 'learning_rate': 1.0652006799195822e-05, 'epoch': 0.49}
 49%|████▉     | 823/1663 [7:09:04<7:26:20, 31.88s/it] 50%|████▉     | 824/1663 [7:09:35<7:21:05, 31.54s/it]                                                      {'loss': 0.3489, 'learning_rate': 1.0632570312049064e-05, 'epoch': 0.5}
 50%|████▉     | 824/1663 [7:09:35<7:21:05, 31.54s/it] 50%|████▉     | 825/1663 [7:10:06<7:16:41, 31.27s/it]                                                      {'loss': 0.4403, 'learning_rate': 1.0613131425297745e-05, 'epoch': 0.5}
 50%|████▉     | 825/1663 [7:10:06<7:16:41, 31.27s/it] 50%|████▉     | 826/1663 [7:10:38<7:18:57, 31.47s/it]                                                      {'loss': 0.4258, 'learning_rate': 1.0593690212681715e-05, 'epoch': 0.5}
 50%|████▉     | 826/1663 [7:10:38<7:18:57, 31.47s/it] 50%|████▉     | 827/1663 [7:11:09<7:18:15, 31.45s/it]                                                      {'loss': 0.3204, 'learning_rate': 1.0574246747949652e-05, 'epoch': 0.5}
 50%|████▉     | 827/1663 [7:11:09<7:18:15, 31.45s/it] 50%|████▉     | 828/1663 [7:11:39<7:12:57, 31.11s/it]                                                      {'loss': 0.4474, 'learning_rate': 1.0554801104858771e-05, 'epoch': 0.5}
 50%|████▉     | 828/1663 [7:11:39<7:12:57, 31.11s/it] 50%|████▉     | 829/1663 [7:12:11<7:13:22, 31.18s/it]                                                      {'loss': 0.3613, 'learning_rate': 1.0535353357174558e-05, 'epoch': 0.5}
 50%|████▉     | 829/1663 [7:12:11<7:13:22, 31.18s/it] 50%|████▉     | 830/1663 [7:12:42<7:13:45, 31.24s/it]                                                      {'loss': 0.4103, 'learning_rate': 1.0515903578670474e-05, 'epoch': 0.5}
 50%|████▉     | 830/1663 [7:12:42<7:13:45, 31.24s/it] 50%|████▉     | 831/1663 [7:13:13<7:11:21, 31.11s/it]                                                      {'loss': 0.3474, 'learning_rate': 1.0496451843127691e-05, 'epoch': 0.5}
 50%|████▉     | 831/1663 [7:13:13<7:11:21, 31.11s/it] 50%|█████     | 832/1663 [7:13:43<7:06:45, 30.81s/it]                                                      {'loss': 0.3922, 'learning_rate': 1.0476998224334802e-05, 'epoch': 0.5}
 50%|█████     | 832/1663 [7:13:43<7:06:45, 30.81s/it] 50%|█████     | 833/1663 [7:14:16<7:14:43, 31.43s/it]                                                      {'loss': 0.3787, 'learning_rate': 1.045754279608754e-05, 'epoch': 0.5}
 50%|█████     | 833/1663 [7:14:16<7:14:43, 31.43s/it] 50%|█████     | 834/1663 [7:14:47<7:11:52, 31.26s/it]                                                      {'loss': 0.3422, 'learning_rate': 1.0438085632188512e-05, 'epoch': 0.5}
 50%|█████     | 834/1663 [7:14:47<7:11:52, 31.26s/it] 50%|█████     | 835/1663 [7:15:15<7:01:18, 30.53s/it]                                                      {'loss': 0.3663, 'learning_rate': 1.0418626806446901e-05, 'epoch': 0.5}
 50%|█████     | 835/1663 [7:15:15<7:01:18, 30.53s/it] 50%|█████     | 836/1663 [7:15:45<6:58:15, 30.35s/it]                                                      {'loss': 0.3384, 'learning_rate': 1.0399166392678195e-05, 'epoch': 0.5}
 50%|█████     | 836/1663 [7:15:45<6:58:15, 30.35s/it] 50%|█████     | 837/1663 [7:16:16<6:58:56, 30.43s/it]                                                      {'loss': 0.5335, 'learning_rate': 1.0379704464703907e-05, 'epoch': 0.5}
 50%|█████     | 837/1663 [7:16:16<6:58:56, 30.43s/it] 50%|█████     | 838/1663 [7:16:47<6:58:47, 30.46s/it]                                                      {'loss': 0.3482, 'learning_rate': 1.0360241096351297e-05, 'epoch': 0.5}
 50%|█████     | 838/1663 [7:16:47<6:58:47, 30.46s/it] 50%|█████     | 839/1663 [7:17:14<6:45:23, 29.52s/it]                                                      {'loss': 0.3844, 'learning_rate': 1.0340776361453084e-05, 'epoch': 0.5}
 50%|█████     | 839/1663 [7:17:14<6:45:23, 29.52s/it] 51%|█████     | 840/1663 [7:17:44<6:45:34, 29.57s/it]                                                      {'loss': 0.4451, 'learning_rate': 1.0321310333847172e-05, 'epoch': 0.5}
 51%|█████     | 840/1663 [7:17:44<6:45:34, 29.57s/it] 51%|█████     | 841/1663 [7:18:19<7:09:02, 31.32s/it]                                                      {'loss': 0.4187, 'learning_rate': 1.0301843087376373e-05, 'epoch': 0.51}
 51%|█████     | 841/1663 [7:18:19<7:09:02, 31.32s/it] 51%|█████     | 842/1663 [7:18:51<7:11:20, 31.52s/it]                                                      {'loss': 0.38, 'learning_rate': 1.0282374695888116e-05, 'epoch': 0.51}
 51%|█████     | 842/1663 [7:18:51<7:11:20, 31.52s/it] 51%|█████     | 843/1663 [7:19:23<7:11:10, 31.55s/it]                                                      {'loss': 0.4047, 'learning_rate': 1.026290523323418e-05, 'epoch': 0.51}
 51%|█████     | 843/1663 [7:19:23<7:11:10, 31.55s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2588 > 2560). Running this sequence through the model will result in indexing errors
 51%|█████     | 844/1663 [7:19:55<7:14:41, 31.85s/it]                                                      {'loss': 0.5294, 'learning_rate': 1.0243434773270402e-05, 'epoch': 0.51}
 51%|█████     | 844/1663 [7:19:55<7:14:41, 31.85s/it] 51%|█████     | 845/1663 [7:20:26<7:08:37, 31.44s/it]                                                      {'loss': 0.4229, 'learning_rate': 1.0223963389856409e-05, 'epoch': 0.51}
 51%|█████     | 845/1663 [7:20:26<7:08:37, 31.44s/it] 51%|█████     | 846/1663 [7:20:57<7:06:42, 31.34s/it]                                                      {'loss': 0.4518, 'learning_rate': 1.020449115685532e-05, 'epoch': 0.51}
 51%|█████     | 846/1663 [7:20:57<7:06:42, 31.34s/it] 51%|█████     | 847/1663 [7:21:29<7:11:49, 31.75s/it]                                                      {'loss': 0.3095, 'learning_rate': 1.018501814813349e-05, 'epoch': 0.51}
 51%|█████     | 847/1663 [7:21:29<7:11:49, 31.75s/it] 51%|█████     | 848/1663 [7:22:00<7:05:13, 31.30s/it]                                                      {'loss': 0.3299, 'learning_rate': 1.0165544437560207e-05, 'epoch': 0.51}
 51%|█████     | 848/1663 [7:22:00<7:05:13, 31.30s/it] 51%|█████     | 849/1663 [7:22:35<7:19:10, 32.37s/it]                                                      {'loss': 0.4147, 'learning_rate': 1.0146070099007425e-05, 'epoch': 0.51}
 51%|█████     | 849/1663 [7:22:35<7:19:10, 32.37s/it] 51%|█████     | 850/1663 [7:23:06<7:14:11, 32.04s/it]                                                      {'loss': 0.4086, 'learning_rate': 1.012659520634948e-05, 'epoch': 0.51}
 51%|█████     | 850/1663 [7:23:06<7:14:11, 32.04s/it] 51%|█████     | 851/1663 [7:23:33<6:54:54, 30.66s/it]                                                      {'loss': 0.4782, 'learning_rate': 1.0107119833462809e-05, 'epoch': 0.51}
 51%|█████     | 851/1663 [7:23:33<6:54:54, 30.66s/it] 51%|█████     | 852/1663 [7:24:03<6:51:54, 30.47s/it]                                                      {'loss': 0.4889, 'learning_rate': 1.0087644054225672e-05, 'epoch': 0.51}
 51%|█████     | 852/1663 [7:24:03<6:51:54, 30.47s/it] 51%|█████▏    | 853/1663 [7:24:34<6:51:50, 30.51s/it]                                                      {'loss': 0.4777, 'learning_rate': 1.006816794251787e-05, 'epoch': 0.51}
 51%|█████▏    | 853/1663 [7:24:34<6:51:50, 30.51s/it] 51%|█████▏    | 854/1663 [7:25:06<6:56:09, 30.86s/it]                                                      {'loss': 0.4367, 'learning_rate': 1.0048691572220464e-05, 'epoch': 0.51}
 51%|█████▏    | 854/1663 [7:25:06<6:56:09, 30.86s/it] 51%|█████▏    | 855/1663 [7:25:41<7:14:47, 32.29s/it]                                                      {'loss': 0.4731, 'learning_rate': 1.0029215017215499e-05, 'epoch': 0.51}
 51%|█████▏    | 855/1663 [7:25:41<7:14:47, 32.29s/it] 51%|█████▏    | 856/1663 [7:26:10<7:02:10, 31.39s/it]                                                      {'loss': 0.4396, 'learning_rate': 1.0009738351385718e-05, 'epoch': 0.51}
 51%|█████▏    | 856/1663 [7:26:10<7:02:10, 31.39s/it] 52%|█████▏    | 857/1663 [7:26:42<7:00:43, 31.32s/it]                                                      {'loss': 0.4354, 'learning_rate': 9.990261648614285e-06, 'epoch': 0.52}
 52%|█████▏    | 857/1663 [7:26:42<7:00:43, 31.32s/it] 52%|█████▏    | 858/1663 [7:27:15<7:09:14, 31.99s/it]                                                      {'loss': 0.3181, 'learning_rate': 9.970784982784504e-06, 'epoch': 0.52}
 52%|█████▏    | 858/1663 [7:27:15<7:09:14, 31.99s/it] 52%|█████▏    | 859/1663 [7:27:46<7:05:49, 31.78s/it]                                                      {'loss': 0.4109, 'learning_rate': 9.951308427779537e-06, 'epoch': 0.52}
 52%|█████▏    | 859/1663 [7:27:46<7:05:49, 31.78s/it] 52%|█████▏    | 860/1663 [7:28:20<7:13:06, 32.36s/it]                                                      {'loss': 0.3821, 'learning_rate': 9.931832057482134e-06, 'epoch': 0.52}
 52%|█████▏    | 860/1663 [7:28:20<7:13:06, 32.36s/it] 52%|█████▏    | 861/1663 [7:28:53<7:15:09, 32.56s/it]                                                      {'loss': 0.3052, 'learning_rate': 9.912355945774331e-06, 'epoch': 0.52}
 52%|█████▏    | 861/1663 [7:28:53<7:15:09, 32.56s/it] 52%|█████▏    | 862/1663 [7:29:24<7:09:08, 32.15s/it]                                                      {'loss': 0.4619, 'learning_rate': 9.892880166537194e-06, 'epoch': 0.52}
 52%|█████▏    | 862/1663 [7:29:24<7:09:08, 32.15s/it] 52%|█████▏    | 863/1663 [7:29:55<7:03:01, 31.73s/it]                                                      {'loss': 0.3633, 'learning_rate': 9.873404793650524e-06, 'epoch': 0.52}
 52%|█████▏    | 863/1663 [7:29:55<7:03:01, 31.73s/it] 52%|█████▏    | 864/1663 [7:30:26<6:58:22, 31.42s/it]                                                      {'loss': 0.4546, 'learning_rate': 9.853929900992578e-06, 'epoch': 0.52}
 52%|█████▏    | 864/1663 [7:30:26<6:58:22, 31.42s/it] 52%|█████▏    | 865/1663 [7:30:57<6:55:52, 31.27s/it]                                                      {'loss': 0.4938, 'learning_rate': 9.834455562439795e-06, 'epoch': 0.52}
 52%|█████▏    | 865/1663 [7:30:57<6:55:52, 31.27s/it] 52%|█████▏    | 866/1663 [7:31:27<6:49:24, 30.82s/it]                                                      {'loss': 0.3776, 'learning_rate': 9.814981851866513e-06, 'epoch': 0.52}
 52%|█████▏    | 866/1663 [7:31:27<6:49:24, 30.82s/it] 52%|█████▏    | 867/1663 [7:31:53<6:31:25, 29.50s/it]                                                      {'loss': 0.4283, 'learning_rate': 9.795508843144681e-06, 'epoch': 0.52}
 52%|█████▏    | 867/1663 [7:31:53<6:31:25, 29.50s/it] 52%|█████▏    | 868/1663 [7:32:23<6:31:24, 29.54s/it]                                                      {'loss': 0.4389, 'learning_rate': 9.776036610143595e-06, 'epoch': 0.52}
 52%|█████▏    | 868/1663 [7:32:23<6:31:24, 29.54s/it] 52%|█████▏    | 869/1663 [7:32:56<6:46:04, 30.69s/it]                                                      {'loss': 0.4918, 'learning_rate': 9.7565652267296e-06, 'epoch': 0.52}
 52%|█████▏    | 869/1663 [7:32:56<6:46:04, 30.69s/it] 52%|█████▏    | 870/1663 [7:33:29<6:53:30, 31.29s/it]                                                      {'loss': 0.4326, 'learning_rate': 9.737094766765824e-06, 'epoch': 0.52}
 52%|█████▏    | 870/1663 [7:33:29<6:53:30, 31.29s/it] 52%|█████▏    | 871/1663 [7:33:58<6:46:18, 30.78s/it]                                                      {'loss': 0.3852, 'learning_rate': 9.717625304111886e-06, 'epoch': 0.52}
 52%|█████▏    | 871/1663 [7:33:58<6:46:18, 30.78s/it] 52%|█████▏    | 872/1663 [7:34:34<7:06:26, 32.35s/it]                                                      {'loss': 0.2988, 'learning_rate': 9.69815691262363e-06, 'epoch': 0.52}
 52%|█████▏    | 872/1663 [7:34:34<7:06:26, 32.35s/it] 52%|█████▏    | 873/1663 [7:35:07<7:08:01, 32.51s/it]                                                      {'loss': 0.4143, 'learning_rate': 9.67868966615283e-06, 'epoch': 0.52}
 52%|█████▏    | 873/1663 [7:35:07<7:08:01, 32.51s/it] 53%|█████▎    | 874/1663 [7:35:38<7:01:44, 32.07s/it]                                                      {'loss': 0.3532, 'learning_rate': 9.65922363854692e-06, 'epoch': 0.53}
 53%|█████▎    | 874/1663 [7:35:38<7:01:44, 32.07s/it] 53%|█████▎    | 875/1663 [7:36:08<6:53:13, 31.46s/it]                                                      {'loss': 0.3914, 'learning_rate': 9.639758903648706e-06, 'epoch': 0.53}
 53%|█████▎    | 875/1663 [7:36:08<6:53:13, 31.46s/it] 53%|█████▎    | 876/1663 [7:36:41<6:56:40, 31.77s/it]                                                      {'loss': 0.4992, 'learning_rate': 9.620295535296094e-06, 'epoch': 0.53}
 53%|█████▎    | 876/1663 [7:36:41<6:56:40, 31.77s/it] 53%|█████▎    | 877/1663 [7:37:10<6:46:47, 31.05s/it]                                                      {'loss': 0.3274, 'learning_rate': 9.600833607321807e-06, 'epoch': 0.53}
 53%|█████▎    | 877/1663 [7:37:10<6:46:47, 31.05s/it] 53%|█████▎    | 878/1663 [7:37:41<6:46:13, 31.05s/it]                                                      {'loss': 0.4944, 'learning_rate': 9.5813731935531e-06, 'epoch': 0.53}
 53%|█████▎    | 878/1663 [7:37:41<6:46:13, 31.05s/it] 53%|█████▎    | 879/1663 [7:38:13<6:48:08, 31.24s/it]                                                      {'loss': 0.5108, 'learning_rate': 9.56191436781149e-06, 'epoch': 0.53}
 53%|█████▎    | 879/1663 [7:38:13<6:48:08, 31.24s/it] 53%|█████▎    | 880/1663 [7:38:45<6:50:41, 31.47s/it]                                                      {'loss': 0.3617, 'learning_rate': 9.542457203912462e-06, 'epoch': 0.53}
 53%|█████▎    | 880/1663 [7:38:45<6:50:41, 31.47s/it] 53%|█████▎    | 881/1663 [7:39:16<6:48:33, 31.35s/it]                                                      {'loss': 0.423, 'learning_rate': 9.523001775665202e-06, 'epoch': 0.53}
 53%|█████▎    | 881/1663 [7:39:16<6:48:33, 31.35s/it] 53%|█████▎    | 882/1663 [7:39:48<6:52:50, 31.72s/it]                                                      {'loss': 0.3895, 'learning_rate': 9.503548156872312e-06, 'epoch': 0.53}
 53%|█████▎    | 882/1663 [7:39:48<6:52:50, 31.72s/it] 53%|█████▎    | 883/1663 [7:40:19<6:48:32, 31.43s/it]                                                      {'loss': 0.4683, 'learning_rate': 9.484096421329528e-06, 'epoch': 0.53}
 53%|█████▎    | 883/1663 [7:40:19<6:48:32, 31.43s/it] 53%|█████▎    | 884/1663 [7:40:52<6:52:18, 31.76s/it]                                                      {'loss': 0.3939, 'learning_rate': 9.464646642825445e-06, 'epoch': 0.53}
 53%|█████▎    | 884/1663 [7:40:52<6:52:18, 31.76s/it] 53%|█████▎    | 885/1663 [7:41:19<6:33:19, 30.33s/it]                                                      {'loss': 0.5358, 'learning_rate': 9.44519889514123e-06, 'epoch': 0.53}
 53%|█████▎    | 885/1663 [7:41:19<6:33:19, 30.33s/it] 53%|█████▎    | 886/1663 [7:41:51<6:42:02, 31.05s/it]                                                      {'loss': 0.4045, 'learning_rate': 9.425753252050351e-06, 'epoch': 0.53}
 53%|█████▎    | 886/1663 [7:41:51<6:42:02, 31.05s/it] 53%|█████▎    | 887/1663 [7:42:22<6:39:49, 30.91s/it]                                                      {'loss': 0.4762, 'learning_rate': 9.406309787318288e-06, 'epoch': 0.53}
 53%|█████▎    | 887/1663 [7:42:22<6:39:49, 30.91s/it] 53%|█████▎    | 888/1663 [7:42:53<6:41:14, 31.06s/it]                                                      {'loss': 0.5145, 'learning_rate': 9.386868574702259e-06, 'epoch': 0.53}
 53%|█████▎    | 888/1663 [7:42:53<6:41:14, 31.06s/it] 53%|█████▎    | 889/1663 [7:43:24<6:38:58, 30.93s/it]                                                      {'loss': 0.3649, 'learning_rate': 9.367429687950938e-06, 'epoch': 0.53}
 53%|█████▎    | 889/1663 [7:43:24<6:38:58, 30.93s/it] 54%|█████▎    | 890/1663 [7:43:57<6:45:59, 31.51s/it]                                                      {'loss': 0.4106, 'learning_rate': 9.34799320080418e-06, 'epoch': 0.54}
 54%|█████▎    | 890/1663 [7:43:57<6:45:59, 31.51s/it] 54%|█████▎    | 891/1663 [7:44:31<6:56:33, 32.38s/it]                                                      {'loss': 0.3865, 'learning_rate': 9.328559186992737e-06, 'epoch': 0.54}
 54%|█████▎    | 891/1663 [7:44:31<6:56:33, 32.38s/it] 54%|█████▎    | 892/1663 [7:45:04<6:55:56, 32.37s/it]                                                      {'loss': 0.3078, 'learning_rate': 9.30912772023797e-06, 'epoch': 0.54}
 54%|█████▎    | 892/1663 [7:45:04<6:55:56, 32.37s/it] 54%|█████▎    | 893/1663 [7:45:33<6:45:20, 31.59s/it]                                                      {'loss': 0.4287, 'learning_rate': 9.289698874251588e-06, 'epoch': 0.54}
 54%|█████▎    | 893/1663 [7:45:33<6:45:20, 31.59s/it] 54%|█████▍    | 894/1663 [7:46:04<6:40:54, 31.28s/it]                                                      {'loss': 0.4148, 'learning_rate': 9.270272722735353e-06, 'epoch': 0.54}
 54%|█████▍    | 894/1663 [7:46:04<6:40:54, 31.28s/it] 54%|█████▍    | 895/1663 [7:46:35<6:40:42, 31.31s/it]                                                      {'loss': 0.4372, 'learning_rate': 9.250849339380808e-06, 'epoch': 0.54}
 54%|█████▍    | 895/1663 [7:46:35<6:40:42, 31.31s/it] 54%|█████▍    | 896/1663 [7:47:06<6:38:10, 31.15s/it]                                                      {'loss': 0.5819, 'learning_rate': 9.231428797868993e-06, 'epoch': 0.54}
 54%|█████▍    | 896/1663 [7:47:06<6:38:10, 31.15s/it] 54%|█████▍    | 897/1663 [7:47:36<6:32:43, 30.76s/it]                                                      {'loss': 0.4857, 'learning_rate': 9.21201117187017e-06, 'epoch': 0.54}
 54%|█████▍    | 897/1663 [7:47:36<6:32:43, 30.76s/it] 54%|█████▍    | 898/1663 [7:48:06<6:29:29, 30.55s/it]                                                      {'loss': 0.4203, 'learning_rate': 9.192596535043541e-06, 'epoch': 0.54}
 54%|█████▍    | 898/1663 [7:48:06<6:29:29, 30.55s/it] 54%|█████▍    | 899/1663 [7:48:36<6:26:39, 30.37s/it]                                                      {'loss': 0.4066, 'learning_rate': 9.173184961036967e-06, 'epoch': 0.54}
 54%|█████▍    | 899/1663 [7:48:36<6:26:39, 30.37s/it] 54%|█████▍    | 900/1663 [7:49:08<6:31:43, 30.80s/it]                                                      {'loss': 0.427, 'learning_rate': 9.15377652348669e-06, 'epoch': 0.54}
 54%|█████▍    | 900/1663 [7:49:08<6:31:43, 30.80s/it] 54%|█████▍    | 901/1663 [7:49:41<6:38:36, 31.39s/it]                                                      {'loss': 0.3748, 'learning_rate': 9.134371296017059e-06, 'epoch': 0.54}
 54%|█████▍    | 901/1663 [7:49:41<6:38:36, 31.39s/it] 54%|█████▍    | 902/1663 [7:50:15<6:48:44, 32.23s/it]                                                      {'loss': 0.4799, 'learning_rate': 9.11496935224024e-06, 'epoch': 0.54}
 54%|█████▍    | 902/1663 [7:50:15<6:48:44, 32.23s/it] 54%|█████▍    | 903/1663 [7:50:46<6:43:03, 31.82s/it]                                                      {'loss': 0.4659, 'learning_rate': 9.095570765755946e-06, 'epoch': 0.54}
 54%|█████▍    | 903/1663 [7:50:46<6:43:03, 31.82s/it] 54%|█████▍    | 904/1663 [7:51:16<6:37:24, 31.42s/it]                                                      {'loss': 0.4496, 'learning_rate': 9.076175610151154e-06, 'epoch': 0.54}
 54%|█████▍    | 904/1663 [7:51:16<6:37:24, 31.42s/it] 54%|█████▍    | 905/1663 [7:51:47<6:33:36, 31.16s/it]                                                      {'loss': 0.4412, 'learning_rate': 9.056783958999825e-06, 'epoch': 0.54}
 54%|█████▍    | 905/1663 [7:51:47<6:33:36, 31.16s/it] 54%|█████▍    | 906/1663 [7:52:17<6:29:36, 30.88s/it]                                                      {'loss': 0.3911, 'learning_rate': 9.037395885862625e-06, 'epoch': 0.54}
 54%|█████▍    | 906/1663 [7:52:17<6:29:36, 30.88s/it] 55%|█████▍    | 907/1663 [7:52:47<6:25:23, 30.59s/it]                                                      {'loss': 0.2927, 'learning_rate': 9.018011464286652e-06, 'epoch': 0.55}
 55%|█████▍    | 907/1663 [7:52:47<6:25:23, 30.59s/it] 55%|█████▍    | 908/1663 [7:53:18<6:27:52, 30.82s/it]                                                      {'loss': 0.5251, 'learning_rate': 8.998630767805147e-06, 'epoch': 0.55}
 55%|█████▍    | 908/1663 [7:53:18<6:27:52, 30.82s/it] 55%|█████▍    | 909/1663 [7:53:54<6:46:10, 32.32s/it]                                                      {'loss': 0.3823, 'learning_rate': 8.979253869937222e-06, 'epoch': 0.55}
 55%|█████▍    | 909/1663 [7:53:54<6:46:10, 32.32s/it] 55%|█████▍    | 910/1663 [7:54:26<6:43:07, 32.12s/it]                                                      {'loss': 0.4516, 'learning_rate': 8.95988084418758e-06, 'epoch': 0.55}
 55%|█████▍    | 910/1663 [7:54:26<6:43:07, 32.12s/it] 55%|█████▍    | 911/1663 [7:55:00<6:49:53, 32.70s/it]                                                      {'loss': 0.4243, 'learning_rate': 8.940511764046235e-06, 'epoch': 0.55}
 55%|█████▍    | 911/1663 [7:55:00<6:49:53, 32.70s/it] 55%|█████▍    | 912/1663 [7:55:32<6:48:56, 32.67s/it]                                                      {'loss': 0.3072, 'learning_rate': 8.921146702988234e-06, 'epoch': 0.55}
 55%|█████▍    | 912/1663 [7:55:32<6:48:56, 32.67s/it] 55%|█████▍    | 913/1663 [7:56:06<6:51:54, 32.95s/it]                                                      {'loss': 0.4958, 'learning_rate': 8.901785734473376e-06, 'epoch': 0.55}
 55%|█████▍    | 913/1663 [7:56:06<6:51:54, 32.95s/it] 55%|█████▍    | 914/1663 [7:56:38<6:47:49, 32.67s/it]                                                      {'loss': 0.3942, 'learning_rate': 8.882428931945937e-06, 'epoch': 0.55}
 55%|█████▍    | 914/1663 [7:56:38<6:47:49, 32.67s/it] 55%|█████▌    | 915/1663 [7:57:08<6:36:24, 31.80s/it]                                                      {'loss': 0.5291, 'learning_rate': 8.86307636883439e-06, 'epoch': 0.55}
 55%|█████▌    | 915/1663 [7:57:08<6:36:24, 31.80s/it] 55%|█████▌    | 916/1663 [7:57:38<6:31:10, 31.42s/it]                                                      {'loss': 0.4378, 'learning_rate': 8.843728118551124e-06, 'epoch': 0.55}
 55%|█████▌    | 916/1663 [7:57:38<6:31:10, 31.42s/it] 55%|█████▌    | 917/1663 [7:58:08<6:24:28, 30.92s/it]                                                      {'loss': 0.4549, 'learning_rate': 8.824384254492171e-06, 'epoch': 0.55}
 55%|█████▌    | 917/1663 [7:58:08<6:24:28, 30.92s/it] 55%|█████▌    | 918/1663 [7:58:39<6:23:13, 30.86s/it]                                                      {'loss': 0.4099, 'learning_rate': 8.805044850036924e-06, 'epoch': 0.55}
 55%|█████▌    | 918/1663 [7:58:39<6:23:13, 30.86s/it] 55%|█████▌    | 919/1663 [7:59:11<6:26:26, 31.16s/it]                                                      {'loss': 0.3655, 'learning_rate': 8.785709978547852e-06, 'epoch': 0.55}
 55%|█████▌    | 919/1663 [7:59:11<6:26:26, 31.16s/it] 55%|█████▌    | 920/1663 [7:59:40<6:20:23, 30.72s/it]                                                      {'loss': 0.4549, 'learning_rate': 8.766379713370237e-06, 'epoch': 0.55}
 55%|█████▌    | 920/1663 [7:59:40<6:20:23, 30.72s/it] 55%|█████▌    | 921/1663 [8:00:12<6:25:32, 31.18s/it]                                                      {'loss': 0.3658, 'learning_rate': 8.747054127831882e-06, 'epoch': 0.55}
 55%|█████▌    | 921/1663 [8:00:12<6:25:32, 31.18s/it] 55%|█████▌    | 922/1663 [8:00:42<6:20:03, 30.77s/it]                                                      {'loss': 0.4544, 'learning_rate': 8.727733295242842e-06, 'epoch': 0.55}
 55%|█████▌    | 922/1663 [8:00:42<6:20:03, 30.77s/it] 56%|█████▌    | 923/1663 [8:01:13<6:19:32, 30.77s/it]                                                      {'loss': 0.442, 'learning_rate': 8.708417288895141e-06, 'epoch': 0.55}
 56%|█████▌    | 923/1663 [8:01:13<6:19:32, 30.77s/it] 56%|█████▌    | 924/1663 [8:01:45<6:21:57, 31.01s/it]                                                      {'loss': 0.423, 'learning_rate': 8.689106182062493e-06, 'epoch': 0.56}
 56%|█████▌    | 924/1663 [8:01:45<6:21:57, 31.01s/it] 56%|█████▌    | 925/1663 [8:02:20<6:35:36, 32.16s/it]                                                      {'loss': 0.4499, 'learning_rate': 8.669800048000027e-06, 'epoch': 0.56}
 56%|█████▌    | 925/1663 [8:02:20<6:35:36, 32.16s/it] 56%|█████▌    | 926/1663 [8:02:51<6:34:08, 32.09s/it]                                                      {'loss': 0.3582, 'learning_rate': 8.650498959944009e-06, 'epoch': 0.56}
 56%|█████▌    | 926/1663 [8:02:51<6:34:08, 32.09s/it] 56%|█████▌    | 927/1663 [8:03:20<6:18:56, 30.89s/it]                                                      {'loss': 0.3977, 'learning_rate': 8.631202991111563e-06, 'epoch': 0.56}
 56%|█████▌    | 927/1663 [8:03:20<6:18:56, 30.89s/it] 56%|█████▌    | 928/1663 [8:03:53<6:28:27, 31.71s/it]                                                      {'loss': 0.4506, 'learning_rate': 8.611912214700393e-06, 'epoch': 0.56}
 56%|█████▌    | 928/1663 [8:03:53<6:28:27, 31.71s/it] 56%|█████▌    | 929/1663 [8:04:26<6:33:00, 32.13s/it]                                                      {'loss': 0.2773, 'learning_rate': 8.592626703888508e-06, 'epoch': 0.56}
 56%|█████▌    | 929/1663 [8:04:26<6:33:00, 32.13s/it] 56%|█████▌    | 930/1663 [8:04:57<6:26:04, 31.60s/it]                                                      {'loss': 0.3247, 'learning_rate': 8.57334653183394e-06, 'epoch': 0.56}
 56%|█████▌    | 930/1663 [8:04:57<6:26:04, 31.60s/it] 56%|█████▌    | 931/1663 [8:05:29<6:30:10, 31.98s/it]                                                      {'loss': 0.292, 'learning_rate': 8.55407177167447e-06, 'epoch': 0.56}
 56%|█████▌    | 931/1663 [8:05:29<6:30:10, 31.98s/it] 56%|█████▌    | 932/1663 [8:06:01<6:26:15, 31.70s/it]                                                      {'loss': 0.4552, 'learning_rate': 8.53480249652735e-06, 'epoch': 0.56}
 56%|█████▌    | 932/1663 [8:06:01<6:26:15, 31.70s/it] 56%|█████▌    | 933/1663 [8:06:31<6:20:58, 31.31s/it]                                                      {'loss': 0.3669, 'learning_rate': 8.515538779489023e-06, 'epoch': 0.56}
 56%|█████▌    | 933/1663 [8:06:31<6:20:58, 31.31s/it] 56%|█████▌    | 934/1663 [8:07:02<6:19:00, 31.19s/it]                                                      {'loss': 0.4349, 'learning_rate': 8.496280693634849e-06, 'epoch': 0.56}
 56%|█████▌    | 934/1663 [8:07:02<6:19:00, 31.19s/it] 56%|█████▌    | 935/1663 [8:07:35<6:26:47, 31.88s/it]                                                      {'loss': 0.4507, 'learning_rate': 8.477028312018827e-06, 'epoch': 0.56}
 56%|█████▌    | 935/1663 [8:07:35<6:26:47, 31.88s/it] 56%|█████▋    | 936/1663 [8:08:08<6:30:43, 32.25s/it]                                                      {'loss': 0.4085, 'learning_rate': 8.457781707673317e-06, 'epoch': 0.56}
 56%|█████▋    | 936/1663 [8:08:08<6:30:43, 32.25s/it] 56%|█████▋    | 937/1663 [8:08:40<6:27:03, 31.99s/it]                                                      {'loss': 0.38, 'learning_rate': 8.438540953608764e-06, 'epoch': 0.56}
 56%|█████▋    | 937/1663 [8:08:40<6:27:03, 31.99s/it] 56%|█████▋    | 938/1663 [8:09:12<6:27:30, 32.07s/it]                                                      {'loss': 0.3734, 'learning_rate': 8.419306122813418e-06, 'epoch': 0.56}
 56%|█████▋    | 938/1663 [8:09:12<6:27:30, 32.07s/it] 56%|█████▋    | 939/1663 [8:09:44<6:25:57, 31.99s/it]                                                      {'loss': 0.3679, 'learning_rate': 8.400077288253064e-06, 'epoch': 0.56}
 56%|█████▋    | 939/1663 [8:09:44<6:25:57, 31.99s/it] 57%|█████▋    | 940/1663 [8:10:15<6:23:03, 31.79s/it]                                                      {'loss': 0.3568, 'learning_rate': 8.380854522870737e-06, 'epoch': 0.57}
 57%|█████▋    | 940/1663 [8:10:15<6:23:03, 31.79s/it] 57%|█████▋    | 941/1663 [8:10:48<6:24:31, 31.95s/it]                                                      {'loss': 0.3509, 'learning_rate': 8.361637899586448e-06, 'epoch': 0.57}
 57%|█████▋    | 941/1663 [8:10:48<6:24:31, 31.95s/it] 57%|█████▋    | 942/1663 [8:11:16<6:10:11, 30.81s/it]                                                      {'loss': 0.3831, 'learning_rate': 8.342427491296915e-06, 'epoch': 0.57}
 57%|█████▋    | 942/1663 [8:11:16<6:10:11, 30.81s/it] 57%|█████▋    | 943/1663 [8:11:46<6:07:23, 30.62s/it]                                                      {'loss': 0.3363, 'learning_rate': 8.323223370875271e-06, 'epoch': 0.57}
 57%|█████▋    | 943/1663 [8:11:46<6:07:23, 30.62s/it] 57%|█████▋    | 944/1663 [8:12:19<6:15:23, 31.33s/it]                                                      {'loss': 0.4327, 'learning_rate': 8.304025611170804e-06, 'epoch': 0.57}
 57%|█████▋    | 944/1663 [8:12:19<6:15:23, 31.33s/it] 57%|█████▋    | 945/1663 [8:12:51<6:18:21, 31.62s/it]                                                      {'loss': 0.5765, 'learning_rate': 8.284834285008672e-06, 'epoch': 0.57}
 57%|█████▋    | 945/1663 [8:12:51<6:18:21, 31.62s/it] 57%|█████▋    | 946/1663 [8:13:21<6:11:06, 31.05s/it]                                                      {'loss': 0.3972, 'learning_rate': 8.26564946518962e-06, 'epoch': 0.57}
 57%|█████▋    | 946/1663 [8:13:21<6:11:06, 31.05s/it] 57%|█████▋    | 947/1663 [8:13:54<6:18:41, 31.73s/it]                                                      {'loss': 0.3582, 'learning_rate': 8.246471224489723e-06, 'epoch': 0.57}
 57%|█████▋    | 947/1663 [8:13:54<6:18:41, 31.73s/it] 57%|█████▋    | 948/1663 [8:14:25<6:14:23, 31.42s/it]                                                      {'loss': 0.3841, 'learning_rate': 8.227299635660092e-06, 'epoch': 0.57}
 57%|█████▋    | 948/1663 [8:14:25<6:14:23, 31.42s/it] 57%|█████▋    | 949/1663 [8:14:56<6:11:07, 31.19s/it]                                                      {'loss': 0.3707, 'learning_rate': 8.208134771426605e-06, 'epoch': 0.57}
 57%|█████▋    | 949/1663 [8:14:56<6:11:07, 31.19s/it] 57%|█████▋    | 950/1663 [8:15:28<6:15:41, 31.61s/it]                                                      {'loss': 0.3819, 'learning_rate': 8.188976704489633e-06, 'epoch': 0.57}
 57%|█████▋    | 950/1663 [8:15:28<6:15:41, 31.61s/it] 57%|█████▋    | 951/1663 [8:15:59<6:13:13, 31.45s/it]                                                      {'loss': 0.4234, 'learning_rate': 8.169825507523759e-06, 'epoch': 0.57}
 57%|█████▋    | 951/1663 [8:15:59<6:13:13, 31.45s/it] 57%|█████▋    | 952/1663 [8:16:30<6:11:57, 31.39s/it]                                                      {'loss': 0.5488, 'learning_rate': 8.15068125317751e-06, 'epoch': 0.57}
 57%|█████▋    | 952/1663 [8:16:30<6:11:57, 31.39s/it] 57%|█████▋    | 953/1663 [8:17:01<6:09:53, 31.26s/it]                                                      {'loss': 0.2922, 'learning_rate': 8.131544014073073e-06, 'epoch': 0.57}
 57%|█████▋    | 953/1663 [8:17:01<6:09:53, 31.26s/it] 57%|█████▋    | 954/1663 [8:17:33<6:10:44, 31.37s/it]                                                      {'loss': 0.468, 'learning_rate': 8.112413862806021e-06, 'epoch': 0.57}
 57%|█████▋    | 954/1663 [8:17:33<6:10:44, 31.37s/it] 57%|█████▋    | 955/1663 [8:18:04<6:07:42, 31.16s/it]                                                      {'loss': 0.36, 'learning_rate': 8.093290871945047e-06, 'epoch': 0.57}
 57%|█████▋    | 955/1663 [8:18:04<6:07:42, 31.16s/it] 57%|█████▋    | 956/1663 [8:18:35<6:06:06, 31.07s/it]                                                      {'loss': 0.5276, 'learning_rate': 8.074175114031678e-06, 'epoch': 0.57}
 57%|█████▋    | 956/1663 [8:18:35<6:06:06, 31.07s/it] 58%|█████▊    | 957/1663 [8:19:07<6:09:03, 31.36s/it]                                                      {'loss': 0.3561, 'learning_rate': 8.05506666158e-06, 'epoch': 0.58}
 58%|█████▊    | 957/1663 [8:19:07<6:09:03, 31.36s/it] 58%|█████▊    | 958/1663 [8:19:38<6:07:33, 31.28s/it]                                                      {'loss': 0.4114, 'learning_rate': 8.035965587076393e-06, 'epoch': 0.58}
 58%|█████▊    | 958/1663 [8:19:38<6:07:33, 31.28s/it] 58%|█████▊    | 959/1663 [8:20:09<6:08:39, 31.42s/it]                                                      {'loss': 0.3888, 'learning_rate': 8.01687196297924e-06, 'epoch': 0.58}
 58%|█████▊    | 959/1663 [8:20:09<6:08:39, 31.42s/it] 58%|█████▊    | 960/1663 [8:20:42<6:10:56, 31.66s/it]                                                      {'loss': 0.3583, 'learning_rate': 7.997785861718673e-06, 'epoch': 0.58}
 58%|█████▊    | 960/1663 [8:20:42<6:10:56, 31.66s/it] 58%|█████▊    | 961/1663 [8:21:12<6:07:27, 31.41s/it]                                                      {'loss': 0.3598, 'learning_rate': 7.978707355696276e-06, 'epoch': 0.58}
 58%|█████▊    | 961/1663 [8:21:12<6:07:27, 31.41s/it] 58%|█████▊    | 962/1663 [8:21:42<6:00:54, 30.89s/it]                                                      {'loss': 0.399, 'learning_rate': 7.95963651728483e-06, 'epoch': 0.58}
 58%|█████▊    | 962/1663 [8:21:42<6:00:54, 30.89s/it] 58%|█████▊    | 963/1663 [8:22:13<5:59:47, 30.84s/it]                                                      {'loss': 0.3176, 'learning_rate': 7.940573418828022e-06, 'epoch': 0.58}
 58%|█████▊    | 963/1663 [8:22:13<5:59:47, 30.84s/it] 58%|█████▊    | 964/1663 [8:22:48<6:13:26, 32.06s/it]                                                      {'loss': 0.57, 'learning_rate': 7.921518132640185e-06, 'epoch': 0.58}
 58%|█████▊    | 964/1663 [8:22:48<6:13:26, 32.06s/it] 58%|█████▊    | 965/1663 [8:23:17<6:03:53, 31.28s/it]                                                      {'loss': 0.4127, 'learning_rate': 7.90247073100601e-06, 'epoch': 0.58}
 58%|█████▊    | 965/1663 [8:23:17<6:03:53, 31.28s/it] 58%|█████▊    | 966/1663 [8:23:48<6:02:33, 31.21s/it]                                                      {'loss': 0.4483, 'learning_rate': 7.883431286180286e-06, 'epoch': 0.58}
 58%|█████▊    | 966/1663 [8:23:48<6:02:33, 31.21s/it] 58%|█████▊    | 967/1663 [8:24:22<6:09:30, 31.85s/it]                                                      {'loss': 0.37, 'learning_rate': 7.86439987038761e-06, 'epoch': 0.58}
 58%|█████▊    | 967/1663 [8:24:22<6:09:30, 31.85s/it] 58%|█████▊    | 968/1663 [8:24:52<6:02:26, 31.29s/it]                                                      {'loss': 0.3307, 'learning_rate': 7.845376555822128e-06, 'epoch': 0.58}
 58%|█████▊    | 968/1663 [8:24:52<6:02:26, 31.29s/it] 58%|█████▊    | 969/1663 [8:25:23<6:03:12, 31.40s/it]                                                      {'loss': 0.4398, 'learning_rate': 7.826361414647254e-06, 'epoch': 0.58}
 58%|█████▊    | 969/1663 [8:25:23<6:03:12, 31.40s/it] 58%|█████▊    | 970/1663 [8:25:53<5:56:21, 30.85s/it]                                                      {'loss': 0.4442, 'learning_rate': 7.807354518995393e-06, 'epoch': 0.58}
 58%|█████▊    | 970/1663 [8:25:53<5:56:21, 30.85s/it] 58%|█████▊    | 971/1663 [8:26:21<5:46:48, 30.07s/it]                                                      {'loss': 0.4347, 'learning_rate': 7.788355940967675e-06, 'epoch': 0.58}
 58%|█████▊    | 971/1663 [8:26:21<5:46:48, 30.07s/it] 58%|█████▊    | 972/1663 [8:26:54<5:55:33, 30.87s/it]                                                      {'loss': 0.4282, 'learning_rate': 7.769365752633676e-06, 'epoch': 0.58}
 58%|█████▊    | 972/1663 [8:26:54<5:55:33, 30.87s/it] 59%|█████▊    | 973/1663 [8:27:25<5:55:25, 30.91s/it]                                                      {'loss': 0.512, 'learning_rate': 7.750384026031148e-06, 'epoch': 0.58}
 59%|█████▊    | 973/1663 [8:27:25<5:55:25, 30.91s/it] 59%|█████▊    | 974/1663 [8:27:58<6:02:37, 31.58s/it]                                                      {'loss': 0.4037, 'learning_rate': 7.731410833165741e-06, 'epoch': 0.59}
 59%|█████▊    | 974/1663 [8:27:58<6:02:37, 31.58s/it] 59%|█████▊    | 975/1663 [8:28:33<6:13:53, 32.61s/it]                                                      {'loss': 0.4023, 'learning_rate': 7.712446246010738e-06, 'epoch': 0.59}
 59%|█████▊    | 975/1663 [8:28:33<6:13:53, 32.61s/it] 59%|█████▊    | 976/1663 [8:29:07<6:18:17, 33.04s/it]                                                      {'loss': 0.4668, 'learning_rate': 7.69349033650677e-06, 'epoch': 0.59}
 59%|█████▊    | 976/1663 [8:29:07<6:18:17, 33.04s/it] 59%|█████▊    | 977/1663 [8:29:37<6:06:34, 32.06s/it]                                                      {'loss': 0.4354, 'learning_rate': 7.674543176561558e-06, 'epoch': 0.59}
 59%|█████▊    | 977/1663 [8:29:37<6:06:34, 32.06s/it] 59%|█████▉    | 978/1663 [8:30:08<6:04:18, 31.91s/it]                                                      {'loss': 0.4035, 'learning_rate': 7.655604838049623e-06, 'epoch': 0.59}
 59%|█████▉    | 978/1663 [8:30:08<6:04:18, 31.91s/it] 59%|█████▉    | 979/1663 [8:30:39<5:59:16, 31.52s/it]                                                      {'loss': 0.4532, 'learning_rate': 7.636675392812033e-06, 'epoch': 0.59}
 59%|█████▉    | 979/1663 [8:30:39<5:59:16, 31.52s/it] 59%|█████▉    | 980/1663 [8:31:11<6:00:44, 31.69s/it]                                                      {'loss': 0.3858, 'learning_rate': 7.6177549126561135e-06, 'epoch': 0.59}
 59%|█████▉    | 980/1663 [8:31:11<6:00:44, 31.69s/it] 59%|█████▉    | 981/1663 [8:31:41<5:55:16, 31.26s/it]                                                      {'loss': 0.3947, 'learning_rate': 7.598843469355181e-06, 'epoch': 0.59}
 59%|█████▉    | 981/1663 [8:31:41<5:55:16, 31.26s/it] 59%|█████▉    | 982/1663 [8:32:12<5:52:27, 31.05s/it]                                                      {'loss': 0.4089, 'learning_rate': 7.579941134648275e-06, 'epoch': 0.59}
 59%|█████▉    | 982/1663 [8:32:12<5:52:27, 31.05s/it] 59%|█████▉    | 983/1663 [8:32:43<5:52:56, 31.14s/it]                                                      {'loss': 0.5646, 'learning_rate': 7.5610479802398815e-06, 'epoch': 0.59}
 59%|█████▉    | 983/1663 [8:32:43<5:52:56, 31.14s/it] 59%|█████▉    | 984/1663 [8:33:13<5:47:04, 30.67s/it]                                                      {'loss': 0.4461, 'learning_rate': 7.542164077799659e-06, 'epoch': 0.59}
 59%|█████▉    | 984/1663 [8:33:13<5:47:04, 30.67s/it] 59%|█████▉    | 985/1663 [8:33:46<5:54:59, 31.42s/it]                                                      {'loss': 0.3284, 'learning_rate': 7.523289498962172e-06, 'epoch': 0.59}
 59%|█████▉    | 985/1663 [8:33:46<5:54:59, 31.42s/it] 59%|█████▉    | 986/1663 [8:34:17<5:53:39, 31.34s/it]                                                      {'loss': 0.3539, 'learning_rate': 7.5044243153266175e-06, 'epoch': 0.59}
 59%|█████▉    | 986/1663 [8:34:17<5:53:39, 31.34s/it] 59%|█████▉    | 987/1663 [8:34:46<5:43:24, 30.48s/it]                                                      {'loss': 0.4426, 'learning_rate': 7.48556859845655e-06, 'epoch': 0.59}
 59%|█████▉    | 987/1663 [8:34:46<5:43:24, 30.48s/it] 59%|█████▉    | 988/1663 [8:35:16<5:43:01, 30.49s/it]                                                      {'loss': 0.3959, 'learning_rate': 7.4667224198796125e-06, 'epoch': 0.59}
 59%|█████▉    | 988/1663 [8:35:16<5:43:01, 30.49s/it] 59%|█████▉    | 989/1663 [8:35:46<5:39:28, 30.22s/it]                                                      {'loss': 0.3787, 'learning_rate': 7.447885851087269e-06, 'epoch': 0.59}
 59%|█████▉    | 989/1663 [8:35:46<5:39:28, 30.22s/it] 60%|█████▉    | 990/1663 [8:36:20<5:53:28, 31.51s/it]                                                      {'loss': 0.4215, 'learning_rate': 7.429058963534525e-06, 'epoch': 0.6}
 60%|█████▉    | 990/1663 [8:36:20<5:53:28, 31.51s/it] 60%|█████▉    | 991/1663 [8:36:52<5:53:02, 31.52s/it]                                                      {'loss': 0.3896, 'learning_rate': 7.4102418286396635e-06, 'epoch': 0.6}
 60%|█████▉    | 991/1663 [8:36:52<5:53:02, 31.52s/it] 60%|█████▉    | 992/1663 [8:37:19<5:39:04, 30.32s/it]                                                      {'loss': 0.5001, 'learning_rate': 7.391434517783973e-06, 'epoch': 0.6}
 60%|█████▉    | 992/1663 [8:37:19<5:39:04, 30.32s/it] 60%|█████▉    | 993/1663 [8:37:49<5:37:49, 30.25s/it]                                                      {'loss': 0.4131, 'learning_rate': 7.372637102311471e-06, 'epoch': 0.6}
 60%|█████▉    | 993/1663 [8:37:49<5:37:49, 30.25s/it] 60%|█████▉    | 994/1663 [8:38:20<5:37:49, 30.30s/it]                                                      {'loss': 0.3506, 'learning_rate': 7.353849653528642e-06, 'epoch': 0.6}
 60%|█████▉    | 994/1663 [8:38:20<5:37:49, 30.30s/it] 60%|█████▉    | 995/1663 [8:38:52<5:43:16, 30.83s/it]                                                      {'loss': 0.4334, 'learning_rate': 7.335072242704157e-06, 'epoch': 0.6}
 60%|█████▉    | 995/1663 [8:38:52<5:43:16, 30.83s/it] 60%|█████▉    | 996/1663 [8:39:23<5:42:35, 30.82s/it]                                                      {'loss': 0.4093, 'learning_rate': 7.316304941068618e-06, 'epoch': 0.6}
 60%|█████▉    | 996/1663 [8:39:23<5:42:35, 30.82s/it] 60%|█████▉    | 997/1663 [8:39:54<5:44:30, 31.04s/it]                                                      {'loss': 0.3488, 'learning_rate': 7.297547819814269e-06, 'epoch': 0.6}
 60%|█████▉    | 997/1663 [8:39:54<5:44:30, 31.04s/it] 60%|██████    | 998/1663 [8:40:24<5:41:02, 30.77s/it]                                                      {'loss': 0.459, 'learning_rate': 7.278800950094742e-06, 'epoch': 0.6}
 60%|██████    | 998/1663 [8:40:24<5:41:02, 30.77s/it] 60%|██████    | 999/1663 [8:40:57<5:46:49, 31.34s/it]                                                      {'loss': 0.3654, 'learning_rate': 7.260064403024776e-06, 'epoch': 0.6}
 60%|██████    | 999/1663 [8:40:57<5:46:49, 31.34s/it] 60%|██████    | 1000/1663 [8:41:31<5:54:30, 32.08s/it]                                                       {'loss': 0.395, 'learning_rate': 7.241338249679956e-06, 'epoch': 0.6}
 60%|██████    | 1000/1663 [8:41:31<5:54:30, 32.08s/it] 60%|██████    | 1001/1663 [8:42:03<5:55:06, 32.19s/it]                                                       {'loss': 0.4081, 'learning_rate': 7.222622561096437e-06, 'epoch': 0.6}
 60%|██████    | 1001/1663 [8:42:03<5:55:06, 32.19s/it] 60%|██████    | 1002/1663 [8:42:30<5:35:10, 30.42s/it]                                                       {'loss': 0.4827, 'learning_rate': 7.203917408270677e-06, 'epoch': 0.6}
 60%|██████    | 1002/1663 [8:42:30<5:35:10, 30.42s/it] 60%|██████    | 1003/1663 [8:43:01<5:38:48, 30.80s/it]                                                       {'loss': 0.4182, 'learning_rate': 7.185222862159168e-06, 'epoch': 0.6}
 60%|██████    | 1003/1663 [8:43:01<5:38:48, 30.80s/it] 60%|██████    | 1004/1663 [8:43:32<5:36:43, 30.66s/it]                                                       {'loss': 0.4305, 'learning_rate': 7.1665389936781644e-06, 'epoch': 0.6}
 60%|██████    | 1004/1663 [8:43:32<5:36:43, 30.66s/it] 60%|██████    | 1005/1663 [8:44:01<5:31:22, 30.22s/it]                                                       {'loss': 0.4141, 'learning_rate': 7.147865873703421e-06, 'epoch': 0.6}
 60%|██████    | 1005/1663 [8:44:01<5:31:22, 30.22s/it] 60%|██████    | 1006/1663 [8:44:36<5:45:51, 31.58s/it]                                                       {'loss': 0.3222, 'learning_rate': 7.129203573069912e-06, 'epoch': 0.6}
 60%|██████    | 1006/1663 [8:44:36<5:45:51, 31.58s/it] 61%|██████    | 1007/1663 [8:45:06<5:40:40, 31.16s/it]                                                       {'loss': 0.4343, 'learning_rate': 7.110552162571574e-06, 'epoch': 0.61}
 61%|██████    | 1007/1663 [8:45:06<5:40:40, 31.16s/it] 61%|██████    | 1008/1663 [8:45:36<5:38:23, 31.00s/it]                                                       {'loss': 0.2643, 'learning_rate': 7.091911712961031e-06, 'epoch': 0.61}
 61%|██████    | 1008/1663 [8:45:36<5:38:23, 31.00s/it] 61%|██████    | 1009/1663 [8:46:07<5:36:07, 30.84s/it]                                                       {'loss': 0.5082, 'learning_rate': 7.0732822949493275e-06, 'epoch': 0.61}
 61%|██████    | 1009/1663 [8:46:07<5:36:07, 30.84s/it] 61%|██████    | 1010/1663 [8:46:39<5:38:27, 31.10s/it]                                                       {'loss': 0.3087, 'learning_rate': 7.0546639792056624e-06, 'epoch': 0.61}
 61%|██████    | 1010/1663 [8:46:39<5:38:27, 31.10s/it] 61%|██████    | 1011/1663 [8:47:11<5:42:06, 31.48s/it]                                                       {'loss': 0.3695, 'learning_rate': 7.036056836357119e-06, 'epoch': 0.61}
 61%|██████    | 1011/1663 [8:47:11<5:42:06, 31.48s/it] 61%|██████    | 1012/1663 [8:47:40<5:35:26, 30.92s/it]                                                       {'loss': 0.5132, 'learning_rate': 7.0174609369883925e-06, 'epoch': 0.61}
 61%|██████    | 1012/1663 [8:47:40<5:35:26, 30.92s/it] 61%|██████    | 1013/1663 [8:48:12<5:36:55, 31.10s/it]                                                       {'loss': 0.3415, 'learning_rate': 6.998876351641534e-06, 'epoch': 0.61}
 61%|██████    | 1013/1663 [8:48:12<5:36:55, 31.10s/it] 61%|██████    | 1014/1663 [8:48:47<5:50:10, 32.37s/it]                                                       {'loss': 0.3667, 'learning_rate': 6.98030315081567e-06, 'epoch': 0.61}
 61%|██████    | 1014/1663 [8:48:47<5:50:10, 32.37s/it] 61%|██████    | 1015/1663 [8:49:17<5:39:56, 31.48s/it]                                                       {'loss': 0.4791, 'learning_rate': 6.961741404966743e-06, 'epoch': 0.61}
 61%|██████    | 1015/1663 [8:49:17<5:39:56, 31.48s/it] 61%|██████    | 1016/1663 [8:49:49<5:43:20, 31.84s/it]                                                       {'loss': 0.354, 'learning_rate': 6.943191184507243e-06, 'epoch': 0.61}
 61%|██████    | 1016/1663 [8:49:49<5:43:20, 31.84s/it] 61%|██████    | 1017/1663 [8:50:20<5:38:52, 31.47s/it]                                                       {'loss': 0.4148, 'learning_rate': 6.924652559805935e-06, 'epoch': 0.61}
 61%|██████    | 1017/1663 [8:50:20<5:38:52, 31.47s/it] 61%|██████    | 1018/1663 [8:50:51<5:36:27, 31.30s/it]                                                       {'loss': 0.3502, 'learning_rate': 6.906125601187606e-06, 'epoch': 0.61}
 61%|██████    | 1018/1663 [8:50:51<5:36:27, 31.30s/it] 61%|██████▏   | 1019/1663 [8:51:24<5:41:40, 31.83s/it]                                                       {'loss': 0.4151, 'learning_rate': 6.887610378932773e-06, 'epoch': 0.61}
 61%|██████▏   | 1019/1663 [8:51:24<5:41:40, 31.83s/it] 61%|██████▏   | 1020/1663 [8:52:00<5:53:56, 33.03s/it]                                                       {'loss': 0.3805, 'learning_rate': 6.86910696327745e-06, 'epoch': 0.61}
 61%|██████▏   | 1020/1663 [8:52:00<5:53:56, 33.03s/it] 61%|██████▏   | 1021/1663 [8:52:31<5:47:57, 32.52s/it]                                                       {'loss': 0.4342, 'learning_rate': 6.85061542441285e-06, 'epoch': 0.61}
 61%|██████▏   | 1021/1663 [8:52:31<5:47:57, 32.52s/it] 61%|██████▏   | 1022/1663 [8:53:03<5:43:45, 32.18s/it]                                                       {'loss': 0.4529, 'learning_rate': 6.83213583248514e-06, 'epoch': 0.61}
 61%|██████▏   | 1022/1663 [8:53:03<5:43:45, 32.18s/it] 62%|██████▏   | 1023/1663 [8:53:33<5:37:45, 31.67s/it]                                                       {'loss': 0.4021, 'learning_rate': 6.813668257595163e-06, 'epoch': 0.61}
 62%|██████▏   | 1023/1663 [8:53:33<5:37:45, 31.67s/it] 62%|██████▏   | 1024/1663 [8:54:04<5:34:12, 31.38s/it]                                                       {'loss': 0.4266, 'learning_rate': 6.7952127697981784e-06, 'epoch': 0.62}
 62%|██████▏   | 1024/1663 [8:54:04<5:34:12, 31.38s/it] 62%|██████▏   | 1025/1663 [8:54:35<5:33:18, 31.35s/it]                                                       {'loss': 0.4148, 'learning_rate': 6.776769439103592e-06, 'epoch': 0.62}
 62%|██████▏   | 1025/1663 [8:54:35<5:33:18, 31.35s/it] 62%|██████▏   | 1026/1663 [8:55:07<5:36:06, 31.66s/it]                                                       {'loss': 0.4614, 'learning_rate': 6.758338335474697e-06, 'epoch': 0.62}
 62%|██████▏   | 1026/1663 [8:55:07<5:36:06, 31.66s/it] 62%|██████▏   | 1027/1663 [8:55:38<5:32:53, 31.40s/it]                                                       {'loss': 0.4376, 'learning_rate': 6.739919528828399e-06, 'epoch': 0.62}
 62%|██████▏   | 1027/1663 [8:55:38<5:32:53, 31.40s/it] 62%|██████▏   | 1028/1663 [8:56:11<5:35:53, 31.74s/it]                                                       {'loss': 0.288, 'learning_rate': 6.72151308903496e-06, 'epoch': 0.62}
 62%|██████▏   | 1028/1663 [8:56:11<5:35:53, 31.74s/it] 62%|██████▏   | 1029/1663 [8:56:43<5:36:38, 31.86s/it]                                                       {'loss': 0.3782, 'learning_rate': 6.703119085917728e-06, 'epoch': 0.62}
 62%|██████▏   | 1029/1663 [8:56:43<5:36:38, 31.86s/it] 62%|██████▏   | 1030/1663 [8:57:17<5:42:02, 32.42s/it]                                                       {'loss': 0.404, 'learning_rate': 6.684737589252872e-06, 'epoch': 0.62}
 62%|██████▏   | 1030/1663 [8:57:17<5:42:02, 32.42s/it] 62%|██████▏   | 1031/1663 [8:57:48<5:37:59, 32.09s/it]                                                       {'loss': 0.361, 'learning_rate': 6.66636866876912e-06, 'epoch': 0.62}
 62%|██████▏   | 1031/1663 [8:57:48<5:37:59, 32.09s/it] 62%|██████▏   | 1032/1663 [8:58:19<5:33:56, 31.75s/it]                                                       {'loss': 0.352, 'learning_rate': 6.648012394147494e-06, 'epoch': 0.62}
 62%|██████▏   | 1032/1663 [8:58:19<5:33:56, 31.75s/it] 62%|██████▏   | 1033/1663 [8:58:52<5:37:28, 32.14s/it]                                                       {'loss': 0.535, 'learning_rate': 6.629668835021046e-06, 'epoch': 0.62}
 62%|██████▏   | 1033/1663 [8:58:52<5:37:28, 32.14s/it] 62%|██████▏   | 1034/1663 [8:59:24<5:36:20, 32.08s/it]                                                       {'loss': 0.3697, 'learning_rate': 6.611338060974587e-06, 'epoch': 0.62}
 62%|██████▏   | 1034/1663 [8:59:24<5:36:20, 32.08s/it] 62%|██████▏   | 1035/1663 [8:59:57<5:37:48, 32.27s/it]                                                       {'loss': 0.4228, 'learning_rate': 6.593020141544436e-06, 'epoch': 0.62}
 62%|██████▏   | 1035/1663 [8:59:57<5:37:48, 32.27s/it] 62%|██████▏   | 1036/1663 [9:00:32<5:46:01, 33.11s/it]                                                       {'loss': 0.386, 'learning_rate': 6.5747151462181445e-06, 'epoch': 0.62}
 62%|██████▏   | 1036/1663 [9:00:32<5:46:01, 33.11s/it] 62%|██████▏   | 1037/1663 [9:01:03<5:39:35, 32.55s/it]                                                       {'loss': 0.4799, 'learning_rate': 6.5564231444342405e-06, 'epoch': 0.62}
 62%|██████▏   | 1037/1663 [9:01:03<5:39:35, 32.55s/it] 62%|██████▏   | 1038/1663 [9:01:34<5:35:47, 32.24s/it]                                                       {'loss': 0.3439, 'learning_rate': 6.5381442055819585e-06, 'epoch': 0.62}
 62%|██████▏   | 1038/1663 [9:01:34<5:35:47, 32.24s/it] 62%|██████▏   | 1039/1663 [9:02:05<5:30:53, 31.82s/it]                                                       {'loss': 0.4189, 'learning_rate': 6.519878399000983e-06, 'epoch': 0.62}
 62%|██████▏   | 1039/1663 [9:02:05<5:30:53, 31.82s/it] 63%|██████▎   | 1040/1663 [9:02:37<5:30:42, 31.85s/it]                                                       {'loss': 0.4593, 'learning_rate': 6.50162579398118e-06, 'epoch': 0.63}
 63%|██████▎   | 1040/1663 [9:02:37<5:30:42, 31.85s/it] 63%|██████▎   | 1041/1663 [9:03:09<5:31:14, 31.95s/it]                                                       {'loss': 0.4531, 'learning_rate': 6.483386459762339e-06, 'epoch': 0.63}
 63%|██████▎   | 1041/1663 [9:03:09<5:31:14, 31.95s/it] 63%|██████▎   | 1042/1663 [9:03:40<5:26:51, 31.58s/it]                                                       {'loss': 0.3848, 'learning_rate': 6.465160465533904e-06, 'epoch': 0.63}
 63%|██████▎   | 1042/1663 [9:03:40<5:26:51, 31.58s/it] 63%|██████▎   | 1043/1663 [9:04:08<5:15:04, 30.49s/it]                                                       {'loss': 0.4598, 'learning_rate': 6.4469478804347194e-06, 'epoch': 0.63}
 63%|██████▎   | 1043/1663 [9:04:08<5:15:04, 30.49s/it] 63%|██████▎   | 1044/1663 [9:04:40<5:19:39, 30.98s/it]                                                       {'loss': 0.4142, 'learning_rate': 6.42874877355276e-06, 'epoch': 0.63}
 63%|██████▎   | 1044/1663 [9:04:40<5:19:39, 30.98s/it] 63%|██████▎   | 1045/1663 [9:05:12<5:22:57, 31.36s/it]                                                       {'loss': 0.4555, 'learning_rate': 6.4105632139248706e-06, 'epoch': 0.63}
 63%|██████▎   | 1045/1663 [9:05:12<5:22:57, 31.36s/it] 63%|██████▎   | 1046/1663 [9:05:40<5:11:15, 30.27s/it]                                                       {'loss': 0.4211, 'learning_rate': 6.392391270536511e-06, 'epoch': 0.63}
 63%|██████▎   | 1046/1663 [9:05:40<5:11:15, 30.27s/it] 63%|██████▎   | 1047/1663 [9:06:13<5:19:20, 31.10s/it]                                                       {'loss': 0.4507, 'learning_rate': 6.374233012321486e-06, 'epoch': 0.63}
 63%|██████▎   | 1047/1663 [9:06:13<5:19:20, 31.10s/it] 63%|██████▎   | 1048/1663 [9:06:44<5:16:48, 30.91s/it]                                                       {'loss': 0.433, 'learning_rate': 6.3560885081616844e-06, 'epoch': 0.63}
 63%|██████▎   | 1048/1663 [9:06:44<5:16:48, 30.91s/it] 63%|██████▎   | 1049/1663 [9:07:15<5:16:55, 30.97s/it]                                                       {'loss': 0.3771, 'learning_rate': 6.3379578268868226e-06, 'epoch': 0.63}
 63%|██████▎   | 1049/1663 [9:07:15<5:16:55, 30.97s/it] 63%|██████▎   | 1050/1663 [9:07:47<5:21:17, 31.45s/it]                                                       {'loss': 0.4578, 'learning_rate': 6.319841037274182e-06, 'epoch': 0.63}
 63%|██████▎   | 1050/1663 [9:07:47<5:21:17, 31.45s/it] 63%|██████▎   | 1051/1663 [9:08:20<5:25:00, 31.86s/it]                                                       {'loss': 0.3452, 'learning_rate': 6.3017382080483426e-06, 'epoch': 0.63}
 63%|██████▎   | 1051/1663 [9:08:20<5:25:00, 31.86s/it] 63%|██████▎   | 1052/1663 [9:08:53<5:26:49, 32.09s/it]                                                       {'loss': 0.3919, 'learning_rate': 6.283649407880934e-06, 'epoch': 0.63}
 63%|██████▎   | 1052/1663 [9:08:53<5:26:49, 32.09s/it] 63%|██████▎   | 1053/1663 [9:09:24<5:24:10, 31.89s/it]                                                       {'loss': 0.4315, 'learning_rate': 6.2655747053903626e-06, 'epoch': 0.63}
 63%|██████▎   | 1053/1663 [9:09:24<5:24:10, 31.89s/it] 63%|██████▎   | 1054/1663 [9:09:54<5:16:41, 31.20s/it]                                                       {'loss': 0.3476, 'learning_rate': 6.247514169141555e-06, 'epoch': 0.63}
 63%|██████▎   | 1054/1663 [9:09:54<5:16:41, 31.20s/it] 63%|██████▎   | 1055/1663 [9:10:25<5:16:52, 31.27s/it]                                                       {'loss': 0.4485, 'learning_rate': 6.229467867645704e-06, 'epoch': 0.63}
 63%|██████▎   | 1055/1663 [9:10:25<5:16:52, 31.27s/it] 63%|██████▎   | 1056/1663 [9:10:58<5:20:17, 31.66s/it]                                                       {'loss': 0.4109, 'learning_rate': 6.211435869360002e-06, 'epoch': 0.63}
 63%|██████▎   | 1056/1663 [9:10:58<5:20:17, 31.66s/it] 64%|██████▎   | 1057/1663 [9:11:32<5:27:31, 32.43s/it]                                                       {'loss': 0.4079, 'learning_rate': 6.193418242687381e-06, 'epoch': 0.64}
 64%|██████▎   | 1057/1663 [9:11:32<5:27:31, 32.43s/it] 64%|██████▎   | 1058/1663 [9:12:04<5:25:43, 32.30s/it]                                                       {'loss': 0.4289, 'learning_rate': 6.175415055976259e-06, 'epoch': 0.64}
 64%|██████▎   | 1058/1663 [9:12:04<5:25:43, 32.30s/it] 64%|██████▎   | 1059/1663 [9:12:34<5:17:54, 31.58s/it]                                                       {'loss': 0.3916, 'learning_rate': 6.157426377520277e-06, 'epoch': 0.64}
 64%|██████▎   | 1059/1663 [9:12:34<5:17:54, 31.58s/it] 64%|██████▎   | 1060/1663 [9:13:06<5:19:27, 31.79s/it]                                                       {'loss': 0.4359, 'learning_rate': 6.1394522755580355e-06, 'epoch': 0.64}
 64%|██████▎   | 1060/1663 [9:13:06<5:19:27, 31.79s/it] 64%|██████▍   | 1061/1663 [9:13:39<5:21:21, 32.03s/it]                                                       {'loss': 0.3763, 'learning_rate': 6.121492818272846e-06, 'epoch': 0.64}
 64%|██████▍   | 1061/1663 [9:13:39<5:21:21, 32.03s/it] 64%|██████▍   | 1062/1663 [9:14:09<5:15:39, 31.51s/it]                                                       {'loss': 0.4497, 'learning_rate': 6.103548073792463e-06, 'epoch': 0.64}
 64%|██████▍   | 1062/1663 [9:14:09<5:15:39, 31.51s/it] 64%|██████▍   | 1063/1663 [9:14:38<5:08:26, 30.84s/it]                                                       {'loss': 0.4874, 'learning_rate': 6.085618110188831e-06, 'epoch': 0.64}
 64%|██████▍   | 1063/1663 [9:14:38<5:08:26, 30.84s/it] 64%|██████▍   | 1064/1663 [9:15:10<5:10:07, 31.06s/it]                                                       {'loss': 0.3577, 'learning_rate': 6.067702995477824e-06, 'epoch': 0.64}
 64%|██████▍   | 1064/1663 [9:15:10<5:10:07, 31.06s/it] 64%|██████▍   | 1065/1663 [9:15:41<5:08:18, 30.93s/it]                                                       {'loss': 0.4199, 'learning_rate': 6.049802797618986e-06, 'epoch': 0.64}
 64%|██████▍   | 1065/1663 [9:15:41<5:08:18, 30.93s/it] 64%|██████▍   | 1066/1663 [9:16:13<5:11:22, 31.29s/it]                                                       {'loss': 0.3651, 'learning_rate': 6.031917584515279e-06, 'epoch': 0.64}
 64%|██████▍   | 1066/1663 [9:16:13<5:11:22, 31.29s/it] 64%|██████▍   | 1067/1663 [9:16:45<5:14:00, 31.61s/it]                                                       {'loss': 0.3936, 'learning_rate': 6.014047424012817e-06, 'epoch': 0.64}
 64%|██████▍   | 1067/1663 [9:16:45<5:14:00, 31.61s/it] 64%|██████▍   | 1068/1663 [9:17:17<5:13:49, 31.65s/it]                                                       {'loss': 0.3236, 'learning_rate': 5.9961923839006165e-06, 'epoch': 0.64}
 64%|██████▍   | 1068/1663 [9:17:17<5:13:49, 31.65s/it] 64%|██████▍   | 1069/1663 [9:17:48<5:10:47, 31.39s/it]                                                       {'loss': 0.4032, 'learning_rate': 5.978352531910335e-06, 'epoch': 0.64}
 64%|██████▍   | 1069/1663 [9:17:48<5:10:47, 31.39s/it] 64%|██████▍   | 1070/1663 [9:18:19<5:09:52, 31.35s/it]                                                       {'loss': 0.4572, 'learning_rate': 5.960527935716017e-06, 'epoch': 0.64}
 64%|██████▍   | 1070/1663 [9:18:19<5:09:52, 31.35s/it] 64%|██████▍   | 1071/1663 [9:18:49<5:04:44, 30.89s/it]                                                       {'loss': 0.4519, 'learning_rate': 5.9427186629338284e-06, 'epoch': 0.64}
 64%|██████▍   | 1071/1663 [9:18:49<5:04:44, 30.89s/it] 64%|██████▍   | 1072/1663 [9:19:21<5:08:18, 31.30s/it]                                                       {'loss': 0.3617, 'learning_rate': 5.924924781121817e-06, 'epoch': 0.64}
 64%|██████▍   | 1072/1663 [9:19:21<5:08:18, 31.30s/it] 65%|██████▍   | 1073/1663 [9:19:52<5:08:00, 31.32s/it]                                                       {'loss': 0.4257, 'learning_rate': 5.90714635777964e-06, 'epoch': 0.65}
 65%|██████▍   | 1073/1663 [9:19:52<5:08:00, 31.32s/it] 65%|██████▍   | 1074/1663 [9:20:23<5:06:41, 31.24s/it]                                                       {'loss': 0.4295, 'learning_rate': 5.889383460348314e-06, 'epoch': 0.65}
 65%|██████▍   | 1074/1663 [9:20:23<5:06:41, 31.24s/it] 65%|██████▍   | 1075/1663 [9:20:57<5:12:32, 31.89s/it]                                                       {'loss': 0.4017, 'learning_rate': 5.871636156209961e-06, 'epoch': 0.65}
 65%|██████▍   | 1075/1663 [9:20:57<5:12:32, 31.89s/it] 65%|██████▍   | 1076/1663 [9:21:27<5:08:08, 31.50s/it]                                                       {'loss': 0.4601, 'learning_rate': 5.853904512687551e-06, 'epoch': 0.65}
 65%|██████▍   | 1076/1663 [9:21:27<5:08:08, 31.50s/it] 65%|██████▍   | 1077/1663 [9:21:56<5:00:28, 30.76s/it]                                                       {'loss': 0.431, 'learning_rate': 5.8361885970446456e-06, 'epoch': 0.65}
 65%|██████▍   | 1077/1663 [9:21:56<5:00:28, 30.76s/it] 65%|██████▍   | 1078/1663 [9:22:29<5:04:21, 31.22s/it]                                                       {'loss': 0.4018, 'learning_rate': 5.818488476485147e-06, 'epoch': 0.65}
 65%|██████▍   | 1078/1663 [9:22:29<5:04:21, 31.22s/it] 65%|██████▍   | 1079/1663 [9:22:59<4:59:57, 30.82s/it]                                                       {'loss': 0.3951, 'learning_rate': 5.800804218153036e-06, 'epoch': 0.65}
 65%|██████▍   | 1079/1663 [9:22:59<4:59:57, 30.82s/it] 65%|██████▍   | 1080/1663 [9:23:29<4:57:28, 30.61s/it]                                                       {'loss': 0.465, 'learning_rate': 5.783135889132125e-06, 'epoch': 0.65}
 65%|██████▍   | 1080/1663 [9:23:29<4:57:28, 30.61s/it] 65%|██████▌   | 1081/1663 [9:24:00<4:58:28, 30.77s/it]                                                       {'loss': 0.318, 'learning_rate': 5.765483556445795e-06, 'epoch': 0.65}
 65%|██████▌   | 1081/1663 [9:24:00<4:58:28, 30.77s/it] 65%|██████▌   | 1082/1663 [9:24:28<4:51:46, 30.13s/it]                                                       {'loss': 0.4717, 'learning_rate': 5.747847287056753e-06, 'epoch': 0.65}
 65%|██████▌   | 1082/1663 [9:24:28<4:51:46, 30.13s/it] 65%|██████▌   | 1083/1663 [9:25:00<4:54:36, 30.48s/it]                                                       {'loss': 0.4228, 'learning_rate': 5.730227147866765e-06, 'epoch': 0.65}
 65%|██████▌   | 1083/1663 [9:25:00<4:54:36, 30.48s/it] 65%|██████▌   | 1084/1663 [9:25:31<4:55:28, 30.62s/it]                                                       {'loss': 0.4186, 'learning_rate': 5.71262320571641e-06, 'epoch': 0.65}
 65%|██████▌   | 1084/1663 [9:25:31<4:55:28, 30.62s/it] 65%|██████▌   | 1085/1663 [9:26:01<4:54:31, 30.57s/it]                                                       {'loss': 0.3593, 'learning_rate': 5.695035527384827e-06, 'epoch': 0.65}
 65%|██████▌   | 1085/1663 [9:26:01<4:54:31, 30.57s/it] 65%|██████▌   | 1086/1663 [9:26:37<5:08:41, 32.10s/it]                                                       {'loss': 0.337, 'learning_rate': 5.677464179589457e-06, 'epoch': 0.65}
 65%|██████▌   | 1086/1663 [9:26:37<5:08:41, 32.10s/it] 65%|██████▌   | 1087/1663 [9:27:12<5:18:15, 33.15s/it]                                                       {'loss': 0.3994, 'learning_rate': 5.6599092289857945e-06, 'epoch': 0.65}
 65%|██████▌   | 1087/1663 [9:27:12<5:18:15, 33.15s/it] 65%|██████▌   | 1088/1663 [9:27:44<5:14:07, 32.78s/it]                                                       {'loss': 0.5024, 'learning_rate': 5.642370742167132e-06, 'epoch': 0.65}
 65%|██████▌   | 1088/1663 [9:27:44<5:14:07, 32.78s/it] 65%|██████▌   | 1089/1663 [9:28:16<5:09:19, 32.33s/it]                                                       {'loss': 0.4967, 'learning_rate': 5.624848785664305e-06, 'epoch': 0.65}
 65%|██████▌   | 1089/1663 [9:28:16<5:09:19, 32.33s/it] 66%|██████▌   | 1090/1663 [9:28:48<5:09:50, 32.44s/it]                                                       {'loss': 0.3971, 'learning_rate': 5.60734342594545e-06, 'epoch': 0.66}
 66%|██████▌   | 1090/1663 [9:28:48<5:09:50, 32.44s/it] 66%|██████▌   | 1091/1663 [9:29:21<5:09:32, 32.47s/it]                                                       {'loss': 0.4291, 'learning_rate': 5.589854729415735e-06, 'epoch': 0.66}
 66%|██████▌   | 1091/1663 [9:29:21<5:09:32, 32.47s/it] 66%|██████▌   | 1092/1663 [9:29:51<5:01:46, 31.71s/it]                                                       {'loss': 0.4254, 'learning_rate': 5.572382762417125e-06, 'epoch': 0.66}
 66%|██████▌   | 1092/1663 [9:29:51<5:01:46, 31.71s/it] 66%|██████▌   | 1093/1663 [9:30:23<5:03:04, 31.90s/it]                                                       {'loss': 0.3311, 'learning_rate': 5.55492759122812e-06, 'epoch': 0.66}
 66%|██████▌   | 1093/1663 [9:30:23<5:03:04, 31.90s/it] 66%|██████▌   | 1094/1663 [9:30:58<5:09:46, 32.67s/it]                                                       {'loss': 0.4356, 'learning_rate': 5.537489282063506e-06, 'epoch': 0.66}
 66%|██████▌   | 1094/1663 [9:30:58<5:09:46, 32.67s/it] 66%|██████▌   | 1095/1663 [9:31:30<5:08:56, 32.64s/it]                                                       {'loss': 0.3799, 'learning_rate': 5.520067901074109e-06, 'epoch': 0.66}
 66%|██████▌   | 1095/1663 [9:31:30<5:08:56, 32.64s/it] 66%|██████▌   | 1096/1663 [9:32:02<5:07:23, 32.53s/it]                                                       {'loss': 0.5151, 'learning_rate': 5.502663514346529e-06, 'epoch': 0.66}
 66%|██████▌   | 1096/1663 [9:32:02<5:07:23, 32.53s/it] 66%|██████▌   | 1097/1663 [9:32:33<5:02:16, 32.04s/it]                                                       {'loss': 0.3989, 'learning_rate': 5.4852761879029125e-06, 'epoch': 0.66}
 66%|██████▌   | 1097/1663 [9:32:33<5:02:16, 32.04s/it] 66%|██████▌   | 1098/1663 [9:33:07<5:05:52, 32.48s/it]                                                       {'loss': 0.3937, 'learning_rate': 5.467905987700679e-06, 'epoch': 0.66}
 66%|██████▌   | 1098/1663 [9:33:07<5:05:52, 32.48s/it] 66%|██████▌   | 1099/1663 [9:33:37<4:58:01, 31.71s/it]                                                       {'loss': 0.3699, 'learning_rate': 5.450552979632286e-06, 'epoch': 0.66}
 66%|██████▌   | 1099/1663 [9:33:37<4:58:01, 31.71s/it] 66%|██████▌   | 1100/1663 [9:34:11<5:04:40, 32.47s/it]                                                       {'loss': 0.5352, 'learning_rate': 5.433217229524974e-06, 'epoch': 0.66}
 66%|██████▌   | 1100/1663 [9:34:11<5:04:40, 32.47s/it] 66%|██████▌   | 1101/1663 [9:34:44<5:04:39, 32.53s/it]                                                       {'loss': 0.5432, 'learning_rate': 5.4158988031405136e-06, 'epoch': 0.66}
 66%|██████▌   | 1101/1663 [9:34:44<5:04:39, 32.53s/it] 66%|██████▋   | 1102/1663 [9:35:16<5:05:06, 32.63s/it]                                                       {'loss': 0.3936, 'learning_rate': 5.398597766174962e-06, 'epoch': 0.66}
 66%|██████▋   | 1102/1663 [9:35:17<5:05:06, 32.63s/it] 66%|██████▋   | 1103/1663 [9:35:48<5:00:16, 32.17s/it]                                                       {'loss': 0.3194, 'learning_rate': 5.3813141842584105e-06, 'epoch': 0.66}
 66%|██████▋   | 1103/1663 [9:35:48<5:00:16, 32.17s/it] 66%|██████▋   | 1104/1663 [9:36:20<4:59:17, 32.12s/it]                                                       {'loss': 0.4277, 'learning_rate': 5.364048122954736e-06, 'epoch': 0.66}
 66%|██████▋   | 1104/1663 [9:36:20<4:59:17, 32.12s/it] 66%|██████▋   | 1105/1663 [9:36:53<5:02:48, 32.56s/it]                                                       {'loss': 0.4768, 'learning_rate': 5.346799647761352e-06, 'epoch': 0.66}
 66%|██████▋   | 1105/1663 [9:36:53<5:02:48, 32.56s/it] 67%|██████▋   | 1106/1663 [9:37:26<5:03:12, 32.66s/it]                                                       {'loss': 0.3191, 'learning_rate': 5.329568824108962e-06, 'epoch': 0.66}
 67%|██████▋   | 1106/1663 [9:37:26<5:03:12, 32.66s/it] 67%|██████▋   | 1107/1663 [9:37:56<4:54:43, 31.81s/it]                                                       {'loss': 0.4829, 'learning_rate': 5.312355717361306e-06, 'epoch': 0.67}
 67%|██████▋   | 1107/1663 [9:37:56<4:54:43, 31.81s/it] 67%|██████▋   | 1108/1663 [9:38:26<4:50:21, 31.39s/it]                                                       {'loss': 0.3678, 'learning_rate': 5.295160392814922e-06, 'epoch': 0.67}
 67%|██████▋   | 1108/1663 [9:38:26<4:50:21, 31.39s/it] 67%|██████▋   | 1109/1663 [9:38:56<4:46:01, 30.98s/it]                                                       {'loss': 0.3591, 'learning_rate': 5.277982915698887e-06, 'epoch': 0.67}
 67%|██████▋   | 1109/1663 [9:38:56<4:46:01, 30.98s/it] 67%|██████▋   | 1110/1663 [9:39:31<4:57:05, 32.23s/it]                                                       {'loss': 0.3334, 'learning_rate': 5.26082335117458e-06, 'epoch': 0.67}
 67%|██████▋   | 1110/1663 [9:39:32<4:57:05, 32.23s/it] 67%|██████▋   | 1111/1663 [9:40:04<4:58:11, 32.41s/it]                                                       {'loss': 0.5121, 'learning_rate': 5.243681764335426e-06, 'epoch': 0.67}
 67%|██████▋   | 1111/1663 [9:40:04<4:58:11, 32.41s/it] 67%|██████▋   | 1112/1663 [9:40:36<4:56:38, 32.30s/it]                                                       {'loss': 0.361, 'learning_rate': 5.2265582202066546e-06, 'epoch': 0.67}
 67%|██████▋   | 1112/1663 [9:40:36<4:56:38, 32.30s/it] 67%|██████▋   | 1113/1663 [9:41:10<4:58:55, 32.61s/it]                                                       {'loss': 0.3476, 'learning_rate': 5.209452783745055e-06, 'epoch': 0.67}
 67%|██████▋   | 1113/1663 [9:41:10<4:58:55, 32.61s/it] 67%|██████▋   | 1114/1663 [9:41:43<5:01:06, 32.91s/it]                                                       {'loss': 0.3313, 'learning_rate': 5.19236551983872e-06, 'epoch': 0.67}
 67%|██████▋   | 1114/1663 [9:41:43<5:01:06, 32.91s/it] 67%|██████▋   | 1115/1663 [9:42:14<4:55:46, 32.38s/it]                                                       {'loss': 0.4433, 'learning_rate': 5.175296493306814e-06, 'epoch': 0.67}
 67%|██████▋   | 1115/1663 [9:42:14<4:55:46, 32.38s/it] 67%|██████▋   | 1116/1663 [9:42:50<5:04:55, 33.45s/it]                                                       {'loss': 0.2892, 'learning_rate': 5.15824576889931e-06, 'epoch': 0.67}
 67%|██████▋   | 1116/1663 [9:42:50<5:04:55, 33.45s/it] 67%|██████▋   | 1117/1663 [9:43:23<5:02:17, 33.22s/it]                                                       {'loss': 0.4196, 'learning_rate': 5.1412134112967636e-06, 'epoch': 0.67}
 67%|██████▋   | 1117/1663 [9:43:23<5:02:17, 33.22s/it] 67%|██████▋   | 1118/1663 [9:43:54<4:55:08, 32.49s/it]                                                       {'loss': 0.389, 'learning_rate': 5.1241994851100505e-06, 'epoch': 0.67}
 67%|██████▋   | 1118/1663 [9:43:54<4:55:08, 32.49s/it] 67%|██████▋   | 1119/1663 [9:44:24<4:47:41, 31.73s/it]                                                       {'loss': 0.3319, 'learning_rate': 5.107204054880128e-06, 'epoch': 0.67}
 67%|██████▋   | 1119/1663 [9:44:24<4:47:41, 31.73s/it] 67%|██████▋   | 1120/1663 [9:44:54<4:43:26, 31.32s/it]                                                       {'loss': 0.3933, 'learning_rate': 5.090227185077796e-06, 'epoch': 0.67}
 67%|██████▋   | 1120/1663 [9:44:54<4:43:26, 31.32s/it] 67%|██████▋   | 1121/1663 [9:45:24<4:39:09, 30.90s/it]                                                       {'loss': 0.4351, 'learning_rate': 5.073268940103443e-06, 'epoch': 0.67}
 67%|██████▋   | 1121/1663 [9:45:24<4:39:09, 30.90s/it] 67%|██████▋   | 1122/1663 [9:45:58<4:47:24, 31.87s/it]                                                       {'loss': 0.4513, 'learning_rate': 5.0563293842868046e-06, 'epoch': 0.67}
 67%|██████▋   | 1122/1663 [9:45:58<4:47:24, 31.87s/it] 68%|██████▊   | 1123/1663 [9:46:28<4:39:50, 31.09s/it]                                                       {'loss': 0.4007, 'learning_rate': 5.039408581886723e-06, 'epoch': 0.68}
 68%|██████▊   | 1123/1663 [9:46:28<4:39:50, 31.09s/it] 68%|██████▊   | 1124/1663 [9:46:58<4:36:47, 30.81s/it]                                                       {'loss': 0.4079, 'learning_rate': 5.022506597090902e-06, 'epoch': 0.68}
 68%|██████▊   | 1124/1663 [9:46:58<4:36:47, 30.81s/it] 68%|██████▊   | 1125/1663 [9:47:26<4:29:46, 30.09s/it]                                                       {'loss': 0.4517, 'learning_rate': 5.0056234940156564e-06, 'epoch': 0.68}
 68%|██████▊   | 1125/1663 [9:47:26<4:29:46, 30.09s/it] 68%|██████▊   | 1126/1663 [9:47:58<4:33:31, 30.56s/it]                                                       {'loss': 0.3889, 'learning_rate': 4.988759336705683e-06, 'epoch': 0.68}
 68%|██████▊   | 1126/1663 [9:47:58<4:33:31, 30.56s/it] 68%|██████▊   | 1127/1663 [9:48:27<4:30:48, 30.32s/it]                                                       {'loss': 0.3137, 'learning_rate': 4.971914189133803e-06, 'epoch': 0.68}
 68%|██████▊   | 1127/1663 [9:48:28<4:30:48, 30.32s/it] 68%|██████▊   | 1128/1663 [9:49:00<4:34:58, 30.84s/it]                                                       {'loss': 0.3617, 'learning_rate': 4.955088115200728e-06, 'epoch': 0.68}
 68%|██████▊   | 1128/1663 [9:49:00<4:34:58, 30.84s/it] 68%|██████▊   | 1129/1663 [9:49:30<4:32:58, 30.67s/it]                                                       {'loss': 0.3963, 'learning_rate': 4.938281178734815e-06, 'epoch': 0.68}
 68%|██████▊   | 1129/1663 [9:49:30<4:32:58, 30.67s/it] 68%|██████▊   | 1130/1663 [9:50:01<4:34:59, 30.96s/it]                                                       {'loss': 0.4391, 'learning_rate': 4.921493443491825e-06, 'epoch': 0.68}
 68%|██████▊   | 1130/1663 [9:50:01<4:34:59, 30.96s/it] 68%|██████▊   | 1131/1663 [9:50:36<4:43:53, 32.02s/it]                                                       {'loss': 0.316, 'learning_rate': 4.904724973154681e-06, 'epoch': 0.68}
 68%|██████▊   | 1131/1663 [9:50:36<4:43:53, 32.02s/it] 68%|██████▊   | 1132/1663 [9:51:05<4:36:37, 31.26s/it]                                                       {'loss': 0.5146, 'learning_rate': 4.887975831333225e-06, 'epoch': 0.68}
 68%|██████▊   | 1132/1663 [9:51:05<4:36:37, 31.26s/it] 68%|██████▊   | 1133/1663 [9:51:36<4:33:20, 30.94s/it]                                                       {'loss': 0.3728, 'learning_rate': 4.871246081563977e-06, 'epoch': 0.68}
 68%|██████▊   | 1133/1663 [9:51:36<4:33:20, 30.94s/it] 68%|██████▊   | 1134/1663 [9:52:05<4:29:54, 30.61s/it]                                                       {'loss': 0.4153, 'learning_rate': 4.854535787309898e-06, 'epoch': 0.68}
 68%|██████▊   | 1134/1663 [9:52:05<4:29:54, 30.61s/it] 68%|██████▊   | 1135/1663 [9:52:33<4:21:50, 29.75s/it]                                                       {'loss': 0.3864, 'learning_rate': 4.837845011960144e-06, 'epoch': 0.68}
 68%|██████▊   | 1135/1663 [9:52:33<4:21:50, 29.75s/it] 68%|██████▊   | 1136/1663 [9:53:04<4:23:09, 29.96s/it]                                                       {'loss': 0.394, 'learning_rate': 4.8211738188298265e-06, 'epoch': 0.68}
 68%|██████▊   | 1136/1663 [9:53:04<4:23:09, 29.96s/it] 68%|██████▊   | 1137/1663 [9:53:37<4:30:32, 30.86s/it]                                                       {'loss': 0.4251, 'learning_rate': 4.804522271159776e-06, 'epoch': 0.68}
 68%|██████▊   | 1137/1663 [9:53:37<4:30:32, 30.86s/it] 68%|██████▊   | 1138/1663 [9:54:08<4:31:36, 31.04s/it]                                                       {'loss': 0.3718, 'learning_rate': 4.787890432116298e-06, 'epoch': 0.68}
 68%|██████▊   | 1138/1663 [9:54:08<4:31:36, 31.04s/it] 68%|██████▊   | 1139/1663 [9:54:38<4:27:30, 30.63s/it]                                                       {'loss': 0.3339, 'learning_rate': 4.771278364790934e-06, 'epoch': 0.68}
 68%|██████▊   | 1139/1663 [9:54:38<4:27:30, 30.63s/it] 69%|██████▊   | 1140/1663 [9:55:11<4:33:55, 31.42s/it]                                                       {'loss': 0.3834, 'learning_rate': 4.754686132200227e-06, 'epoch': 0.69}
 69%|██████▊   | 1140/1663 [9:55:11<4:33:55, 31.42s/it] 69%|██████▊   | 1141/1663 [9:55:42<4:32:39, 31.34s/it]                                                       {'loss': 0.4551, 'learning_rate': 4.738113797285474e-06, 'epoch': 0.69}
 69%|██████▊   | 1141/1663 [9:55:42<4:32:39, 31.34s/it] 69%|██████▊   | 1142/1663 [9:56:16<4:37:29, 31.96s/it]                                                       {'loss': 0.3283, 'learning_rate': 4.721561422912493e-06, 'epoch': 0.69}
 69%|██████▊   | 1142/1663 [9:56:16<4:37:29, 31.96s/it] 69%|██████▊   | 1143/1663 [9:56:43<4:23:50, 30.44s/it]                                                       {'loss': 0.4205, 'learning_rate': 4.705029071871384e-06, 'epoch': 0.69}
 69%|██████▊   | 1143/1663 [9:56:43<4:23:50, 30.44s/it] 69%|██████▉   | 1144/1663 [9:57:14<4:25:51, 30.74s/it]                                                       {'loss': 0.322, 'learning_rate': 4.688516806876292e-06, 'epoch': 0.69}
 69%|██████▉   | 1144/1663 [9:57:14<4:25:51, 30.74s/it] 69%|██████▉   | 1145/1663 [9:57:48<4:34:49, 31.83s/it]                                                       {'loss': 0.3686, 'learning_rate': 4.672024690565163e-06, 'epoch': 0.69}
 69%|██████▉   | 1145/1663 [9:57:48<4:34:49, 31.83s/it] 69%|██████▉   | 1146/1663 [9:58:16<4:23:30, 30.58s/it]                                                       {'loss': 0.4625, 'learning_rate': 4.655552785499513e-06, 'epoch': 0.69}
 69%|██████▉   | 1146/1663 [9:58:16<4:23:30, 30.58s/it] 69%|██████▉   | 1147/1663 [9:58:51<4:34:00, 31.86s/it]                                                       {'loss': 0.4314, 'learning_rate': 4.63910115416419e-06, 'epoch': 0.69}
 69%|██████▉   | 1147/1663 [9:58:51<4:34:00, 31.86s/it] 69%|██████▉   | 1148/1663 [9:59:22<4:31:51, 31.67s/it]                                                       {'loss': 0.3482, 'learning_rate': 4.622669858967131e-06, 'epoch': 0.69}
 69%|██████▉   | 1148/1663 [9:59:22<4:31:51, 31.67s/it] 69%|██████▉   | 1149/1663 [9:59:53<4:28:36, 31.36s/it]                                                       {'loss': 0.4214, 'learning_rate': 4.60625896223913e-06, 'epoch': 0.69}
 69%|██████▉   | 1149/1663 [9:59:53<4:28:36, 31.36s/it] 69%|██████▉   | 1150/1663 [10:00:25<4:29:46, 31.55s/it]                                                        {'loss': 0.4329, 'learning_rate': 4.5898685262336086e-06, 'epoch': 0.69}
 69%|██████▉   | 1150/1663 [10:00:25<4:29:46, 31.55s/it] 69%|██████▉   | 1151/1663 [10:01:00<4:38:18, 32.61s/it]                                                        {'loss': 0.4107, 'learning_rate': 4.5734986131263615e-06, 'epoch': 0.69}
 69%|██████▉   | 1151/1663 [10:01:00<4:38:18, 32.61s/it] 69%|██████▉   | 1152/1663 [10:01:32<4:35:45, 32.38s/it]                                                        {'loss': 0.3284, 'learning_rate': 4.557149285015339e-06, 'epoch': 0.69}
 69%|██████▉   | 1152/1663 [10:01:32<4:35:45, 32.38s/it] 69%|██████▉   | 1153/1663 [10:02:04<4:34:48, 32.33s/it]                                                        {'loss': 0.4835, 'learning_rate': 4.5408206039204e-06, 'epoch': 0.69}
 69%|██████▉   | 1153/1663 [10:02:04<4:34:48, 32.33s/it] 69%|██████▉   | 1154/1663 [10:02:34<4:29:14, 31.74s/it]                                                        {'loss': 0.4279, 'learning_rate': 4.524512631783082e-06, 'epoch': 0.69}
 69%|██████▉   | 1154/1663 [10:02:34<4:29:14, 31.74s/it] 69%|██████▉   | 1155/1663 [10:03:06<4:28:10, 31.67s/it]                                                        {'loss': 0.3928, 'learning_rate': 4.508225430466365e-06, 'epoch': 0.69}
 69%|██████▉   | 1155/1663 [10:03:06<4:28:10, 31.67s/it] 70%|██████▉   | 1156/1663 [10:03:36<4:24:31, 31.31s/it]                                                        {'loss': 0.4467, 'learning_rate': 4.491959061754436e-06, 'epoch': 0.69}
 70%|██████▉   | 1156/1663 [10:03:36<4:24:31, 31.31s/it] 70%|██████▉   | 1157/1663 [10:04:05<4:17:37, 30.55s/it]                                                        {'loss': 0.5404, 'learning_rate': 4.475713587352456e-06, 'epoch': 0.7}
 70%|██████▉   | 1157/1663 [10:04:05<4:17:37, 30.55s/it] 70%|██████▉   | 1158/1663 [10:04:37<4:21:55, 31.12s/it]                                                        {'loss': 0.365, 'learning_rate': 4.459489068886324e-06, 'epoch': 0.7}
 70%|██████▉   | 1158/1663 [10:04:37<4:21:55, 31.12s/it] 70%|██████▉   | 1159/1663 [10:05:09<4:21:38, 31.15s/it]                                                        {'loss': 0.4184, 'learning_rate': 4.443285567902446e-06, 'epoch': 0.7}
 70%|██████▉   | 1159/1663 [10:05:09<4:21:38, 31.15s/it] 70%|██████▉   | 1160/1663 [10:05:40<4:21:41, 31.22s/it]                                                        {'loss': 0.3065, 'learning_rate': 4.427103145867497e-06, 'epoch': 0.7}
 70%|██████▉   | 1160/1663 [10:05:40<4:21:41, 31.22s/it] 70%|██████▉   | 1161/1663 [10:06:10<4:18:16, 30.87s/it]                                                        {'loss': 0.5523, 'learning_rate': 4.410941864168193e-06, 'epoch': 0.7}
 70%|██████▉   | 1161/1663 [10:06:10<4:18:16, 30.87s/it] 70%|██████▉   | 1162/1663 [10:06:40<4:15:52, 30.64s/it]                                                        {'loss': 0.4698, 'learning_rate': 4.394801784111053e-06, 'epoch': 0.7}
 70%|██████▉   | 1162/1663 [10:06:40<4:15:52, 30.64s/it] 70%|██████▉   | 1163/1663 [10:07:13<4:20:51, 31.30s/it]                                                        {'loss': 0.3186, 'learning_rate': 4.378682966922178e-06, 'epoch': 0.7}
 70%|██████▉   | 1163/1663 [10:07:13<4:20:51, 31.30s/it] 70%|██████▉   | 1164/1663 [10:07:43<4:16:11, 30.81s/it]                                                        {'loss': 0.3282, 'learning_rate': 4.362585473746997e-06, 'epoch': 0.7}
 70%|██████▉   | 1164/1663 [10:07:43<4:16:11, 30.81s/it] 70%|███████   | 1165/1663 [10:08:16<4:21:09, 31.46s/it]                                                        {'loss': 0.411, 'learning_rate': 4.346509365650058e-06, 'epoch': 0.7}
 70%|███████   | 1165/1663 [10:08:16<4:21:09, 31.46s/it] 70%|███████   | 1166/1663 [10:08:46<4:18:20, 31.19s/it]                                                        {'loss': 0.4118, 'learning_rate': 4.3304547036147824e-06, 'epoch': 0.7}
 70%|███████   | 1166/1663 [10:08:46<4:18:20, 31.19s/it] 70%|███████   | 1167/1663 [10:09:17<4:16:31, 31.03s/it]                                                        {'loss': 0.4879, 'learning_rate': 4.314421548543238e-06, 'epoch': 0.7}
 70%|███████   | 1167/1663 [10:09:17<4:16:31, 31.03s/it] 70%|███████   | 1168/1663 [10:09:47<4:14:19, 30.83s/it]                                                        {'loss': 0.4851, 'learning_rate': 4.298409961255908e-06, 'epoch': 0.7}
 70%|███████   | 1168/1663 [10:09:47<4:14:19, 30.83s/it] 70%|███████   | 1169/1663 [10:10:19<4:17:04, 31.22s/it]                                                        {'loss': 0.4223, 'learning_rate': 4.282420002491461e-06, 'epoch': 0.7}
 70%|███████   | 1169/1663 [10:10:19<4:17:04, 31.22s/it] 70%|███████   | 1170/1663 [10:10:49<4:12:58, 30.79s/it]                                                        {'loss': 0.4536, 'learning_rate': 4.266451732906518e-06, 'epoch': 0.7}
 70%|███████   | 1170/1663 [10:10:49<4:12:58, 30.79s/it] 70%|███████   | 1171/1663 [10:11:21<4:15:52, 31.20s/it]                                                        {'loss': 0.5331, 'learning_rate': 4.250505213075424e-06, 'epoch': 0.7}
 70%|███████   | 1171/1663 [10:11:21<4:15:52, 31.20s/it] 70%|███████   | 1172/1663 [10:11:52<4:13:32, 30.98s/it]                                                        {'loss': 0.434, 'learning_rate': 4.234580503490018e-06, 'epoch': 0.7}
 70%|███████   | 1172/1663 [10:11:52<4:13:32, 30.98s/it] 71%|███████   | 1173/1663 [10:12:24<4:16:06, 31.36s/it]                                                        {'loss': 0.3785, 'learning_rate': 4.218677664559404e-06, 'epoch': 0.71}
 71%|███████   | 1173/1663 [10:12:24<4:16:06, 31.36s/it] 71%|███████   | 1174/1663 [10:12:57<4:20:34, 31.97s/it]                                                        {'loss': 0.3896, 'learning_rate': 4.202796756609723e-06, 'epoch': 0.71}
 71%|███████   | 1174/1663 [10:12:57<4:20:34, 31.97s/it] 71%|███████   | 1175/1663 [10:13:30<4:21:28, 32.15s/it]                                                        {'loss': 0.3811, 'learning_rate': 4.186937839883919e-06, 'epoch': 0.71}
 71%|███████   | 1175/1663 [10:13:30<4:21:28, 32.15s/it] 71%|███████   | 1176/1663 [10:14:00<4:14:53, 31.40s/it]                                                        {'loss': 0.4086, 'learning_rate': 4.1711009745415184e-06, 'epoch': 0.71}
 71%|███████   | 1176/1663 [10:14:00<4:14:53, 31.40s/it] 71%|███████   | 1177/1663 [10:14:32<4:15:49, 31.58s/it]                                                        {'loss': 0.4838, 'learning_rate': 4.155286220658393e-06, 'epoch': 0.71}
 71%|███████   | 1177/1663 [10:14:32<4:15:49, 31.58s/it] 71%|███████   | 1178/1663 [10:15:05<4:19:59, 32.16s/it]                                                        {'loss': 0.3412, 'learning_rate': 4.139493638226541e-06, 'epoch': 0.71}
 71%|███████   | 1178/1663 [10:15:05<4:19:59, 32.16s/it] 71%|███████   | 1179/1663 [10:15:35<4:12:41, 31.32s/it]                                                        {'loss': 0.4005, 'learning_rate': 4.1237232871538494e-06, 'epoch': 0.71}
 71%|███████   | 1179/1663 [10:15:35<4:12:41, 31.32s/it] 71%|███████   | 1180/1663 [10:16:07<4:15:37, 31.75s/it]                                                        {'loss': 0.4097, 'learning_rate': 4.107975227263877e-06, 'epoch': 0.71}
 71%|███████   | 1180/1663 [10:16:07<4:15:37, 31.75s/it] 71%|███████   | 1181/1663 [10:16:37<4:09:47, 31.09s/it]                                                        {'loss': 0.3679, 'learning_rate': 4.09224951829562e-06, 'epoch': 0.71}
 71%|███████   | 1181/1663 [10:16:37<4:09:47, 31.09s/it] 71%|███████   | 1182/1663 [10:17:10<4:15:03, 31.82s/it]                                                        {'loss': 0.4365, 'learning_rate': 4.0765462199032945e-06, 'epoch': 0.71}
 71%|███████   | 1182/1663 [10:17:10<4:15:03, 31.82s/it] 71%|███████   | 1183/1663 [10:17:41<4:11:06, 31.39s/it]                                                        {'loss': 0.3659, 'learning_rate': 4.0608653916560955e-06, 'epoch': 0.71}
 71%|███████   | 1183/1663 [10:17:41<4:11:06, 31.39s/it] 71%|███████   | 1184/1663 [10:18:17<4:21:55, 32.81s/it]                                                        {'loss': 0.3918, 'learning_rate': 4.0452070930379835e-06, 'epoch': 0.71}
 71%|███████   | 1184/1663 [10:18:17<4:21:55, 32.81s/it] 71%|███████▏  | 1185/1663 [10:18:52<4:27:49, 33.62s/it]                                                        {'loss': 0.3904, 'learning_rate': 4.029571383447455e-06, 'epoch': 0.71}
 71%|███████▏  | 1185/1663 [10:18:52<4:27:49, 33.62s/it] 71%|███████▏  | 1186/1663 [10:19:21<4:16:08, 32.22s/it]                                                        {'loss': 0.451, 'learning_rate': 4.013958322197313e-06, 'epoch': 0.71}
 71%|███████▏  | 1186/1663 [10:19:21<4:16:08, 32.22s/it] 71%|███████▏  | 1187/1663 [10:19:55<4:19:40, 32.73s/it]                                                        {'loss': 0.3858, 'learning_rate': 3.998367968514451e-06, 'epoch': 0.71}
 71%|███████▏  | 1187/1663 [10:19:55<4:19:40, 32.73s/it] 71%|███████▏  | 1188/1663 [10:20:27<4:16:21, 32.38s/it]                                                        {'loss': 0.2982, 'learning_rate': 3.982800381539619e-06, 'epoch': 0.71}
 71%|███████▏  | 1188/1663 [10:20:27<4:16:21, 32.38s/it] 71%|███████▏  | 1189/1663 [10:20:58<4:12:15, 31.93s/it]                                                        {'loss': 0.4359, 'learning_rate': 3.967255620327206e-06, 'epoch': 0.71}
 71%|███████▏  | 1189/1663 [10:20:58<4:12:15, 31.93s/it] 72%|███████▏  | 1190/1663 [10:21:33<4:20:15, 33.01s/it]                                                        {'loss': 0.4681, 'learning_rate': 3.951733743845012e-06, 'epoch': 0.72}
 72%|███████▏  | 1190/1663 [10:21:33<4:20:15, 33.01s/it] 72%|███████▏  | 1191/1663 [10:22:04<4:15:27, 32.47s/it]                                                        {'loss': 0.3993, 'learning_rate': 3.936234810974028e-06, 'epoch': 0.72}
 72%|███████▏  | 1191/1663 [10:22:04<4:15:27, 32.47s/it] 72%|███████▏  | 1192/1663 [10:22:36<4:12:45, 32.20s/it]                                                        {'loss': 0.3319, 'learning_rate': 3.920758880508205e-06, 'epoch': 0.72}
 72%|███████▏  | 1192/1663 [10:22:36<4:12:45, 32.20s/it] 72%|███████▏  | 1193/1663 [10:23:07<4:10:12, 31.94s/it]                                                        {'loss': 0.3772, 'learning_rate': 3.905306011154243e-06, 'epoch': 0.72}
 72%|███████▏  | 1193/1663 [10:23:07<4:10:12, 31.94s/it] 72%|███████▏  | 1194/1663 [10:23:38<4:06:57, 31.59s/it]                                                        {'loss': 0.3941, 'learning_rate': 3.889876261531356e-06, 'epoch': 0.72}
 72%|███████▏  | 1194/1663 [10:23:38<4:06:57, 31.59s/it] 72%|███████▏  | 1195/1663 [10:24:11<4:09:13, 31.95s/it]                                                        {'loss': 0.4214, 'learning_rate': 3.8744696901710565e-06, 'epoch': 0.72}
 72%|███████▏  | 1195/1663 [10:24:11<4:09:13, 31.95s/it] 72%|███████▏  | 1196/1663 [10:24:40<4:02:25, 31.15s/it]                                                        {'loss': 0.4445, 'learning_rate': 3.8590863555169355e-06, 'epoch': 0.72}
 72%|███████▏  | 1196/1663 [10:24:40<4:02:25, 31.15s/it] 72%|███████▏  | 1197/1663 [10:25:11<4:00:30, 30.97s/it]                                                        {'loss': 0.2966, 'learning_rate': 3.843726315924433e-06, 'epoch': 0.72}
 72%|███████▏  | 1197/1663 [10:25:11<4:00:30, 30.97s/it] 72%|███████▏  | 1198/1663 [10:25:41<3:59:01, 30.84s/it]                                                        {'loss': 0.3933, 'learning_rate': 3.828389629660623e-06, 'epoch': 0.72}
 72%|███████▏  | 1198/1663 [10:25:41<3:59:01, 30.84s/it] 72%|███████▏  | 1199/1663 [10:26:13<3:59:49, 31.01s/it]                                                        {'loss': 0.4262, 'learning_rate': 3.8130763549039895e-06, 'epoch': 0.72}
 72%|███████▏  | 1199/1663 [10:26:13<3:59:49, 31.01s/it] 72%|███████▏  | 1200/1663 [10:26:44<4:01:09, 31.25s/it]                                                        {'loss': 0.4019, 'learning_rate': 3.79778654974421e-06, 'epoch': 0.72}
 72%|███████▏  | 1200/1663 [10:26:44<4:01:09, 31.25s/it] 72%|███████▏  | 1201/1663 [10:27:11<3:50:50, 29.98s/it]                                                        {'loss': 0.3765, 'learning_rate': 3.7825202721819275e-06, 'epoch': 0.72}
 72%|███████▏  | 1201/1663 [10:27:11<3:50:50, 29.98s/it] 72%|███████▏  | 1202/1663 [10:27:42<3:51:27, 30.12s/it]                                                        {'loss': 0.4857, 'learning_rate': 3.767277580128539e-06, 'epoch': 0.72}
 72%|███████▏  | 1202/1663 [10:27:42<3:51:27, 30.12s/it] 72%|███████▏  | 1203/1663 [10:28:13<3:52:33, 30.33s/it]                                                        {'loss': 0.3064, 'learning_rate': 3.7520585314059686e-06, 'epoch': 0.72}
 72%|███████▏  | 1203/1663 [10:28:13<3:52:33, 30.33s/it] 72%|███████▏  | 1204/1663 [10:28:43<3:51:11, 30.22s/it]                                                        {'loss': 0.4411, 'learning_rate': 3.736863183746452e-06, 'epoch': 0.72}
 72%|███████▏  | 1204/1663 [10:28:43<3:51:11, 30.22s/it] 72%|███████▏  | 1205/1663 [10:29:12<3:49:11, 30.02s/it]                                                        {'loss': 0.5294, 'learning_rate': 3.7216915947923194e-06, 'epoch': 0.72}
 72%|███████▏  | 1205/1663 [10:29:12<3:49:11, 30.02s/it] 73%|███████▎  | 1206/1663 [10:29:45<3:54:49, 30.83s/it]                                                        {'loss': 0.388, 'learning_rate': 3.7065438220957706e-06, 'epoch': 0.72}
 73%|███████▎  | 1206/1663 [10:29:45<3:54:49, 30.83s/it] 73%|███████▎  | 1207/1663 [10:30:18<4:00:10, 31.60s/it]                                                        {'loss': 0.3483, 'learning_rate': 3.6914199231186633e-06, 'epoch': 0.73}
 73%|███████▎  | 1207/1663 [10:30:18<4:00:10, 31.60s/it] 73%|███████▎  | 1208/1663 [10:30:51<4:01:49, 31.89s/it]                                                        {'loss': 0.4055, 'learning_rate': 3.6763199552322902e-06, 'epoch': 0.73}
 73%|███████▎  | 1208/1663 [10:30:51<4:01:49, 31.89s/it] 73%|███████▎  | 1209/1663 [10:31:22<3:59:41, 31.68s/it]                                                        {'loss': 0.3618, 'learning_rate': 3.6612439757171647e-06, 'epoch': 0.73}
 73%|███████▎  | 1209/1663 [10:31:22<3:59:41, 31.68s/it] 73%|███████▎  | 1210/1663 [10:31:53<3:58:11, 31.55s/it]                                                        {'loss': 0.5609, 'learning_rate': 3.6461920417628003e-06, 'epoch': 0.73}
 73%|███████▎  | 1210/1663 [10:31:53<3:58:11, 31.55s/it] 73%|███████▎  | 1211/1663 [10:32:24<3:54:55, 31.19s/it]                                                        {'loss': 0.4676, 'learning_rate': 3.6311642104674983e-06, 'epoch': 0.73}
 73%|███████▎  | 1211/1663 [10:32:24<3:54:55, 31.19s/it] 73%|███████▎  | 1212/1663 [10:32:56<3:57:32, 31.60s/it]                                                        {'loss': 0.4185, 'learning_rate': 3.616160538838126e-06, 'epoch': 0.73}
 73%|███████▎  | 1212/1663 [10:32:56<3:57:32, 31.60s/it] 73%|███████▎  | 1213/1663 [10:33:28<3:56:14, 31.50s/it]                                                        {'loss': 0.3248, 'learning_rate': 3.6011810837899053e-06, 'epoch': 0.73}
 73%|███████▎  | 1213/1663 [10:33:28<3:56:14, 31.50s/it] 73%|███████▎  | 1214/1663 [10:33:59<3:56:38, 31.62s/it]                                                        {'loss': 0.4438, 'learning_rate': 3.586225902146192e-06, 'epoch': 0.73}
 73%|███████▎  | 1214/1663 [10:33:59<3:56:38, 31.62s/it] 73%|███████▎  | 1215/1663 [10:34:31<3:55:00, 31.47s/it]                                                        {'loss': 0.4424, 'learning_rate': 3.571295050638265e-06, 'epoch': 0.73}
 73%|███████▎  | 1215/1663 [10:34:31<3:55:00, 31.47s/it] 73%|███████▎  | 1216/1663 [10:35:01<3:52:07, 31.16s/it]                                                        {'loss': 0.401, 'learning_rate': 3.5563885859051063e-06, 'epoch': 0.73}
 73%|███████▎  | 1216/1663 [10:35:01<3:52:07, 31.16s/it] 73%|███████▎  | 1217/1663 [10:35:34<3:54:32, 31.55s/it]                                                        {'loss': 0.3109, 'learning_rate': 3.5415065644931913e-06, 'epoch': 0.73}
 73%|███████▎  | 1217/1663 [10:35:34<3:54:32, 31.55s/it] 73%|███████▎  | 1218/1663 [10:36:05<3:54:11, 31.58s/it]                                                        {'loss': 0.4732, 'learning_rate': 3.5266490428562695e-06, 'epoch': 0.73}
 73%|███████▎  | 1218/1663 [10:36:05<3:54:11, 31.58s/it] 73%|███████▎  | 1219/1663 [10:36:36<3:51:43, 31.31s/it]                                                        {'loss': 0.5117, 'learning_rate': 3.5118160773551535e-06, 'epoch': 0.73}
 73%|███████▎  | 1219/1663 [10:36:36<3:51:43, 31.31s/it] 73%|███████▎  | 1220/1663 [10:37:07<3:51:34, 31.36s/it]                                                        {'loss': 0.4614, 'learning_rate': 3.497007724257505e-06, 'epoch': 0.73}
 73%|███████▎  | 1220/1663 [10:37:07<3:51:34, 31.36s/it] 73%|███████▎  | 1221/1663 [10:37:40<3:53:29, 31.70s/it]                                                        {'loss': 0.3447, 'learning_rate': 3.4822240397376183e-06, 'epoch': 0.73}
 73%|███████▎  | 1221/1663 [10:37:40<3:53:29, 31.70s/it] 73%|███████▎  | 1222/1663 [10:38:10<3:48:40, 31.11s/it]                                                        {'loss': 0.3293, 'learning_rate': 3.467465079876211e-06, 'epoch': 0.73}
 73%|███████▎  | 1222/1663 [10:38:10<3:48:40, 31.11s/it] 74%|███████▎  | 1223/1663 [10:38:40<3:46:51, 30.93s/it]                                                        {'loss': 0.3499, 'learning_rate': 3.4527309006602095e-06, 'epoch': 0.74}
 74%|███████▎  | 1223/1663 [10:38:40<3:46:51, 30.93s/it] 74%|███████▎  | 1224/1663 [10:39:13<3:50:14, 31.47s/it]                                                        {'loss': 0.4196, 'learning_rate': 3.438021557982536e-06, 'epoch': 0.74}
 74%|███████▎  | 1224/1663 [10:39:13<3:50:14, 31.47s/it] 74%|███████▎  | 1225/1663 [10:39:39<3:37:23, 29.78s/it]                                                        {'loss': 0.3811, 'learning_rate': 3.4233371076418997e-06, 'epoch': 0.74}
 74%|███████▎  | 1225/1663 [10:39:39<3:37:23, 29.78s/it] 74%|███████▎  | 1226/1663 [10:40:10<3:41:26, 30.40s/it]                                                        {'loss': 0.4004, 'learning_rate': 3.4086776053425796e-06, 'epoch': 0.74}
 74%|███████▎  | 1226/1663 [10:40:10<3:41:26, 30.40s/it] 74%|███████▍  | 1227/1663 [10:40:37<3:33:22, 29.36s/it]                                                        {'loss': 0.4735, 'learning_rate': 3.394043106694218e-06, 'epoch': 0.74}
 74%|███████▍  | 1227/1663 [10:40:37<3:33:22, 29.36s/it] 74%|███████▍  | 1228/1663 [10:41:09<3:37:19, 29.98s/it]                                                        {'loss': 0.4211, 'learning_rate': 3.3794336672116067e-06, 'epoch': 0.74}
 74%|███████▍  | 1228/1663 [10:41:09<3:37:19, 29.98s/it] 74%|███████▍  | 1229/1663 [10:41:42<3:42:48, 30.80s/it]                                                        {'loss': 0.407, 'learning_rate': 3.36484934231448e-06, 'epoch': 0.74}
 74%|███████▍  | 1229/1663 [10:41:42<3:42:48, 30.80s/it] 74%|███████▍  | 1230/1663 [10:42:13<3:43:12, 30.93s/it]                                                        {'loss': 0.4779, 'learning_rate': 3.3502901873273e-06, 'epoch': 0.74}
 74%|███████▍  | 1230/1663 [10:42:13<3:43:12, 30.93s/it] 74%|███████▍  | 1231/1663 [10:42:45<3:45:16, 31.29s/it]                                                        {'loss': 0.3347, 'learning_rate': 3.335756257479049e-06, 'epoch': 0.74}
 74%|███████▍  | 1231/1663 [10:42:45<3:45:16, 31.29s/it] 74%|███████▍  | 1232/1663 [10:43:17<3:45:54, 31.45s/it]                                                        {'loss': 0.3507, 'learning_rate': 3.3212476079030198e-06, 'epoch': 0.74}
 74%|███████▍  | 1232/1663 [10:43:17<3:45:54, 31.45s/it] 74%|███████▍  | 1233/1663 [10:43:48<3:45:30, 31.47s/it]                                                        {'loss': 0.3293, 'learning_rate': 3.3067642936366073e-06, 'epoch': 0.74}
 74%|███████▍  | 1233/1663 [10:43:48<3:45:30, 31.47s/it] 74%|███████▍  | 1234/1663 [10:44:22<3:50:06, 32.18s/it]                                                        {'loss': 0.3527, 'learning_rate': 3.292306369621098e-06, 'epoch': 0.74}
 74%|███████▍  | 1234/1663 [10:44:22<3:50:06, 32.18s/it] 74%|███████▍  | 1235/1663 [10:44:54<3:47:57, 31.96s/it]                                                        {'loss': 0.3566, 'learning_rate': 3.277873890701463e-06, 'epoch': 0.74}
 74%|███████▍  | 1235/1663 [10:44:54<3:47:57, 31.96s/it] 74%|███████▍  | 1236/1663 [10:45:29<3:54:09, 32.90s/it]                                                        {'loss': 0.3777, 'learning_rate': 3.2634669116261485e-06, 'epoch': 0.74}
 74%|███████▍  | 1236/1663 [10:45:29<3:54:09, 32.90s/it] 74%|███████▍  | 1237/1663 [10:45:59<3:49:01, 32.26s/it]                                                        {'loss': 0.5433, 'learning_rate': 3.2490854870468713e-06, 'epoch': 0.74}
 74%|███████▍  | 1237/1663 [10:45:59<3:49:01, 32.26s/it] 74%|███████▍  | 1238/1663 [10:46:31<3:48:04, 32.20s/it]                                                        {'loss': 0.4257, 'learning_rate': 3.2347296715184086e-06, 'epoch': 0.74}
 74%|███████▍  | 1238/1663 [10:46:31<3:48:04, 32.20s/it] 75%|███████▍  | 1239/1663 [10:47:03<3:46:35, 32.06s/it]                                                        {'loss': 0.3349, 'learning_rate': 3.2203995194983893e-06, 'epoch': 0.74}
 75%|███████▍  | 1239/1663 [10:47:03<3:46:35, 32.06s/it] 75%|███████▍  | 1240/1663 [10:47:35<3:46:17, 32.10s/it]                                                        {'loss': 0.3102, 'learning_rate': 3.2060950853470916e-06, 'epoch': 0.75}
 75%|███████▍  | 1240/1663 [10:47:35<3:46:17, 32.10s/it] 75%|███████▍  | 1241/1663 [10:48:06<3:42:15, 31.60s/it]                                                        {'loss': 0.2955, 'learning_rate': 3.1918164233272364e-06, 'epoch': 0.75}
 75%|███████▍  | 1241/1663 [10:48:06<3:42:15, 31.60s/it] 75%|███████▍  | 1242/1663 [10:48:36<3:38:54, 31.20s/it]                                                        {'loss': 0.3334, 'learning_rate': 3.177563587603779e-06, 'epoch': 0.75}
 75%|███████▍  | 1242/1663 [10:48:36<3:38:54, 31.20s/it] 75%|███████▍  | 1243/1663 [10:49:08<3:39:37, 31.38s/it]                                                        {'loss': 0.3397, 'learning_rate': 3.163336632243703e-06, 'epoch': 0.75}
 75%|███████▍  | 1243/1663 [10:49:08<3:39:37, 31.38s/it] 75%|███████▍  | 1244/1663 [10:49:37<3:35:03, 30.80s/it]                                                        {'loss': 0.4724, 'learning_rate': 3.149135611215819e-06, 'epoch': 0.75}
 75%|███████▍  | 1244/1663 [10:49:37<3:35:03, 30.80s/it] 75%|███████▍  | 1245/1663 [10:50:13<3:45:18, 32.34s/it]                                                        {'loss': 0.3762, 'learning_rate': 3.1349605783905567e-06, 'epoch': 0.75}
 75%|███████▍  | 1245/1663 [10:50:13<3:45:18, 32.34s/it] 75%|███████▍  | 1246/1663 [10:50:44<3:41:32, 31.88s/it]                                                        {'loss': 0.3896, 'learning_rate': 3.1208115875397637e-06, 'epoch': 0.75}
 75%|███████▍  | 1246/1663 [10:50:44<3:41:32, 31.88s/it] 75%|███████▍  | 1247/1663 [10:51:15<3:38:30, 31.52s/it]                                                        {'loss': 0.4433, 'learning_rate': 3.106688692336497e-06, 'epoch': 0.75}
 75%|███████▍  | 1247/1663 [10:51:15<3:38:30, 31.52s/it] 75%|███████▌  | 1248/1663 [10:51:46<3:37:46, 31.49s/it]                                                        {'loss': 0.3241, 'learning_rate': 3.0925919463548226e-06, 'epoch': 0.75}
 75%|███████▌  | 1248/1663 [10:51:46<3:37:46, 31.49s/it] 75%|███████▌  | 1249/1663 [10:52:16<3:33:36, 30.96s/it]                                                        {'loss': 0.5181, 'learning_rate': 3.078521403069611e-06, 'epoch': 0.75}
 75%|███████▌  | 1249/1663 [10:52:16<3:33:36, 30.96s/it] 75%|███████▌  | 1250/1663 [10:52:47<3:33:02, 30.95s/it]                                                        {'loss': 0.4429, 'learning_rate': 3.064477115856337e-06, 'epoch': 0.75}
 75%|███████▌  | 1250/1663 [10:52:47<3:33:02, 30.95s/it] 75%|███████▌  | 1251/1663 [10:53:18<3:32:48, 30.99s/it]                                                        {'loss': 0.356, 'learning_rate': 3.0504591379908733e-06, 'epoch': 0.75}
 75%|███████▌  | 1251/1663 [10:53:18<3:32:48, 30.99s/it] 75%|███████▌  | 1252/1663 [10:53:50<3:33:53, 31.22s/it]                                                        {'loss': 0.3646, 'learning_rate': 3.03646752264929e-06, 'epoch': 0.75}
 75%|███████▌  | 1252/1663 [10:53:50<3:33:53, 31.22s/it] 75%|███████▌  | 1253/1663 [10:54:22<3:36:00, 31.61s/it]                                                        {'loss': 0.4347, 'learning_rate': 3.0225023229076543e-06, 'epoch': 0.75}
 75%|███████▌  | 1253/1663 [10:54:22<3:36:00, 31.61s/it] 75%|███████▌  | 1254/1663 [10:54:54<3:35:56, 31.68s/it]                                                        {'loss': 0.3028, 'learning_rate': 3.0085635917418277e-06, 'epoch': 0.75}
 75%|███████▌  | 1254/1663 [10:54:54<3:35:56, 31.68s/it] 75%|███████▌  | 1255/1663 [10:55:29<3:41:51, 32.63s/it]                                                        {'loss': 0.3628, 'learning_rate': 2.994651382027264e-06, 'epoch': 0.75}
 75%|███████▌  | 1255/1663 [10:55:29<3:41:51, 32.63s/it] 76%|███████▌  | 1256/1663 [10:55:59<3:37:01, 31.99s/it]                                                        {'loss': 0.3409, 'learning_rate': 2.9807657465388116e-06, 'epoch': 0.76}
 76%|███████▌  | 1256/1663 [10:55:59<3:37:01, 31.99s/it] 76%|███████▌  | 1257/1663 [10:56:31<3:34:59, 31.77s/it]                                                        {'loss': 0.4111, 'learning_rate': 2.96690673795051e-06, 'epoch': 0.76}
 76%|███████▌  | 1257/1663 [10:56:31<3:34:59, 31.77s/it] 76%|███████▌  | 1258/1663 [10:57:01<3:32:13, 31.44s/it]                                                        {'loss': 0.3985, 'learning_rate': 2.9530744088353948e-06, 'epoch': 0.76}
 76%|███████▌  | 1258/1663 [10:57:01<3:32:13, 31.44s/it] 76%|███████▌  | 1259/1663 [10:57:34<3:34:16, 31.82s/it]                                                        {'loss': 0.3918, 'learning_rate': 2.939268811665291e-06, 'epoch': 0.76}
 76%|███████▌  | 1259/1663 [10:57:34<3:34:16, 31.82s/it] 76%|███████▌  | 1260/1663 [10:58:04<3:29:48, 31.24s/it]                                                        {'loss': 0.4143, 'learning_rate': 2.925489998810618e-06, 'epoch': 0.76}
 76%|███████▌  | 1260/1663 [10:58:04<3:29:48, 31.24s/it] 76%|███████▌  | 1261/1663 [10:58:35<3:29:53, 31.33s/it]                                                        {'loss': 0.4967, 'learning_rate': 2.911738022540199e-06, 'epoch': 0.76}
 76%|███████▌  | 1261/1663 [10:58:35<3:29:53, 31.33s/it] 76%|███████▌  | 1262/1663 [10:59:08<3:31:04, 31.58s/it]                                                        {'loss': 0.4341, 'learning_rate': 2.898012935021047e-06, 'epoch': 0.76}
 76%|███████▌  | 1262/1663 [10:59:08<3:31:04, 31.58s/it] 76%|███████▌  | 1263/1663 [10:59:43<3:37:48, 32.67s/it]                                                        {'loss': 0.4999, 'learning_rate': 2.8843147883181764e-06, 'epoch': 0.76}
 76%|███████▌  | 1263/1663 [10:59:43<3:37:48, 32.67s/it] 76%|███████▌  | 1264/1663 [11:00:14<3:34:01, 32.18s/it]                                                        {'loss': 0.2928, 'learning_rate': 2.8706436343944033e-06, 'epoch': 0.76}
 76%|███████▌  | 1264/1663 [11:00:14<3:34:01, 32.18s/it] 76%|███████▌  | 1265/1663 [11:00:41<3:23:33, 30.69s/it]                                                        {'loss': 0.3225, 'learning_rate': 2.8569995251101513e-06, 'epoch': 0.76}
 76%|███████▌  | 1265/1663 [11:00:41<3:23:33, 30.69s/it] 76%|███████▌  | 1266/1663 [11:01:14<3:27:09, 31.31s/it]                                                        {'loss': 0.4076, 'learning_rate': 2.8433825122232485e-06, 'epoch': 0.76}
 76%|███████▌  | 1266/1663 [11:01:14<3:27:09, 31.31s/it] 76%|███████▌  | 1267/1663 [11:01:45<3:26:07, 31.23s/it]                                                        {'loss': 0.4883, 'learning_rate': 2.8297926473887395e-06, 'epoch': 0.76}
 76%|███████▌  | 1267/1663 [11:01:45<3:26:07, 31.23s/it] 76%|███████▌  | 1268/1663 [11:02:17<3:27:28, 31.52s/it]                                                        {'loss': 0.4887, 'learning_rate': 2.8162299821586814e-06, 'epoch': 0.76}
 76%|███████▌  | 1268/1663 [11:02:17<3:27:28, 31.52s/it] 76%|███████▋  | 1269/1663 [11:02:49<3:28:50, 31.80s/it]                                                        {'loss': 0.4698, 'learning_rate': 2.8026945679819528e-06, 'epoch': 0.76}
 76%|███████▋  | 1269/1663 [11:02:49<3:28:50, 31.80s/it] 76%|███████▋  | 1270/1663 [11:03:20<3:25:10, 31.32s/it]                                                        {'loss': 0.3031, 'learning_rate': 2.789186456204058e-06, 'epoch': 0.76}
 76%|███████▋  | 1270/1663 [11:03:20<3:25:10, 31.32s/it] 76%|███████▋  | 1271/1663 [11:03:51<3:23:48, 31.19s/it]                                                        {'loss': 0.3882, 'learning_rate': 2.775705698066934e-06, 'epoch': 0.76}
 76%|███████▋  | 1271/1663 [11:03:51<3:23:48, 31.19s/it] 76%|███████▋  | 1272/1663 [11:04:21<3:22:11, 31.03s/it]                                                        {'loss': 0.4016, 'learning_rate': 2.7622523447087478e-06, 'epoch': 0.76}
 76%|███████▋  | 1272/1663 [11:04:21<3:22:11, 31.03s/it] 77%|███████▋  | 1273/1663 [11:04:52<3:21:54, 31.06s/it]                                                        {'loss': 0.4173, 'learning_rate': 2.748826447163716e-06, 'epoch': 0.77}
 77%|███████▋  | 1273/1663 [11:04:52<3:21:54, 31.06s/it] 77%|███████▋  | 1274/1663 [11:05:24<3:22:37, 31.25s/it]                                                        {'loss': 0.3456, 'learning_rate': 2.7354280563618984e-06, 'epoch': 0.77}
 77%|███████▋  | 1274/1663 [11:05:24<3:22:37, 31.25s/it] 77%|███████▋  | 1275/1663 [11:05:54<3:19:32, 30.86s/it]                                                        {'loss': 0.4715, 'learning_rate': 2.722057223129012e-06, 'epoch': 0.77}
 77%|███████▋  | 1275/1663 [11:05:54<3:19:32, 30.86s/it] 77%|███████▋  | 1276/1663 [11:06:25<3:19:48, 30.98s/it]                                                        {'loss': 0.4152, 'learning_rate': 2.7087139981862377e-06, 'epoch': 0.77}
 77%|███████▋  | 1276/1663 [11:06:25<3:19:48, 30.98s/it] 77%|███████▋  | 1277/1663 [11:06:56<3:19:20, 30.98s/it]                                                        {'loss': 0.3563, 'learning_rate': 2.695398432150024e-06, 'epoch': 0.77}
 77%|███████▋  | 1277/1663 [11:06:56<3:19:20, 30.98s/it] 77%|███████▋  | 1278/1663 [11:07:29<3:21:44, 31.44s/it]                                                        {'loss': 0.4667, 'learning_rate': 2.6821105755319e-06, 'epoch': 0.77}
 77%|███████▋  | 1278/1663 [11:07:29<3:21:44, 31.44s/it] 77%|███████▋  | 1279/1663 [11:07:59<3:19:45, 31.21s/it]                                                        {'loss': 0.3624, 'learning_rate': 2.6688504787382787e-06, 'epoch': 0.77}
 77%|███████▋  | 1279/1663 [11:07:59<3:19:45, 31.21s/it] 77%|███████▋  | 1280/1663 [11:08:30<3:18:36, 31.11s/it]                                                        {'loss': 0.4763, 'learning_rate': 2.6556181920702715e-06, 'epoch': 0.77}
 77%|███████▋  | 1280/1663 [11:08:30<3:18:36, 31.11s/it] 77%|███████▋  | 1281/1663 [11:09:02<3:19:00, 31.26s/it]                                                        {'loss': 0.4252, 'learning_rate': 2.6424137657234917e-06, 'epoch': 0.77}
 77%|███████▋  | 1281/1663 [11:09:02<3:19:00, 31.26s/it] 77%|███████▋  | 1282/1663 [11:09:32<3:16:13, 30.90s/it]                                                        {'loss': 0.4664, 'learning_rate': 2.629237249787868e-06, 'epoch': 0.77}
 77%|███████▋  | 1282/1663 [11:09:32<3:16:13, 30.90s/it] 77%|███████▋  | 1283/1663 [11:10:02<3:13:56, 30.62s/it]                                                        {'loss': 0.3746, 'learning_rate': 2.616088694247454e-06, 'epoch': 0.77}
 77%|███████▋  | 1283/1663 [11:10:02<3:13:56, 30.62s/it] 77%|███████▋  | 1284/1663 [11:10:32<3:13:00, 30.56s/it]                                                        {'loss': 0.4206, 'learning_rate': 2.6029681489802348e-06, 'epoch': 0.77}
 77%|███████▋  | 1284/1663 [11:10:32<3:13:00, 30.56s/it] 77%|███████▋  | 1285/1663 [11:11:03<3:13:32, 30.72s/it]                                                        {'loss': 0.4469, 'learning_rate': 2.5898756637579457e-06, 'epoch': 0.77}
 77%|███████▋  | 1285/1663 [11:11:03<3:13:32, 30.72s/it] 77%|███████▋  | 1286/1663 [11:11:36<3:17:07, 31.37s/it]                                                        {'loss': 0.3563, 'learning_rate': 2.576811288245873e-06, 'epoch': 0.77}
 77%|███████▋  | 1286/1663 [11:11:36<3:17:07, 31.37s/it] 77%|███████▋  | 1287/1663 [11:12:06<3:13:28, 30.87s/it]                                                        {'loss': 0.4273, 'learning_rate': 2.563775072002674e-06, 'epoch': 0.77}
 77%|███████▋  | 1287/1663 [11:12:06<3:13:28, 30.87s/it] 77%|███████▋  | 1288/1663 [11:12:37<3:13:07, 30.90s/it]                                                        {'loss': 0.4064, 'learning_rate': 2.5507670644801874e-06, 'epoch': 0.77}
 77%|███████▋  | 1288/1663 [11:12:37<3:13:07, 30.90s/it] 78%|███████▊  | 1289/1663 [11:13:09<3:15:12, 31.32s/it]                                                        {'loss': 0.4562, 'learning_rate': 2.53778731502324e-06, 'epoch': 0.77}
 78%|███████▊  | 1289/1663 [11:13:09<3:15:12, 31.32s/it] 78%|███████▊  | 1290/1663 [11:13:40<3:13:58, 31.20s/it]                                                        {'loss': 0.3409, 'learning_rate': 2.52483587286947e-06, 'epoch': 0.78}
 78%|███████▊  | 1290/1663 [11:13:40<3:13:58, 31.20s/it] 78%|███████▊  | 1291/1663 [11:14:10<3:10:27, 30.72s/it]                                                        {'loss': 0.4691, 'learning_rate': 2.5119127871491277e-06, 'epoch': 0.78}
 78%|███████▊  | 1291/1663 [11:14:10<3:10:27, 30.72s/it] 78%|███████▊  | 1292/1663 [11:14:44<3:16:24, 31.76s/it]                                                        {'loss': 0.4543, 'learning_rate': 2.4990181068848995e-06, 'epoch': 0.78}
 78%|███████▊  | 1292/1663 [11:14:44<3:16:24, 31.76s/it] 78%|███████▊  | 1293/1663 [11:15:16<3:16:12, 31.82s/it]                                                        {'loss': 0.3746, 'learning_rate': 2.486151880991717e-06, 'epoch': 0.78}
 78%|███████▊  | 1293/1663 [11:15:16<3:16:12, 31.82s/it] 78%|███████▊  | 1294/1663 [11:15:46<3:12:40, 31.33s/it]                                                        {'loss': 0.2905, 'learning_rate': 2.473314158276574e-06, 'epoch': 0.78}
 78%|███████▊  | 1294/1663 [11:15:46<3:12:40, 31.33s/it] 78%|███████▊  | 1295/1663 [11:16:16<3:09:09, 30.84s/it]                                                        {'loss': 0.4978, 'learning_rate': 2.460504987438337e-06, 'epoch': 0.78}
 78%|███████▊  | 1295/1663 [11:16:16<3:09:09, 30.84s/it] 78%|███████▊  | 1296/1663 [11:16:48<3:10:34, 31.16s/it]                                                        {'loss': 0.3314, 'learning_rate': 2.447724417067564e-06, 'epoch': 0.78}
 78%|███████▊  | 1296/1663 [11:16:48<3:10:34, 31.16s/it] 78%|███████▊  | 1297/1663 [11:17:19<3:10:36, 31.25s/it]                                                        {'loss': 0.3894, 'learning_rate': 2.4349724956463207e-06, 'epoch': 0.78}
 78%|███████▊  | 1297/1663 [11:17:19<3:10:36, 31.25s/it] 78%|███████▊  | 1298/1663 [11:17:49<3:07:20, 30.80s/it]                                                        {'loss': 0.412, 'learning_rate': 2.422249271547995e-06, 'epoch': 0.78}
 78%|███████▊  | 1298/1663 [11:17:49<3:07:20, 30.80s/it] 78%|███████▊  | 1299/1663 [11:18:21<3:09:56, 31.31s/it]                                                        {'loss': 0.3962, 'learning_rate': 2.4095547930371123e-06, 'epoch': 0.78}
 78%|███████▊  | 1299/1663 [11:18:21<3:09:56, 31.31s/it] 78%|███████▊  | 1300/1663 [11:18:49<3:02:08, 30.11s/it]                                                        {'loss': 0.4216, 'learning_rate': 2.396889108269156e-06, 'epoch': 0.78}
 78%|███████▊  | 1300/1663 [11:18:49<3:02:08, 30.11s/it] 78%|███████▊  | 1301/1663 [11:19:21<3:05:17, 30.71s/it]                                                        {'loss': 0.407, 'learning_rate': 2.384252265290382e-06, 'epoch': 0.78}
 78%|███████▊  | 1301/1663 [11:19:21<3:05:17, 30.71s/it] 78%|███████▊  | 1302/1663 [11:19:48<2:58:33, 29.68s/it]                                                        {'loss': 0.4143, 'learning_rate': 2.3716443120376355e-06, 'epoch': 0.78}
 78%|███████▊  | 1302/1663 [11:19:48<2:58:33, 29.68s/it] 78%|███████▊  | 1303/1663 [11:20:18<2:58:39, 29.78s/it]                                                        {'loss': 0.4172, 'learning_rate': 2.359065296338173e-06, 'epoch': 0.78}
 78%|███████▊  | 1303/1663 [11:20:18<2:58:39, 29.78s/it] 78%|███████▊  | 1304/1663 [11:20:45<2:53:37, 29.02s/it]                                                        {'loss': 0.3612, 'learning_rate': 2.3465152659094793e-06, 'epoch': 0.78}
 78%|███████▊  | 1304/1663 [11:20:45<2:53:37, 29.02s/it] 78%|███████▊  | 1305/1663 [11:21:17<2:57:58, 29.83s/it]                                                        {'loss': 0.382, 'learning_rate': 2.333994268359083e-06, 'epoch': 0.78}
 78%|███████▊  | 1305/1663 [11:21:17<2:57:58, 29.83s/it] 79%|███████▊  | 1306/1663 [11:21:49<3:00:51, 30.40s/it]                                                        {'loss': 0.4141, 'learning_rate': 2.3215023511843816e-06, 'epoch': 0.79}
 79%|███████▊  | 1306/1663 [11:21:49<3:00:51, 30.40s/it] 79%|███████▊  | 1307/1663 [11:22:19<2:59:16, 30.21s/it]                                                        {'loss': 0.3674, 'learning_rate': 2.309039561772457e-06, 'epoch': 0.79}
 79%|███████▊  | 1307/1663 [11:22:19<2:59:16, 30.21s/it] 79%|███████▊  | 1308/1663 [11:22:52<3:03:42, 31.05s/it]                                                        {'loss': 0.4162, 'learning_rate': 2.2966059473998968e-06, 'epoch': 0.79}
 79%|███████▊  | 1308/1663 [11:22:52<3:03:42, 31.05s/it] 79%|███████▊  | 1309/1663 [11:23:23<3:03:58, 31.18s/it]                                                        {'loss': 0.4406, 'learning_rate': 2.284201555232618e-06, 'epoch': 0.79}
 79%|███████▊  | 1309/1663 [11:23:23<3:03:58, 31.18s/it] 79%|███████▉  | 1310/1663 [11:23:53<3:01:49, 30.91s/it]                                                        {'loss': 0.5073, 'learning_rate': 2.2718264323256822e-06, 'epoch': 0.79}
 79%|███████▉  | 1310/1663 [11:23:53<3:01:49, 30.91s/it] 79%|███████▉  | 1311/1663 [11:24:24<3:00:14, 30.72s/it]                                                        {'loss': 0.4212, 'learning_rate': 2.259480625623124e-06, 'epoch': 0.79}
 79%|███████▉  | 1311/1663 [11:24:24<3:00:14, 30.72s/it] 79%|███████▉  | 1312/1663 [11:25:00<3:08:40, 32.25s/it]                                                        {'loss': 0.3196, 'learning_rate': 2.247164181957765e-06, 'epoch': 0.79}
 79%|███████▉  | 1312/1663 [11:25:00<3:08:40, 32.25s/it] 79%|███████▉  | 1313/1663 [11:25:32<3:07:52, 32.21s/it]                                                        {'loss': 0.5077, 'learning_rate': 2.2348771480510444e-06, 'epoch': 0.79}
 79%|███████▉  | 1313/1663 [11:25:32<3:07:52, 32.21s/it] 79%|███████▉  | 1314/1663 [11:26:05<3:10:04, 32.68s/it]                                                        {'loss': 0.2584, 'learning_rate': 2.2226195705128363e-06, 'epoch': 0.79}
 79%|███████▉  | 1314/1663 [11:26:05<3:10:04, 32.68s/it] 79%|███████▉  | 1315/1663 [11:26:37<3:08:11, 32.45s/it]                                                        {'loss': 0.5312, 'learning_rate': 2.210391495841274e-06, 'epoch': 0.79}
 79%|███████▉  | 1315/1663 [11:26:37<3:08:11, 32.45s/it] 79%|███████▉  | 1316/1663 [11:27:10<3:07:38, 32.44s/it]                                                        {'loss': 0.4134, 'learning_rate': 2.1981929704225747e-06, 'epoch': 0.79}
 79%|███████▉  | 1316/1663 [11:27:10<3:07:38, 32.44s/it] 79%|███████▉  | 1317/1663 [11:27:40<3:03:21, 31.80s/it]                                                        {'loss': 0.3792, 'learning_rate': 2.186024040530863e-06, 'epoch': 0.79}
 79%|███████▉  | 1317/1663 [11:27:40<3:03:21, 31.80s/it] 79%|███████▉  | 1318/1663 [11:28:15<3:08:00, 32.70s/it]                                                        {'loss': 0.4308, 'learning_rate': 2.173884752327995e-06, 'epoch': 0.79}
 79%|███████▉  | 1318/1663 [11:28:15<3:08:00, 32.70s/it] 79%|███████▉  | 1319/1663 [11:28:48<3:08:49, 32.93s/it]                                                        {'loss': 0.4083, 'learning_rate': 2.1617751518633823e-06, 'epoch': 0.79}
 79%|███████▉  | 1319/1663 [11:28:48<3:08:49, 32.93s/it] 79%|███████▉  | 1320/1663 [11:29:19<3:04:51, 32.34s/it]                                                        {'loss': 0.4913, 'learning_rate': 2.1496952850738207e-06, 'epoch': 0.79}
 79%|███████▉  | 1320/1663 [11:29:19<3:04:51, 32.34s/it] 79%|███████▉  | 1321/1663 [11:29:51<3:03:08, 32.13s/it]                                                        {'loss': 0.4145, 'learning_rate': 2.137645197783311e-06, 'epoch': 0.79}
 79%|███████▉  | 1321/1663 [11:29:51<3:03:08, 32.13s/it] 79%|███████▉  | 1322/1663 [11:30:22<3:00:50, 31.82s/it]                                                        {'loss': 0.4442, 'learning_rate': 2.125624935702891e-06, 'epoch': 0.79}
 79%|███████▉  | 1322/1663 [11:30:22<3:00:50, 31.82s/it] 80%|███████▉  | 1323/1663 [11:30:55<3:02:56, 32.28s/it]                                                        {'loss': 0.4782, 'learning_rate': 2.1136345444304583e-06, 'epoch': 0.8}
 80%|███████▉  | 1323/1663 [11:30:55<3:02:56, 32.28s/it] 80%|███████▉  | 1324/1663 [11:31:28<3:02:25, 32.29s/it]                                                        {'loss': 0.3755, 'learning_rate': 2.1016740694505944e-06, 'epoch': 0.8}
 80%|███████▉  | 1324/1663 [11:31:28<3:02:25, 32.29s/it] 80%|███████▉  | 1325/1663 [11:32:02<3:04:40, 32.78s/it]                                                        {'loss': 0.4115, 'learning_rate': 2.0897435561344005e-06, 'epoch': 0.8}
 80%|███████▉  | 1325/1663 [11:32:02<3:04:40, 32.78s/it] 80%|███████▉  | 1326/1663 [11:32:35<3:04:49, 32.91s/it]                                                        {'loss': 0.3346, 'learning_rate': 2.0778430497393166e-06, 'epoch': 0.8}
 80%|███████▉  | 1326/1663 [11:32:35<3:04:49, 32.91s/it] 80%|███████▉  | 1327/1663 [11:33:05<3:00:34, 32.25s/it]                                                        {'loss': 0.4289, 'learning_rate': 2.0659725954089573e-06, 'epoch': 0.8}
 80%|███████▉  | 1327/1663 [11:33:06<3:00:34, 32.25s/it] 80%|███████▉  | 1328/1663 [11:33:38<2:59:44, 32.19s/it]                                                        {'loss': 0.3648, 'learning_rate': 2.0541322381729355e-06, 'epoch': 0.8}
 80%|███████▉  | 1328/1663 [11:33:38<2:59:44, 32.19s/it] 80%|███████▉  | 1329/1663 [11:34:09<2:57:46, 31.93s/it]                                                        {'loss': 0.5071, 'learning_rate': 2.0423220229466935e-06, 'epoch': 0.8}
 80%|███████▉  | 1329/1663 [11:34:09<2:57:46, 31.93s/it] 80%|███████▉  | 1330/1663 [11:34:42<2:59:03, 32.26s/it]                                                        {'loss': 0.3908, 'learning_rate': 2.030541994531331e-06, 'epoch': 0.8}
 80%|███████▉  | 1330/1663 [11:34:42<2:59:03, 32.26s/it] 80%|████████  | 1331/1663 [11:35:12<2:54:39, 31.57s/it]                                                        {'loss': 0.4646, 'learning_rate': 2.0187921976134395e-06, 'epoch': 0.8}
 80%|████████  | 1331/1663 [11:35:12<2:54:39, 31.57s/it] 80%|████████  | 1332/1663 [11:35:43<2:52:52, 31.34s/it]                                                        {'loss': 0.3463, 'learning_rate': 2.007072676764926e-06, 'epoch': 0.8}
 80%|████████  | 1332/1663 [11:35:43<2:52:52, 31.34s/it] 80%|████████  | 1333/1663 [11:36:13<2:51:24, 31.17s/it]                                                        {'loss': 0.4178, 'learning_rate': 1.99538347644285e-06, 'epoch': 0.8}
 80%|████████  | 1333/1663 [11:36:13<2:51:24, 31.17s/it] 80%|████████  | 1334/1663 [11:36:43<2:48:24, 30.71s/it]                                                        {'loss': 0.3994, 'learning_rate': 1.983724640989252e-06, 'epoch': 0.8}
 80%|████████  | 1334/1663 [11:36:43<2:48:24, 30.71s/it] 80%|████████  | 1335/1663 [11:37:16<2:50:48, 31.25s/it]                                                        {'loss': 0.3396, 'learning_rate': 1.9720962146309876e-06, 'epoch': 0.8}
 80%|████████  | 1335/1663 [11:37:16<2:50:48, 31.25s/it] 80%|████████  | 1336/1663 [11:37:46<2:49:30, 31.10s/it]                                                        {'loss': 0.4436, 'learning_rate': 1.9604982414795528e-06, 'epoch': 0.8}
 80%|████████  | 1336/1663 [11:37:46<2:49:30, 31.10s/it] 80%|████████  | 1337/1663 [11:38:16<2:46:52, 30.71s/it]                                                        {'loss': 0.4664, 'learning_rate': 1.9489307655309285e-06, 'epoch': 0.8}
 80%|████████  | 1337/1663 [11:38:16<2:46:52, 30.71s/it] 80%|████████  | 1338/1663 [11:38:47<2:46:10, 30.68s/it]                                                        {'loss': 0.3073, 'learning_rate': 1.9373938306654017e-06, 'epoch': 0.8}
 80%|████████  | 1338/1663 [11:38:47<2:46:10, 30.68s/it] 81%|████████  | 1339/1663 [11:39:21<2:50:56, 31.66s/it]                                                        {'loss': 0.447, 'learning_rate': 1.9258874806474038e-06, 'epoch': 0.8}
 81%|████████  | 1339/1663 [11:39:21<2:50:56, 31.66s/it] 81%|████████  | 1340/1663 [11:39:53<2:50:41, 31.71s/it]                                                        {'loss': 0.3576, 'learning_rate': 1.9144117591253543e-06, 'epoch': 0.81}
 81%|████████  | 1340/1663 [11:39:53<2:50:41, 31.71s/it] 81%|████████  | 1341/1663 [11:40:25<2:51:47, 32.01s/it]                                                        {'loss': 0.3579, 'learning_rate': 1.9029667096314742e-06, 'epoch': 0.81}
 81%|████████  | 1341/1663 [11:40:25<2:51:47, 32.01s/it] 81%|████████  | 1342/1663 [11:40:56<2:49:00, 31.59s/it]                                                        {'loss': 0.4621, 'learning_rate': 1.8915523755816378e-06, 'epoch': 0.81}
 81%|████████  | 1342/1663 [11:40:56<2:49:00, 31.59s/it] 81%|████████  | 1343/1663 [11:41:28<2:49:13, 31.73s/it]                                                        {'loss': 0.3495, 'learning_rate': 1.880168800275205e-06, 'epoch': 0.81}
 81%|████████  | 1343/1663 [11:41:28<2:49:13, 31.73s/it] 81%|████████  | 1344/1663 [11:41:59<2:48:17, 31.65s/it]                                                        {'loss': 0.4851, 'learning_rate': 1.8688160268948496e-06, 'epoch': 0.81}
 81%|████████  | 1344/1663 [11:41:59<2:48:17, 31.65s/it] 81%|████████  | 1345/1663 [11:42:25<2:37:32, 29.73s/it]                                                        {'loss': 0.3902, 'learning_rate': 1.857494098506405e-06, 'epoch': 0.81}
 81%|████████  | 1345/1663 [11:42:25<2:37:32, 29.73s/it] 81%|████████  | 1346/1663 [11:42:57<2:41:10, 30.51s/it]                                                        {'loss': 0.5252, 'learning_rate': 1.8462030580586942e-06, 'epoch': 0.81}
 81%|████████  | 1346/1663 [11:42:57<2:41:10, 30.51s/it] 81%|████████  | 1347/1663 [11:43:27<2:39:37, 30.31s/it]                                                        {'loss': 0.3326, 'learning_rate': 1.8349429483833713e-06, 'epoch': 0.81}
 81%|████████  | 1347/1663 [11:43:27<2:39:37, 30.31s/it] 81%|████████  | 1348/1663 [11:43:55<2:35:47, 29.67s/it]                                                        {'loss': 0.3556, 'learning_rate': 1.823713812194756e-06, 'epoch': 0.81}
 81%|████████  | 1348/1663 [11:43:55<2:35:47, 29.67s/it] 81%|████████  | 1349/1663 [11:44:22<2:31:19, 28.91s/it]                                                        {'loss': 0.3811, 'learning_rate': 1.8125156920896724e-06, 'epoch': 0.81}
 81%|████████  | 1349/1663 [11:44:22<2:31:19, 28.91s/it] 81%|████████  | 1350/1663 [11:44:54<2:34:48, 29.68s/it]                                                        {'loss': 0.4039, 'learning_rate': 1.8013486305472883e-06, 'epoch': 0.81}
 81%|████████  | 1350/1663 [11:44:54<2:34:48, 29.68s/it] 81%|████████  | 1351/1663 [11:45:24<2:35:47, 29.96s/it]                                                        {'loss': 0.4306, 'learning_rate': 1.7902126699289513e-06, 'epoch': 0.81}
 81%|████████  | 1351/1663 [11:45:24<2:35:47, 29.96s/it] 81%|████████▏ | 1352/1663 [11:45:57<2:40:16, 30.92s/it]                                                        {'loss': 0.4365, 'learning_rate': 1.7791078524780336e-06, 'epoch': 0.81}
 81%|████████▏ | 1352/1663 [11:45:57<2:40:16, 30.92s/it] 81%|████████▏ | 1353/1663 [11:46:29<2:41:30, 31.26s/it]                                                        {'loss': 0.3469, 'learning_rate': 1.7680342203197641e-06, 'epoch': 0.81}
 81%|████████▏ | 1353/1663 [11:46:29<2:41:30, 31.26s/it] 81%|████████▏ | 1354/1663 [11:47:00<2:40:24, 31.15s/it]                                                        {'loss': 0.3072, 'learning_rate': 1.7569918154610766e-06, 'epoch': 0.81}
 81%|████████▏ | 1354/1663 [11:47:00<2:40:24, 31.15s/it] 81%|████████▏ | 1355/1663 [11:47:32<2:40:02, 31.18s/it]                                                        {'loss': 0.3114, 'learning_rate': 1.7459806797904454e-06, 'epoch': 0.81}
 81%|████████▏ | 1355/1663 [11:47:32<2:40:02, 31.18s/it] 82%|████████▏ | 1356/1663 [11:48:01<2:37:00, 30.69s/it]                                                        {'loss': 0.3398, 'learning_rate': 1.7350008550777264e-06, 'epoch': 0.82}
 82%|████████▏ | 1356/1663 [11:48:01<2:37:00, 30.69s/it] 82%|████████▏ | 1357/1663 [11:48:32<2:36:26, 30.68s/it]                                                        {'loss': 0.4801, 'learning_rate': 1.7240523829740009e-06, 'epoch': 0.82}
 82%|████████▏ | 1357/1663 [11:48:32<2:36:26, 30.68s/it] 82%|████████▏ | 1358/1663 [11:49:03<2:36:25, 30.77s/it]                                                        {'loss': 0.53, 'learning_rate': 1.7131353050114174e-06, 'epoch': 0.82}
 82%|████████▏ | 1358/1663 [11:49:03<2:36:25, 30.77s/it] 82%|████████▏ | 1359/1663 [11:49:34<2:37:02, 30.99s/it]                                                        {'loss': 0.4095, 'learning_rate': 1.7022496626030317e-06, 'epoch': 0.82}
 82%|████████▏ | 1359/1663 [11:49:34<2:37:02, 30.99s/it] 82%|████████▏ | 1360/1663 [11:50:01<2:30:30, 29.80s/it]                                                        {'loss': 0.4594, 'learning_rate': 1.6913954970426516e-06, 'epoch': 0.82}
 82%|████████▏ | 1360/1663 [11:50:01<2:30:30, 29.80s/it] 82%|████████▏ | 1361/1663 [11:50:31<2:30:34, 29.92s/it]                                                        {'loss': 0.4299, 'learning_rate': 1.6805728495046825e-06, 'epoch': 0.82}
 82%|████████▏ | 1361/1663 [11:50:31<2:30:34, 29.92s/it] 82%|████████▏ | 1362/1663 [11:51:02<2:31:27, 30.19s/it]                                                        {'loss': 0.433, 'learning_rate': 1.669781761043965e-06, 'epoch': 0.82}
 82%|████████▏ | 1362/1663 [11:51:02<2:31:27, 30.19s/it] 82%|████████▏ | 1363/1663 [11:51:33<2:32:21, 30.47s/it]                                                        {'loss': 0.4104, 'learning_rate': 1.659022272595624e-06, 'epoch': 0.82}
 82%|████████▏ | 1363/1663 [11:51:33<2:32:21, 30.47s/it] 82%|████████▏ | 1364/1663 [11:52:04<2:32:34, 30.62s/it]                                                        {'loss': 0.4487, 'learning_rate': 1.6482944249749144e-06, 'epoch': 0.82}
 82%|████████▏ | 1364/1663 [11:52:04<2:32:34, 30.62s/it] 82%|████████▏ | 1365/1663 [11:52:33<2:29:48, 30.16s/it]                                                        {'loss': 0.4157, 'learning_rate': 1.6375982588770622e-06, 'epoch': 0.82}
 82%|████████▏ | 1365/1663 [11:52:33<2:29:48, 30.16s/it] 82%|████████▏ | 1366/1663 [11:53:06<2:32:37, 30.83s/it]                                                        {'loss': 0.3893, 'learning_rate': 1.6269338148771118e-06, 'epoch': 0.82}
 82%|████████▏ | 1366/1663 [11:53:06<2:32:37, 30.83s/it] 82%|████████▏ | 1367/1663 [11:53:37<2:32:22, 30.89s/it]                                                        {'loss': 0.4139, 'learning_rate': 1.616301133429775e-06, 'epoch': 0.82}
 82%|████████▏ | 1367/1663 [11:53:37<2:32:22, 30.89s/it] 82%|████████▏ | 1368/1663 [11:54:07<2:31:20, 30.78s/it]                                                        {'loss': 0.3583, 'learning_rate': 1.6057002548692701e-06, 'epoch': 0.82}
 82%|████████▏ | 1368/1663 [11:54:07<2:31:20, 30.78s/it] 82%|████████▏ | 1369/1663 [11:54:39<2:32:03, 31.03s/it]                                                        {'loss': 0.4535, 'learning_rate': 1.5951312194091794e-06, 'epoch': 0.82}
 82%|████████▏ | 1369/1663 [11:54:39<2:32:03, 31.03s/it] 82%|████████▏ | 1370/1663 [11:55:10<2:31:12, 30.97s/it]                                                        {'loss': 0.45, 'learning_rate': 1.5845940671422878e-06, 'epoch': 0.82}
 82%|████████▏ | 1370/1663 [11:55:10<2:31:12, 30.97s/it] 82%|████████▏ | 1371/1663 [11:55:35<2:22:14, 29.23s/it]                                                        {'loss': 0.3576, 'learning_rate': 1.5740888380404317e-06, 'epoch': 0.82}
 82%|████████▏ | 1371/1663 [11:55:35<2:22:14, 29.23s/it] 83%|████████▎ | 1372/1663 [11:56:06<2:23:47, 29.65s/it]                                                        {'loss': 0.4077, 'learning_rate': 1.5636155719543556e-06, 'epoch': 0.82}
 83%|████████▎ | 1372/1663 [11:56:06<2:23:47, 29.65s/it] 83%|████████▎ | 1373/1663 [11:56:37<2:26:25, 30.29s/it]                                                        {'loss': 0.345, 'learning_rate': 1.5531743086135487e-06, 'epoch': 0.83}
 83%|████████▎ | 1373/1663 [11:56:37<2:26:25, 30.29s/it] 83%|████████▎ | 1374/1663 [11:57:05<2:21:25, 29.36s/it]                                                        {'loss': 0.4624, 'learning_rate': 1.5427650876261047e-06, 'epoch': 0.83}
 83%|████████▎ | 1374/1663 [11:57:05<2:21:25, 29.36s/it] 83%|████████▎ | 1375/1663 [11:57:37<2:24:54, 30.19s/it]                                                        {'loss': 0.3985, 'learning_rate': 1.5323879484785654e-06, 'epoch': 0.83}
 83%|████████▎ | 1375/1663 [11:57:37<2:24:54, 30.19s/it] 83%|████████▎ | 1376/1663 [11:58:12<2:31:11, 31.61s/it]                                                        {'loss': 0.3529, 'learning_rate': 1.522042930535772e-06, 'epoch': 0.83}
 83%|████████▎ | 1376/1663 [11:58:12<2:31:11, 31.61s/it] 83%|████████▎ | 1377/1663 [11:58:44<2:31:11, 31.72s/it]                                                        {'loss': 0.4591, 'learning_rate': 1.5117300730407181e-06, 'epoch': 0.83}
 83%|████████▎ | 1377/1663 [11:58:44<2:31:11, 31.72s/it] 83%|████████▎ | 1378/1663 [11:59:17<2:32:39, 32.14s/it]                                                        {'loss': 0.4824, 'learning_rate': 1.5014494151143977e-06, 'epoch': 0.83}
 83%|████████▎ | 1378/1663 [11:59:17<2:32:39, 32.14s/it] 83%|████████▎ | 1379/1663 [11:59:47<2:29:01, 31.48s/it]                                                        {'loss': 0.4305, 'learning_rate': 1.4912009957556594e-06, 'epoch': 0.83}
 83%|████████▎ | 1379/1663 [11:59:47<2:29:01, 31.48s/it] 83%|████████▎ | 1380/1663 [12:00:20<2:31:41, 32.16s/it]                                                        {'loss': 0.4077, 'learning_rate': 1.4809848538410587e-06, 'epoch': 0.83}
 83%|████████▎ | 1380/1663 [12:00:20<2:31:41, 32.16s/it] 83%|████████▎ | 1381/1663 [12:00:51<2:28:58, 31.70s/it]                                                        {'loss': 0.5618, 'learning_rate': 1.4708010281247054e-06, 'epoch': 0.83}
 83%|████████▎ | 1381/1663 [12:00:51<2:28:58, 31.70s/it] 83%|████████▎ | 1382/1663 [12:01:22<2:26:46, 31.34s/it]                                                        {'loss': 0.3303, 'learning_rate': 1.4606495572381242e-06, 'epoch': 0.83}
 83%|████████▎ | 1382/1663 [12:01:22<2:26:46, 31.34s/it] 83%|████████▎ | 1383/1663 [12:01:52<2:24:36, 30.99s/it]                                                        {'loss': 0.532, 'learning_rate': 1.4505304796901021e-06, 'epoch': 0.83}
 83%|████████▎ | 1383/1663 [12:01:52<2:24:36, 30.99s/it] 83%|████████▎ | 1384/1663 [12:02:23<2:24:11, 31.01s/it]                                                        {'loss': 0.3949, 'learning_rate': 1.4404438338665449e-06, 'epoch': 0.83}
 83%|████████▎ | 1384/1663 [12:02:23<2:24:11, 31.01s/it] 83%|████████▎ | 1385/1663 [12:02:53<2:22:25, 30.74s/it]                                                        {'loss': 0.4351, 'learning_rate': 1.4303896580303323e-06, 'epoch': 0.83}
 83%|████████▎ | 1385/1663 [12:02:53<2:22:25, 30.74s/it] 83%|████████▎ | 1386/1663 [12:03:24<2:22:23, 30.84s/it]                                                        {'loss': 0.3583, 'learning_rate': 1.4203679903211709e-06, 'epoch': 0.83}
 83%|████████▎ | 1386/1663 [12:03:24<2:22:23, 30.84s/it] 83%|████████▎ | 1387/1663 [12:03:53<2:19:03, 30.23s/it]                                                        {'loss': 0.2875, 'learning_rate': 1.410378868755451e-06, 'epoch': 0.83}
 83%|████████▎ | 1387/1663 [12:03:53<2:19:03, 30.23s/it] 83%|████████▎ | 1388/1663 [12:04:25<2:21:15, 30.82s/it]                                                        {'loss': 0.4499, 'learning_rate': 1.4004223312261e-06, 'epoch': 0.83}
 83%|████████▎ | 1388/1663 [12:04:25<2:21:15, 30.82s/it] 84%|████████▎ | 1389/1663 [12:04:58<2:23:41, 31.46s/it]                                                        {'loss': 0.3977, 'learning_rate': 1.3904984155024425e-06, 'epoch': 0.83}
 84%|████████▎ | 1389/1663 [12:04:58<2:23:41, 31.46s/it] 84%|████████▎ | 1390/1663 [12:05:32<2:26:09, 32.12s/it]                                                        {'loss': 0.335, 'learning_rate': 1.3806071592300541e-06, 'epoch': 0.84}
 84%|████████▎ | 1390/1663 [12:05:32<2:26:09, 32.12s/it] 84%|████████▎ | 1391/1663 [12:06:03<2:24:48, 31.94s/it]                                                        {'loss': 0.4025, 'learning_rate': 1.370748599930619e-06, 'epoch': 0.84}
 84%|████████▎ | 1391/1663 [12:06:03<2:24:48, 31.94s/it] 84%|████████▎ | 1392/1663 [12:06:36<2:25:29, 32.21s/it]                                                        {'loss': 0.4574, 'learning_rate': 1.3609227750017884e-06, 'epoch': 0.84}
 84%|████████▎ | 1392/1663 [12:06:36<2:25:29, 32.21s/it] 84%|████████▍ | 1393/1663 [12:07:06<2:22:06, 31.58s/it]                                                        {'loss': 0.3664, 'learning_rate': 1.3511297217170382e-06, 'epoch': 0.84}
 84%|████████▍ | 1393/1663 [12:07:06<2:22:06, 31.58s/it] 84%|████████▍ | 1394/1663 [12:07:37<2:20:17, 31.29s/it]                                                        {'loss': 0.4403, 'learning_rate': 1.3413694772255281e-06, 'epoch': 0.84}
 84%|████████▍ | 1394/1663 [12:07:37<2:20:17, 31.29s/it] 84%|████████▍ | 1395/1663 [12:08:03<2:12:41, 29.71s/it]                                                        {'loss': 0.5171, 'learning_rate': 1.3316420785519591e-06, 'epoch': 0.84}
 84%|████████▍ | 1395/1663 [12:08:03<2:12:41, 29.71s/it] 84%|████████▍ | 1396/1663 [12:08:30<2:09:27, 29.09s/it]                                                        {'loss': 0.4059, 'learning_rate': 1.3219475625964363e-06, 'epoch': 0.84}
 84%|████████▍ | 1396/1663 [12:08:30<2:09:27, 29.09s/it] 84%|████████▍ | 1397/1663 [12:09:03<2:13:43, 30.16s/it]                                                        {'loss': 0.3575, 'learning_rate': 1.3122859661343246e-06, 'epoch': 0.84}
 84%|████████▍ | 1397/1663 [12:09:03<2:13:43, 30.16s/it] 84%|████████▍ | 1398/1663 [12:09:34<2:13:55, 30.32s/it]                                                        {'loss': 0.4289, 'learning_rate': 1.3026573258161124e-06, 'epoch': 0.84}
 84%|████████▍ | 1398/1663 [12:09:34<2:13:55, 30.32s/it] 84%|████████▍ | 1399/1663 [12:10:03<2:12:11, 30.04s/it]                                                        {'loss': 0.4071, 'learning_rate': 1.2930616781672734e-06, 'epoch': 0.84}
 84%|████████▍ | 1399/1663 [12:10:03<2:12:11, 30.04s/it] 84%|████████▍ | 1400/1663 [12:10:36<2:14:58, 30.79s/it]                                                        {'loss': 0.3454, 'learning_rate': 1.2834990595881235e-06, 'epoch': 0.84}
 84%|████████▍ | 1400/1663 [12:10:36<2:14:58, 30.79s/it] 84%|████████▍ | 1401/1663 [12:11:06<2:13:21, 30.54s/it]                                                        {'loss': 0.3764, 'learning_rate': 1.2739695063536862e-06, 'epoch': 0.84}
 84%|████████▍ | 1401/1663 [12:11:06<2:13:21, 30.54s/it] 84%|████████▍ | 1402/1663 [12:11:33<2:09:11, 29.70s/it]                                                        {'loss': 0.3604, 'learning_rate': 1.2644730546135543e-06, 'epoch': 0.84}
 84%|████████▍ | 1402/1663 [12:11:33<2:09:11, 29.70s/it] 84%|████████▍ | 1403/1663 [12:12:06<2:11:55, 30.44s/it]                                                        {'loss': 0.437, 'learning_rate': 1.2550097403917549e-06, 'epoch': 0.84}
 84%|████████▍ | 1403/1663 [12:12:06<2:11:55, 30.44s/it] 84%|████████▍ | 1404/1663 [12:12:36<2:11:38, 30.50s/it]                                                        {'loss': 0.3624, 'learning_rate': 1.2455795995866072e-06, 'epoch': 0.84}
 84%|████████▍ | 1404/1663 [12:12:36<2:11:38, 30.50s/it] 84%|████████▍ | 1405/1663 [12:13:07<2:11:06, 30.49s/it]                                                        {'loss': 0.4344, 'learning_rate': 1.2361826679705914e-06, 'epoch': 0.84}
 84%|████████▍ | 1405/1663 [12:13:07<2:11:06, 30.49s/it] 85%|████████▍ | 1406/1663 [12:13:37<2:10:30, 30.47s/it]                                                        {'loss': 0.3265, 'learning_rate': 1.226818981190212e-06, 'epoch': 0.85}
 85%|████████▍ | 1406/1663 [12:13:37<2:10:30, 30.47s/it] 85%|████████▍ | 1407/1663 [12:14:08<2:10:45, 30.64s/it]                                                        {'loss': 0.3167, 'learning_rate': 1.2174885747658606e-06, 'epoch': 0.85}
 85%|████████▍ | 1407/1663 [12:14:08<2:10:45, 30.64s/it] 85%|████████▍ | 1408/1663 [12:14:35<2:05:34, 29.55s/it]                                                        {'loss': 0.4399, 'learning_rate': 1.208191484091682e-06, 'epoch': 0.85}
 85%|████████▍ | 1408/1663 [12:14:35<2:05:34, 29.55s/it] 85%|████████▍ | 1409/1663 [12:15:08<2:08:56, 30.46s/it]                                                        {'loss': 0.4448, 'learning_rate': 1.198927744435443e-06, 'epoch': 0.85}
 85%|████████▍ | 1409/1663 [12:15:08<2:08:56, 30.46s/it] 85%|████████▍ | 1410/1663 [12:15:43<2:14:12, 31.83s/it]                                                        {'loss': 0.4393, 'learning_rate': 1.1896973909383946e-06, 'epoch': 0.85}
 85%|████████▍ | 1410/1663 [12:15:43<2:14:12, 31.83s/it] 85%|████████▍ | 1411/1663 [12:16:14<2:13:02, 31.68s/it]                                                        {'loss': 0.3943, 'learning_rate': 1.1805004586151381e-06, 'epoch': 0.85}
 85%|████████▍ | 1411/1663 [12:16:14<2:13:02, 31.68s/it] 85%|████████▍ | 1412/1663 [12:16:45<2:12:04, 31.57s/it]                                                        {'loss': 0.2911, 'learning_rate': 1.171336982353497e-06, 'epoch': 0.85}
 85%|████████▍ | 1412/1663 [12:16:45<2:12:04, 31.57s/it] 85%|████████▍ | 1413/1663 [12:17:17<2:11:37, 31.59s/it]                                                        {'loss': 0.4747, 'learning_rate': 1.1622069969143812e-06, 'epoch': 0.85}
 85%|████████▍ | 1413/1663 [12:17:17<2:11:37, 31.59s/it] 85%|████████▌ | 1414/1663 [12:17:49<2:12:13, 31.86s/it]                                                        {'loss': 0.3693, 'learning_rate': 1.1531105369316542e-06, 'epoch': 0.85}
 85%|████████▌ | 1414/1663 [12:17:49<2:12:13, 31.86s/it] 85%|████████▌ | 1415/1663 [12:18:24<2:15:28, 32.78s/it]                                                        {'loss': 0.3445, 'learning_rate': 1.1440476369120056e-06, 'epoch': 0.85}
 85%|████████▌ | 1415/1663 [12:18:24<2:15:28, 32.78s/it] 85%|████████▌ | 1416/1663 [12:18:57<2:15:20, 32.88s/it]                                                        {'loss': 0.3737, 'learning_rate': 1.1350183312348183e-06, 'epoch': 0.85}
 85%|████████▌ | 1416/1663 [12:18:57<2:15:20, 32.88s/it] 85%|████████▌ | 1417/1663 [12:19:34<2:19:53, 34.12s/it]                                                        {'loss': 0.5402, 'learning_rate': 1.1260226541520347e-06, 'epoch': 0.85}
 85%|████████▌ | 1417/1663 [12:19:35<2:19:53, 34.12s/it] 85%|████████▌ | 1418/1663 [12:20:04<2:13:38, 32.73s/it]                                                        {'loss': 0.4026, 'learning_rate': 1.1170606397880324e-06, 'epoch': 0.85}
 85%|████████▌ | 1418/1663 [12:20:04<2:13:38, 32.73s/it] 85%|████████▌ | 1419/1663 [12:20:43<2:21:20, 34.75s/it]                                                        {'loss': 0.445, 'learning_rate': 1.1081323221394923e-06, 'epoch': 0.85}
 85%|████████▌ | 1419/1663 [12:20:43<2:21:20, 34.75s/it] 85%|████████▌ | 1420/1663 [12:21:20<2:22:34, 35.20s/it]                                                        {'loss': 0.4463, 'learning_rate': 1.0992377350752682e-06, 'epoch': 0.85}
 85%|████████▌ | 1420/1663 [12:21:20<2:22:34, 35.20s/it] 85%|████████▌ | 1421/1663 [12:21:56<2:23:12, 35.51s/it]                                                        {'loss': 0.3418, 'learning_rate': 1.0903769123362594e-06, 'epoch': 0.85}
 85%|████████▌ | 1421/1663 [12:21:56<2:23:12, 35.51s/it] 86%|████████▌ | 1422/1663 [12:22:39<2:32:14, 37.90s/it]                                                        {'loss': 0.4463, 'learning_rate': 1.0815498875352848e-06, 'epoch': 0.85}
 86%|████████▌ | 1422/1663 [12:22:39<2:32:14, 37.90s/it] 86%|████████▌ | 1423/1663 [12:23:18<2:32:23, 38.10s/it]                                                        {'loss': 0.3473, 'learning_rate': 1.0727566941569522e-06, 'epoch': 0.86}
 86%|████████▌ | 1423/1663 [12:23:18<2:32:23, 38.10s/it] 86%|████████▌ | 1424/1663 [12:23:57<2:33:11, 38.46s/it]                                                        {'loss': 0.3402, 'learning_rate': 1.0639973655575319e-06, 'epoch': 0.86}
 86%|████████▌ | 1424/1663 [12:23:57<2:33:11, 38.46s/it] 86%|████████▌ | 1425/1663 [12:24:34<2:30:07, 37.85s/it]                                                        {'loss': 0.3864, 'learning_rate': 1.0552719349648344e-06, 'epoch': 0.86}
 86%|████████▌ | 1425/1663 [12:24:34<2:30:07, 37.85s/it] 86%|████████▌ | 1426/1663 [12:25:11<2:29:04, 37.74s/it]                                                        {'loss': 0.4194, 'learning_rate': 1.046580435478075e-06, 'epoch': 0.86}
 86%|████████▌ | 1426/1663 [12:25:11<2:29:04, 37.74s/it] 86%|████████▌ | 1427/1663 [12:25:44<2:22:53, 36.33s/it]                                                        {'loss': 0.4781, 'learning_rate': 1.0379229000677604e-06, 'epoch': 0.86}
 86%|████████▌ | 1427/1663 [12:25:44<2:22:53, 36.33s/it] 86%|████████▌ | 1428/1663 [12:26:16<2:17:17, 35.05s/it]                                                        {'loss': 0.354, 'learning_rate': 1.0292993615755531e-06, 'epoch': 0.86}
 86%|████████▌ | 1428/1663 [12:26:16<2:17:17, 35.05s/it] 86%|████████▌ | 1429/1663 [12:26:51<2:16:28, 34.99s/it]                                                        {'loss': 0.358, 'learning_rate': 1.0207098527141512e-06, 'epoch': 0.86}
 86%|████████▌ | 1429/1663 [12:26:51<2:16:28, 34.99s/it] 86%|████████▌ | 1430/1663 [12:27:29<2:18:52, 35.76s/it]                                                        {'loss': 0.3576, 'learning_rate': 1.0121544060671674e-06, 'epoch': 0.86}
 86%|████████▌ | 1430/1663 [12:27:29<2:18:52, 35.76s/it] 86%|████████▌ | 1431/1663 [12:28:04<2:17:33, 35.57s/it]                                                        {'loss': 0.4084, 'learning_rate': 1.0036330540889982e-06, 'epoch': 0.86}
 86%|████████▌ | 1431/1663 [12:28:04<2:17:33, 35.57s/it] 86%|████████▌ | 1432/1663 [12:28:41<2:18:21, 35.94s/it]                                                        {'loss': 0.3393, 'learning_rate': 9.951458291047067e-07, 'epoch': 0.86}
 86%|████████▌ | 1432/1663 [12:28:41<2:18:21, 35.94s/it] 86%|████████▌ | 1433/1663 [12:29:17<2:17:43, 35.93s/it]                                                        {'loss': 0.3616, 'learning_rate': 9.866927633098988e-07, 'epoch': 0.86}
 86%|████████▌ | 1433/1663 [12:29:17<2:17:43, 35.93s/it] 86%|████████▌ | 1434/1663 [12:30:00<2:25:22, 38.09s/it]                                                        {'loss': 0.3168, 'learning_rate': 9.78273888770598e-07, 'epoch': 0.86}
 86%|████████▌ | 1434/1663 [12:30:00<2:25:22, 38.09s/it] 86%|████████▋ | 1435/1663 [12:30:35<2:21:46, 37.31s/it]                                                        {'loss': 0.3699, 'learning_rate': 9.698892374231273e-07, 'epoch': 0.86}
 86%|████████▋ | 1435/1663 [12:30:35<2:21:46, 37.31s/it] 86%|████████▋ | 1436/1663 [12:31:12<2:21:10, 37.31s/it]                                                        {'loss': 0.3235, 'learning_rate': 9.615388410739868e-07, 'epoch': 0.86}
 86%|████████▋ | 1436/1663 [12:31:12<2:21:10, 37.31s/it] 86%|████████▋ | 1437/1663 [12:31:52<2:22:54, 37.94s/it]                                                        {'loss': 0.4643, 'learning_rate': 9.532227313997333e-07, 'epoch': 0.86}
 86%|████████▋ | 1437/1663 [12:31:52<2:22:54, 37.94s/it] 86%|████████▋ | 1438/1663 [12:32:27<2:18:35, 36.96s/it]                                                        {'loss': 0.4441, 'learning_rate': 9.44940939946859e-07, 'epoch': 0.86}
 86%|████████▋ | 1438/1663 [12:32:27<2:18:35, 36.96s/it] 87%|████████▋ | 1439/1663 [12:33:00<2:13:40, 35.81s/it]                                                        {'loss': 0.3511, 'learning_rate': 9.366934981316744e-07, 'epoch': 0.87}
 87%|████████▋ | 1439/1663 [12:33:00<2:13:40, 35.81s/it] 87%|████████▋ | 1440/1663 [12:33:36<2:13:25, 35.90s/it]                                                        {'loss': 0.3691, 'learning_rate': 9.284804372401845e-07, 'epoch': 0.87}
 87%|████████▋ | 1440/1663 [12:33:36<2:13:25, 35.90s/it] 87%|████████▋ | 1441/1663 [12:34:11<2:11:45, 35.61s/it]                                                        {'loss': 0.3483, 'learning_rate': 9.203017884279753e-07, 'epoch': 0.87}
 87%|████████▋ | 1441/1663 [12:34:11<2:11:45, 35.61s/it] 87%|████████▋ | 1442/1663 [12:34:43<2:07:04, 34.50s/it]                                                        {'loss': 0.5502, 'learning_rate': 9.121575827200935e-07, 'epoch': 0.87}
 87%|████████▋ | 1442/1663 [12:34:43<2:07:04, 34.50s/it] 87%|████████▋ | 1443/1663 [12:35:17<2:06:01, 34.37s/it]                                                        {'loss': 0.5126, 'learning_rate': 9.040478510109263e-07, 'epoch': 0.87}
 87%|████████▋ | 1443/1663 [12:35:17<2:06:01, 34.37s/it] 87%|████████▋ | 1444/1663 [12:35:55<2:09:48, 35.56s/it]                                                        {'loss': 0.4912, 'learning_rate': 8.959726240640898e-07, 'epoch': 0.87}
 87%|████████▋ | 1444/1663 [12:35:55<2:09:48, 35.56s/it] 87%|████████▋ | 1445/1663 [12:36:36<2:15:12, 37.21s/it]                                                        {'loss': 0.3798, 'learning_rate': 8.87931932512307e-07, 'epoch': 0.87}
 87%|████████▋ | 1445/1663 [12:36:36<2:15:12, 37.21s/it] 87%|████████▋ | 1446/1663 [12:37:14<2:15:42, 37.52s/it]                                                        {'loss': 0.3861, 'learning_rate': 8.799258068572935e-07, 'epoch': 0.87}
 87%|████████▋ | 1446/1663 [12:37:14<2:15:42, 37.52s/it] 87%|████████▋ | 1447/1663 [12:37:50<2:13:08, 36.98s/it]                                                        {'loss': 0.4744, 'learning_rate': 8.719542774696433e-07, 'epoch': 0.87}
 87%|████████▋ | 1447/1663 [12:37:50<2:13:08, 36.98s/it] 87%|████████▋ | 1448/1663 [12:38:26<2:11:25, 36.67s/it]                                                        {'loss': 0.372, 'learning_rate': 8.640173745887104e-07, 'epoch': 0.87}
 87%|████████▋ | 1448/1663 [12:38:26<2:11:25, 36.67s/it] 87%|████████▋ | 1449/1663 [12:39:02<2:10:07, 36.48s/it]                                                        {'loss': 0.3421, 'learning_rate': 8.561151283224978e-07, 'epoch': 0.87}
 87%|████████▋ | 1449/1663 [12:39:02<2:10:07, 36.48s/it] 87%|████████▋ | 1450/1663 [12:39:42<2:13:35, 37.63s/it]                                                        {'loss': 0.3412, 'learning_rate': 8.482475686475411e-07, 'epoch': 0.87}
 87%|████████▋ | 1450/1663 [12:39:42<2:13:35, 37.63s/it] 87%|████████▋ | 1451/1663 [12:40:18<2:10:28, 36.93s/it]                                                        {'loss': 0.3454, 'learning_rate': 8.404147254087947e-07, 'epoch': 0.87}
 87%|████████▋ | 1451/1663 [12:40:18<2:10:28, 36.93s/it] 87%|████████▋ | 1452/1663 [12:40:56<2:11:04, 37.27s/it]                                                        {'loss': 0.3641, 'learning_rate': 8.32616628319518e-07, 'epoch': 0.87}
 87%|████████▋ | 1452/1663 [12:40:56<2:11:04, 37.27s/it] 87%|████████▋ | 1453/1663 [12:41:30<2:07:33, 36.44s/it]                                                        {'loss': 0.3054, 'learning_rate': 8.248533069611641e-07, 'epoch': 0.87}
 87%|████████▋ | 1453/1663 [12:41:30<2:07:33, 36.44s/it] 87%|████████▋ | 1454/1663 [12:42:06<2:05:49, 36.12s/it]                                                        {'loss': 0.4072, 'learning_rate': 8.171247907832692e-07, 'epoch': 0.87}
 87%|████████▋ | 1454/1663 [12:42:06<2:05:49, 36.12s/it] 87%|████████▋ | 1455/1663 [12:42:44<2:07:06, 36.67s/it]                                                        {'loss': 0.336, 'learning_rate': 8.094311091033369e-07, 'epoch': 0.87}
 87%|████████▋ | 1455/1663 [12:42:44<2:07:06, 36.67s/it] 88%|████████▊ | 1456/1663 [12:43:21<2:07:29, 36.95s/it]                                                        {'loss': 0.3882, 'learning_rate': 8.017722911067294e-07, 'epoch': 0.88}
 88%|████████▊ | 1456/1663 [12:43:21<2:07:29, 36.95s/it] 88%|████████▊ | 1457/1663 [12:43:55<2:03:39, 36.02s/it]                                                        {'loss': 0.3987, 'learning_rate': 7.941483658465565e-07, 'epoch': 0.88}
 88%|████████▊ | 1457/1663 [12:43:55<2:03:39, 36.02s/it] 88%|████████▊ | 1458/1663 [12:44:32<2:04:08, 36.33s/it]                                                        {'loss': 0.3682, 'learning_rate': 7.865593622435641e-07, 'epoch': 0.88}
 88%|████████▊ | 1458/1663 [12:44:32<2:04:08, 36.33s/it] 88%|████████▊ | 1459/1663 [12:45:09<2:04:20, 36.57s/it]                                                        {'loss': 0.4416, 'learning_rate': 7.790053090860273e-07, 'epoch': 0.88}
 88%|████████▊ | 1459/1663 [12:45:09<2:04:20, 36.57s/it] 88%|████████▊ | 1460/1663 [12:45:51<2:08:51, 38.09s/it]                                                        {'loss': 0.4568, 'learning_rate': 7.714862350296382e-07, 'epoch': 0.88}
 88%|████████▊ | 1460/1663 [12:45:51<2:08:51, 38.09s/it] 88%|████████▊ | 1461/1663 [12:46:28<2:06:55, 37.70s/it]                                                        {'loss': 0.3861, 'learning_rate': 7.640021685973998e-07, 'epoch': 0.88}
 88%|████████▊ | 1461/1663 [12:46:28<2:06:55, 37.70s/it] 88%|████████▊ | 1462/1663 [12:47:03<2:04:05, 37.04s/it]                                                        {'loss': 0.5055, 'learning_rate': 7.565531381795144e-07, 'epoch': 0.88}
 88%|████████▊ | 1462/1663 [12:47:03<2:04:05, 37.04s/it] 88%|████████▊ | 1463/1663 [12:47:40<2:02:56, 36.88s/it]                                                        {'loss': 0.4825, 'learning_rate': 7.491391720332808e-07, 'epoch': 0.88}
 88%|████████▊ | 1463/1663 [12:47:40<2:02:56, 36.88s/it] 88%|████████▊ | 1464/1663 [12:48:21<2:06:18, 38.08s/it]                                                        {'loss': 0.3425, 'learning_rate': 7.417602982829819e-07, 'epoch': 0.88}
 88%|████████▊ | 1464/1663 [12:48:21<2:06:18, 38.08s/it] 88%|████████▊ | 1465/1663 [12:48:56<2:02:55, 37.25s/it]                                                        {'loss': 0.4511, 'learning_rate': 7.344165449197815e-07, 'epoch': 0.88}
 88%|████████▊ | 1465/1663 [12:48:56<2:02:55, 37.25s/it] 88%|████████▊ | 1466/1663 [12:49:35<2:04:22, 37.88s/it]                                                        {'loss': 0.3956, 'learning_rate': 7.271079398016167e-07, 'epoch': 0.88}
 88%|████████▊ | 1466/1663 [12:49:35<2:04:22, 37.88s/it] 88%|████████▊ | 1467/1663 [12:50:13<2:03:31, 37.81s/it]                                                        {'loss': 0.3902, 'learning_rate': 7.198345106530935e-07, 'epoch': 0.88}
 88%|████████▊ | 1467/1663 [12:50:13<2:03:31, 37.81s/it] 88%|████████▊ | 1468/1663 [12:50:48<1:59:52, 36.89s/it]                                                        {'loss': 0.4246, 'learning_rate': 7.125962850653789e-07, 'epoch': 0.88}
 88%|████████▊ | 1468/1663 [12:50:48<1:59:52, 36.89s/it] 88%|████████▊ | 1469/1663 [12:51:21<1:55:30, 35.72s/it]                                                        {'loss': 0.3958, 'learning_rate': 7.053932904960981e-07, 'epoch': 0.88}
 88%|████████▊ | 1469/1663 [12:51:21<1:55:30, 35.72s/it] 88%|████████▊ | 1470/1663 [12:51:56<1:54:37, 35.63s/it]                                                        {'loss': 0.4472, 'learning_rate': 6.98225554269234e-07, 'epoch': 0.88}
 88%|████████▊ | 1470/1663 [12:51:56<1:54:37, 35.63s/it] 88%|████████▊ | 1471/1663 [12:52:31<1:53:21, 35.42s/it]                                                        {'loss': 0.4636, 'learning_rate': 6.910931035750168e-07, 'epoch': 0.88}
 88%|████████▊ | 1471/1663 [12:52:31<1:53:21, 35.42s/it] 89%|████████▊ | 1472/1663 [12:53:07<1:53:38, 35.70s/it]                                                        {'loss': 0.3405, 'learning_rate': 6.839959654698225e-07, 'epoch': 0.88}
 89%|████████▊ | 1472/1663 [12:53:07<1:53:38, 35.70s/it] 89%|████████▊ | 1473/1663 [12:53:43<1:52:39, 35.57s/it]                                                        {'loss': 0.4619, 'learning_rate': 6.769341668760731e-07, 'epoch': 0.89}
 89%|████████▊ | 1473/1663 [12:53:43<1:52:39, 35.57s/it] 89%|████████▊ | 1474/1663 [12:54:17<1:51:15, 35.32s/it]                                                        {'loss': 0.4554, 'learning_rate': 6.699077345821337e-07, 'epoch': 0.89}
 89%|████████▊ | 1474/1663 [12:54:17<1:51:15, 35.32s/it] 89%|████████▊ | 1475/1663 [12:54:51<1:48:51, 34.74s/it]                                                        {'loss': 0.3967, 'learning_rate': 6.629166952422106e-07, 'epoch': 0.89}
 89%|████████▊ | 1475/1663 [12:54:51<1:48:51, 34.74s/it] 89%|████████▉ | 1476/1663 [12:55:35<1:57:00, 37.54s/it]                                                        {'loss': 0.4993, 'learning_rate': 6.55961075376248e-07, 'epoch': 0.89}
 89%|████████▉ | 1476/1663 [12:55:35<1:57:00, 37.54s/it] 89%|████████▉ | 1477/1663 [12:56:09<1:53:20, 36.56s/it]                                                        {'loss': 0.2979, 'learning_rate': 6.490409013698296e-07, 'epoch': 0.89}
 89%|████████▉ | 1477/1663 [12:56:09<1:53:20, 36.56s/it] 89%|████████▉ | 1478/1663 [12:56:41<1:48:45, 35.27s/it]                                                        {'loss': 0.4122, 'learning_rate': 6.421561994740788e-07, 'epoch': 0.89}
 89%|████████▉ | 1478/1663 [12:56:41<1:48:45, 35.27s/it] 89%|████████▉ | 1479/1663 [12:57:18<1:49:55, 35.84s/it]                                                        {'loss': 0.4243, 'learning_rate': 6.35306995805558e-07, 'epoch': 0.89}
 89%|████████▉ | 1479/1663 [12:57:18<1:49:55, 35.84s/it] 89%|████████▉ | 1480/1663 [12:57:53<1:48:16, 35.50s/it]                                                        {'loss': 0.3435, 'learning_rate': 6.284933163461704e-07, 'epoch': 0.89}
 89%|████████▉ | 1480/1663 [12:57:53<1:48:16, 35.50s/it] 89%|████████▉ | 1481/1663 [12:58:29<1:47:50, 35.55s/it]                                                        {'loss': 0.359, 'learning_rate': 6.217151869430593e-07, 'epoch': 0.89}
 89%|████████▉ | 1481/1663 [12:58:29<1:47:50, 35.55s/it] 89%|████████▉ | 1482/1663 [12:59:05<1:47:41, 35.70s/it]                                                        {'loss': 0.3185, 'learning_rate': 6.149726333085149e-07, 'epoch': 0.89}
 89%|████████▉ | 1482/1663 [12:59:05<1:47:41, 35.70s/it] 89%|████████▉ | 1483/1663 [12:59:37<1:43:53, 34.63s/it]                                                        {'loss': 0.2876, 'learning_rate': 6.082656810198717e-07, 'epoch': 0.89}
 89%|████████▉ | 1483/1663 [12:59:37<1:43:53, 34.63s/it] 89%|████████▉ | 1484/1663 [13:00:12<1:43:30, 34.69s/it]                                                        {'loss': 0.5302, 'learning_rate': 6.015943555194115e-07, 'epoch': 0.89}
 89%|████████▉ | 1484/1663 [13:00:12<1:43:30, 34.69s/it] 89%|████████▉ | 1485/1663 [13:00:49<1:45:04, 35.42s/it]                                                        {'loss': 0.436, 'learning_rate': 5.949586821142717e-07, 'epoch': 0.89}
 89%|████████▉ | 1485/1663 [13:00:49<1:45:04, 35.42s/it] 89%|████████▉ | 1486/1663 [13:01:26<1:45:36, 35.80s/it]                                                        {'loss': 0.4113, 'learning_rate': 5.883586859763446e-07, 'epoch': 0.89}
 89%|████████▉ | 1486/1663 [13:01:26<1:45:36, 35.80s/it] 89%|████████▉ | 1487/1663 [13:02:03<1:46:16, 36.23s/it]                                                        {'loss': 0.5154, 'learning_rate': 5.817943921421854e-07, 'epoch': 0.89}
 89%|████████▉ | 1487/1663 [13:02:03<1:46:16, 36.23s/it] 89%|████████▉ | 1488/1663 [13:02:40<1:46:11, 36.41s/it]                                                        {'loss': 0.3851, 'learning_rate': 5.752658255129129e-07, 'epoch': 0.89}
 89%|████████▉ | 1488/1663 [13:02:40<1:46:11, 36.41s/it] 90%|████████▉ | 1489/1663 [13:03:17<1:46:20, 36.67s/it]                                                        {'loss': 0.3479, 'learning_rate': 5.687730108541212e-07, 'epoch': 0.9}
 90%|████████▉ | 1489/1663 [13:03:17<1:46:20, 36.67s/it] 90%|████████▉ | 1490/1663 [13:03:52<1:44:06, 36.11s/it]                                                        {'loss': 0.3864, 'learning_rate': 5.623159727957784e-07, 'epoch': 0.9}
 90%|████████▉ | 1490/1663 [13:03:52<1:44:06, 36.11s/it] 90%|████████▉ | 1491/1663 [13:04:33<1:47:56, 37.65s/it]                                                        {'loss': 0.432, 'learning_rate': 5.558947358321387e-07, 'epoch': 0.9}
 90%|████████▉ | 1491/1663 [13:04:33<1:47:56, 37.65s/it] 90%|████████▉ | 1492/1663 [13:05:09<1:45:40, 37.08s/it]                                                        {'loss': 0.3264, 'learning_rate': 5.495093243216487e-07, 'epoch': 0.9}
 90%|████████▉ | 1492/1663 [13:05:09<1:45:40, 37.08s/it] 90%|████████▉ | 1493/1663 [13:05:48<1:46:50, 37.71s/it]                                                        {'loss': 0.3687, 'learning_rate': 5.431597624868523e-07, 'epoch': 0.9}
 90%|████████▉ | 1493/1663 [13:05:48<1:46:50, 37.71s/it] 90%|████████▉ | 1494/1663 [13:06:23<1:44:22, 37.06s/it]                                                        {'loss': 0.4292, 'learning_rate': 5.368460744143023e-07, 'epoch': 0.9}
 90%|████████▉ | 1494/1663 [13:06:23<1:44:22, 37.06s/it] 90%|████████▉ | 1495/1663 [13:06:59<1:42:43, 36.68s/it]                                                        {'loss': 0.4121, 'learning_rate': 5.305682840544635e-07, 'epoch': 0.9}
 90%|████████▉ | 1495/1663 [13:06:59<1:42:43, 36.68s/it] 90%|████████▉ | 1496/1663 [13:07:34<1:40:38, 36.16s/it]                                                        {'loss': 0.3757, 'learning_rate': 5.243264152216309e-07, 'epoch': 0.9}
 90%|████████▉ | 1496/1663 [13:07:34<1:40:38, 36.16s/it] 90%|█████████ | 1497/1663 [13:08:10<1:39:46, 36.07s/it]                                                        {'loss': 0.3833, 'learning_rate': 5.181204915938309e-07, 'epoch': 0.9}
 90%|█████████ | 1497/1663 [13:08:10<1:39:46, 36.07s/it] 90%|█████████ | 1498/1663 [13:08:45<1:38:24, 35.78s/it]                                                        {'loss': 0.3546, 'learning_rate': 5.119505367127353e-07, 'epoch': 0.9}
 90%|█████████ | 1498/1663 [13:08:45<1:38:24, 35.78s/it] 90%|█████████ | 1499/1663 [13:09:19<1:36:30, 35.31s/it]                                                        {'loss': 0.4737, 'learning_rate': 5.058165739835697e-07, 'epoch': 0.9}
 90%|█████████ | 1499/1663 [13:09:19<1:36:30, 35.31s/it] 90%|█████████ | 1500/1663 [13:09:56<1:36:34, 35.55s/it]                                                        {'loss': 0.3213, 'learning_rate': 4.997186266750309e-07, 'epoch': 0.9}
 90%|█████████ | 1500/1663 [13:09:56<1:36:34, 35.55s/it] 90%|█████████ | 1501/1663 [13:10:33<1:37:40, 36.18s/it]                                                        {'loss': 0.3926, 'learning_rate': 4.936567179191887e-07, 'epoch': 0.9}
 90%|█████████ | 1501/1663 [13:10:33<1:37:40, 36.18s/it] 90%|█████████ | 1502/1663 [13:11:09<1:36:25, 35.93s/it]                                                        {'loss': 0.4272, 'learning_rate': 4.876308707114063e-07, 'epoch': 0.9}
 90%|█████████ | 1502/1663 [13:11:09<1:36:25, 35.93s/it] 90%|█████████ | 1503/1663 [13:11:46<1:37:05, 36.41s/it]                                                        {'loss': 0.449, 'learning_rate': 4.816411079102523e-07, 'epoch': 0.9}
 90%|█████████ | 1503/1663 [13:11:46<1:37:05, 36.41s/it] 90%|█████████ | 1504/1663 [13:12:24<1:38:04, 37.01s/it]                                                        {'loss': 0.3668, 'learning_rate': 4.756874522374066e-07, 'epoch': 0.9}
 90%|█████████ | 1504/1663 [13:12:24<1:38:04, 37.01s/it] 90%|█████████ | 1505/1663 [13:12:59<1:35:49, 36.39s/it]                                                        {'loss': 0.4812, 'learning_rate': 4.6976992627758567e-07, 'epoch': 0.9}
 90%|█████████ | 1505/1663 [13:12:59<1:35:49, 36.39s/it] 91%|█████████ | 1506/1663 [13:13:33<1:33:22, 35.68s/it]                                                        {'loss': 0.4561, 'learning_rate': 4.6388855247844534e-07, 'epoch': 0.91}
 91%|█████████ | 1506/1663 [13:13:33<1:33:22, 35.68s/it] 91%|█████████ | 1507/1663 [13:14:09<1:32:59, 35.77s/it]                                                        {'loss': 0.4615, 'learning_rate': 4.5804335315050577e-07, 'epoch': 0.91}
 91%|█████████ | 1507/1663 [13:14:09<1:32:59, 35.77s/it] 91%|█████████ | 1508/1663 [13:14:41<1:28:51, 34.40s/it]                                                        {'loss': 0.4159, 'learning_rate': 4.5223435046705897e-07, 'epoch': 0.91}
 91%|█████████ | 1508/1663 [13:14:41<1:28:51, 34.40s/it] 91%|█████████ | 1509/1663 [13:15:19<1:31:44, 35.74s/it]                                                        {'loss': 0.4272, 'learning_rate': 4.464615664640903e-07, 'epoch': 0.91}
 91%|█████████ | 1509/1663 [13:15:20<1:31:44, 35.74s/it] 91%|█████████ | 1510/1663 [13:15:55<1:30:53, 35.65s/it]                                                        {'loss': 0.482, 'learning_rate': 4.407250230401894e-07, 'epoch': 0.91}
 91%|█████████ | 1510/1663 [13:15:55<1:30:53, 35.65s/it] 91%|█████████ | 1511/1663 [13:16:30<1:29:41, 35.40s/it]                                                        {'loss': 0.3888, 'learning_rate': 4.350247419564724e-07, 'epoch': 0.91}
 91%|█████████ | 1511/1663 [13:16:30<1:29:41, 35.40s/it] 91%|█████████ | 1512/1663 [13:17:05<1:29:20, 35.50s/it]                                                        {'loss': 0.4104, 'learning_rate': 4.293607448364989e-07, 'epoch': 0.91}
 91%|█████████ | 1512/1663 [13:17:05<1:29:20, 35.50s/it] 91%|█████████ | 1513/1663 [13:17:45<1:31:23, 36.56s/it]                                                        {'loss': 0.3925, 'learning_rate': 4.2373305316618316e-07, 'epoch': 0.91}
 91%|█████████ | 1513/1663 [13:17:45<1:31:23, 36.56s/it] 91%|█████████ | 1514/1663 [13:18:20<1:29:55, 36.21s/it]                                                        {'loss': 0.5028, 'learning_rate': 4.181416882937217e-07, 'epoch': 0.91}
 91%|█████████ | 1514/1663 [13:18:20<1:29:55, 36.21s/it] 91%|█████████ | 1515/1663 [13:18:56<1:29:13, 36.17s/it]                                                        {'loss': 0.3357, 'learning_rate': 4.125866714295079e-07, 'epoch': 0.91}
 91%|█████████ | 1515/1663 [13:18:56<1:29:13, 36.17s/it] 91%|█████████ | 1516/1663 [13:19:32<1:28:38, 36.18s/it]                                                        {'loss': 0.3361, 'learning_rate': 4.0706802364605e-07, 'epoch': 0.91}
 91%|█████████ | 1516/1663 [13:19:32<1:28:38, 36.18s/it] 91%|█████████ | 1517/1663 [13:20:07<1:27:13, 35.84s/it]                                                        {'loss': 0.4056, 'learning_rate': 4.015857658778954e-07, 'epoch': 0.91}
 91%|█████████ | 1517/1663 [13:20:07<1:27:13, 35.84s/it] 91%|█████████▏| 1518/1663 [13:20:42<1:25:51, 35.53s/it]                                                        {'loss': 0.397, 'learning_rate': 3.9613991892154534e-07, 'epoch': 0.91}
 91%|█████████▏| 1518/1663 [13:20:42<1:25:51, 35.53s/it] 91%|█████████▏| 1519/1663 [13:21:18<1:25:20, 35.56s/it]                                                        {'loss': 0.4107, 'learning_rate': 3.9073050343538476e-07, 'epoch': 0.91}
 91%|█████████▏| 1519/1663 [13:21:18<1:25:20, 35.56s/it] 91%|█████████▏| 1520/1663 [13:21:54<1:25:16, 35.78s/it]                                                        {'loss': 0.3797, 'learning_rate': 3.8535753993959477e-07, 'epoch': 0.91}
 91%|█████████▏| 1520/1663 [13:21:54<1:25:16, 35.78s/it] 91%|█████████▏| 1521/1663 [13:22:29<1:23:52, 35.44s/it]                                                        {'loss': 0.4511, 'learning_rate': 3.8002104881607826e-07, 'epoch': 0.91}
 91%|█████████▏| 1521/1663 [13:22:29<1:23:52, 35.44s/it] 92%|█████████▏| 1522/1663 [13:23:05<1:24:11, 35.83s/it]                                                        {'loss': 0.3753, 'learning_rate': 3.7472105030838755e-07, 'epoch': 0.91}
 92%|█████████▏| 1522/1663 [13:23:05<1:24:11, 35.83s/it] 92%|█████████▏| 1523/1663 [13:23:41<1:23:18, 35.70s/it]                                                        {'loss': 0.3698, 'learning_rate': 3.694575645216392e-07, 'epoch': 0.92}
 92%|█████████▏| 1523/1663 [13:23:41<1:23:18, 35.70s/it] 92%|█████████▏| 1524/1663 [13:24:16<1:22:31, 35.62s/it]                                                        {'loss': 0.48, 'learning_rate': 3.6423061142244145e-07, 'epoch': 0.92}
 92%|█████████▏| 1524/1663 [13:24:16<1:22:31, 35.62s/it] 92%|█████████▏| 1525/1663 [13:24:49<1:19:52, 34.73s/it]                                                        {'loss': 0.4732, 'learning_rate': 3.5904021083882243e-07, 'epoch': 0.92}
 92%|█████████▏| 1525/1663 [13:24:49<1:19:52, 34.73s/it] 92%|█████████▏| 1526/1663 [13:25:20<1:16:57, 33.71s/it]                                                        {'loss': 0.3397, 'learning_rate': 3.5388638246014684e-07, 'epoch': 0.92}
 92%|█████████▏| 1526/1663 [13:25:20<1:16:57, 33.71s/it] 92%|█████████▏| 1527/1663 [13:25:55<1:17:22, 34.13s/it]                                                        {'loss': 0.4031, 'learning_rate': 3.487691458370501e-07, 'epoch': 0.92}
 92%|█████████▏| 1527/1663 [13:25:55<1:17:22, 34.13s/it] 92%|█████████▏| 1528/1663 [13:26:32<1:18:23, 34.84s/it]                                                        {'loss': 0.4503, 'learning_rate': 3.436885203813556e-07, 'epoch': 0.92}
 92%|█████████▏| 1528/1663 [13:26:32<1:18:23, 34.84s/it] 92%|█████████▏| 1529/1663 [13:27:08<1:18:34, 35.19s/it]                                                        {'loss': 0.3728, 'learning_rate': 3.386445253660087e-07, 'epoch': 0.92}
 92%|█████████▏| 1529/1663 [13:27:08<1:18:34, 35.19s/it] 92%|█████████▏| 1530/1663 [13:27:44<1:18:28, 35.40s/it]                                                        {'loss': 0.4259, 'learning_rate': 3.33637179924996e-07, 'epoch': 0.92}
 92%|█████████▏| 1530/1663 [13:27:44<1:18:28, 35.40s/it] 92%|█████████▏| 1531/1663 [13:28:25<1:21:37, 37.10s/it]                                                        {'loss': 0.333, 'learning_rate': 3.286665030532821e-07, 'epoch': 0.92}
 92%|█████████▏| 1531/1663 [13:28:25<1:21:37, 37.10s/it] 92%|█████████▏| 1532/1663 [13:29:00<1:19:30, 36.41s/it]                                                        {'loss': 0.4012, 'learning_rate': 3.237325136067282e-07, 'epoch': 0.92}
 92%|█████████▏| 1532/1663 [13:29:00<1:19:30, 36.41s/it] 92%|█████████▏| 1533/1663 [13:29:36<1:18:48, 36.38s/it]                                                        {'loss': 0.3791, 'learning_rate': 3.188352303020259e-07, 'epoch': 0.92}
 92%|█████████▏| 1533/1663 [13:29:36<1:18:48, 36.38s/it] 92%|█████████▏| 1534/1663 [13:30:10<1:16:29, 35.58s/it]                                                        {'loss': 0.3808, 'learning_rate': 3.139746717166259e-07, 'epoch': 0.92}
 92%|█████████▏| 1534/1663 [13:30:10<1:16:29, 35.58s/it] 92%|█████████▏| 1535/1663 [13:30:46<1:16:14, 35.74s/it]                                                        {'loss': 0.396, 'learning_rate': 3.0915085628866583e-07, 'epoch': 0.92}
 92%|█████████▏| 1535/1663 [13:30:46<1:16:14, 35.74s/it] 92%|█████████▏| 1536/1663 [13:31:22<1:15:43, 35.77s/it]                                                        {'loss': 0.4838, 'learning_rate': 3.0436380231690153e-07, 'epoch': 0.92}
 92%|█████████▏| 1536/1663 [13:31:22<1:15:43, 35.77s/it] 92%|█████████▏| 1537/1663 [13:31:57<1:14:57, 35.69s/it]                                                        {'loss': 0.4694, 'learning_rate': 2.9961352796063606e-07, 'epoch': 0.92}
 92%|█████████▏| 1537/1663 [13:31:57<1:14:57, 35.69s/it] 92%|█████████▏| 1538/1663 [13:32:35<1:15:59, 36.48s/it]                                                        {'loss': 0.4586, 'learning_rate': 2.949000512396527e-07, 'epoch': 0.92}
 92%|█████████▏| 1538/1663 [13:32:35<1:15:59, 36.48s/it] 93%|█████████▎| 1539/1663 [13:33:15<1:17:26, 37.47s/it]                                                        {'loss': 0.4147, 'learning_rate': 2.902233900341478e-07, 'epoch': 0.93}
 93%|█████████▎| 1539/1663 [13:33:15<1:17:26, 37.47s/it] 93%|█████████▎| 1540/1663 [13:33:53<1:16:48, 37.47s/it]                                                        {'loss': 0.4021, 'learning_rate': 2.8558356208465697e-07, 'epoch': 0.93}
 93%|█████████▎| 1540/1663 [13:33:53<1:16:48, 37.47s/it] 93%|█████████▎| 1541/1663 [13:34:31<1:16:44, 37.74s/it]                                                        {'loss': 0.4099, 'learning_rate': 2.8098058499199556e-07, 'epoch': 0.93}
 93%|█████████▎| 1541/1663 [13:34:31<1:16:44, 37.74s/it] 93%|█████████▎| 1542/1663 [13:35:05<1:13:59, 36.69s/it]                                                        {'loss': 0.3362, 'learning_rate': 2.764144762171861e-07, 'epoch': 0.93}
 93%|█████████▎| 1542/1663 [13:35:05<1:13:59, 36.69s/it] 93%|█████████▎| 1543/1663 [13:35:41<1:13:01, 36.51s/it]                                                        {'loss': 0.303, 'learning_rate': 2.7188525308139533e-07, 'epoch': 0.93}
 93%|█████████▎| 1543/1663 [13:35:41<1:13:01, 36.51s/it] 93%|█████████▎| 1544/1663 [13:36:18<1:12:26, 36.52s/it]                                                        {'loss': 0.4604, 'learning_rate': 2.6739293276586534e-07, 'epoch': 0.93}
 93%|█████████▎| 1544/1663 [13:36:18<1:12:26, 36.52s/it] 93%|█████████▎| 1545/1663 [13:36:55<1:12:07, 36.67s/it]                                                        {'loss': 0.4736, 'learning_rate': 2.6293753231185216e-07, 'epoch': 0.93}
 93%|█████████▎| 1545/1663 [13:36:55<1:12:07, 36.67s/it] 93%|█████████▎| 1546/1663 [13:37:32<1:11:48, 36.82s/it]                                                        {'loss': 0.4607, 'learning_rate': 2.5851906862055965e-07, 'epoch': 0.93}
 93%|█████████▎| 1546/1663 [13:37:32<1:11:48, 36.82s/it] 93%|█████████▎| 1547/1663 [13:38:07<1:10:14, 36.33s/it]                                                        {'loss': 0.4267, 'learning_rate': 2.5413755845307364e-07, 'epoch': 0.93}
 93%|█████████▎| 1547/1663 [13:38:07<1:10:14, 36.33s/it] 93%|█████████▎| 1548/1663 [13:38:44<1:09:49, 36.43s/it]                                                        {'loss': 0.3903, 'learning_rate': 2.49793018430301e-07, 'epoch': 0.93}
 93%|█████████▎| 1548/1663 [13:38:44<1:09:49, 36.43s/it] 93%|█████████▎| 1549/1663 [13:39:19<1:08:12, 35.89s/it]                                                        {'loss': 0.3847, 'learning_rate': 2.4548546503290307e-07, 'epoch': 0.93}
 93%|█████████▎| 1549/1663 [13:39:19<1:08:12, 35.89s/it] 93%|█████████▎| 1550/1663 [13:39:54<1:07:14, 35.70s/it]                                                        {'loss': 0.4143, 'learning_rate': 2.412149146012377e-07, 'epoch': 0.93}
 93%|█████████▎| 1550/1663 [13:39:54<1:07:14, 35.70s/it] 93%|█████████▎| 1551/1663 [13:40:28<1:06:02, 35.38s/it]                                                        {'loss': 0.4179, 'learning_rate': 2.3698138333529408e-07, 'epoch': 0.93}
 93%|█████████▎| 1551/1663 [13:40:28<1:06:02, 35.38s/it] 93%|█████████▎| 1552/1663 [13:41:03<1:04:59, 35.13s/it]                                                        {'loss': 0.3634, 'learning_rate': 2.3278488729463257e-07, 'epoch': 0.93}
 93%|█████████▎| 1552/1663 [13:41:03<1:04:59, 35.13s/it] 93%|█████████▎| 1553/1663 [13:41:38<1:04:23, 35.12s/it]                                                        {'loss': 0.358, 'learning_rate': 2.2862544239832364e-07, 'epoch': 0.93}
 93%|█████████▎| 1553/1663 [13:41:38<1:04:23, 35.12s/it] 93%|█████████▎| 1554/1663 [13:42:13<1:03:42, 35.07s/it]                                                        {'loss': 0.5145, 'learning_rate': 2.2450306442488467e-07, 'epoch': 0.93}
 93%|█████████▎| 1554/1663 [13:42:13<1:03:42, 35.07s/it] 94%|█████████▎| 1555/1663 [13:42:52<1:04:58, 36.10s/it]                                                        {'loss': 0.468, 'learning_rate': 2.2041776901222667e-07, 'epoch': 0.93}
 94%|█████████▎| 1555/1663 [13:42:52<1:04:58, 36.10s/it] 94%|█████████▎| 1556/1663 [13:43:29<1:05:22, 36.66s/it]                                                        {'loss': 0.5499, 'learning_rate': 2.1636957165758866e-07, 'epoch': 0.94}
 94%|█████████▎| 1556/1663 [13:43:29<1:05:22, 36.66s/it] 94%|█████████▎| 1557/1663 [13:44:04<1:03:40, 36.04s/it]                                                        {'loss': 0.3922, 'learning_rate': 2.1235848771748113e-07, 'epoch': 0.94}
 94%|█████████▎| 1557/1663 [13:44:04<1:03:40, 36.04s/it] 94%|█████████▎| 1558/1663 [13:44:39<1:02:19, 35.62s/it]                                                        {'loss': 0.4017, 'learning_rate': 2.0838453240762835e-07, 'epoch': 0.94}
 94%|█████████▎| 1558/1663 [13:44:39<1:02:19, 35.62s/it] 94%|█████████▎| 1559/1663 [13:45:16<1:02:27, 36.04s/it]                                                        {'loss': 0.3531, 'learning_rate': 2.0444772080290943e-07, 'epoch': 0.94}
 94%|█████████▎| 1559/1663 [13:45:16<1:02:27, 36.04s/it] 94%|█████████▍| 1560/1663 [13:45:51<1:01:33, 35.86s/it]                                                        {'loss': 0.4902, 'learning_rate': 2.0054806783730285e-07, 'epoch': 0.94}
 94%|█████████▍| 1560/1663 [13:45:51<1:01:33, 35.86s/it] 94%|█████████▍| 1561/1663 [13:46:29<1:01:48, 36.36s/it]                                                        {'loss': 0.4413, 'learning_rate': 1.9668558830382768e-07, 'epoch': 0.94}
 94%|█████████▍| 1561/1663 [13:46:29<1:01:48, 36.36s/it] 94%|█████████▍| 1562/1663 [13:47:03<1:00:06, 35.71s/it]                                                        {'loss': 0.3793, 'learning_rate': 1.9286029685449016e-07, 'epoch': 0.94}
 94%|█████████▍| 1562/1663 [13:47:03<1:00:06, 35.71s/it] 94%|█████████▍| 1563/1663 [13:47:38<58:59, 35.39s/it]                                                        {'loss': 0.3505, 'learning_rate': 1.8907220800022386e-07, 'epoch': 0.94}
 94%|█████████▍| 1563/1663 [13:47:38<58:59, 35.39s/it] 94%|█████████▍| 1564/1663 [13:48:15<59:25, 36.01s/it]                                                      {'loss': 0.3704, 'learning_rate': 1.853213361108408e-07, 'epoch': 0.94}
 94%|█████████▍| 1564/1663 [13:48:15<59:25, 36.01s/it] 94%|█████████▍| 1565/1663 [13:48:50<58:18, 35.70s/it]                                                      {'loss': 0.3759, 'learning_rate': 1.8160769541497036e-07, 'epoch': 0.94}
 94%|█████████▍| 1565/1663 [13:48:50<58:18, 35.70s/it] 94%|█████████▍| 1566/1663 [13:49:32<1:00:40, 37.53s/it]                                                        {'loss': 0.3791, 'learning_rate': 1.7793130000000935e-07, 'epoch': 0.94}
 94%|█████████▍| 1566/1663 [13:49:32<1:00:40, 37.53s/it] 94%|█████████▍| 1567/1663 [13:50:09<1:00:03, 37.54s/it]                                                        {'loss': 0.4286, 'learning_rate': 1.742921638120698e-07, 'epoch': 0.94}
 94%|█████████▍| 1567/1663 [13:50:09<1:00:03, 37.54s/it] 94%|█████████▍| 1568/1663 [13:50:50<1:00:48, 38.40s/it]                                                        {'loss': 0.4485, 'learning_rate': 1.7069030065591908e-07, 'epoch': 0.94}
 94%|█████████▍| 1568/1663 [13:50:50<1:00:48, 38.40s/it] 94%|█████████▍| 1569/1663 [13:51:27<59:30, 37.99s/it]                                                        {'loss': 0.4831, 'learning_rate': 1.6712572419493755e-07, 'epoch': 0.94}
 94%|█████████▍| 1569/1663 [13:51:27<59:30, 37.99s/it] 94%|█████████▍| 1570/1663 [13:52:03<57:51, 37.33s/it]                                                      {'loss': 0.3314, 'learning_rate': 1.6359844795105774e-07, 'epoch': 0.94}
 94%|█████████▍| 1570/1663 [13:52:03<57:51, 37.33s/it] 94%|█████████▍| 1571/1663 [13:52:38<56:10, 36.63s/it]                                                      {'loss': 0.4322, 'learning_rate': 1.6010848530471857e-07, 'epoch': 0.94}
 94%|█████████▍| 1571/1663 [13:52:38<56:10, 36.63s/it] 95%|█████████▍| 1572/1663 [13:53:15<55:49, 36.81s/it]                                                      {'loss': 0.456, 'learning_rate': 1.5665584949481227e-07, 'epoch': 0.94}
 95%|█████████▍| 1572/1663 [13:53:15<55:49, 36.81s/it] 95%|█████████▍| 1573/1663 [13:53:48<53:32, 35.70s/it]                                                      {'loss': 0.4108, 'learning_rate': 1.5324055361863544e-07, 'epoch': 0.95}
 95%|█████████▍| 1573/1663 [13:53:48<53:32, 35.70s/it] 95%|█████████▍| 1574/1663 [13:54:28<55:08, 37.17s/it]                                                      {'loss': 0.5071, 'learning_rate': 1.4986261063183794e-07, 'epoch': 0.95}
 95%|█████████▍| 1574/1663 [13:54:28<55:08, 37.17s/it] 95%|█████████▍| 1575/1663 [13:55:03<53:21, 36.38s/it]                                                      {'loss': 0.4124, 'learning_rate': 1.4652203334837412e-07, 'epoch': 0.95}
 95%|█████████▍| 1575/1663 [13:55:03<53:21, 36.38s/it] 95%|█████████▍| 1576/1663 [13:55:41<53:31, 36.91s/it]                                                      {'loss': 0.4238, 'learning_rate': 1.4321883444045503e-07, 'epoch': 0.95}
 95%|█████████▍| 1576/1663 [13:55:41<53:31, 36.91s/it] 95%|█████████▍| 1577/1663 [13:56:24<55:17, 38.57s/it]                                                      {'loss': 0.4695, 'learning_rate': 1.399530264384996e-07, 'epoch': 0.95}
 95%|█████████▍| 1577/1663 [13:56:24<55:17, 38.57s/it] 95%|█████████▍| 1578/1663 [13:56:59<53:21, 37.66s/it]                                                      {'loss': 0.4523, 'learning_rate': 1.3672462173108915e-07, 'epoch': 0.95}
 95%|█████████▍| 1578/1663 [13:56:59<53:21, 37.66s/it] 95%|█████████▍| 1579/1663 [13:57:36<52:25, 37.44s/it]                                                      {'loss': 0.3513, 'learning_rate': 1.3353363256491502e-07, 'epoch': 0.95}
 95%|█████████▍| 1579/1663 [13:57:36<52:25, 37.44s/it] 95%|█████████▌| 1580/1663 [13:58:11<50:47, 36.72s/it]                                                      {'loss': 0.4753, 'learning_rate': 1.3038007104474004e-07, 'epoch': 0.95}
 95%|█████████▌| 1580/1663 [13:58:11<50:47, 36.72s/it] 95%|█████████▌| 1581/1663 [13:58:46<49:36, 36.30s/it]                                                      {'loss': 0.3873, 'learning_rate': 1.2726394913334384e-07, 'epoch': 0.95}
 95%|█████████▌| 1581/1663 [13:58:46<49:36, 36.30s/it] 95%|█████████▌| 1582/1663 [13:59:23<48:54, 36.23s/it]                                                      {'loss': 0.3427, 'learning_rate': 1.2418527865148523e-07, 'epoch': 0.95}
 95%|█████████▌| 1582/1663 [13:59:23<48:54, 36.23s/it] 95%|█████████▌| 1583/1663 [13:59:57<47:45, 35.82s/it]                                                      {'loss': 0.361, 'learning_rate': 1.2114407127785223e-07, 'epoch': 0.95}
 95%|█████████▌| 1583/1663 [13:59:57<47:45, 35.82s/it] 95%|█████████▌| 1584/1663 [14:00:34<47:36, 36.15s/it]                                                      {'loss': 0.3871, 'learning_rate': 1.1814033854902095e-07, 'epoch': 0.95}
 95%|█████████▌| 1584/1663 [14:00:34<47:36, 36.15s/it] 95%|█████████▌| 1585/1663 [14:01:11<47:21, 36.42s/it]                                                      {'loss': 0.4006, 'learning_rate': 1.1517409185940909e-07, 'epoch': 0.95}
 95%|█████████▌| 1585/1663 [14:01:11<47:21, 36.42s/it] 95%|█████████▌| 1586/1663 [14:01:49<47:02, 36.65s/it]                                                      {'loss': 0.4817, 'learning_rate': 1.1224534246123465e-07, 'epoch': 0.95}
 95%|█████████▌| 1586/1663 [14:01:49<47:02, 36.65s/it] 95%|█████████▌| 1587/1663 [14:02:24<45:53, 36.22s/it]                                                      {'loss': 0.3553, 'learning_rate': 1.0935410146447389e-07, 'epoch': 0.95}
 95%|█████████▌| 1587/1663 [14:02:24<45:53, 36.22s/it] 95%|█████████▌| 1588/1663 [14:03:01<45:31, 36.41s/it]                                                      {'loss': 0.3097, 'learning_rate': 1.0650037983681583e-07, 'epoch': 0.95}
 95%|█████████▌| 1588/1663 [14:03:01<45:31, 36.41s/it] 96%|█████████▌| 1589/1663 [14:03:37<45:02, 36.51s/it]                                                      {'loss': 0.4197, 'learning_rate': 1.0368418840362327e-07, 'epoch': 0.96}
 96%|█████████▌| 1589/1663 [14:03:37<45:02, 36.51s/it] 96%|█████████▌| 1590/1663 [14:04:17<45:27, 37.36s/it]                                                      {'loss': 0.3584, 'learning_rate': 1.0090553784789292e-07, 'epoch': 0.96}
 96%|█████████▌| 1590/1663 [14:04:17<45:27, 37.36s/it] 96%|█████████▌| 1591/1663 [14:04:50<43:27, 36.21s/it]                                                      {'loss': 0.3701, 'learning_rate': 9.816443871021098e-08, 'epoch': 0.96}
 96%|█████████▌| 1591/1663 [14:04:50<43:27, 36.21s/it] 96%|█████████▌| 1592/1663 [14:05:30<44:07, 37.29s/it]                                                      {'loss': 0.4047, 'learning_rate': 9.546090138871755e-08, 'epoch': 0.96}
 96%|█████████▌| 1592/1663 [14:05:30<44:07, 37.29s/it] 96%|█████████▌| 1593/1663 [14:06:06<42:52, 36.75s/it]                                                      {'loss': 0.3282, 'learning_rate': 9.279493613906232e-08, 'epoch': 0.96}
 96%|█████████▌| 1593/1663 [14:06:06<42:52, 36.75s/it] 96%|█████████▌| 1594/1663 [14:06:40<41:21, 35.96s/it]                                                      {'loss': 0.4206, 'learning_rate': 9.016655307437117e-08, 'epoch': 0.96}
 96%|█████████▌| 1594/1663 [14:06:40<41:21, 35.96s/it] 96%|█████████▌| 1595/1663 [14:07:21<42:39, 37.64s/it]                                                      {'loss': 0.3887, 'learning_rate': 8.757576216520402e-08, 'epoch': 0.96}
 96%|█████████▌| 1595/1663 [14:07:21<42:39, 37.64s/it] 96%|█████████▌| 1596/1663 [14:07:56<41:09, 36.86s/it]                                                      {'loss': 0.3527, 'learning_rate': 8.502257323951602e-08, 'epoch': 0.96}
 96%|█████████▌| 1596/1663 [14:07:56<41:09, 36.86s/it] 96%|█████████▌| 1597/1663 [14:08:31<39:46, 36.16s/it]                                                      {'loss': 0.4496, 'learning_rate': 8.250699598262523e-08, 'epoch': 0.96}
 96%|█████████▌| 1597/1663 [14:08:31<39:46, 36.16s/it] 96%|█████████▌| 1598/1663 [14:09:05<38:26, 35.49s/it]                                                      {'loss': 0.3453, 'learning_rate': 8.00290399371706e-08, 'epoch': 0.96}
 96%|█████████▌| 1598/1663 [14:09:05<38:26, 35.49s/it] 96%|█████████▌| 1599/1663 [14:09:47<39:58, 37.47s/it]                                                      {'loss': 0.4328, 'learning_rate': 7.758871450307848e-08, 'epoch': 0.96}
 96%|█████████▌| 1599/1663 [14:09:47<39:58, 37.47s/it] 96%|█████████▌| 1600/1663 [14:10:22<38:37, 36.79s/it]                                                      {'loss': 0.4269, 'learning_rate': 7.518602893752835e-08, 'epoch': 0.96}
 96%|█████████▌| 1600/1663 [14:10:22<38:37, 36.79s/it] 96%|█████████▋| 1601/1663 [14:10:56<37:12, 36.00s/it]                                                      {'loss': 0.3696, 'learning_rate': 7.282099235491391e-08, 'epoch': 0.96}
 96%|█████████▋| 1601/1663 [14:10:56<37:12, 36.00s/it] 96%|█████████▋| 1602/1663 [14:11:33<36:47, 36.19s/it]                                                      {'loss': 0.4106, 'learning_rate': 7.049361372681195e-08, 'epoch': 0.96}
 96%|█████████▋| 1602/1663 [14:11:33<36:47, 36.19s/it] 96%|█████████▋| 1603/1663 [14:12:08<35:58, 35.98s/it]                                                      {'loss': 0.4087, 'learning_rate': 6.82039018819447e-08, 'epoch': 0.96}
 96%|█████████▋| 1603/1663 [14:12:08<35:58, 35.98s/it] 96%|█████████▋| 1604/1663 [14:12:44<35:18, 35.90s/it]                                                      {'loss': 0.372, 'learning_rate': 6.595186550614973e-08, 'epoch': 0.96}
 96%|█████████▋| 1604/1663 [14:12:44<35:18, 35.90s/it] 97%|█████████▋| 1605/1663 [14:13:19<34:33, 35.75s/it]                                                      {'loss': 0.4537, 'learning_rate': 6.373751314234678e-08, 'epoch': 0.96}
 97%|█████████▋| 1605/1663 [14:13:19<34:33, 35.75s/it] 97%|█████████▋| 1606/1663 [14:13:57<34:21, 36.17s/it]                                                      {'loss': 0.3684, 'learning_rate': 6.15608531905032e-08, 'epoch': 0.97}
 97%|█████████▋| 1606/1663 [14:13:57<34:21, 36.17s/it] 97%|█████████▋| 1607/1663 [14:14:33<33:57, 36.39s/it]                                                      {'loss': 0.4327, 'learning_rate': 5.942189390760189e-08, 'epoch': 0.97}
 97%|█████████▋| 1607/1663 [14:14:33<33:57, 36.39s/it] 97%|█████████▋| 1608/1663 [14:15:09<33:09, 36.17s/it]                                                      {'loss': 0.3578, 'learning_rate': 5.732064340761345e-08, 'epoch': 0.97}
 97%|█████████▋| 1608/1663 [14:15:09<33:09, 36.17s/it] 97%|█████████▋| 1609/1663 [14:15:45<32:25, 36.03s/it]                                                      {'loss': 0.327, 'learning_rate': 5.5257109661464024e-08, 'epoch': 0.97}
 97%|█████████▋| 1609/1663 [14:15:45<32:25, 36.03s/it] 97%|█████████▋| 1610/1663 [14:16:21<31:55, 36.15s/it]                                                      {'loss': 0.374, 'learning_rate': 5.323130049699976e-08, 'epoch': 0.97}
 97%|█████████▋| 1610/1663 [14:16:21<31:55, 36.15s/it] 97%|█████████▋| 1611/1663 [14:16:58<31:24, 36.23s/it]                                                      {'loss': 0.3528, 'learning_rate': 5.124322359896794e-08, 'epoch': 0.97}
 97%|█████████▋| 1611/1663 [14:16:58<31:24, 36.23s/it] 97%|█████████▋| 1612/1663 [14:17:34<30:44, 36.16s/it]                                                      {'loss': 0.3254, 'learning_rate': 4.9292886508975904e-08, 'epoch': 0.97}
 97%|█████████▋| 1612/1663 [14:17:34<30:44, 36.16s/it] 97%|█████████▋| 1613/1663 [14:18:12<30:47, 36.94s/it]                                                      {'loss': 0.3764, 'learning_rate': 4.7380296625472163e-08, 'epoch': 0.97}
 97%|█████████▋| 1613/1663 [14:18:12<30:47, 36.94s/it] 97%|█████████▋| 1614/1663 [14:18:46<29:18, 35.88s/it]                                                      {'loss': 0.4421, 'learning_rate': 4.550546120371091e-08, 'epoch': 0.97}
 97%|█████████▋| 1614/1663 [14:18:46<29:18, 35.88s/it] 97%|█████████▋| 1615/1663 [14:19:20<28:23, 35.49s/it]                                                      {'loss': 0.4265, 'learning_rate': 4.3668387355729756e-08, 'epoch': 0.97}
 97%|█████████▋| 1615/1663 [14:19:20<28:23, 35.49s/it] 97%|█████████▋| 1616/1663 [14:19:59<28:37, 36.54s/it]                                                      {'loss': 0.483, 'learning_rate': 4.186908205032092e-08, 'epoch': 0.97}
 97%|█████████▋| 1616/1663 [14:19:59<28:37, 36.54s/it] 97%|█████████▋| 1617/1663 [14:20:34<27:36, 36.02s/it]                                                      {'loss': 0.3695, 'learning_rate': 4.0107552113004545e-08, 'epoch': 0.97}
 97%|█████████▋| 1617/1663 [14:20:34<27:36, 36.02s/it] 97%|█████████▋| 1618/1663 [14:21:08<26:31, 35.38s/it]                                                      {'loss': 0.4091, 'learning_rate': 3.8383804226002074e-08, 'epoch': 0.97}
 97%|█████████▋| 1618/1663 [14:21:08<26:31, 35.38s/it] 97%|█████████▋| 1619/1663 [14:21:44<25:59, 35.45s/it]                                                      {'loss': 0.4697, 'learning_rate': 3.669784492821182e-08, 'epoch': 0.97}
 97%|█████████▋| 1619/1663 [14:21:44<25:59, 35.45s/it] 97%|█████████▋| 1620/1663 [14:22:22<25:58, 36.25s/it]                                                      {'loss': 0.4227, 'learning_rate': 3.504968061518565e-08, 'epoch': 0.97}
 97%|█████████▋| 1620/1663 [14:22:22<25:58, 36.25s/it] 97%|█████████▋| 1621/1663 [14:23:00<25:48, 36.86s/it]                                                      {'loss': 0.3028, 'learning_rate': 3.343931753910234e-08, 'epoch': 0.97}
 97%|█████████▋| 1621/1663 [14:23:00<25:48, 36.86s/it] 98%|█████████▊| 1622/1663 [14:23:37<25:13, 36.91s/it]                                                      {'loss': 0.4483, 'learning_rate': 3.186676180874426e-08, 'epoch': 0.98}
 98%|█████████▊| 1622/1663 [14:23:37<25:13, 36.91s/it] 98%|█████████▊| 1623/1663 [14:24:14<24:41, 37.04s/it]                                                      {'loss': 0.3823, 'learning_rate': 3.0332019389475165e-08, 'epoch': 0.98}
 98%|█████████▊| 1623/1663 [14:24:15<24:41, 37.04s/it] 98%|█████████▊| 1624/1663 [14:24:50<23:41, 36.46s/it]                                                      {'loss': 0.4707, 'learning_rate': 2.8835096103215776e-08, 'epoch': 0.98}
 98%|█████████▊| 1624/1663 [14:24:50<23:41, 36.46s/it] 98%|█████████▊| 1625/1663 [14:25:23<22:26, 35.44s/it]                                                      {'loss': 0.3925, 'learning_rate': 2.737599762842602e-08, 'epoch': 0.98}
 98%|█████████▊| 1625/1663 [14:25:23<22:26, 35.44s/it] 98%|█████████▊| 1626/1663 [14:26:00<22:10, 35.96s/it]                                                      {'loss': 0.3713, 'learning_rate': 2.595472950007727e-08, 'epoch': 0.98}
 98%|█████████▊| 1626/1663 [14:26:00<22:10, 35.96s/it] 98%|█████████▊| 1627/1663 [14:26:36<21:39, 36.09s/it]                                                      {'loss': 0.4843, 'learning_rate': 2.4571297109635684e-08, 'epoch': 0.98}
 98%|█████████▊| 1627/1663 [14:26:36<21:39, 36.09s/it] 98%|█████████▊| 1628/1663 [14:27:10<20:43, 35.54s/it]                                                      {'loss': 0.4256, 'learning_rate': 2.3225705705040014e-08, 'epoch': 0.98}
 98%|█████████▊| 1628/1663 [14:27:11<20:43, 35.54s/it] 98%|█████████▊| 1629/1663 [14:27:47<20:22, 35.97s/it]                                                      {'loss': 0.3899, 'learning_rate': 2.1917960390684946e-08, 'epoch': 0.98}
 98%|█████████▊| 1629/1663 [14:27:47<20:22, 35.97s/it] 98%|█████████▊| 1630/1663 [14:28:31<21:01, 38.23s/it]                                                      {'loss': 0.4871, 'learning_rate': 2.0648066127396672e-08, 'epoch': 0.98}
 98%|█████████▊| 1630/1663 [14:28:31<21:01, 38.23s/it] 98%|█████████▊| 1631/1663 [14:29:06<19:51, 37.25s/it]                                                      {'loss': 0.4502, 'learning_rate': 1.9416027732415134e-08, 'epoch': 0.98}
 98%|█████████▊| 1631/1663 [14:29:06<19:51, 37.25s/it] 98%|█████████▊| 1632/1663 [14:29:40<18:47, 36.36s/it]                                                      {'loss': 0.2878, 'learning_rate': 1.822184987937958e-08, 'epoch': 0.98}
 98%|█████████▊| 1632/1663 [14:29:40<18:47, 36.36s/it] 98%|█████████▊| 1633/1663 [14:30:15<17:52, 35.76s/it]                                                      {'loss': 0.3595, 'learning_rate': 1.7065537098308606e-08, 'epoch': 0.98}
 98%|█████████▊| 1633/1663 [14:30:15<17:52, 35.76s/it] 98%|█████████▊| 1634/1663 [14:30:48<17:00, 35.19s/it]                                                      {'loss': 0.4152, 'learning_rate': 1.5947093775581235e-08, 'epoch': 0.98}
 98%|█████████▊| 1634/1663 [14:30:48<17:00, 35.19s/it] 98%|█████████▊| 1635/1663 [14:31:29<17:08, 36.75s/it]                                                      {'loss': 0.4247, 'learning_rate': 1.4866524153921425e-08, 'epoch': 0.98}
 98%|█████████▊| 1635/1663 [14:31:29<17:08, 36.75s/it] 98%|█████████▊| 1636/1663 [14:32:04<16:21, 36.35s/it]                                                      {'loss': 0.4266, 'learning_rate': 1.3823832332383603e-08, 'epoch': 0.98}
 98%|█████████▊| 1636/1663 [14:32:04<16:21, 36.35s/it] 98%|█████████▊| 1637/1663 [14:32:38<15:26, 35.63s/it]                                                      {'loss': 0.414, 'learning_rate': 1.2819022266334913e-08, 'epoch': 0.98}
 98%|█████████▊| 1637/1663 [14:32:38<15:26, 35.63s/it] 98%|█████████▊| 1638/1663 [14:33:14<14:51, 35.66s/it]                                                      {'loss': 0.3042, 'learning_rate': 1.1852097767441895e-08, 'epoch': 0.98}
 98%|█████████▊| 1638/1663 [14:33:14<14:51, 35.66s/it] 99%|█████████▊| 1639/1663 [14:33:51<14:28, 36.17s/it]                                                      {'loss': 0.386, 'learning_rate': 1.0923062503654935e-08, 'epoch': 0.99}
 99%|█████████▊| 1639/1663 [14:33:51<14:28, 36.17s/it] 99%|█████████▊| 1640/1663 [14:34:26<13:43, 35.80s/it]                                                      {'loss': 0.3747, 'learning_rate': 1.0031919999194951e-08, 'epoch': 0.99}
 99%|█████████▊| 1640/1663 [14:34:26<13:43, 35.80s/it] 99%|█████████▊| 1641/1663 [14:34:59<12:50, 35.03s/it]                                                      {'loss': 0.3939, 'learning_rate': 9.178673634537839e-09, 'epoch': 0.99}
 99%|█████████▊| 1641/1663 [14:34:59<12:50, 35.03s/it] 99%|█████████▊| 1642/1663 [14:35:35<12:18, 35.17s/it]                                                      {'loss': 0.4913, 'learning_rate': 8.3633266464056e-09, 'epoch': 0.99}
 99%|█████████▊| 1642/1663 [14:35:35<12:18, 35.17s/it] 99%|█████████▉| 1643/1663 [14:36:11<11:47, 35.36s/it]                                                      {'loss': 0.3634, 'learning_rate': 7.58588212775191e-09, 'epoch': 0.99}
 99%|█████████▉| 1643/1663 [14:36:11<11:47, 35.36s/it] 99%|█████████▉| 1644/1663 [14:36:44<11:01, 34.82s/it]                                                      {'loss': 0.452, 'learning_rate': 6.846343027748781e-09, 'epoch': 0.99}
 99%|█████████▉| 1644/1663 [14:36:44<11:01, 34.82s/it] 99%|█████████▉| 1645/1663 [14:37:24<10:55, 36.42s/it]                                                      {'loss': 0.5065, 'learning_rate': 6.144712151779919e-09, 'epoch': 0.99}
 99%|█████████▉| 1645/1663 [14:37:24<10:55, 36.42s/it] 99%|█████████▉| 1646/1663 [14:37:59<10:10, 35.89s/it]                                                      {'loss': 0.3105, 'learning_rate': 5.4809921614251696e-09, 'epoch': 0.99}
 99%|█████████▉| 1646/1663 [14:37:59<10:10, 35.89s/it] 99%|█████████▉| 1647/1663 [14:38:36<09:39, 36.21s/it]                                                      {'loss': 0.3697, 'learning_rate': 4.8551855744516375e-09, 'epoch': 0.99}
 99%|█████████▉| 1647/1663 [14:38:36<09:39, 36.21s/it] 99%|█████████▉| 1648/1663 [14:39:09<08:49, 35.29s/it]                                                      {'loss': 0.344, 'learning_rate': 4.2672947648081384e-09, 'epoch': 0.99}
 99%|█████████▉| 1648/1663 [14:39:09<08:49, 35.29s/it] 99%|█████████▉| 1649/1663 [14:39:43<08:07, 34.82s/it]                                                      {'loss': 0.3703, 'learning_rate': 3.7173219626085444e-09, 'epoch': 0.99}
 99%|█████████▉| 1649/1663 [14:39:43<08:07, 34.82s/it] 99%|█████████▉| 1650/1663 [14:40:20<07:40, 35.42s/it]                                                      {'loss': 0.3875, 'learning_rate': 3.2052692541328923e-09, 'epoch': 0.99}
 99%|█████████▉| 1650/1663 [14:40:20<07:40, 35.42s/it] 99%|█████████▉| 1651/1663 [14:40:55<07:04, 35.39s/it]                                                      {'loss': 0.3129, 'learning_rate': 2.7311385818118428e-09, 'epoch': 0.99}
 99%|█████████▉| 1651/1663 [14:40:55<07:04, 35.39s/it] 99%|█████████▉| 1652/1663 [14:41:28<06:21, 34.70s/it]                                                      {'loss': 0.365, 'learning_rate': 2.294931744220019e-09, 'epoch': 0.99}
 99%|█████████▉| 1652/1663 [14:41:28<06:21, 34.70s/it] 99%|█████████▉| 1653/1663 [14:42:05<05:52, 35.24s/it]                                                      {'loss': 0.3294, 'learning_rate': 1.896650396073785e-09, 'epoch': 0.99}
 99%|█████████▉| 1653/1663 [14:42:05<05:52, 35.24s/it] 99%|█████████▉| 1654/1663 [14:42:48<05:37, 37.53s/it]                                                      {'loss': 0.497, 'learning_rate': 1.5362960482223632e-09, 'epoch': 0.99}
 99%|█████████▉| 1654/1663 [14:42:48<05:37, 37.53s/it]100%|█████████▉| 1655/1663 [14:43:22<04:53, 36.74s/it]                                                      {'loss': 0.3017, 'learning_rate': 1.213870067640066e-09, 'epoch': 0.99}
100%|█████████▉| 1655/1663 [14:43:22<04:53, 36.74s/it]100%|█████████▉| 1656/1663 [14:43:57<04:12, 36.07s/it]                                                      {'loss': 0.3214, 'learning_rate': 9.293736774240724e-10, 'epoch': 1.0}
100%|█████████▉| 1656/1663 [14:43:57<04:12, 36.07s/it]100%|█████████▉| 1657/1663 [14:44:33<03:36, 36.16s/it]                                                      {'loss': 0.3731, 'learning_rate': 6.828079567877677e-10, 'epoch': 1.0}
100%|█████████▉| 1657/1663 [14:44:33<03:36, 36.16s/it]100%|█████████▉| 1658/1663 [14:45:08<02:58, 35.68s/it]                                                      {'loss': 0.4267, 'learning_rate': 4.74173841059633e-10, 'epoch': 1.0}
100%|█████████▉| 1658/1663 [14:45:08<02:58, 35.68s/it]100%|█████████▉| 1659/1663 [14:45:41<02:20, 35.03s/it]                                                      {'loss': 0.3963, 'learning_rate': 3.034721216765846e-10, 'epoch': 1.0}
100%|█████████▉| 1659/1663 [14:45:41<02:20, 35.03s/it]100%|█████████▉| 1660/1663 [14:46:19<01:47, 35.72s/it]                                                      {'loss': 0.3766, 'learning_rate': 1.7070344618064226e-10, 'epoch': 1.0}
100%|█████████▉| 1660/1663 [14:46:19<01:47, 35.72s/it]100%|█████████▉| 1661/1663 [14:46:55<01:11, 35.74s/it]                                                      {'loss': 0.4466, 'learning_rate': 7.586831821893014e-11, 'epoch': 1.0}
100%|█████████▉| 1661/1663 [14:46:55<01:11, 35.74s/it]100%|█████████▉| 1662/1663 [14:47:29<00:35, 35.39s/it]                                                      {'loss': 0.4032, 'learning_rate': 1.8967097542565982e-11, 'epoch': 1.0}
100%|█████████▉| 1662/1663 [14:47:29<00:35, 35.39s/it]100%|██████████| 1663/1663 [14:48:11<00:00, 37.46s/it]                                                      {'loss': 0.3845, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 1663/1663 [14:48:11<00:00, 37.46s/it]                                                      {'train_runtime': 53292.2881, 'train_samples_per_second': 4.37, 'train_steps_per_second': 0.031, 'train_loss': 0.44145119844325964, 'epoch': 1.0}
100%|██████████| 1663/1663 [14:48:12<00:00, 37.46s/it]100%|██████████| 1663/1663 [14:48:12<00:00, 32.05s/it]
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
[2024-11-04 09:01:32,942] [INFO] [launch.py:351:main] Process 4448 exits successfully.
[2024-11-04 09:01:33,947] [INFO] [launch.py:351:main] Process 4449 exits successfully.
[2024-11-04 09:01:34,948] [INFO] [launch.py:351:main] Process 4451 exits successfully.
[2024-11-04 09:01:35,950] [INFO] [launch.py:351:main] Process 4453 exits successfully.
[2024-11-04 09:01:36,951] [INFO] [launch.py:351:main] Process 4447 exits successfully.
[2024-11-04 09:01:38,954] [INFO] [launch.py:351:main] Process 4452 exits successfully.
[2024-11-04 09:01:38,954] [INFO] [launch.py:351:main] Process 4450 exits successfully.
