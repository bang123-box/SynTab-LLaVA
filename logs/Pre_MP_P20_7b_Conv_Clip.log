[2024-11-02 10:01:53,355] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-02 10:01:55,212] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-11-02 10:01:55,212] [INFO] [runner.py:568:main] cmd = /opt/conda/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=21055 --enable_each_rank_log=None llava/train/train_mem.py --deepspeed ./scripts/zero2.json --model_name_or_path /home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d --version plain --data_path pretrain.jsonl --image_folder none --highres_vision_tower /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 --lowres_vision_tower /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1 --mm_projector_type mlp2x_gelu --tune_mm_mlp_adapter True --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --bf16 True --output_dir ./pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip --num_train_epochs 1 --per_device_train_batch_size 9 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 6000 --save_total_limit 1 --learning_rate 1e-3 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2560 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none
[2024-11-02 10:01:57,398] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-02 10:01:59,219] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
[2024-11-02 10:01:59,219] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 3, 4, 5, 6, 7]}
[2024-11-02 10:01:59,219] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=7, node_rank=0
[2024-11-02 10:01:59,219] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6]})
[2024-11-02 10:01:59,219] [INFO] [launch.py:164:main] dist_world_size=7
[2024-11-02 10:01:59,219] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,3,4,5,6,7
[2024-11-02 10:01:59,219] [INFO] [launch.py:256:main] process 8736 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=0', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:01:59,220] [INFO] [launch.py:256:main] process 8737 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=1', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:01:59,220] [INFO] [launch.py:256:main] process 8738 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=2', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:01:59,221] [INFO] [launch.py:256:main] process 8739 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=3', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:01:59,222] [INFO] [launch.py:256:main] process 8740 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=4', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:01:59,222] [INFO] [launch.py:256:main] process 8741 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=5', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:01:59,223] [INFO] [launch.py:256:main] process 8742 spawned with command: ['/opt/conda/envs/llava/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=6', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', '/home/zbb/modelscope/hub/models--lmsys--vicuna-7b-v1.5/snapshots/3321f76e3f527bd14065daf69dad9344000a201d', '--version', 'plain', '--data_path', 'pretrain.jsonl', '--image_folder', 'none', '--highres_vision_tower', '/home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536', '--lowres_vision_tower', '/home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1', '--mm_projector_type', 'mlp2x_gelu', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './pretrained_mm_projector/Pre_MP_P20_7b_Conv_Clip', '--num_train_epochs', '1', '--per_device_train_batch_size', '9', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '6000', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2560', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
[2024-11-02 10:02:03,411] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-02 10:02:03,462] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-11-02 10:02:03,672] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-02 10:02:03,716] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-02 10:02:03,775] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-11-02 10:02:03,796] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-02 10:02:03,814] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-02 10:02:05,132] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-02 10:02:05,132] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-02 10:02:05,203] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-02 10:02:05,252] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-02 10:02:05,381] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-02 10:02:05,385] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-02 10:02:05,385] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-02 10:02:05,385] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.07s/it]You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.92s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.09s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.72s/it]
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.69s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.75s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.73s/it]
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.82s/it]
entering load model, load /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of ConvNextModel were not initialized from the model checkpoint at /home/zbb/modelscope/hub/ConvLLaVA-ConvNeXt-1536 and are newly initialized: ['layernorm.bias', 'layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
entering load model, load /home/zbb/modelscope/hub/models--openai--clip-vit-large-patch14-336/snapshots/ce19dc912ca5cd21c8a653c79e251e808ccabcd1
Formatting inputs...Skip in lazy mode
Formatting inputs...Skip in lazy mode
  0%|          | 0/1102 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (5664 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5494 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2664 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5921 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (3589 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (3199 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2677 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2931 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5516 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2661 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5665 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (7631 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (3102 > 2560). Running this sequence through the model will result in indexing errors
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (2762 > 2560). Running this sequence through the model will result in indexing errors
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (4075 > 2560). Running this sequence through the model will result in indexing errors
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (2960 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (9195 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (4309 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5481 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (3613 > 2560). Running this sequence through the model will result in indexing errors
  0%|          | 1/1102 [00:56<17:24:12, 56.90s/it]                                                   {'loss': 4.8283, 'learning_rate': 2.9411764705882354e-05, 'epoch': 0.0}
  0%|          | 1/1102 [00:56<17:24:12, 56.90s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (5508 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2575 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (20085 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (7391 > 2560). Running this sequence through the model will result in indexing errors
  0%|          | 2/1102 [01:46<15:59:42, 52.35s/it]                                                   {'loss': 5.0922, 'learning_rate': 5.882352941176471e-05, 'epoch': 0.0}
  0%|          | 2/1102 [01:46<15:59:42, 52.35s/it]  0%|          | 3/1102 [02:35<15:34:36, 51.03s/it]                                                   {'loss': 3.197, 'learning_rate': 8.823529411764706e-05, 'epoch': 0.0}
  0%|          | 3/1102 [02:35<15:34:36, 51.03s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2664 > 2560). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (5655 > 2560). Running this sequence through the model will result in indexing errors
  0%|          | 4/1102 [03:24<15:22:17, 50.40s/it]                                                   {'loss': 2.9292, 'learning_rate': 0.00011764705882352942, 'epoch': 0.0}
  0%|          | 4/1102 [03:24<15:22:17, 50.40s/it]  0%|          | 5/1102 [04:14<15:16:53, 50.15s/it]                                                   {'loss': 2.1014, 'learning_rate': 0.00014705882352941178, 'epoch': 0.0}
  0%|          | 5/1102 [04:14<15:16:53, 50.15s/it]  1%|          | 6/1102 [05:04<15:11:26, 49.90s/it]                                                   {'loss': 1.8896, 'learning_rate': 0.00017647058823529413, 'epoch': 0.01}
  1%|          | 6/1102 [05:04<15:11:26, 49.90s/it]  1%|          | 7/1102 [05:53<15:06:19, 49.66s/it]                                                   {'loss': 1.702, 'learning_rate': 0.00020588235294117645, 'epoch': 0.01}
  1%|          | 7/1102 [05:53<15:06:19, 49.66s/it]  1%|          | 8/1102 [06:42<15:04:26, 49.60s/it]                                                   {'loss': 1.2161, 'learning_rate': 0.00023529411764705883, 'epoch': 0.01}
  1%|          | 8/1102 [06:42<15:04:26, 49.60s/it]  1%|          | 9/1102 [07:32<15:03:19, 49.59s/it]                                                   {'loss': 1.0484, 'learning_rate': 0.0002647058823529412, 'epoch': 0.01}
  1%|          | 9/1102 [07:32<15:03:19, 49.59s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2843 > 2560). Running this sequence through the model will result in indexing errors
  1%|          | 10/1102 [08:21<15:01:01, 49.51s/it]                                                    {'loss': 1.0215, 'learning_rate': 0.00029411764705882356, 'epoch': 0.01}
  1%|          | 10/1102 [08:21<15:01:01, 49.51s/it]  1%|          | 11/1102 [09:10<14:56:31, 49.31s/it]                                                    {'loss': 0.9499, 'learning_rate': 0.0003235294117647059, 'epoch': 0.01}
  1%|          | 11/1102 [09:10<14:56:31, 49.31s/it]  1%|          | 12/1102 [10:04<15:19:28, 50.61s/it]                                                    {'loss': 0.942, 'learning_rate': 0.00035294117647058826, 'epoch': 0.01}
  1%|          | 12/1102 [10:04<15:19:28, 50.61s/it]  1%|          | 13/1102 [11:07<16:29:37, 54.52s/it]                                                    {'loss': 0.9209, 'learning_rate': 0.00038235294117647055, 'epoch': 0.01}
  1%|          | 13/1102 [11:07<16:29:37, 54.52s/it]  1%|▏         | 14/1102 [12:03<16:36:51, 54.97s/it]                                                    {'loss': 0.8427, 'learning_rate': 0.0004117647058823529, 'epoch': 0.01}
  1%|▏         | 14/1102 [12:03<16:36:51, 54.97s/it]  1%|▏         | 15/1102 [12:52<16:02:14, 53.11s/it]                                                    {'loss': 0.9397, 'learning_rate': 0.0004411764705882353, 'epoch': 0.01}
  1%|▏         | 15/1102 [12:52<16:02:14, 53.11s/it]  1%|▏         | 16/1102 [13:41<15:39:14, 51.89s/it]                                                    {'loss': 0.9148, 'learning_rate': 0.00047058823529411766, 'epoch': 0.01}
  1%|▏         | 16/1102 [13:41<15:39:14, 51.89s/it]  2%|▏         | 17/1102 [14:30<15:24:36, 51.13s/it]                                                    {'loss': 0.9141, 'learning_rate': 0.0005, 'epoch': 0.02}
  2%|▏         | 17/1102 [14:30<15:24:36, 51.13s/it]  2%|▏         | 18/1102 [15:19<15:11:36, 50.46s/it]                                                    {'loss': 0.9494, 'learning_rate': 0.0005294117647058824, 'epoch': 0.02}
  2%|▏         | 18/1102 [15:19<15:11:36, 50.46s/it]  2%|▏         | 19/1102 [16:09<15:07:30, 50.28s/it]                                                    {'loss': 0.8567, 'learning_rate': 0.0005588235294117647, 'epoch': 0.02}
  2%|▏         | 19/1102 [16:09<15:07:30, 50.28s/it]  2%|▏         | 20/1102 [17:05<15:36:52, 51.95s/it]                                                    {'loss': 0.8662, 'learning_rate': 0.0005882352941176471, 'epoch': 0.02}
  2%|▏         | 20/1102 [17:05<15:36:52, 51.95s/it]  2%|▏         | 21/1102 [18:10<16:46:52, 55.89s/it]                                                    {'loss': 0.8883, 'learning_rate': 0.0006176470588235294, 'epoch': 0.02}
  2%|▏         | 21/1102 [18:10<16:46:52, 55.89s/it]  2%|▏         | 22/1102 [19:01<16:22:04, 54.56s/it]                                                    {'loss': 0.87, 'learning_rate': 0.0006470588235294118, 'epoch': 0.02}
  2%|▏         | 22/1102 [19:01<16:22:04, 54.56s/it]  2%|▏         | 23/1102 [19:50<15:49:09, 52.78s/it]                                                    {'loss': 0.894, 'learning_rate': 0.0006764705882352942, 'epoch': 0.02}
  2%|▏         | 23/1102 [19:50<15:49:09, 52.78s/it]  2%|▏         | 24/1102 [20:39<15:28:27, 51.68s/it]                                                    {'loss': 0.8489, 'learning_rate': 0.0007058823529411765, 'epoch': 0.02}
  2%|▏         | 24/1102 [20:39<15:28:27, 51.68s/it]  2%|▏         | 25/1102 [21:28<15:14:04, 50.92s/it]                                                    {'loss': 0.8119, 'learning_rate': 0.0007352941176470589, 'epoch': 0.02}
  2%|▏         | 25/1102 [21:28<15:14:04, 50.92s/it]  2%|▏         | 26/1102 [22:18<15:04:30, 50.44s/it]                                                    {'loss': 0.848, 'learning_rate': 0.0007647058823529411, 'epoch': 0.02}
  2%|▏         | 26/1102 [22:18<15:04:30, 50.44s/it]  2%|▏         | 27/1102 [23:07<14:55:16, 49.97s/it]                                                    {'loss': 0.8412, 'learning_rate': 0.0007941176470588235, 'epoch': 0.02}
  2%|▏         | 27/1102 [23:07<14:55:16, 49.97s/it]  3%|▎         | 28/1102 [23:55<14:48:29, 49.64s/it]                                                    {'loss': 0.818, 'learning_rate': 0.0008235294117647058, 'epoch': 0.03}
  3%|▎         | 28/1102 [23:55<14:48:29, 49.64s/it]  3%|▎         | 29/1102 [24:44<14:43:59, 49.43s/it]                                                    {'loss': 0.884, 'learning_rate': 0.0008529411764705882, 'epoch': 0.03}
  3%|▎         | 29/1102 [24:44<14:43:59, 49.43s/it]  3%|▎         | 30/1102 [25:33<14:41:43, 49.35s/it]                                                    {'loss': 0.7931, 'learning_rate': 0.0008823529411764706, 'epoch': 0.03}
  3%|▎         | 30/1102 [25:33<14:41:43, 49.35s/it]  3%|▎         | 31/1102 [26:23<14:43:41, 49.51s/it]                                                    {'loss': 0.8465, 'learning_rate': 0.0009117647058823529, 'epoch': 0.03}
  3%|▎         | 31/1102 [26:23<14:43:41, 49.51s/it]  3%|▎         | 32/1102 [27:12<14:40:52, 49.40s/it]                                                    {'loss': 0.8417, 'learning_rate': 0.0009411764705882353, 'epoch': 0.03}
  3%|▎         | 32/1102 [27:12<14:40:52, 49.40s/it]  3%|▎         | 33/1102 [28:01<14:37:42, 49.26s/it]                                                    {'loss': 0.8556, 'learning_rate': 0.0009705882352941176, 'epoch': 0.03}
  3%|▎         | 33/1102 [28:01<14:37:42, 49.26s/it]  3%|▎         | 34/1102 [28:51<14:37:26, 49.29s/it]                                                    {'loss': 0.8053, 'learning_rate': 0.001, 'epoch': 0.03}
  3%|▎         | 34/1102 [28:51<14:37:26, 49.29s/it]  3%|▎         | 35/1102 [29:40<14:36:05, 49.26s/it]                                                    {'loss': 0.833, 'learning_rate': 0.0009999978367986988, 'epoch': 0.03}
  3%|▎         | 35/1102 [29:40<14:36:05, 49.26s/it]  3%|▎         | 36/1102 [30:29<14:34:20, 49.21s/it]                                                    {'loss': 0.8143, 'learning_rate': 0.0009999913472135125, 'epoch': 0.03}
  3%|▎         | 36/1102 [30:29<14:34:20, 49.21s/it]  3%|▎         | 37/1102 [31:18<14:33:45, 49.23s/it]                                                    {'loss': 0.817, 'learning_rate': 0.0009999805313005946, 'epoch': 0.03}
  3%|▎         | 37/1102 [31:18<14:33:45, 49.23s/it]  3%|▎         | 38/1102 [32:07<14:29:51, 49.05s/it]                                                    {'loss': 0.8301, 'learning_rate': 0.000999965389153533, 'epoch': 0.03}
  3%|▎         | 38/1102 [32:07<14:29:51, 49.05s/it]  4%|▎         | 39/1102 [32:56<14:29:33, 49.08s/it]                                                    {'loss': 0.7947, 'learning_rate': 0.0009999459209033494, 'epoch': 0.04}
  4%|▎         | 39/1102 [32:56<14:29:33, 49.08s/it]  4%|▎         | 40/1102 [33:45<14:29:27, 49.12s/it]                                                    {'loss': 0.7943, 'learning_rate': 0.0009999221267184993, 'epoch': 0.04}
  4%|▎         | 40/1102 [33:45<14:29:27, 49.12s/it]  4%|▎         | 41/1102 [34:34<14:27:55, 49.08s/it]                                                    {'loss': 0.7828, 'learning_rate': 0.0009998940068048688, 'epoch': 0.04}
  4%|▎         | 41/1102 [34:34<14:27:55, 49.08s/it]  4%|▍         | 42/1102 [35:23<14:26:51, 49.07s/it]                                                    {'loss': 0.8318, 'learning_rate': 0.0009998615614057742, 'epoch': 0.04}
  4%|▍         | 42/1102 [35:23<14:26:51, 49.07s/it]  4%|▍         | 43/1102 [36:11<14:20:04, 48.73s/it]                                                    {'loss': 0.8463, 'learning_rate': 0.0009998247908019594, 'epoch': 0.04}
  4%|▍         | 43/1102 [36:11<14:20:04, 48.73s/it]  4%|▍         | 44/1102 [37:01<14:23:36, 48.98s/it]                                                    {'loss': 0.7994, 'learning_rate': 0.0009997836953115926, 'epoch': 0.04}
  4%|▍         | 44/1102 [37:01<14:23:36, 48.98s/it]  4%|▍         | 45/1102 [37:50<14:25:42, 49.14s/it]                                                    {'loss': 0.7915, 'learning_rate': 0.0009997382752902656, 'epoch': 0.04}
  4%|▍         | 45/1102 [37:50<14:25:42, 49.14s/it]  4%|▍         | 46/1102 [38:39<14:19:56, 48.86s/it]                                                    {'loss': 0.8228, 'learning_rate': 0.0009996885311309891, 'epoch': 0.04}
  4%|▍         | 46/1102 [38:39<14:19:56, 48.86s/it]  4%|▍         | 47/1102 [39:28<14:19:31, 48.88s/it]                                                    {'loss': 0.812, 'learning_rate': 0.0009996344632641895, 'epoch': 0.04}
  4%|▍         | 47/1102 [39:28<14:19:31, 48.88s/it]  4%|▍         | 48/1102 [40:17<14:23:38, 49.16s/it]                                                    {'loss': 0.785, 'learning_rate': 0.0009995760721577052, 'epoch': 0.04}
  4%|▍         | 48/1102 [40:17<14:23:38, 49.16s/it]  4%|▍         | 49/1102 [41:07<14:26:27, 49.37s/it]                                                    {'loss': 0.778, 'learning_rate': 0.0009995133583167832, 'epoch': 0.04}
  4%|▍         | 49/1102 [41:07<14:26:27, 49.37s/it]  5%|▍         | 50/1102 [41:57<14:25:57, 49.39s/it]                                                    {'loss': 0.7485, 'learning_rate': 0.0009994463222840746, 'epoch': 0.05}
  5%|▍         | 50/1102 [41:57<14:25:57, 49.39s/it]  5%|▍         | 51/1102 [42:46<14:26:06, 49.44s/it]                                                    {'loss': 0.7801, 'learning_rate': 0.0009993749646396287, 'epoch': 0.05}
  5%|▍         | 51/1102 [42:46<14:26:06, 49.44s/it]  5%|▍         | 52/1102 [43:35<14:23:47, 49.36s/it]                                                    {'loss': 0.7607, 'learning_rate': 0.0009992992860008891, 'epoch': 0.05}
  5%|▍         | 52/1102 [43:35<14:23:47, 49.36s/it]  5%|▍         | 53/1102 [44:25<14:22:05, 49.31s/it]                                                    {'loss': 0.8098, 'learning_rate': 0.000999219287022689, 'epoch': 0.05}
  5%|▍         | 53/1102 [44:25<14:22:05, 49.31s/it]  5%|▍         | 54/1102 [45:13<14:18:30, 49.15s/it]                                                    {'loss': 0.7811, 'learning_rate': 0.0009991349683972433, 'epoch': 0.05}
  5%|▍         | 54/1102 [45:13<14:18:30, 49.15s/it]  5%|▍         | 55/1102 [46:03<14:17:45, 49.15s/it]                                                    {'loss': 0.7608, 'learning_rate': 0.000999046330854145, 'epoch': 0.05}
  5%|▍         | 55/1102 [46:03<14:17:45, 49.15s/it]  5%|▌         | 56/1102 [46:52<14:17:57, 49.21s/it]                                                    {'loss': 0.8087, 'learning_rate': 0.0009989533751603578, 'epoch': 0.05}
  5%|▌         | 56/1102 [46:52<14:17:57, 49.21s/it]  5%|▌         | 57/1102 [47:40<14:09:38, 48.78s/it]                                                    {'loss': 0.81, 'learning_rate': 0.0009988561021202083, 'epoch': 0.05}
  5%|▌         | 57/1102 [47:40<14:09:38, 48.78s/it]  5%|▌         | 58/1102 [48:29<14:11:25, 48.93s/it]                                                    {'loss': 0.7966, 'learning_rate': 0.0009987545125753818, 'epoch': 0.05}
  5%|▌         | 58/1102 [48:29<14:11:25, 48.93s/it]  5%|▌         | 59/1102 [49:18<14:12:54, 49.06s/it]                                                    {'loss': 0.8033, 'learning_rate': 0.000998648607404913, 'epoch': 0.05}
  5%|▌         | 59/1102 [49:18<14:12:54, 49.06s/it]  5%|▌         | 60/1102 [50:07<14:11:32, 49.03s/it]                                                    {'loss': 0.8016, 'learning_rate': 0.0009985383875251784, 'epoch': 0.05}
  5%|▌         | 60/1102 [50:07<14:11:32, 49.03s/it]  6%|▌         | 61/1102 [50:56<14:10:40, 49.03s/it]                                                    {'loss': 0.8027, 'learning_rate': 0.000998423853889889, 'epoch': 0.06}
  6%|▌         | 61/1102 [50:56<14:10:40, 49.03s/it]  6%|▌         | 62/1102 [51:46<14:11:53, 49.15s/it]                                                    {'loss': 0.7156, 'learning_rate': 0.0009983050074900825, 'epoch': 0.06}
  6%|▌         | 62/1102 [51:46<14:11:53, 49.15s/it]  6%|▌         | 63/1102 [52:35<14:12:39, 49.24s/it]                                                    {'loss': 0.7774, 'learning_rate': 0.000998181849354113, 'epoch': 0.06}
  6%|▌         | 63/1102 [52:35<14:12:39, 49.24s/it]  6%|▌         | 64/1102 [53:25<14:13:17, 49.32s/it]                                                    {'loss': 0.7803, 'learning_rate': 0.0009980543805476446, 'epoch': 0.06}
  6%|▌         | 64/1102 [53:25<14:13:17, 49.32s/it]  6%|▌         | 65/1102 [54:14<14:11:20, 49.26s/it]                                                    {'loss': 0.7868, 'learning_rate': 0.0009979226021736396, 'epoch': 0.06}
  6%|▌         | 65/1102 [54:14<14:11:20, 49.26s/it]  6%|▌         | 66/1102 [55:03<14:08:32, 49.14s/it]                                                    {'loss': 0.8269, 'learning_rate': 0.0009977865153723506, 'epoch': 0.06}
  6%|▌         | 66/1102 [55:03<14:08:32, 49.14s/it]  6%|▌         | 67/1102 [55:51<14:05:48, 49.03s/it]                                                    {'loss': 0.7888, 'learning_rate': 0.0009976461213213105, 'epoch': 0.06}
  6%|▌         | 67/1102 [55:51<14:05:48, 49.03s/it]  6%|▌         | 68/1102 [56:41<14:05:14, 49.05s/it]                                                    {'loss': 0.7228, 'learning_rate': 0.0009975014212353212, 'epoch': 0.06}
  6%|▌         | 68/1102 [56:41<14:05:14, 49.05s/it]  6%|▋         | 69/1102 [57:30<14:07:48, 49.24s/it]                                                    {'loss': 0.7517, 'learning_rate': 0.0009973524163664448, 'epoch': 0.06}
  6%|▋         | 69/1102 [57:30<14:07:48, 49.24s/it]  6%|▋         | 70/1102 [58:19<14:06:10, 49.20s/it]                                                    {'loss': 0.7924, 'learning_rate': 0.000997199108003991, 'epoch': 0.06}
  6%|▋         | 70/1102 [58:19<14:06:10, 49.20s/it]  6%|▋         | 71/1102 [59:08<14:02:43, 49.04s/it]                                                    {'loss': 0.7904, 'learning_rate': 0.0009970414974745075, 'epoch': 0.06}
  6%|▋         | 71/1102 [59:08<14:02:43, 49.04s/it]  7%|▋         | 72/1102 [1:00:10<15:08:34, 52.93s/it]                                                      {'loss': 0.8256, 'learning_rate': 0.0009968795861417675, 'epoch': 0.07}
  7%|▋         | 72/1102 [1:00:10<15:08:34, 52.93s/it]  7%|▋         | 73/1102 [1:00:59<14:48:09, 51.79s/it]                                                      {'loss': 0.7874, 'learning_rate': 0.0009967133754067582, 'epoch': 0.07}
  7%|▋         | 73/1102 [1:00:59<14:48:09, 51.79s/it]  7%|▋         | 74/1102 [1:01:48<14:33:16, 50.97s/it]                                                      {'loss': 0.8176, 'learning_rate': 0.0009965428667076685, 'epoch': 0.07}
  7%|▋         | 74/1102 [1:01:48<14:33:16, 50.97s/it]  7%|▋         | 75/1102 [1:02:37<14:23:24, 50.44s/it]                                                      {'loss': 0.7648, 'learning_rate': 0.0009963680615198772, 'epoch': 0.07}
  7%|▋         | 75/1102 [1:02:37<14:23:24, 50.44s/it]  7%|▋         | 76/1102 [1:03:26<14:14:31, 49.97s/it]                                                      {'loss': 0.7315, 'learning_rate': 0.0009961889613559396, 'epoch': 0.07}
  7%|▋         | 76/1102 [1:03:26<14:14:31, 49.97s/it]  7%|▋         | 77/1102 [1:04:16<14:10:04, 49.76s/it]                                                      {'loss': 0.7392, 'learning_rate': 0.0009960055677655742, 'epoch': 0.07}
  7%|▋         | 77/1102 [1:04:16<14:10:04, 49.76s/it]  7%|▋         | 78/1102 [1:05:05<14:06:50, 49.62s/it]                                                      {'loss': 0.7916, 'learning_rate': 0.0009958178823356503, 'epoch': 0.07}
  7%|▋         | 78/1102 [1:05:05<14:06:50, 49.62s/it]  7%|▋         | 79/1102 [1:05:54<14:05:02, 49.56s/it]                                                      {'loss': 0.788, 'learning_rate': 0.0009956259066901732, 'epoch': 0.07}
  7%|▋         | 79/1102 [1:05:54<14:05:02, 49.56s/it]  7%|▋         | 80/1102 [1:06:43<13:58:54, 49.25s/it]                                                      {'loss': 0.8009, 'learning_rate': 0.0009954296424902708, 'epoch': 0.07}
  7%|▋         | 80/1102 [1:06:43<13:58:54, 49.25s/it]  7%|▋         | 81/1102 [1:07:32<13:57:31, 49.22s/it]                                                      {'loss': 0.7753, 'learning_rate': 0.000995229091434179, 'epoch': 0.07}
  7%|▋         | 81/1102 [1:07:32<13:57:31, 49.22s/it]  7%|▋         | 82/1102 [1:08:21<13:54:46, 49.10s/it]                                                      {'loss': 0.7646, 'learning_rate': 0.0009950242552572272, 'epoch': 0.07}
  7%|▋         | 82/1102 [1:08:21<13:54:46, 49.10s/it]  8%|▊         | 83/1102 [1:09:11<13:57:33, 49.32s/it]                                                      {'loss': 0.7967, 'learning_rate': 0.0009948151357318227, 'epoch': 0.08}
  8%|▊         | 83/1102 [1:09:11<13:57:33, 49.32s/it]  8%|▊         | 84/1102 [1:09:59<13:53:02, 49.10s/it]                                                      {'loss': 0.8077, 'learning_rate': 0.0009946017346674362, 'epoch': 0.08}
  8%|▊         | 84/1102 [1:09:59<13:53:02, 49.10s/it]  8%|▊         | 85/1102 [1:10:48<13:52:44, 49.13s/it]                                                      {'loss': 0.7578, 'learning_rate': 0.0009943840539105853, 'epoch': 0.08}
  8%|▊         | 85/1102 [1:10:48<13:52:44, 49.13s/it]  8%|▊         | 86/1102 [1:11:38<13:55:00, 49.31s/it]                                                      {'loss': 0.7953, 'learning_rate': 0.0009941620953448193, 'epoch': 0.08}
  8%|▊         | 86/1102 [1:11:38<13:55:00, 49.31s/it]  8%|▊         | 87/1102 [1:12:27<13:51:29, 49.15s/it]                                                      {'loss': 0.8195, 'learning_rate': 0.0009939358608907025, 'epoch': 0.08}
  8%|▊         | 87/1102 [1:12:27<13:51:29, 49.15s/it]  8%|▊         | 88/1102 [1:13:16<13:51:36, 49.21s/it]                                                      {'loss': 0.8088, 'learning_rate': 0.0009937053525057977, 'epoch': 0.08}
  8%|▊         | 88/1102 [1:13:16<13:51:36, 49.21s/it]  8%|▊         | 89/1102 [1:14:05<13:49:51, 49.15s/it]                                                      {'loss': 0.785, 'learning_rate': 0.0009934705721846486, 'epoch': 0.08}
  8%|▊         | 89/1102 [1:14:05<13:49:51, 49.15s/it]  8%|▊         | 90/1102 [1:14:54<13:47:49, 49.08s/it]                                                      {'loss': 0.7728, 'learning_rate': 0.000993231521958764, 'epoch': 0.08}
  8%|▊         | 90/1102 [1:14:54<13:47:49, 49.08s/it]  8%|▊         | 91/1102 [1:15:43<13:47:40, 49.12s/it]                                                      {'loss': 0.7536, 'learning_rate': 0.0009929882038965988, 'epoch': 0.08}
  8%|▊         | 91/1102 [1:15:43<13:47:40, 49.12s/it]  8%|▊         | 92/1102 [1:16:33<13:48:41, 49.23s/it]                                                      {'loss': 0.7866, 'learning_rate': 0.0009927406201035366, 'epoch': 0.08}
  8%|▊         | 92/1102 [1:16:33<13:48:41, 49.23s/it]  8%|▊         | 93/1102 [1:17:51<16:14:14, 57.93s/it]                                                      {'loss': 0.7721, 'learning_rate': 0.0009924887727218723, 'epoch': 0.08}
  8%|▊         | 93/1102 [1:17:51<16:14:14, 57.93s/it]  9%|▊         | 94/1102 [1:19:56<21:52:02, 78.10s/it]                                                      {'loss': 0.7514, 'learning_rate': 0.0009922326639307916, 'epoch': 0.09}
  9%|▊         | 94/1102 [1:19:56<21:52:02, 78.10s/it]  9%|▊         | 95/1102 [1:20:45<19:22:46, 69.28s/it]                                                      {'loss': 0.8048, 'learning_rate': 0.0009919722959463545, 'epoch': 0.09}
  9%|▊         | 95/1102 [1:20:45<19:22:46, 69.28s/it]  9%|▊         | 96/1102 [1:21:34<17:41:31, 63.31s/it]                                                      {'loss': 0.7386, 'learning_rate': 0.000991707671021474, 'epoch': 0.09}
  9%|▊         | 96/1102 [1:21:34<17:41:31, 63.31s/it]  9%|▉         | 97/1102 [1:22:23<16:28:30, 59.02s/it]                                                      {'loss': 0.7522, 'learning_rate': 0.0009914387914458983, 'epoch': 0.09}
  9%|▉         | 97/1102 [1:22:23<16:28:30, 59.02s/it]  9%|▉         | 98/1102 [1:23:13<15:39:11, 56.13s/it]                                                      {'loss': 0.6929, 'learning_rate': 0.0009911656595461898, 'epoch': 0.09}
  9%|▉         | 98/1102 [1:23:13<15:39:11, 56.13s/it]  9%|▉         | 99/1102 [1:24:02<15:02:31, 53.99s/it]                                                      {'loss': 0.7346, 'learning_rate': 0.0009908882776857057, 'epoch': 0.09}
  9%|▉         | 99/1102 [1:24:02<15:02:31, 53.99s/it]  9%|▉         | 100/1102 [1:24:51<14:40:16, 52.71s/it]                                                       {'loss': 0.6909, 'learning_rate': 0.0009906066482645772, 'epoch': 0.09}
  9%|▉         | 100/1102 [1:24:51<14:40:16, 52.71s/it]  9%|▉         | 101/1102 [1:25:41<14:22:10, 51.68s/it]                                                       {'loss': 0.7744, 'learning_rate': 0.000990320773719689, 'epoch': 0.09}
  9%|▉         | 101/1102 [1:25:41<14:22:10, 51.68s/it]  9%|▉         | 102/1102 [1:26:29<14:06:08, 50.77s/it]                                                       {'loss': 0.7901, 'learning_rate': 0.0009900306565246578, 'epoch': 0.09}
  9%|▉         | 102/1102 [1:26:29<14:06:08, 50.77s/it]  9%|▉         | 103/1102 [1:27:19<13:59:34, 50.42s/it]                                                       {'loss': 0.7195, 'learning_rate': 0.000989736299189811, 'epoch': 0.09}
  9%|▉         | 103/1102 [1:27:19<13:59:34, 50.42s/it]  9%|▉         | 104/1102 [1:28:08<13:52:20, 50.04s/it]                                                       {'loss': 0.7188, 'learning_rate': 0.0009894377042621654, 'epoch': 0.09}
  9%|▉         | 104/1102 [1:28:08<13:52:20, 50.04s/it] 10%|▉         | 105/1102 [1:28:57<13:48:01, 49.83s/it]                                                       {'loss': 0.7618, 'learning_rate': 0.0009891348743254046, 'epoch': 0.1}
 10%|▉         | 105/1102 [1:28:57<13:48:01, 49.83s/it] 10%|▉         | 106/1102 [1:29:47<13:45:42, 49.74s/it]                                                       {'loss': 0.7787, 'learning_rate': 0.0009888278119998572, 'epoch': 0.1}
 10%|▉         | 106/1102 [1:29:47<13:45:42, 49.74s/it] 10%|▉         | 107/1102 [1:30:36<13:41:10, 49.52s/it]                                                       {'loss': 0.7937, 'learning_rate': 0.0009885165199424737, 'epoch': 0.1}
 10%|▉         | 107/1102 [1:30:36<13:41:10, 49.52s/it] 10%|▉         | 108/1102 [1:31:25<13:38:38, 49.41s/it]                                                       {'loss': 0.7658, 'learning_rate': 0.0009882010008468037, 'epoch': 0.1}
 10%|▉         | 108/1102 [1:31:25<13:38:38, 49.41s/it] 10%|▉         | 109/1102 [1:32:14<13:35:58, 49.30s/it]                                                       {'loss': 0.789, 'learning_rate': 0.000987881257442972, 'epoch': 0.1}
 10%|▉         | 109/1102 [1:32:14<13:35:58, 49.30s/it] 10%|▉         | 110/1102 [1:33:03<13:34:31, 49.27s/it]                                                       {'loss': 0.7838, 'learning_rate': 0.0009875572924976568, 'epoch': 0.1}
 10%|▉         | 110/1102 [1:33:03<13:34:31, 49.27s/it] 10%|█         | 111/1102 [1:33:53<13:34:00, 49.28s/it]                                                       {'loss': 0.7964, 'learning_rate': 0.0009872291088140629, 'epoch': 0.1}
 10%|█         | 111/1102 [1:33:53<13:34:00, 49.28s/it] 10%|█         | 112/1102 [1:34:42<13:33:36, 49.31s/it]                                                       {'loss': 0.78, 'learning_rate': 0.0009868967092319003, 'epoch': 0.1}
 10%|█         | 112/1102 [1:34:42<13:33:36, 49.31s/it] 10%|█         | 113/1102 [1:35:31<13:32:09, 49.27s/it]                                                       {'loss': 0.814, 'learning_rate': 0.0009865600966273574, 'epoch': 0.1}
 10%|█         | 113/1102 [1:35:31<13:32:09, 49.27s/it] 10%|█         | 114/1102 [1:36:20<13:30:49, 49.24s/it]                                                       {'loss': 0.7826, 'learning_rate': 0.000986219273913078, 'epoch': 0.1}
 10%|█         | 114/1102 [1:36:20<13:30:49, 49.24s/it] 10%|█         | 115/1102 [1:37:10<13:30:42, 49.28s/it]                                                       {'loss': 0.799, 'learning_rate': 0.0009858742440381342, 'epoch': 0.1}
 10%|█         | 115/1102 [1:37:10<13:30:42, 49.28s/it] 11%|█         | 116/1102 [1:37:59<13:30:22, 49.31s/it]                                                       {'loss': 0.8014, 'learning_rate': 0.0009855250099880025, 'epoch': 0.11}
 11%|█         | 116/1102 [1:37:59<13:30:22, 49.31s/it] 11%|█         | 117/1102 [1:38:48<13:29:25, 49.30s/it]                                                       {'loss': 0.7716, 'learning_rate': 0.0009851715747845372, 'epoch': 0.11}
 11%|█         | 117/1102 [1:38:48<13:29:25, 49.30s/it] 11%|█         | 118/1102 [1:39:38<13:28:55, 49.32s/it]                                                       {'loss': 0.7607, 'learning_rate': 0.000984813941485944, 'epoch': 0.11}
 11%|█         | 118/1102 [1:39:38<13:28:55, 49.32s/it] 11%|█         | 119/1102 [1:40:27<13:26:54, 49.25s/it]                                                       {'loss': 0.7612, 'learning_rate': 0.0009844521131867545, 'epoch': 0.11}
 11%|█         | 119/1102 [1:40:27<13:26:54, 49.25s/it] 11%|█         | 120/1102 [1:41:16<13:26:08, 49.26s/it]                                                       {'loss': 0.7339, 'learning_rate': 0.0009840860930177982, 'epoch': 0.11}
 11%|█         | 120/1102 [1:41:16<13:26:08, 49.26s/it] 11%|█         | 121/1102 [1:42:05<13:21:57, 49.05s/it]                                                       {'loss': 0.8156, 'learning_rate': 0.0009837158841461767, 'epoch': 0.11}
 11%|█         | 121/1102 [1:42:05<13:21:57, 49.05s/it] 11%|█         | 122/1102 [1:42:54<13:22:24, 49.13s/it]                                                       {'loss': 0.7278, 'learning_rate': 0.0009833414897752347, 'epoch': 0.11}
 11%|█         | 122/1102 [1:42:54<13:22:24, 49.13s/it] 11%|█         | 123/1102 [1:43:43<13:22:35, 49.19s/it]                                                       {'loss': 0.7873, 'learning_rate': 0.0009829629131445341, 'epoch': 0.11}
 11%|█         | 123/1102 [1:43:43<13:22:35, 49.19s/it] 11%|█▏        | 124/1102 [1:44:33<13:22:38, 49.24s/it]                                                       {'loss': 0.753, 'learning_rate': 0.0009825801575298247, 'epoch': 0.11}
 11%|█▏        | 124/1102 [1:44:33<13:22:38, 49.24s/it] 11%|█▏        | 125/1102 [1:45:22<13:20:08, 49.14s/it]                                                       {'loss': 0.6979, 'learning_rate': 0.0009821932262430164, 'epoch': 0.11}
 11%|█▏        | 125/1102 [1:45:22<13:20:08, 49.14s/it] 11%|█▏        | 126/1102 [1:46:11<13:19:13, 49.13s/it]                                                       {'loss': 0.7638, 'learning_rate': 0.00098180212263215, 'epoch': 0.11}
 11%|█▏        | 126/1102 [1:46:11<13:19:13, 49.13s/it] 12%|█▏        | 127/1102 [1:47:00<13:18:08, 49.12s/it]                                                       {'loss': 0.7573, 'learning_rate': 0.000981406850081369, 'epoch': 0.12}
 12%|█▏        | 127/1102 [1:47:00<13:18:08, 49.12s/it] 12%|█▏        | 128/1102 [1:47:48<13:12:35, 48.82s/it]                                                       {'loss': 0.7944, 'learning_rate': 0.00098100741201089, 'epoch': 0.12}
 12%|█▏        | 128/1102 [1:47:48<13:12:35, 48.82s/it] 12%|█▏        | 129/1102 [1:48:37<13:10:44, 48.76s/it]                                                       {'loss': 0.7611, 'learning_rate': 0.0009806038118769724, 'epoch': 0.12}
 12%|█▏        | 129/1102 [1:48:37<13:10:44, 48.76s/it] 12%|█▏        | 130/1102 [1:49:26<13:11:01, 48.83s/it]                                                       {'loss': 0.7732, 'learning_rate': 0.0009801960531718897, 'epoch': 0.12}
 12%|█▏        | 130/1102 [1:49:26<13:11:01, 48.83s/it] 12%|█▏        | 131/1102 [1:50:15<13:10:44, 48.86s/it]                                                       {'loss': 0.7569, 'learning_rate': 0.0009797841394238985, 'epoch': 0.12}
 12%|█▏        | 131/1102 [1:50:15<13:10:44, 48.86s/it] 12%|█▏        | 132/1102 [1:51:04<13:10:24, 48.89s/it]                                                       {'loss': 0.7561, 'learning_rate': 0.0009793680741972085, 'epoch': 0.12}
 12%|█▏        | 132/1102 [1:51:04<13:10:24, 48.89s/it] 12%|█▏        | 133/1102 [1:51:52<13:07:42, 48.77s/it]                                                       {'loss': 0.6987, 'learning_rate': 0.0009789478610919508, 'epoch': 0.12}
 12%|█▏        | 133/1102 [1:51:52<13:07:42, 48.77s/it] 12%|█▏        | 134/1102 [1:52:41<13:06:11, 48.73s/it]                                                       {'loss': 0.7852, 'learning_rate': 0.0009785235037441473, 'epoch': 0.12}
 12%|█▏        | 134/1102 [1:52:41<13:06:11, 48.73s/it] 12%|█▏        | 135/1102 [1:53:30<13:07:06, 48.84s/it]                                                       {'loss': 0.7671, 'learning_rate': 0.0009780950058256802, 'epoch': 0.12}
 12%|█▏        | 135/1102 [1:53:30<13:07:06, 48.84s/it] 12%|█▏        | 136/1102 [1:54:19<13:07:30, 48.91s/it]                                                       {'loss': 0.7435, 'learning_rate': 0.0009776623710442578, 'epoch': 0.12}
 12%|█▏        | 136/1102 [1:54:19<13:07:30, 48.91s/it] 12%|█▏        | 137/1102 [1:55:08<13:07:25, 48.96s/it]                                                       {'loss': 0.7684, 'learning_rate': 0.000977225603143385, 'epoch': 0.12}
 12%|█▏        | 137/1102 [1:55:08<13:07:25, 48.96s/it] 13%|█▎        | 138/1102 [1:55:57<13:06:08, 48.93s/it]                                                       {'loss': 0.8117, 'learning_rate': 0.000976784705902329, 'epoch': 0.13}
 13%|█▎        | 138/1102 [1:55:57<13:06:08, 48.93s/it] 13%|█▎        | 139/1102 [1:56:46<13:08:52, 49.15s/it]                                                       {'loss': 0.7641, 'learning_rate': 0.0009763396831360884, 'epoch': 0.13}
 13%|█▎        | 139/1102 [1:56:47<13:08:52, 49.15s/it] 13%|█▎        | 140/1102 [1:57:39<13:24:18, 50.16s/it]                                                       {'loss': 0.7483, 'learning_rate': 0.0009758905386953578, 'epoch': 0.13}
 13%|█▎        | 140/1102 [1:57:39<13:24:18, 50.16s/it] 13%|█▎        | 141/1102 [1:59:16<17:08:58, 64.24s/it]                                                       {'loss': 0.7381, 'learning_rate': 0.0009754372764664969, 'epoch': 0.13}
 13%|█▎        | 141/1102 [1:59:16<17:08:58, 64.24s/it] 13%|█▎        | 142/1102 [2:00:05<15:52:13, 59.51s/it]                                                       {'loss': 0.806, 'learning_rate': 0.0009749799003714954, 'epoch': 0.13}
 13%|█▎        | 142/1102 [2:00:05<15:52:13, 59.51s/it] 13%|█▎        | 143/1102 [2:00:53<14:58:35, 56.22s/it]                                                       {'loss': 0.7759, 'learning_rate': 0.0009745184143679397, 'epoch': 0.13}
 13%|█▎        | 143/1102 [2:00:53<14:58:35, 56.22s/it] 13%|█▎        | 144/1102 [2:01:42<14:24:09, 54.12s/it]                                                       {'loss': 0.7793, 'learning_rate': 0.0009740528224489779, 'epoch': 0.13}
 13%|█▎        | 144/1102 [2:01:42<14:24:09, 54.12s/it] 13%|█▎        | 145/1102 [2:02:32<14:00:11, 52.68s/it]                                                       {'loss': 0.7603, 'learning_rate': 0.0009735831286432868, 'epoch': 0.13}
 13%|█▎        | 145/1102 [2:02:32<14:00:11, 52.68s/it] 13%|█▎        | 146/1102 [2:03:21<13:42:58, 51.65s/it]                                                       {'loss': 0.6991, 'learning_rate': 0.0009731093370150348, 'epoch': 0.13}
 13%|█▎        | 146/1102 [2:03:21<13:42:58, 51.65s/it] 13%|█▎        | 147/1102 [2:04:10<13:29:01, 50.83s/it]                                                       {'loss': 0.757, 'learning_rate': 0.000972631451663849, 'epoch': 0.13}
 13%|█▎        | 147/1102 [2:04:10<13:29:01, 50.83s/it] 13%|█▎        | 148/1102 [2:04:59<13:22:45, 50.49s/it]                                                       {'loss': 0.703, 'learning_rate': 0.0009721494767247779, 'epoch': 0.13}
 13%|█▎        | 148/1102 [2:04:59<13:22:45, 50.49s/it] 14%|█▎        | 149/1102 [2:05:48<13:14:57, 50.05s/it]                                                       {'loss': 0.7497, 'learning_rate': 0.0009716634163682569, 'epoch': 0.14}
 14%|█▎        | 149/1102 [2:05:48<13:14:57, 50.05s/it] 14%|█▎        | 150/1102 [2:06:38<13:12:56, 49.98s/it]                                                       {'loss': 0.7199, 'learning_rate': 0.0009711732748000719, 'epoch': 0.14}
 14%|█▎        | 150/1102 [2:06:38<13:12:56, 49.98s/it] 14%|█▎        | 151/1102 [2:07:27<13:08:12, 49.73s/it]                                                       {'loss': 0.7434, 'learning_rate': 0.0009706790562613219, 'epoch': 0.14}
 14%|█▎        | 151/1102 [2:07:27<13:08:12, 49.73s/it] 14%|█▍        | 152/1102 [2:08:17<13:06:33, 49.68s/it]                                                       {'loss': 0.7398, 'learning_rate': 0.0009701807650283839, 'epoch': 0.14}
 14%|█▍        | 152/1102 [2:08:17<13:06:33, 49.68s/it] 14%|█▍        | 153/1102 [2:09:06<13:02:41, 49.49s/it]                                                       {'loss': 0.7576, 'learning_rate': 0.0009696784054128749, 'epoch': 0.14}
 14%|█▍        | 153/1102 [2:09:06<13:02:41, 49.49s/it] 14%|█▍        | 154/1102 [2:09:55<12:59:05, 49.31s/it]                                                       {'loss': 0.7481, 'learning_rate': 0.0009691719817616147, 'epoch': 0.14}
 14%|█▍        | 154/1102 [2:09:55<12:59:05, 49.31s/it] 14%|█▍        | 155/1102 [2:10:45<12:59:51, 49.41s/it]                                                       {'loss': 0.7553, 'learning_rate': 0.0009686614984565887, 'epoch': 0.14}
 14%|█▍        | 155/1102 [2:10:45<12:59:51, 49.41s/it] 14%|█▍        | 156/1102 [2:11:32<12:51:47, 48.95s/it]                                                       {'loss': 0.78, 'learning_rate': 0.0009681469599149092, 'epoch': 0.14}
 14%|█▍        | 156/1102 [2:11:32<12:51:47, 48.95s/it] 14%|█▍        | 157/1102 [2:12:21<12:50:27, 48.92s/it]                                                       {'loss': 0.7583, 'learning_rate': 0.0009676283705887782, 'epoch': 0.14}
 14%|█▍        | 157/1102 [2:12:21<12:50:27, 48.92s/it] 14%|█▍        | 158/1102 [2:13:11<12:51:25, 49.03s/it]                                                       {'loss': 0.7422, 'learning_rate': 0.000967105734965448, 'epoch': 0.14}
 14%|█▍        | 158/1102 [2:13:11<12:51:25, 49.03s/it] 14%|█▍        | 159/1102 [2:14:00<12:51:53, 49.11s/it]                                                       {'loss': 0.7865, 'learning_rate': 0.0009665790575671829, 'epoch': 0.14}
 14%|█▍        | 159/1102 [2:14:00<12:51:53, 49.11s/it] 15%|█▍        | 160/1102 [2:14:49<12:53:12, 49.25s/it]                                                       {'loss': 0.7342, 'learning_rate': 0.0009660483429512198, 'epoch': 0.15}
 15%|█▍        | 160/1102 [2:14:49<12:53:12, 49.25s/it] 15%|█▍        | 161/1102 [2:15:39<12:51:38, 49.20s/it]                                                       {'loss': 0.7662, 'learning_rate': 0.0009655135957097289, 'epoch': 0.15}
 15%|█▍        | 161/1102 [2:15:39<12:51:38, 49.20s/it] 15%|█▍        | 162/1102 [2:16:28<12:51:10, 49.22s/it]                                                       {'loss': 0.7433, 'learning_rate': 0.000964974820469774, 'epoch': 0.15}
 15%|█▍        | 162/1102 [2:16:28<12:51:10, 49.22s/it] 15%|█▍        | 163/1102 [2:17:17<12:49:12, 49.15s/it]                                                       {'loss': 0.7774, 'learning_rate': 0.0009644320218932721, 'epoch': 0.15}
 15%|█▍        | 163/1102 [2:17:17<12:49:12, 49.15s/it] 15%|█▍        | 164/1102 [2:18:06<12:48:30, 49.16s/it]                                                       {'loss': 0.7683, 'learning_rate': 0.0009638852046769538, 'epoch': 0.15}
 15%|█▍        | 164/1102 [2:18:06<12:48:30, 49.16s/it] 15%|█▍        | 165/1102 [2:18:55<12:48:10, 49.19s/it]                                                       {'loss': 0.7549, 'learning_rate': 0.0009633343735523219, 'epoch': 0.15}
 15%|█▍        | 165/1102 [2:18:55<12:48:10, 49.19s/it] 15%|█▌        | 166/1102 [2:19:45<12:47:43, 49.21s/it]                                                       {'loss': 0.7256, 'learning_rate': 0.0009627795332856106, 'epoch': 0.15}
 15%|█▌        | 166/1102 [2:19:45<12:47:43, 49.21s/it] 15%|█▌        | 167/1102 [2:20:33<12:43:58, 49.03s/it]                                                       {'loss': 0.7673, 'learning_rate': 0.0009622206886777448, 'epoch': 0.15}
 15%|█▌        | 167/1102 [2:20:33<12:43:58, 49.03s/it] 15%|█▌        | 168/1102 [2:21:23<12:45:19, 49.16s/it]                                                       {'loss': 0.7147, 'learning_rate': 0.000961657844564298, 'epoch': 0.15}
 15%|█▌        | 168/1102 [2:21:23<12:45:19, 49.16s/it] 15%|█▌        | 169/1102 [2:22:12<12:43:56, 49.13s/it]                                                       {'loss': 0.7362, 'learning_rate': 0.000961091005815451, 'epoch': 0.15}
 15%|█▌        | 169/1102 [2:22:12<12:43:56, 49.13s/it] 15%|█▌        | 170/1102 [2:23:01<12:42:50, 49.11s/it]                                                       {'loss': 0.7188, 'learning_rate': 0.0009605201773359484, 'epoch': 0.15}
 15%|█▌        | 170/1102 [2:23:01<12:42:50, 49.11s/it] 16%|█▌        | 171/1102 [2:23:50<12:43:11, 49.19s/it]                                                       {'loss': 0.6983, 'learning_rate': 0.0009599453640650584, 'epoch': 0.16}
 16%|█▌        | 171/1102 [2:23:50<12:43:11, 49.19s/it] 16%|█▌        | 172/1102 [2:24:40<12:43:34, 49.26s/it]                                                       {'loss': 0.7314, 'learning_rate': 0.000959366570976528, 'epoch': 0.16}
 16%|█▌        | 172/1102 [2:24:40<12:43:34, 49.26s/it] 16%|█▌        | 173/1102 [2:25:29<12:43:16, 49.30s/it]                                                       {'loss': 0.7169, 'learning_rate': 0.0009587838030785413, 'epoch': 0.16}
 16%|█▌        | 173/1102 [2:25:29<12:43:16, 49.30s/it] 16%|█▌        | 174/1102 [2:26:18<12:42:17, 49.29s/it]                                                       {'loss': 0.7289, 'learning_rate': 0.0009581970654136752, 'epoch': 0.16}
 16%|█▌        | 174/1102 [2:26:18<12:42:17, 49.29s/it] 16%|█▌        | 175/1102 [2:27:07<12:41:11, 49.27s/it]                                                       {'loss': 0.7833, 'learning_rate': 0.0009576063630588563, 'epoch': 0.16}
 16%|█▌        | 175/1102 [2:27:07<12:41:11, 49.27s/it] 16%|█▌        | 176/1102 [2:27:57<12:40:33, 49.28s/it]                                                       {'loss': 0.7536, 'learning_rate': 0.0009570117011253173, 'epoch': 0.16}
 16%|█▌        | 176/1102 [2:27:57<12:40:33, 49.28s/it] 16%|█▌        | 177/1102 [2:28:46<12:39:13, 49.25s/it]                                                       {'loss': 0.7227, 'learning_rate': 0.0009564130847585519, 'epoch': 0.16}
 16%|█▌        | 177/1102 [2:28:46<12:39:13, 49.25s/it] 16%|█▌        | 178/1102 [2:29:35<12:40:15, 49.37s/it]                                                       {'loss': 0.7351, 'learning_rate': 0.0009558105191382709, 'epoch': 0.16}
 16%|█▌        | 178/1102 [2:29:35<12:40:15, 49.37s/it] 16%|█▌        | 179/1102 [2:30:25<12:38:04, 49.28s/it]                                                       {'loss': 0.7056, 'learning_rate': 0.0009552040094783574, 'epoch': 0.16}
 16%|█▌        | 179/1102 [2:30:25<12:38:04, 49.28s/it] 16%|█▋        | 180/1102 [2:31:14<12:38:11, 49.34s/it]                                                       {'loss': 0.713, 'learning_rate': 0.0009545935610268211, 'epoch': 0.16}
 16%|█▋        | 180/1102 [2:31:14<12:38:11, 49.34s/it] 16%|█▋        | 181/1102 [2:32:03<12:34:36, 49.16s/it]                                                       {'loss': 0.7342, 'learning_rate': 0.0009539791790657539, 'epoch': 0.16}
 16%|█▋        | 181/1102 [2:32:03<12:34:36, 49.16s/it] 17%|█▋        | 182/1102 [2:32:52<12:31:58, 49.04s/it]                                                       {'loss': 0.7692, 'learning_rate': 0.0009533608689112828, 'epoch': 0.17}
 17%|█▋        | 182/1102 [2:32:52<12:31:58, 49.04s/it] 17%|█▋        | 183/1102 [2:33:41<12:32:34, 49.13s/it]                                                       {'loss': 0.7219, 'learning_rate': 0.0009527386359135252, 'epoch': 0.17}
 17%|█▋        | 183/1102 [2:33:41<12:32:34, 49.13s/it] 17%|█▋        | 184/1102 [2:34:30<12:31:27, 49.11s/it]                                                       {'loss': 0.7256, 'learning_rate': 0.0009521124854565424, 'epoch': 0.17}
 17%|█▋        | 184/1102 [2:34:30<12:31:27, 49.11s/it] 17%|█▋        | 185/1102 [2:35:19<12:30:48, 49.13s/it]                                                       {'loss': 0.7609, 'learning_rate': 0.0009514824229582921, 'epoch': 0.17}
 17%|█▋        | 185/1102 [2:35:19<12:30:48, 49.13s/it] 17%|█▋        | 186/1102 [2:36:08<12:28:53, 49.05s/it]                                                       {'loss': 0.7268, 'learning_rate': 0.0009508484538705823, 'epoch': 0.17}
 17%|█▋        | 186/1102 [2:36:08<12:28:53, 49.05s/it] 17%|█▋        | 187/1102 [2:36:57<12:29:17, 49.13s/it]                                                       {'loss': 0.7202, 'learning_rate': 0.000950210583679024, 'epoch': 0.17}
 17%|█▋        | 187/1102 [2:36:57<12:29:17, 49.13s/it] 17%|█▋        | 188/1102 [2:37:46<12:25:14, 48.92s/it]                                                       {'loss': 0.7962, 'learning_rate': 0.0009495688179029838, 'epoch': 0.17}
 17%|█▋        | 188/1102 [2:37:46<12:25:14, 48.92s/it] 17%|█▋        | 189/1102 [2:38:35<12:26:16, 49.04s/it]                                                       {'loss': 0.7324, 'learning_rate': 0.0009489231620955358, 'epoch': 0.17}
 17%|█▋        | 189/1102 [2:38:35<12:26:16, 49.04s/it] 17%|█▋        | 190/1102 [2:39:24<12:26:14, 49.10s/it]                                                       {'loss': 0.7286, 'learning_rate': 0.0009482736218434142, 'epoch': 0.17}
 17%|█▋        | 190/1102 [2:39:24<12:26:14, 49.10s/it] 17%|█▋        | 191/1102 [2:40:14<12:26:16, 49.15s/it]                                                       {'loss': 0.7293, 'learning_rate': 0.0009476202027669643, 'epoch': 0.17}
 17%|█▋        | 191/1102 [2:40:14<12:26:16, 49.15s/it] 17%|█▋        | 192/1102 [2:41:03<12:28:39, 49.36s/it]                                                       {'loss': 0.7304, 'learning_rate': 0.0009469629105200937, 'epoch': 0.17}
 17%|█▋        | 192/1102 [2:41:04<12:28:39, 49.36s/it] 18%|█▊        | 193/1102 [2:44:44<25:23:54, 100.59s/it]                                                        {'loss': 0.7527, 'learning_rate': 0.0009463017507902245, 'epoch': 0.18}
 18%|█▊        | 193/1102 [2:44:44<25:23:54, 100.59s/it] 18%|█▊        | 194/1102 [2:45:59<23:27:49, 93.03s/it]                                                        {'loss': 0.7621, 'learning_rate': 0.0009456367292982428, 'epoch': 0.18}
 18%|█▊        | 194/1102 [2:45:59<23:27:49, 93.03s/it] 18%|█▊        | 195/1102 [2:46:48<20:09:05, 79.98s/it]                                                       {'loss': 0.7524, 'learning_rate': 0.0009449678517984502, 'epoch': 0.18}
 18%|█▊        | 195/1102 [2:46:48<20:09:05, 79.98s/it] 18%|█▊        | 196/1102 [2:47:37<17:47:25, 70.69s/it]                                                       {'loss': 0.7562, 'learning_rate': 0.0009442951240785135, 'epoch': 0.18}
 18%|█▊        | 196/1102 [2:47:38<17:47:25, 70.69s/it] 18%|█▊        | 197/1102 [2:48:26<16:07:13, 64.13s/it]                                                       {'loss': 0.8067, 'learning_rate': 0.0009436185519594145, 'epoch': 0.18}
 18%|█▊        | 197/1102 [2:48:26<16:07:13, 64.13s/it] 18%|█▊        | 198/1102 [2:49:15<14:58:38, 59.64s/it]                                                       {'loss': 0.7391, 'learning_rate': 0.0009429381412953999, 'epoch': 0.18}
 18%|█▊        | 198/1102 [2:49:15<14:58:38, 59.64s/it] 18%|█▊        | 199/1102 [2:50:05<14:11:37, 56.59s/it]                                                       {'loss': 0.7564, 'learning_rate': 0.0009422538979739307, 'epoch': 0.18}
 18%|█▊        | 199/1102 [2:50:05<14:11:37, 56.59s/it] 18%|█▊        | 200/1102 [2:50:54<13:36:56, 54.34s/it]                                                       {'loss': 0.718, 'learning_rate': 0.000941565827915631, 'epoch': 0.18}
 18%|█▊        | 200/1102 [2:50:54<13:36:56, 54.34s/it] 18%|█▊        | 201/1102 [2:51:43<13:11:54, 52.73s/it]                                                       {'loss': 0.7818, 'learning_rate': 0.0009408739370742372, 'epoch': 0.18}
 18%|█▊        | 201/1102 [2:51:43<13:11:54, 52.73s/it] 18%|█▊        | 202/1102 [2:52:33<12:56:45, 51.78s/it]                                                       {'loss': 0.733, 'learning_rate': 0.0009401782314365457, 'epoch': 0.18}
 18%|█▊        | 202/1102 [2:52:33<12:56:45, 51.78s/it] 18%|█▊        | 203/1102 [2:53:22<12:46:56, 51.19s/it]                                                       {'loss': 0.7436, 'learning_rate': 0.0009394787170223619, 'epoch': 0.18}
 18%|█▊        | 203/1102 [2:53:22<12:46:56, 51.19s/it] 19%|█▊        | 204/1102 [2:54:11<12:35:57, 50.51s/it]                                                       {'loss': 0.7209, 'learning_rate': 0.0009387753998844481, 'epoch': 0.19}
 19%|█▊        | 204/1102 [2:54:11<12:35:57, 50.51s/it] 19%|█▊        | 205/1102 [2:55:01<12:29:45, 50.15s/it]                                                       {'loss': 0.7065, 'learning_rate': 0.0009380682861084702, 'epoch': 0.19}
 19%|█▊        | 205/1102 [2:55:01<12:29:45, 50.15s/it] 19%|█▊        | 206/1102 [2:55:49<12:22:33, 49.72s/it]                                                       {'loss': 0.7721, 'learning_rate': 0.0009373573818129458, 'epoch': 0.19}
 19%|█▊        | 206/1102 [2:55:49<12:22:33, 49.72s/it] 19%|█▉        | 207/1102 [2:56:39<12:20:01, 49.61s/it]                                                       {'loss': 0.7303, 'learning_rate': 0.0009366426931491916, 'epoch': 0.19}
 19%|█▉        | 207/1102 [2:56:39<12:20:01, 49.61s/it] 19%|█▉        | 208/1102 [2:57:26<12:07:49, 48.85s/it]                                                       {'loss': 0.7756, 'learning_rate': 0.0009359242263012693, 'epoch': 0.19}
 19%|█▉        | 208/1102 [2:57:26<12:07:49, 48.85s/it] 19%|█▉        | 209/1102 [2:58:15<12:07:28, 48.88s/it]                                                       {'loss': 0.7413, 'learning_rate': 0.0009352019874859325, 'epoch': 0.19}
 19%|█▉        | 209/1102 [2:58:15<12:07:28, 48.88s/it] 19%|█▉        | 210/1102 [2:59:04<12:09:41, 49.08s/it]                                                       {'loss': 0.71, 'learning_rate': 0.0009344759829525733, 'epoch': 0.19}
 19%|█▉        | 210/1102 [2:59:04<12:09:41, 49.08s/it] 19%|█▉        | 211/1102 [2:59:54<12:11:17, 49.25s/it]                                                       {'loss': 0.7227, 'learning_rate': 0.0009337462189831669, 'epoch': 0.19}
 19%|█▉        | 211/1102 [2:59:54<12:11:17, 49.25s/it] 19%|█▉        | 212/1102 [3:00:43<12:08:38, 49.12s/it]                                                       {'loss': 0.7578, 'learning_rate': 0.0009330127018922195, 'epoch': 0.19}
 19%|█▉        | 212/1102 [3:00:43<12:08:38, 49.12s/it] 19%|█▉        | 213/1102 [3:01:32<12:08:37, 49.18s/it]                                                       {'loss': 0.7074, 'learning_rate': 0.0009322754380267109, 'epoch': 0.19}
 19%|█▉        | 213/1102 [3:01:32<12:08:37, 49.18s/it] 19%|█▉        | 214/1102 [3:02:22<12:10:48, 49.38s/it]                                                       {'loss': 0.7573, 'learning_rate': 0.0009315344337660421, 'epoch': 0.19}
 19%|█▉        | 214/1102 [3:02:22<12:10:48, 49.38s/it] 20%|█▉        | 215/1102 [3:03:11<12:09:29, 49.35s/it]                                                       {'loss': 0.7632, 'learning_rate': 0.0009307896955219786, 'epoch': 0.2}
 20%|█▉        | 215/1102 [3:03:11<12:09:29, 49.35s/it] 20%|█▉        | 216/1102 [3:04:00<12:07:03, 49.24s/it]                                                       {'loss': 0.802, 'learning_rate': 0.0009300412297385954, 'epoch': 0.2}
 20%|█▉        | 216/1102 [3:04:00<12:07:03, 49.24s/it] 20%|█▉        | 217/1102 [3:04:49<12:06:33, 49.26s/it]                                                       {'loss': 0.7282, 'learning_rate': 0.0009292890428922209, 'epoch': 0.2}
 20%|█▉        | 217/1102 [3:04:49<12:06:33, 49.26s/it] 20%|█▉        | 218/1102 [3:05:39<12:05:03, 49.21s/it]                                                       {'loss': 0.7588, 'learning_rate': 0.0009285331414913816, 'epoch': 0.2}
 20%|█▉        | 218/1102 [3:05:39<12:05:03, 49.21s/it] 20%|█▉        | 219/1102 [3:06:27<12:02:20, 49.08s/it]                                                       {'loss': 0.6906, 'learning_rate': 0.0009277735320767449, 'epoch': 0.2}
 20%|█▉        | 219/1102 [3:06:27<12:02:20, 49.08s/it] 20%|█▉        | 220/1102 [3:07:17<12:03:08, 49.19s/it]                                                       {'loss': 0.7332, 'learning_rate': 0.0009270102212210632, 'epoch': 0.2}
 20%|█▉        | 220/1102 [3:07:17<12:03:08, 49.19s/it] 20%|██        | 221/1102 [3:08:06<12:01:44, 49.15s/it]                                                       {'loss': 0.7494, 'learning_rate': 0.0009262432155291167, 'epoch': 0.2}
 20%|██        | 221/1102 [3:08:06<12:01:44, 49.15s/it] 20%|██        | 222/1102 [3:08:55<11:59:13, 49.04s/it]                                                       {'loss': 0.8224, 'learning_rate': 0.000925472521637656, 'epoch': 0.2}
 20%|██        | 222/1102 [3:08:55<11:59:13, 49.04s/it] 20%|██        | 223/1102 [3:09:44<12:00:40, 49.19s/it]                                                       {'loss': 0.7281, 'learning_rate': 0.0009246981462153456, 'epoch': 0.2}
 20%|██        | 223/1102 [3:09:44<12:00:40, 49.19s/it] 20%|██        | 224/1102 [3:10:34<12:00:45, 49.25s/it]                                                       {'loss': 0.6914, 'learning_rate': 0.0009239200959627047, 'epoch': 0.2}
 20%|██        | 224/1102 [3:10:34<12:00:45, 49.25s/it] 20%|██        | 225/1102 [3:11:23<11:59:09, 49.20s/it]                                                       {'loss': 0.7845, 'learning_rate': 0.0009231383776120511, 'epoch': 0.2}
 20%|██        | 225/1102 [3:11:23<11:59:09, 49.20s/it] 21%|██        | 226/1102 [3:12:12<11:57:40, 49.16s/it]                                                       {'loss': 0.7055, 'learning_rate': 0.000922352997927441, 'epoch': 0.21}
 21%|██        | 226/1102 [3:12:12<11:57:40, 49.16s/it] 21%|██        | 227/1102 [3:13:01<11:57:34, 49.21s/it]                                                       {'loss': 0.705, 'learning_rate': 0.000921563963704612, 'epoch': 0.21}
 21%|██        | 227/1102 [3:13:01<11:57:34, 49.21s/it] 21%|██        | 228/1102 [3:13:51<11:58:08, 49.30s/it]                                                       {'loss': 0.7133, 'learning_rate': 0.0009207712817709236, 'epoch': 0.21}
 21%|██        | 228/1102 [3:13:51<11:58:08, 49.30s/it] 21%|██        | 229/1102 [3:14:40<11:55:51, 49.20s/it]                                                       {'loss': 0.7121, 'learning_rate': 0.0009199749589852979, 'epoch': 0.21}
 21%|██        | 229/1102 [3:14:40<11:55:51, 49.20s/it] 21%|██        | 230/1102 [3:15:29<11:55:39, 49.24s/it]                                                       {'loss': 0.7335, 'learning_rate': 0.0009191750022381613, 'epoch': 0.21}
 21%|██        | 230/1102 [3:15:29<11:55:39, 49.24s/it] 21%|██        | 231/1102 [3:16:18<11:53:13, 49.13s/it]                                                       {'loss': 0.7589, 'learning_rate': 0.0009183714184513832, 'epoch': 0.21}
 21%|██        | 231/1102 [3:16:18<11:53:13, 49.13s/it] 21%|██        | 232/1102 [3:17:07<11:55:08, 49.32s/it]                                                       {'loss': 0.7144, 'learning_rate': 0.0009175642145782178, 'epoch': 0.21}
 21%|██        | 232/1102 [3:17:07<11:55:08, 49.32s/it] 21%|██        | 233/1102 [3:17:57<11:53:53, 49.29s/it]                                                       {'loss': 0.7264, 'learning_rate': 0.0009167533976032429, 'epoch': 0.21}
 21%|██        | 233/1102 [3:17:57<11:53:53, 49.29s/it] 21%|██        | 234/1102 [3:18:46<11:52:23, 49.24s/it]                                                       {'loss': 0.7671, 'learning_rate': 0.0009159389745423001, 'epoch': 0.21}
 21%|██        | 234/1102 [3:18:46<11:52:23, 49.24s/it] 21%|██▏       | 235/1102 [3:19:35<11:52:34, 49.31s/it]                                                       {'loss': 0.7116, 'learning_rate': 0.0009151209524424334, 'epoch': 0.21}
 21%|██▏       | 235/1102 [3:19:35<11:52:34, 49.31s/it] 21%|██▏       | 236/1102 [3:20:25<11:51:54, 49.32s/it]                                                       {'loss': 0.7004, 'learning_rate': 0.0009142993383818283, 'epoch': 0.21}
 21%|██▏       | 236/1102 [3:20:25<11:51:54, 49.32s/it] 22%|██▏       | 237/1102 [3:21:14<11:50:35, 49.29s/it]                                                       {'loss': 0.7472, 'learning_rate': 0.0009134741394697517, 'epoch': 0.22}
 22%|██▏       | 237/1102 [3:21:14<11:50:35, 49.29s/it] 22%|██▏       | 238/1102 [3:22:03<11:49:55, 49.30s/it]                                                       {'loss': 0.7349, 'learning_rate': 0.0009126453628464888, 'epoch': 0.22}
 22%|██▏       | 238/1102 [3:22:03<11:49:55, 49.30s/it] 22%|██▏       | 239/1102 [3:22:52<11:47:16, 49.17s/it]                                                       {'loss': 0.7502, 'learning_rate': 0.0009118130156832822, 'epoch': 0.22}
 22%|██▏       | 239/1102 [3:22:52<11:47:16, 49.17s/it] 22%|██▏       | 240/1102 [3:23:41<11:46:51, 49.20s/it]                                                       {'loss': 0.7144, 'learning_rate': 0.0009109771051822702, 'epoch': 0.22}
 22%|██▏       | 240/1102 [3:23:41<11:46:51, 49.20s/it] 22%|██▏       | 241/1102 [3:24:30<11:43:45, 49.04s/it]                                                       {'loss': 0.7508, 'learning_rate': 0.000910137638576423, 'epoch': 0.22}
 22%|██▏       | 241/1102 [3:24:30<11:43:45, 49.04s/it] 22%|██▏       | 242/1102 [3:25:20<11:45:48, 49.24s/it]                                                       {'loss': 0.6619, 'learning_rate': 0.0009092946231294819, 'epoch': 0.22}
 22%|██▏       | 242/1102 [3:25:20<11:45:48, 49.24s/it] 22%|██▏       | 243/1102 [3:26:09<11:45:15, 49.26s/it]                                                       {'loss': 0.7312, 'learning_rate': 0.0009084480661358953, 'epoch': 0.22}
 22%|██▏       | 243/1102 [3:26:09<11:45:15, 49.26s/it] 22%|██▏       | 244/1102 [3:26:58<11:43:29, 49.20s/it]                                                       {'loss': 0.71, 'learning_rate': 0.000907597974920756, 'epoch': 0.22}
 22%|██▏       | 244/1102 [3:26:58<11:43:29, 49.20s/it] 22%|██▏       | 245/1102 [3:27:47<11:41:26, 49.11s/it]                                                       {'loss': 0.7728, 'learning_rate': 0.0009067443568397378, 'epoch': 0.22}
 22%|██▏       | 245/1102 [3:27:47<11:41:26, 49.11s/it] 22%|██▏       | 246/1102 [3:28:37<11:42:53, 49.27s/it]                                                       {'loss': 0.7998, 'learning_rate': 0.0009058872192790313, 'epoch': 0.22}
 22%|██▏       | 246/1102 [3:28:37<11:42:53, 49.27s/it] 22%|██▏       | 247/1102 [3:29:26<11:41:07, 49.20s/it]                                                       {'loss': 0.6999, 'learning_rate': 0.000905026569655281, 'epoch': 0.22}
 22%|██▏       | 247/1102 [3:29:26<11:41:07, 49.20s/it] 23%|██▎       | 248/1102 [3:30:15<11:40:22, 49.21s/it]                                                       {'loss': 0.7456, 'learning_rate': 0.0009041624154155208, 'epoch': 0.22}
 23%|██▎       | 248/1102 [3:30:15<11:40:22, 49.21s/it] 23%|██▎       | 249/1102 [3:31:04<11:37:49, 49.08s/it]                                                       {'loss': 0.7373, 'learning_rate': 0.0009032947640371086, 'epoch': 0.23}
 23%|██▎       | 249/1102 [3:31:04<11:37:49, 49.08s/it] 23%|██▎       | 250/1102 [3:31:53<11:36:34, 49.05s/it]                                                       {'loss': 0.7459, 'learning_rate': 0.000902423623027663, 'epoch': 0.23}
 23%|██▎       | 250/1102 [3:31:53<11:36:34, 49.05s/it] 23%|██▎       | 251/1102 [3:32:42<11:35:56, 49.07s/it]                                                       {'loss': 0.7909, 'learning_rate': 0.000901548999924997, 'epoch': 0.23}
 23%|██▎       | 251/1102 [3:32:42<11:35:56, 49.07s/it] 23%|██▎       | 252/1102 [3:33:31<11:34:57, 49.06s/it]                                                       {'loss': 0.703, 'learning_rate': 0.0009006709022970546, 'epoch': 0.23}
 23%|██▎       | 252/1102 [3:33:31<11:34:57, 49.06s/it] 23%|██▎       | 253/1102 [3:34:20<11:34:27, 49.08s/it]                                                       {'loss': 0.7166, 'learning_rate': 0.0008997893377418431, 'epoch': 0.23}
 23%|██▎       | 253/1102 [3:34:20<11:34:27, 49.08s/it] 23%|██▎       | 254/1102 [3:35:09<11:32:35, 49.00s/it]                                                       {'loss': 0.7385, 'learning_rate': 0.0008989043138873691, 'epoch': 0.23}
 23%|██▎       | 254/1102 [3:35:09<11:32:35, 49.00s/it] 23%|██▎       | 255/1102 [3:35:58<11:33:07, 49.10s/it]                                                       {'loss': 0.7074, 'learning_rate': 0.0008980158383915713, 'epoch': 0.23}
 23%|██▎       | 255/1102 [3:35:58<11:33:07, 49.10s/it] 23%|██▎       | 256/1102 [3:36:47<11:32:05, 49.08s/it]                                                       {'loss': 0.7428, 'learning_rate': 0.0008971239189422555, 'epoch': 0.23}
 23%|██▎       | 256/1102 [3:36:47<11:32:05, 49.08s/it] 23%|██▎       | 257/1102 [3:37:36<11:30:56, 49.06s/it]                                                       {'loss': 0.7393, 'learning_rate': 0.0008962285632570266, 'epoch': 0.23}
 23%|██▎       | 257/1102 [3:37:36<11:30:56, 49.06s/it] 23%|██▎       | 258/1102 [3:38:25<11:28:23, 48.94s/it]                                                       {'loss': 0.7287, 'learning_rate': 0.0008953297790832231, 'epoch': 0.23}
 23%|██▎       | 258/1102 [3:38:25<11:28:23, 48.94s/it] 24%|██▎       | 259/1102 [3:39:14<11:29:12, 49.05s/it]                                                       {'loss': 0.7173, 'learning_rate': 0.0008944275741978494, 'epoch': 0.23}
 24%|██▎       | 259/1102 [3:39:14<11:29:12, 49.05s/it] 24%|██▎       | 260/1102 [3:40:03<11:28:54, 49.09s/it]                                                       {'loss': 0.7212, 'learning_rate': 0.0008935219564075085, 'epoch': 0.24}
 24%|██▎       | 260/1102 [3:40:03<11:28:54, 49.09s/it] 24%|██▎       | 261/1102 [3:40:53<11:30:54, 49.29s/it]                                                       {'loss': 0.7243, 'learning_rate': 0.000892612933548335, 'epoch': 0.24}
 24%|██▎       | 261/1102 [3:40:53<11:30:54, 49.29s/it] 24%|██▍       | 262/1102 [3:41:42<11:30:18, 49.31s/it]                                                       {'loss': 0.6873, 'learning_rate': 0.0008917005134859262, 'epoch': 0.24}
 24%|██▍       | 262/1102 [3:41:42<11:30:18, 49.31s/it] 24%|██▍       | 263/1102 [3:42:32<11:30:20, 49.37s/it]                                                       {'loss': 0.6941, 'learning_rate': 0.0008907847041152757, 'epoch': 0.24}
 24%|██▍       | 263/1102 [3:42:32<11:30:20, 49.37s/it] 24%|██▍       | 264/1102 [3:43:21<11:29:49, 49.39s/it]                                                       {'loss': 0.6798, 'learning_rate': 0.000889865513360703, 'epoch': 0.24}
 24%|██▍       | 264/1102 [3:43:21<11:29:49, 49.39s/it] 24%|██▍       | 265/1102 [3:44:11<11:29:16, 49.41s/it]                                                       {'loss': 0.7378, 'learning_rate': 0.0008889429491757871, 'epoch': 0.24}
 24%|██▍       | 265/1102 [3:44:11<11:29:16, 49.41s/it] 24%|██▍       | 266/1102 [3:45:00<11:25:31, 49.20s/it]                                                       {'loss': 0.7196, 'learning_rate': 0.000888017019543296, 'epoch': 0.24}
 24%|██▍       | 266/1102 [3:45:00<11:25:31, 49.20s/it] 24%|██▍       | 267/1102 [3:45:49<11:24:52, 49.21s/it]                                                       {'loss': 0.7134, 'learning_rate': 0.0008870877324751184, 'epoch': 0.24}
 24%|██▍       | 267/1102 [3:45:49<11:24:52, 49.21s/it] 24%|██▍       | 268/1102 [3:46:38<11:24:07, 49.22s/it]                                                       {'loss': 0.675, 'learning_rate': 0.0008861550960121944, 'epoch': 0.24}
 24%|██▍       | 268/1102 [3:46:38<11:24:07, 49.22s/it] 24%|██▍       | 269/1102 [3:47:27<11:23:08, 49.21s/it]                                                       {'loss': 0.7838, 'learning_rate': 0.0008852191182244456, 'epoch': 0.24}
 24%|██▍       | 269/1102 [3:47:27<11:23:08, 49.21s/it] 25%|██▍       | 270/1102 [3:48:16<11:22:51, 49.24s/it]                                                       {'loss': 0.722, 'learning_rate': 0.0008842798072107055, 'epoch': 0.24}
 25%|██▍       | 270/1102 [3:48:17<11:22:51, 49.24s/it] 25%|██▍       | 271/1102 [3:49:06<11:21:16, 49.19s/it]                                                       {'loss': 0.7381, 'learning_rate': 0.0008833371710986493, 'epoch': 0.25}
 25%|██▍       | 271/1102 [3:49:06<11:21:16, 49.19s/it] 25%|██▍       | 272/1102 [3:49:55<11:21:03, 49.23s/it]                                                       {'loss': 0.7096, 'learning_rate': 0.0008823912180447235, 'epoch': 0.25}
 25%|██▍       | 272/1102 [3:49:55<11:21:03, 49.23s/it] 25%|██▍       | 273/1102 [3:50:44<11:21:07, 49.30s/it]                                                       {'loss': 0.7123, 'learning_rate': 0.0008814419562340759, 'epoch': 0.25}
 25%|██▍       | 273/1102 [3:50:44<11:21:07, 49.30s/it] 25%|██▍       | 274/1102 [3:51:33<11:18:56, 49.20s/it]                                                       {'loss': 0.7468, 'learning_rate': 0.0008804893938804839, 'epoch': 0.25}
 25%|██▍       | 274/1102 [3:51:33<11:18:56, 49.20s/it] 25%|██▍       | 275/1102 [3:52:23<11:19:46, 49.32s/it]                                                       {'loss': 0.6975, 'learning_rate': 0.000879533539226284, 'epoch': 0.25}
 25%|██▍       | 275/1102 [3:52:23<11:19:46, 49.32s/it] 25%|██▌       | 276/1102 [3:53:12<11:17:50, 49.24s/it]                                                       {'loss': 0.7702, 'learning_rate': 0.0008785744005423002, 'epoch': 0.25}
 25%|██▌       | 276/1102 [3:53:12<11:17:50, 49.24s/it] 25%|██▌       | 277/1102 [3:54:01<11:16:05, 49.17s/it]                                                       {'loss': 0.7367, 'learning_rate': 0.0008776119861277729, 'epoch': 0.25}
 25%|██▌       | 277/1102 [3:54:01<11:16:05, 49.17s/it] 25%|██▌       | 278/1102 [3:54:50<11:15:22, 49.18s/it]                                                       {'loss': 0.6898, 'learning_rate': 0.0008766463043102864, 'epoch': 0.25}
 25%|██▌       | 278/1102 [3:54:50<11:15:22, 49.18s/it] 25%|██▌       | 279/1102 [3:55:39<11:12:52, 49.06s/it]                                                       {'loss': 0.7601, 'learning_rate': 0.0008756773634456975, 'epoch': 0.25}
 25%|██▌       | 279/1102 [3:55:39<11:12:52, 49.06s/it] 25%|██▌       | 280/1102 [3:56:27<11:07:17, 48.71s/it]                                                       {'loss': 0.7823, 'learning_rate': 0.0008747051719180625, 'epoch': 0.25}
 25%|██▌       | 280/1102 [3:56:27<11:07:17, 48.71s/it] 25%|██▌       | 281/1102 [3:57:16<11:08:41, 48.87s/it]                                                       {'loss': 0.7166, 'learning_rate': 0.0008737297381395657, 'epoch': 0.25}
 25%|██▌       | 281/1102 [3:57:16<11:08:41, 48.87s/it] 26%|██▌       | 282/1102 [3:58:05<11:08:05, 48.88s/it]                                                       {'loss': 0.7158, 'learning_rate': 0.0008727510705504453, 'epoch': 0.26}
 26%|██▌       | 282/1102 [3:58:05<11:08:05, 48.88s/it] 26%|██▌       | 283/1102 [3:58:54<11:08:36, 48.98s/it]                                                       {'loss': 0.7075, 'learning_rate': 0.0008717691776189214, 'epoch': 0.26}
 26%|██▌       | 283/1102 [3:58:54<11:08:36, 48.98s/it] 26%|██▌       | 284/1102 [3:59:44<11:09:07, 49.08s/it]                                                       {'loss': 0.7371, 'learning_rate': 0.0008707840678411222, 'epoch': 0.26}
 26%|██▌       | 284/1102 [3:59:44<11:09:07, 49.08s/it] 26%|██▌       | 285/1102 [4:00:32<11:07:43, 49.04s/it]                                                       {'loss': 0.6749, 'learning_rate': 0.0008697957497410108, 'epoch': 0.26}
 26%|██▌       | 285/1102 [4:00:32<11:07:43, 49.04s/it] 26%|██▌       | 286/1102 [4:01:22<11:08:19, 49.14s/it]                                                       {'loss': 0.6874, 'learning_rate': 0.0008688042318703111, 'epoch': 0.26}
 26%|██▌       | 286/1102 [4:01:22<11:08:19, 49.14s/it] 26%|██▌       | 287/1102 [4:02:11<11:07:15, 49.12s/it]                                                       {'loss': 0.7047, 'learning_rate': 0.0008678095228084343, 'epoch': 0.26}
 26%|██▌       | 287/1102 [4:02:11<11:07:15, 49.12s/it] 26%|██▌       | 288/1102 [4:03:00<11:07:47, 49.22s/it]                                                       {'loss': 0.7107, 'learning_rate': 0.0008668116311624039, 'epoch': 0.26}
 26%|██▌       | 288/1102 [4:03:00<11:07:47, 49.22s/it] 26%|██▌       | 289/1102 [4:03:49<11:06:10, 49.16s/it]                                                       {'loss': 0.7265, 'learning_rate': 0.0008658105655667819, 'epoch': 0.26}
 26%|██▌       | 289/1102 [4:03:49<11:06:10, 49.16s/it] 26%|██▋       | 290/1102 [4:04:39<11:05:29, 49.17s/it]                                                       {'loss': 0.7214, 'learning_rate': 0.0008648063346835942, 'epoch': 0.26}
 26%|██▋       | 290/1102 [4:04:39<11:05:29, 49.17s/it] 26%|██▋       | 291/1102 [4:05:28<11:07:26, 49.38s/it]                                                       {'loss': 0.6932, 'learning_rate': 0.0008637989472022548, 'epoch': 0.26}
 26%|██▋       | 291/1102 [4:05:28<11:07:26, 49.38s/it] 26%|██▋       | 292/1102 [4:06:17<11:05:07, 49.27s/it]                                                       {'loss': 0.7448, 'learning_rate': 0.0008627884118394913, 'epoch': 0.26}
 26%|██▋       | 292/1102 [4:06:17<11:05:07, 49.27s/it] 27%|██▋       | 293/1102 [4:07:05<10:58:49, 48.86s/it]                                                       {'loss': 0.7435, 'learning_rate': 0.0008617747373392695, 'epoch': 0.27}
 27%|██▋       | 293/1102 [4:07:05<10:58:49, 48.86s/it] 27%|██▋       | 294/1102 [4:07:54<10:57:30, 48.82s/it]                                                       {'loss': 0.7475, 'learning_rate': 0.0008607579324727174, 'epoch': 0.27}
 27%|██▋       | 294/1102 [4:07:54<10:57:30, 48.82s/it] 27%|██▋       | 295/1102 [4:08:43<10:58:49, 48.98s/it]                                                       {'loss': 0.7036, 'learning_rate': 0.0008597380060380493, 'epoch': 0.27}
 27%|██▋       | 295/1102 [4:08:43<10:58:49, 48.98s/it] 27%|██▋       | 296/1102 [4:09:33<10:58:21, 49.01s/it]                                                       {'loss': 0.6976, 'learning_rate': 0.00085871496686049, 'epoch': 0.27}
 27%|██▋       | 296/1102 [4:09:33<10:58:21, 49.01s/it] 27%|██▋       | 297/1102 [4:10:22<10:58:22, 49.07s/it]                                                       {'loss': 0.6667, 'learning_rate': 0.0008576888237921983, 'epoch': 0.27}
 27%|██▋       | 297/1102 [4:10:22<10:58:22, 49.07s/it] 27%|██▋       | 298/1102 [4:11:11<10:56:43, 49.01s/it]                                                       {'loss': 0.7854, 'learning_rate': 0.0008566595857121902, 'epoch': 0.27}
 27%|██▋       | 298/1102 [4:11:11<10:56:43, 49.01s/it] 27%|██▋       | 299/1102 [4:12:00<10:57:44, 49.15s/it]                                                       {'loss': 0.726, 'learning_rate': 0.0008556272615262622, 'epoch': 0.27}
 27%|██▋       | 299/1102 [4:12:00<10:57:44, 49.15s/it] 27%|██▋       | 300/1102 [4:12:49<10:57:24, 49.18s/it]                                                       {'loss': 0.7552, 'learning_rate': 0.0008545918601669147, 'epoch': 0.27}
 27%|██▋       | 300/1102 [4:12:49<10:57:24, 49.18s/it] 27%|██▋       | 301/1102 [4:13:38<10:54:25, 49.02s/it]                                                       {'loss': 0.7568, 'learning_rate': 0.0008535533905932737, 'epoch': 0.27}
 27%|██▋       | 301/1102 [4:13:38<10:54:25, 49.02s/it] 27%|██▋       | 302/1102 [4:14:28<10:55:34, 49.17s/it]                                                       {'loss': 0.7007, 'learning_rate': 0.0008525118617910143, 'epoch': 0.27}
 27%|██▋       | 302/1102 [4:14:28<10:55:34, 49.17s/it] 27%|██▋       | 303/1102 [4:15:16<10:53:24, 49.07s/it]                                                       {'loss': 0.696, 'learning_rate': 0.0008514672827722823, 'epoch': 0.27}
 27%|██▋       | 303/1102 [4:15:16<10:53:24, 49.07s/it] 28%|██▊       | 304/1102 [4:16:05<10:50:56, 48.94s/it]                                                       {'loss': 0.7005, 'learning_rate': 0.0008504196625756165, 'epoch': 0.28}
 28%|██▊       | 304/1102 [4:16:05<10:50:56, 48.94s/it] 28%|██▊       | 305/1102 [4:16:54<10:51:29, 49.05s/it]                                                       {'loss': 0.7678, 'learning_rate': 0.0008493690102658703, 'epoch': 0.28}
 28%|██▊       | 305/1102 [4:16:54<10:51:29, 49.05s/it] 28%|██▊       | 306/1102 [4:17:43<10:50:06, 49.00s/it]                                                       {'loss': 0.7707, 'learning_rate': 0.0008483153349341335, 'epoch': 0.28}
 28%|██▊       | 306/1102 [4:17:43<10:50:06, 49.00s/it] 28%|██▊       | 307/1102 [4:18:33<10:50:49, 49.12s/it]                                                       {'loss': 0.7171, 'learning_rate': 0.0008472586456976535, 'epoch': 0.28}
 28%|██▊       | 307/1102 [4:18:33<10:50:49, 49.12s/it] 28%|██▊       | 308/1102 [4:19:22<10:51:24, 49.23s/it]                                                       {'loss': 0.6875, 'learning_rate': 0.0008461989516997565, 'epoch': 0.28}
 28%|██▊       | 308/1102 [4:19:22<10:51:24, 49.23s/it] 28%|██▊       | 309/1102 [4:20:11<10:50:08, 49.19s/it]                                                       {'loss': 0.7295, 'learning_rate': 0.000845136262109768, 'epoch': 0.28}
 28%|██▊       | 309/1102 [4:20:11<10:50:08, 49.19s/it] 28%|██▊       | 310/1102 [4:21:00<10:48:38, 49.14s/it]                                                       {'loss': 0.7456, 'learning_rate': 0.0008440705861229344, 'epoch': 0.28}
 28%|██▊       | 310/1102 [4:21:00<10:48:38, 49.14s/it] 28%|██▊       | 311/1102 [4:21:50<10:49:30, 49.27s/it]                                                       {'loss': 0.7535, 'learning_rate': 0.0008430019329603422, 'epoch': 0.28}
 28%|██▊       | 311/1102 [4:21:50<10:49:30, 49.27s/it] 28%|██▊       | 312/1102 [4:22:39<10:50:34, 49.41s/it]                                                       {'loss': 0.7162, 'learning_rate': 0.000841930311868839, 'epoch': 0.28}
 28%|██▊       | 312/1102 [4:22:39<10:50:34, 49.41s/it] 28%|██▊       | 313/1102 [4:23:29<10:48:24, 49.31s/it]                                                       {'loss': 0.7101, 'learning_rate': 0.0008408557321209533, 'epoch': 0.28}
 28%|██▊       | 313/1102 [4:23:29<10:48:24, 49.31s/it] 28%|██▊       | 314/1102 [4:24:17<10:45:44, 49.17s/it]                                                       {'loss': 0.714, 'learning_rate': 0.0008397782030148147, 'epoch': 0.28}
 28%|██▊       | 314/1102 [4:24:17<10:45:44, 49.17s/it] 29%|██▊       | 315/1102 [4:25:07<10:46:09, 49.26s/it]                                                       {'loss': 0.6631, 'learning_rate': 0.0008386977338740723, 'epoch': 0.29}
 29%|██▊       | 315/1102 [4:25:07<10:46:09, 49.26s/it] 29%|██▊       | 316/1102 [4:25:56<10:44:33, 49.20s/it]                                                       {'loss': 0.7622, 'learning_rate': 0.0008376143340478153, 'epoch': 0.29}
 29%|██▊       | 316/1102 [4:25:56<10:44:33, 49.20s/it] 29%|██▉       | 317/1102 [4:26:45<10:44:14, 49.24s/it]                                                       {'loss': 0.7167, 'learning_rate': 0.0008365280129104912, 'epoch': 0.29}
 29%|██▉       | 317/1102 [4:26:45<10:44:14, 49.24s/it] 29%|██▉       | 318/1102 [4:27:35<10:44:58, 49.36s/it]                                                       {'loss': 0.756, 'learning_rate': 0.0008354387798618253, 'epoch': 0.29}
 29%|██▉       | 318/1102 [4:27:35<10:44:58, 49.36s/it] 29%|██▉       | 319/1102 [4:28:24<10:43:18, 49.30s/it]                                                       {'loss': 0.7038, 'learning_rate': 0.000834346644326739, 'epoch': 0.29}
 29%|██▉       | 319/1102 [4:28:24<10:43:18, 49.30s/it] 29%|██▉       | 320/1102 [4:29:13<10:43:00, 49.34s/it]                                                       {'loss': 0.7188, 'learning_rate': 0.0008332516157552683, 'epoch': 0.29}
 29%|██▉       | 320/1102 [4:29:13<10:43:00, 49.34s/it] 29%|██▉       | 321/1102 [4:30:03<10:42:44, 49.38s/it]                                                       {'loss': 0.6843, 'learning_rate': 0.0008321537036224821, 'epoch': 0.29}
 29%|██▉       | 321/1102 [4:30:03<10:42:44, 49.38s/it] 29%|██▉       | 322/1102 [4:30:52<10:42:02, 49.39s/it]                                                       {'loss': 0.7018, 'learning_rate': 0.0008310529174284003, 'epoch': 0.29}
 29%|██▉       | 322/1102 [4:30:52<10:42:02, 49.39s/it] 29%|██▉       | 323/1102 [4:31:41<10:39:20, 49.24s/it]                                                       {'loss': 0.6514, 'learning_rate': 0.0008299492666979112, 'epoch': 0.29}
 29%|██▉       | 323/1102 [4:31:41<10:39:20, 49.24s/it] 29%|██▉       | 324/1102 [4:32:30<10:37:05, 49.13s/it]                                                       {'loss': 0.7262, 'learning_rate': 0.0008288427609806899, 'epoch': 0.29}
 29%|██▉       | 324/1102 [4:32:30<10:37:05, 49.13s/it] 29%|██▉       | 325/1102 [4:33:19<10:35:48, 49.10s/it]                                                       {'loss': 0.7071, 'learning_rate': 0.0008277334098511146, 'epoch': 0.29}
 29%|██▉       | 325/1102 [4:33:19<10:35:48, 49.10s/it] 30%|██▉       | 326/1102 [4:34:09<10:35:55, 49.17s/it]                                                       {'loss': 0.6838, 'learning_rate': 0.0008266212229081847, 'epoch': 0.3}
 30%|██▉       | 326/1102 [4:34:09<10:35:55, 49.17s/it] 30%|██▉       | 327/1102 [4:34:57<10:34:05, 49.09s/it]                                                       {'loss': 0.7126, 'learning_rate': 0.0008255062097754371, 'epoch': 0.3}
 30%|██▉       | 327/1102 [4:34:57<10:34:05, 49.09s/it] 30%|██▉       | 328/1102 [4:35:47<10:34:14, 49.17s/it]                                                       {'loss': 0.6804, 'learning_rate': 0.0008243883801008631, 'epoch': 0.3}
 30%|██▉       | 328/1102 [4:35:47<10:34:14, 49.17s/it] 30%|██▉       | 329/1102 [4:36:36<10:32:23, 49.09s/it]                                                       {'loss': 0.7538, 'learning_rate': 0.0008232677435568252, 'epoch': 0.3}
 30%|██▉       | 329/1102 [4:36:36<10:32:23, 49.09s/it] 30%|██▉       | 330/1102 [4:37:25<10:31:36, 49.09s/it]                                                       {'loss': 0.7751, 'learning_rate': 0.0008221443098399733, 'epoch': 0.3}
 30%|██▉       | 330/1102 [4:37:25<10:31:36, 49.09s/it] 30%|███       | 331/1102 [4:38:14<10:33:09, 49.27s/it]                                                       {'loss': 0.6861, 'learning_rate': 0.0008210180886711602, 'epoch': 0.3}
 30%|███       | 331/1102 [4:38:14<10:33:09, 49.27s/it] 30%|███       | 332/1102 [4:39:03<10:30:48, 49.15s/it]                                                       {'loss': 0.737, 'learning_rate': 0.0008198890897953586, 'epoch': 0.3}
 30%|███       | 332/1102 [4:39:03<10:30:48, 49.15s/it] 30%|███       | 333/1102 [4:39:53<10:30:22, 49.18s/it]                                                       {'loss': 0.706, 'learning_rate': 0.0008187573229815757, 'epoch': 0.3}
 30%|███       | 333/1102 [4:39:53<10:30:22, 49.18s/it] 30%|███       | 334/1102 [4:40:42<10:29:48, 49.20s/it]                                                       {'loss': 0.6828, 'learning_rate': 0.0008176227980227693, 'epoch': 0.3}
 30%|███       | 334/1102 [4:40:42<10:29:48, 49.20s/it] 30%|███       | 335/1102 [4:41:31<10:27:37, 49.10s/it]                                                       {'loss': 0.7076, 'learning_rate': 0.0008164855247357628, 'epoch': 0.3}
 30%|███       | 335/1102 [4:41:31<10:27:37, 49.10s/it] 30%|███       | 336/1102 [4:42:19<10:25:06, 48.96s/it]                                                       {'loss': 0.7204, 'learning_rate': 0.0008153455129611605, 'epoch': 0.3}
 30%|███       | 336/1102 [4:42:19<10:25:06, 48.96s/it] 31%|███       | 337/1102 [4:43:09<10:26:42, 49.15s/it]                                                       {'loss': 0.7061, 'learning_rate': 0.0008142027725632623, 'epoch': 0.31}
 31%|███       | 337/1102 [4:43:09<10:26:42, 49.15s/it] 31%|███       | 338/1102 [4:43:59<10:28:24, 49.35s/it]                                                       {'loss': 0.6819, 'learning_rate': 0.0008130573134299781, 'epoch': 0.31}
 31%|███       | 338/1102 [4:43:59<10:28:24, 49.35s/it] 31%|███       | 339/1102 [4:44:48<10:26:25, 49.26s/it]                                                       {'loss': 0.7254, 'learning_rate': 0.0008119091454727428, 'epoch': 0.31}
 31%|███       | 339/1102 [4:44:48<10:26:25, 49.26s/it] 31%|███       | 340/1102 [4:45:37<10:24:53, 49.20s/it]                                                       {'loss': 0.7109, 'learning_rate': 0.0008107582786264298, 'epoch': 0.31}
 31%|███       | 340/1102 [4:45:37<10:24:53, 49.20s/it] 31%|███       | 341/1102 [4:46:26<10:25:06, 49.29s/it]                                                       {'loss': 0.7117, 'learning_rate': 0.000809604722849266, 'epoch': 0.31}
 31%|███       | 341/1102 [4:46:26<10:25:06, 49.29s/it] 31%|███       | 342/1102 [4:47:16<10:25:36, 49.39s/it]                                                       {'loss': 0.73, 'learning_rate': 0.0008084484881227447, 'epoch': 0.31}
 31%|███       | 342/1102 [4:47:16<10:25:36, 49.39s/it] 31%|███       | 343/1102 [4:48:05<10:24:51, 49.40s/it]                                                       {'loss': 0.7223, 'learning_rate': 0.0008072895844515398, 'epoch': 0.31}
 31%|███       | 343/1102 [4:48:05<10:24:51, 49.40s/it] 31%|███       | 344/1102 [4:48:54<10:21:43, 49.21s/it]                                                       {'loss': 0.7544, 'learning_rate': 0.0008061280218634192, 'epoch': 0.31}
 31%|███       | 344/1102 [4:48:54<10:21:43, 49.21s/it] 31%|███▏      | 345/1102 [4:49:43<10:20:23, 49.17s/it]                                                       {'loss': 0.724, 'learning_rate': 0.0008049638104091574, 'epoch': 0.31}
 31%|███▏      | 345/1102 [4:49:43<10:20:23, 49.17s/it] 31%|███▏      | 346/1102 [4:50:32<10:18:56, 49.12s/it]                                                       {'loss': 0.7249, 'learning_rate': 0.0008037969601624495, 'epoch': 0.31}
 31%|███▏      | 346/1102 [4:50:32<10:18:56, 49.12s/it] 31%|███▏      | 347/1102 [4:51:22<10:20:10, 49.29s/it]                                                       {'loss': 0.6311, 'learning_rate': 0.0008026274812198234, 'epoch': 0.31}
 31%|███▏      | 347/1102 [4:51:22<10:20:10, 49.29s/it] 32%|███▏      | 348/1102 [4:52:11<10:19:00, 49.26s/it]                                                       {'loss': 0.706, 'learning_rate': 0.0008014553837005526, 'epoch': 0.32}
 32%|███▏      | 348/1102 [4:52:11<10:19:00, 49.26s/it] 32%|███▏      | 349/1102 [4:53:00<10:17:39, 49.22s/it]                                                       {'loss': 0.7023, 'learning_rate': 0.0008002806777465684, 'epoch': 0.32}
 32%|███▏      | 349/1102 [4:53:00<10:17:39, 49.22s/it] 32%|███▏      | 350/1102 [4:53:50<10:17:25, 49.26s/it]                                                       {'loss': 0.7098, 'learning_rate': 0.000799103373522373, 'epoch': 0.32}
 32%|███▏      | 350/1102 [4:53:50<10:17:25, 49.26s/it] 32%|███▏      | 351/1102 [4:54:38<10:14:26, 49.09s/it]                                                       {'loss': 0.6934, 'learning_rate': 0.00079792348121495, 'epoch': 0.32}
 32%|███▏      | 351/1102 [4:54:38<10:14:26, 49.09s/it] 32%|███▏      | 352/1102 [4:55:27<10:13:15, 49.06s/it]                                                       {'loss': 0.6493, 'learning_rate': 0.0007967410110336781, 'epoch': 0.32}
 32%|███▏      | 352/1102 [4:55:27<10:13:15, 49.06s/it] 32%|███▏      | 353/1102 [4:56:16<10:11:44, 49.00s/it]                                                       {'loss': 0.7502, 'learning_rate': 0.0007955559732102414, 'epoch': 0.32}
 32%|███▏      | 353/1102 [4:56:16<10:11:44, 49.00s/it] 32%|███▏      | 354/1102 [4:57:06<10:12:44, 49.15s/it]                                                       {'loss': 0.6927, 'learning_rate': 0.0007943683779985413, 'epoch': 0.32}
 32%|███▏      | 354/1102 [4:57:06<10:12:44, 49.15s/it] 32%|███▏      | 355/1102 [4:57:55<10:13:51, 49.31s/it]                                                       {'loss': 0.7008, 'learning_rate': 0.0007931782356746076, 'epoch': 0.32}
 32%|███▏      | 355/1102 [4:57:55<10:13:51, 49.31s/it] 32%|███▏      | 356/1102 [4:58:45<10:12:58, 49.30s/it]                                                       {'loss': 0.7132, 'learning_rate': 0.0007919855565365102, 'epoch': 0.32}
 32%|███▏      | 356/1102 [4:58:45<10:12:58, 49.30s/it] 32%|███▏      | 357/1102 [4:59:34<10:13:19, 49.39s/it]                                                       {'loss': 0.6542, 'learning_rate': 0.0007907903509042695, 'epoch': 0.32}
 32%|███▏      | 357/1102 [4:59:34<10:13:19, 49.39s/it] 32%|███▏      | 358/1102 [5:00:24<10:12:36, 49.40s/it]                                                       {'loss': 0.7181, 'learning_rate': 0.0007895926291197667, 'epoch': 0.32}
 32%|███▏      | 358/1102 [5:00:24<10:12:36, 49.40s/it] 33%|███▎      | 359/1102 [5:01:13<10:11:50, 49.41s/it]                                                       {'loss': 0.6951, 'learning_rate': 0.0007883924015466553, 'epoch': 0.33}
 33%|███▎      | 359/1102 [5:01:13<10:11:50, 49.41s/it] 33%|███▎      | 360/1102 [5:02:02<10:09:38, 49.30s/it]                                                       {'loss': 0.6672, 'learning_rate': 0.0007871896785702707, 'epoch': 0.33}
 33%|███▎      | 360/1102 [5:02:02<10:09:38, 49.30s/it] 33%|███▎      | 361/1102 [5:02:51<10:07:34, 49.20s/it]                                                       {'loss': 0.6664, 'learning_rate': 0.0007859844705975404, 'epoch': 0.33}
 33%|███▎      | 361/1102 [5:02:51<10:07:34, 49.20s/it] 33%|███▎      | 362/1102 [5:03:40<10:06:31, 49.18s/it]                                                       {'loss': 0.6866, 'learning_rate': 0.0007847767880568944, 'epoch': 0.33}
 33%|███▎      | 362/1102 [5:03:40<10:06:31, 49.18s/it] 33%|███▎      | 363/1102 [5:04:29<10:05:19, 49.15s/it]                                                       {'loss': 0.7549, 'learning_rate': 0.0007835666413981743, 'epoch': 0.33}
 33%|███▎      | 363/1102 [5:04:29<10:05:19, 49.15s/it] 33%|███▎      | 364/1102 [5:05:18<10:02:59, 49.02s/it]                                                       {'loss': 0.704, 'learning_rate': 0.0007823540410925434, 'epoch': 0.33}
 33%|███▎      | 364/1102 [5:05:18<10:02:59, 49.02s/it] 33%|███▎      | 365/1102 [5:06:07<10:02:48, 49.08s/it]                                                       {'loss': 0.7349, 'learning_rate': 0.0007811389976323962, 'epoch': 0.33}
 33%|███▎      | 365/1102 [5:06:07<10:02:48, 49.08s/it] 33%|███▎      | 366/1102 [5:06:56<10:01:49, 49.06s/it]                                                       {'loss': 0.6457, 'learning_rate': 0.0007799215215312667, 'epoch': 0.33}
 33%|███▎      | 366/1102 [5:06:56<10:01:49, 49.06s/it] 33%|███▎      | 367/1102 [5:07:45<10:00:47, 49.04s/it]                                                       {'loss': 0.7008, 'learning_rate': 0.0007787016233237387, 'epoch': 0.33}
 33%|███▎      | 367/1102 [5:07:45<10:00:47, 49.04s/it] 33%|███▎      | 368/1102 [5:08:34<9:59:27, 49.00s/it]                                                       {'loss': 0.7184, 'learning_rate': 0.0007774793135653538, 'epoch': 0.33}
 33%|███▎      | 368/1102 [5:08:34<9:59:27, 49.00s/it] 33%|███▎      | 369/1102 [5:09:23<9:59:33, 49.08s/it]                                                      {'loss': 0.6806, 'learning_rate': 0.0007762546028325199, 'epoch': 0.33}
 33%|███▎      | 369/1102 [5:09:23<9:59:33, 49.08s/it] 34%|███▎      | 370/1102 [5:10:12<9:58:24, 49.05s/it]                                                      {'loss': 0.721, 'learning_rate': 0.0007750275017224206, 'epoch': 0.34}
 34%|███▎      | 370/1102 [5:10:12<9:58:24, 49.05s/it] 34%|███▎      | 371/1102 [5:11:01<9:57:13, 49.02s/it]                                                      {'loss': 0.7502, 'learning_rate': 0.000773798020852923, 'epoch': 0.34}
 34%|███▎      | 371/1102 [5:11:01<9:57:13, 49.02s/it] 34%|███▍      | 372/1102 [5:11:50<9:55:17, 48.93s/it]                                                      {'loss': 0.7242, 'learning_rate': 0.0007725661708624853, 'epoch': 0.34}
 34%|███▍      | 372/1102 [5:11:50<9:55:17, 48.93s/it] 34%|███▍      | 373/1102 [5:12:40<9:56:31, 49.10s/it]                                                      {'loss': 0.7027, 'learning_rate': 0.0007713319624100657, 'epoch': 0.34}
 34%|███▍      | 373/1102 [5:12:40<9:56:31, 49.10s/it] 34%|███▍      | 374/1102 [5:13:29<9:55:55, 49.11s/it]                                                      {'loss': 0.7027, 'learning_rate': 0.0007700954061750294, 'epoch': 0.34}
 34%|███▍      | 374/1102 [5:13:29<9:55:55, 49.11s/it] 34%|███▍      | 375/1102 [5:14:18<9:54:27, 49.06s/it]                                                      {'loss': 0.6527, 'learning_rate': 0.0007688565128570564, 'epoch': 0.34}
 34%|███▍      | 375/1102 [5:14:18<9:54:27, 49.06s/it] 34%|███▍      | 376/1102 [5:15:07<9:56:10, 49.27s/it]                                                      {'loss': 0.7614, 'learning_rate': 0.0007676152931760497, 'epoch': 0.34}
 34%|███▍      | 376/1102 [5:15:07<9:56:10, 49.27s/it] 34%|███▍      | 377/1102 [5:15:57<9:56:30, 49.37s/it]                                                      {'loss': 0.6624, 'learning_rate': 0.000766371757872041, 'epoch': 0.34}
 34%|███▍      | 377/1102 [5:15:57<9:56:30, 49.37s/it] 34%|███▍      | 378/1102 [5:16:46<9:54:12, 49.24s/it]                                                      {'loss': 0.7142, 'learning_rate': 0.0007651259177050996, 'epoch': 0.34}
 34%|███▍      | 378/1102 [5:16:46<9:54:12, 49.24s/it] 34%|███▍      | 379/1102 [5:17:35<9:51:45, 49.11s/it]                                                      {'loss': 0.7249, 'learning_rate': 0.000763877783455237, 'epoch': 0.34}
 34%|███▍      | 379/1102 [5:17:35<9:51:45, 49.11s/it] 34%|███▍      | 380/1102 [5:18:24<9:51:45, 49.18s/it]                                                      {'loss': 0.7205, 'learning_rate': 0.0007626273659223165, 'epoch': 0.34}
 34%|███▍      | 380/1102 [5:18:24<9:51:45, 49.18s/it] 35%|███▍      | 381/1102 [5:19:13<9:51:22, 49.21s/it]                                                      {'loss': 0.716, 'learning_rate': 0.000761374675925957, 'epoch': 0.35}
 35%|███▍      | 381/1102 [5:19:13<9:51:22, 49.21s/it] 35%|███▍      | 382/1102 [5:20:02<9:48:29, 49.04s/it]                                                      {'loss': 0.7089, 'learning_rate': 0.0007601197243054411, 'epoch': 0.35}
 35%|███▍      | 382/1102 [5:20:02<9:48:29, 49.04s/it] 35%|███▍      | 383/1102 [5:20:51<9:48:31, 49.11s/it]                                                      {'loss': 0.6951, 'learning_rate': 0.0007588625219196208, 'epoch': 0.35}
 35%|███▍      | 383/1102 [5:20:51<9:48:31, 49.11s/it] 35%|███▍      | 384/1102 [5:21:41<9:49:02, 49.22s/it]                                                      {'loss': 0.662, 'learning_rate': 0.0007576030796468232, 'epoch': 0.35}
 35%|███▍      | 384/1102 [5:21:41<9:49:02, 49.22s/it] 35%|███▍      | 385/1102 [5:22:30<9:48:30, 49.25s/it]                                                      {'loss': 0.725, 'learning_rate': 0.0007563414083847573, 'epoch': 0.35}
 35%|███▍      | 385/1102 [5:22:30<9:48:30, 49.25s/it] 35%|███▌      | 386/1102 [5:23:19<9:45:57, 49.10s/it]                                                      {'loss': 0.7507, 'learning_rate': 0.0007550775190504188, 'epoch': 0.35}
 35%|███▌      | 386/1102 [5:23:19<9:45:57, 49.10s/it] 35%|███▌      | 387/1102 [5:24:08<9:45:39, 49.15s/it]                                                      {'loss': 0.6859, 'learning_rate': 0.0007538114225799955, 'epoch': 0.35}
 35%|███▌      | 387/1102 [5:24:08<9:45:39, 49.15s/it] 35%|███▌      | 388/1102 [5:24:57<9:44:36, 49.13s/it]                                                      {'loss': 0.7043, 'learning_rate': 0.0007525431299287737, 'epoch': 0.35}
 35%|███▌      | 388/1102 [5:24:57<9:44:36, 49.13s/it] 35%|███▌      | 389/1102 [5:25:46<9:43:29, 49.10s/it]                                                      {'loss': 0.7194, 'learning_rate': 0.0007512726520710429, 'epoch': 0.35}
 35%|███▌      | 389/1102 [5:25:46<9:43:29, 49.10s/it] 35%|███▌      | 390/1102 [5:26:36<9:44:21, 49.24s/it]                                                      {'loss': 0.734, 'learning_rate': 0.00075, 'epoch': 0.35}
 35%|███▌      | 390/1102 [5:26:36<9:44:21, 49.24s/it] 35%|███▌      | 391/1102 [5:27:25<9:42:30, 49.16s/it]                                                      {'loss': 0.7159, 'learning_rate': 0.0007487251847276559, 'epoch': 0.35}
 35%|███▌      | 391/1102 [5:27:25<9:42:30, 49.16s/it] 36%|███▌      | 392/1102 [5:28:14<9:40:57, 49.10s/it]                                                      {'loss': 0.7259, 'learning_rate': 0.000747448217284739, 'epoch': 0.36}
 36%|███▌      | 392/1102 [5:28:14<9:40:57, 49.10s/it] 36%|███▌      | 393/1102 [5:29:04<9:42:55, 49.33s/it]                                                      {'loss': 0.6301, 'learning_rate': 0.0007461691087205993, 'epoch': 0.36}
 36%|███▌      | 393/1102 [5:29:04<9:42:55, 49.33s/it] 36%|███▌      | 394/1102 [5:29:53<9:41:25, 49.27s/it]                                                      {'loss': 0.714, 'learning_rate': 0.0007448878701031142, 'epoch': 0.36}
 36%|███▌      | 394/1102 [5:29:53<9:41:25, 49.27s/it] 36%|███▌      | 395/1102 [5:30:42<9:40:10, 49.24s/it]                                                      {'loss': 0.6967, 'learning_rate': 0.0007436045125185922, 'epoch': 0.36}
 36%|███▌      | 395/1102 [5:30:42<9:40:10, 49.24s/it] 36%|███▌      | 396/1102 [5:31:31<9:37:51, 49.11s/it]                                                      {'loss': 0.7221, 'learning_rate': 0.0007423190470716761, 'epoch': 0.36}
 36%|███▌      | 396/1102 [5:31:31<9:37:51, 49.11s/it] 36%|███▌      | 397/1102 [5:32:20<9:37:24, 49.14s/it]                                                      {'loss': 0.6937, 'learning_rate': 0.0007410314848852482, 'epoch': 0.36}
 36%|███▌      | 397/1102 [5:32:20<9:37:24, 49.14s/it] 36%|███▌      | 398/1102 [5:33:09<9:37:06, 49.19s/it]                                                      {'loss': 0.6732, 'learning_rate': 0.0007397418371003333, 'epoch': 0.36}
 36%|███▌      | 398/1102 [5:33:09<9:37:06, 49.19s/it] 36%|███▌      | 399/1102 [5:33:58<9:36:41, 49.22s/it]                                                      {'loss': 0.727, 'learning_rate': 0.0007384501148760024, 'epoch': 0.36}
 36%|███▌      | 399/1102 [5:33:58<9:36:41, 49.22s/it] 36%|███▋      | 400/1102 [5:34:47<9:35:07, 49.16s/it]                                                      {'loss': 0.688, 'learning_rate': 0.0007371563293892762, 'epoch': 0.36}
 36%|███▋      | 400/1102 [5:34:47<9:35:07, 49.16s/it] 36%|███▋      | 401/1102 [5:35:37<9:34:46, 49.20s/it]                                                      {'loss': 0.697, 'learning_rate': 0.0007358604918350287, 'epoch': 0.36}
 36%|███▋      | 401/1102 [5:35:37<9:34:46, 49.20s/it] 36%|███▋      | 402/1102 [5:36:26<9:35:12, 49.30s/it]                                                      {'loss': 0.6625, 'learning_rate': 0.0007345626134258897, 'epoch': 0.36}
 36%|███▋      | 402/1102 [5:36:26<9:35:12, 49.30s/it] 37%|███▋      | 403/1102 [5:37:15<9:32:33, 49.15s/it]                                                      {'loss': 0.7563, 'learning_rate': 0.0007332627053921483, 'epoch': 0.37}
 37%|███▋      | 403/1102 [5:37:15<9:32:33, 49.15s/it] 37%|███▋      | 404/1102 [5:38:04<9:29:41, 48.97s/it]                                                      {'loss': 0.7323, 'learning_rate': 0.0007319607789816555, 'epoch': 0.37}
 37%|███▋      | 404/1102 [5:38:04<9:29:41, 48.97s/it] 37%|███▋      | 405/1102 [5:38:54<9:31:54, 49.23s/it]                                                      {'loss': 0.6964, 'learning_rate': 0.0007306568454597269, 'epoch': 0.37}
 37%|███▋      | 405/1102 [5:38:54<9:31:54, 49.23s/it] 37%|███▋      | 406/1102 [5:39:43<9:30:18, 49.16s/it]                                                      {'loss': 0.6591, 'learning_rate': 0.0007293509161090452, 'epoch': 0.37}
 37%|███▋      | 406/1102 [5:39:43<9:30:18, 49.16s/it] 37%|███▋      | 407/1102 [5:40:31<9:28:47, 49.10s/it]                                                      {'loss': 0.7206, 'learning_rate': 0.0007280430022295629, 'epoch': 0.37}
 37%|███▋      | 407/1102 [5:40:31<9:28:47, 49.10s/it] 37%|███▋      | 408/1102 [5:41:20<9:27:14, 49.04s/it]                                                      {'loss': 0.6948, 'learning_rate': 0.0007267331151384039, 'epoch': 0.37}
 37%|███▋      | 408/1102 [5:41:20<9:27:14, 49.04s/it] 37%|███▋      | 409/1102 [5:42:09<9:26:42, 49.07s/it]                                                      {'loss': 0.722, 'learning_rate': 0.0007254212661697659, 'epoch': 0.37}
 37%|███▋      | 409/1102 [5:42:09<9:26:42, 49.07s/it] 37%|███▋      | 410/1102 [5:42:58<9:25:33, 49.04s/it]                                                      {'loss': 0.7658, 'learning_rate': 0.0007241074666748228, 'epoch': 0.37}
 37%|███▋      | 410/1102 [5:42:58<9:25:33, 49.04s/it] 37%|███▋      | 411/1102 [5:43:48<9:25:05, 49.07s/it]                                                      {'loss': 0.6861, 'learning_rate': 0.0007227917280216254, 'epoch': 0.37}
 37%|███▋      | 411/1102 [5:43:48<9:25:05, 49.07s/it] 37%|███▋      | 412/1102 [5:44:37<9:24:38, 49.10s/it]                                                      {'loss': 0.7176, 'learning_rate': 0.0007214740615950041, 'epoch': 0.37}
 37%|███▋      | 412/1102 [5:44:37<9:24:38, 49.10s/it] 37%|███▋      | 413/1102 [5:45:26<9:23:34, 49.08s/it]                                                      {'loss': 0.7179, 'learning_rate': 0.0007201544787964698, 'epoch': 0.37}
 37%|███▋      | 413/1102 [5:45:26<9:23:34, 49.08s/it] 38%|███▊      | 414/1102 [5:46:15<9:23:51, 49.17s/it]                                                      {'loss': 0.6734, 'learning_rate': 0.0007188329910441153, 'epoch': 0.38}
 38%|███▊      | 414/1102 [5:46:15<9:23:51, 49.17s/it] 38%|███▊      | 415/1102 [5:47:04<9:22:29, 49.13s/it]                                                      {'loss': 0.6581, 'learning_rate': 0.0007175096097725168, 'epoch': 0.38}
 38%|███▊      | 415/1102 [5:47:04<9:22:29, 49.13s/it] 38%|███▊      | 416/1102 [5:47:52<9:18:36, 48.86s/it]                                                      {'loss': 0.7663, 'learning_rate': 0.0007161843464326349, 'epoch': 0.38}
 38%|███▊      | 416/1102 [5:47:52<9:18:36, 48.86s/it] 38%|███▊      | 417/1102 [5:48:42<9:19:42, 49.03s/it]                                                      {'loss': 0.7402, 'learning_rate': 0.0007148572124917147, 'epoch': 0.38}
 38%|███▊      | 417/1102 [5:48:42<9:19:42, 49.03s/it] 38%|███▊      | 418/1102 [5:49:31<9:17:35, 48.91s/it]                                                      {'loss': 0.7409, 'learning_rate': 0.000713528219433188, 'epoch': 0.38}
 38%|███▊      | 418/1102 [5:49:31<9:17:35, 48.91s/it] 38%|███▊      | 419/1102 [5:50:20<9:18:52, 49.10s/it]                                                      {'loss': 0.6235, 'learning_rate': 0.0007121973787565727, 'epoch': 0.38}
 38%|███▊      | 419/1102 [5:50:20<9:18:52, 49.10s/it] 38%|███▊      | 420/1102 [5:51:10<9:19:35, 49.23s/it]                                                      {'loss': 0.6875, 'learning_rate': 0.000710864701977374, 'epoch': 0.38}
 38%|███▊      | 420/1102 [5:51:10<9:19:35, 49.23s/it] 38%|███▊      | 421/1102 [5:51:59<9:18:37, 49.22s/it]                                                      {'loss': 0.6976, 'learning_rate': 0.0007095302006269841, 'epoch': 0.38}
 38%|███▊      | 421/1102 [5:51:59<9:18:37, 49.22s/it] 38%|███▊      | 422/1102 [5:52:48<9:17:31, 49.19s/it]                                                      {'loss': 0.7416, 'learning_rate': 0.0007081938862525839, 'epoch': 0.38}
 38%|███▊      | 422/1102 [5:52:48<9:17:31, 49.19s/it] 38%|███▊      | 423/1102 [5:53:37<9:15:39, 49.10s/it]                                                      {'loss': 0.6702, 'learning_rate': 0.000706855770417041, 'epoch': 0.38}
 38%|███▊      | 423/1102 [5:53:37<9:15:39, 49.10s/it] 38%|███▊      | 424/1102 [5:54:26<9:15:03, 49.12s/it]                                                      {'loss': 0.7338, 'learning_rate': 0.0007055158646988109, 'epoch': 0.38}
 38%|███▊      | 424/1102 [5:54:26<9:15:03, 49.12s/it] 39%|███▊      | 425/1102 [5:55:15<9:14:11, 49.12s/it]                                                      {'loss': 0.7228, 'learning_rate': 0.0007041741806918372, 'epoch': 0.39}
 39%|███▊      | 425/1102 [5:55:15<9:14:11, 49.12s/it] 39%|███▊      | 426/1102 [5:56:04<9:13:07, 49.09s/it]                                                      {'loss': 0.6856, 'learning_rate': 0.0007028307300054499, 'epoch': 0.39}
 39%|███▊      | 426/1102 [5:56:04<9:13:07, 49.09s/it] 39%|███▊      | 427/1102 [5:56:53<9:12:35, 49.12s/it]                                                      {'loss': 0.7078, 'learning_rate': 0.0007014855242642662, 'epoch': 0.39}
 39%|███▊      | 427/1102 [5:56:53<9:12:35, 49.12s/it] 39%|███▉      | 428/1102 [5:57:43<9:13:14, 49.25s/it]                                                      {'loss': 0.6775, 'learning_rate': 0.0007001385751080893, 'epoch': 0.39}
 39%|███▉      | 428/1102 [5:57:43<9:13:14, 49.25s/it] 39%|███▉      | 429/1102 [5:58:32<9:11:48, 49.20s/it]                                                      {'loss': 0.6527, 'learning_rate': 0.0006987898941918082, 'epoch': 0.39}
 39%|███▉      | 429/1102 [5:58:32<9:11:48, 49.20s/it] 39%|███▉      | 430/1102 [5:59:21<9:09:59, 49.11s/it]                                                      {'loss': 0.7057, 'learning_rate': 0.0006974394931852957, 'epoch': 0.39}
 39%|███▉      | 430/1102 [5:59:21<9:09:59, 49.11s/it] 39%|███▉      | 431/1102 [6:00:10<9:09:15, 49.11s/it]                                                      {'loss': 0.6522, 'learning_rate': 0.0006960873837733088, 'epoch': 0.39}
 39%|███▉      | 431/1102 [6:00:10<9:09:15, 49.11s/it] 39%|███▉      | 432/1102 [6:00:59<9:08:17, 49.10s/it]                                                      {'loss': 0.6534, 'learning_rate': 0.0006947335776553871, 'epoch': 0.39}
 39%|███▉      | 432/1102 [6:00:59<9:08:17, 49.10s/it] 39%|███▉      | 433/1102 [6:01:49<9:08:54, 49.23s/it]                                                      {'loss': 0.6865, 'learning_rate': 0.0006933780865457507, 'epoch': 0.39}
 39%|███▉      | 433/1102 [6:01:49<9:08:54, 49.23s/it] 39%|███▉      | 434/1102 [6:02:38<9:08:26, 49.26s/it]                                                      {'loss': 0.6603, 'learning_rate': 0.0006920209221732007, 'epoch': 0.39}
 39%|███▉      | 434/1102 [6:02:38<9:08:26, 49.26s/it] 39%|███▉      | 435/1102 [6:03:27<9:06:51, 49.19s/it]                                                      {'loss': 0.7063, 'learning_rate': 0.0006906620962810159, 'epoch': 0.39}
 39%|███▉      | 435/1102 [6:03:27<9:06:51, 49.19s/it] 40%|███▉      | 436/1102 [6:04:16<9:05:20, 49.13s/it]                                                      {'loss': 0.7216, 'learning_rate': 0.0006893016206268518, 'epoch': 0.4}
 40%|███▉      | 436/1102 [6:04:16<9:05:20, 49.13s/it] 40%|███▉      | 437/1102 [6:05:05<9:05:53, 49.25s/it]                                                      {'loss': 0.6909, 'learning_rate': 0.0006879395069826393, 'epoch': 0.4}
 40%|███▉      | 437/1102 [6:05:05<9:05:53, 49.25s/it] 40%|███▉      | 438/1102 [6:05:55<9:04:40, 49.22s/it]                                                      {'loss': 0.6616, 'learning_rate': 0.0006865757671344827, 'epoch': 0.4}
 40%|███▉      | 438/1102 [6:05:55<9:04:40, 49.22s/it] 40%|███▉      | 439/1102 [6:06:44<9:03:35, 49.19s/it]                                                      {'loss': 0.7008, 'learning_rate': 0.0006852104128825569, 'epoch': 0.4}
 40%|███▉      | 439/1102 [6:06:44<9:03:35, 49.19s/it] 40%|███▉      | 440/1102 [6:07:33<9:02:07, 49.13s/it]                                                      {'loss': 0.6527, 'learning_rate': 0.0006838434560410063, 'epoch': 0.4}
 40%|███▉      | 440/1102 [6:07:33<9:02:07, 49.13s/it] 40%|████      | 441/1102 [6:08:22<9:02:17, 49.23s/it]                                                      {'loss': 0.6765, 'learning_rate': 0.0006824749084378427, 'epoch': 0.4}
 40%|████      | 441/1102 [6:08:22<9:02:17, 49.23s/it] 40%|████      | 442/1102 [6:09:11<9:01:46, 49.25s/it]                                                      {'loss': 0.656, 'learning_rate': 0.0006811047819148412, 'epoch': 0.4}
 40%|████      | 442/1102 [6:09:11<9:01:46, 49.25s/it] 40%|████      | 443/1102 [6:10:01<9:02:36, 49.40s/it]                                                      {'loss': 0.6951, 'learning_rate': 0.0006797330883274403, 'epoch': 0.4}
 40%|████      | 443/1102 [6:10:01<9:02:36, 49.40s/it] 40%|████      | 444/1102 [6:10:51<9:01:39, 49.39s/it]                                                      {'loss': 0.7149, 'learning_rate': 0.0006783598395446371, 'epoch': 0.4}
 40%|████      | 444/1102 [6:10:51<9:01:39, 49.39s/it] 40%|████      | 445/1102 [6:11:40<9:00:45, 49.38s/it]                                                      {'loss': 0.6522, 'learning_rate': 0.0006769850474488859, 'epoch': 0.4}
 40%|████      | 445/1102 [6:11:40<9:00:45, 49.38s/it] 40%|████      | 446/1102 [6:12:30<9:00:33, 49.44s/it]                                                      {'loss': 0.6642, 'learning_rate': 0.0006756087239359947, 'epoch': 0.4}
 40%|████      | 446/1102 [6:12:30<9:00:33, 49.44s/it] 41%|████      | 447/1102 [6:13:19<8:59:43, 49.44s/it]                                                      {'loss': 0.7026, 'learning_rate': 0.0006742308809150232, 'epoch': 0.41}
 41%|████      | 447/1102 [6:13:19<8:59:43, 49.44s/it] 41%|████      | 448/1102 [6:14:08<8:58:51, 49.44s/it]                                                      {'loss': 0.7313, 'learning_rate': 0.0006728515303081781, 'epoch': 0.41}
 41%|████      | 448/1102 [6:14:08<8:58:51, 49.44s/it] 41%|████      | 449/1102 [6:14:58<8:57:24, 49.38s/it]                                                      {'loss': 0.6916, 'learning_rate': 0.0006714706840507121, 'epoch': 0.41}
 41%|████      | 449/1102 [6:14:58<8:57:24, 49.38s/it] 41%|████      | 450/1102 [6:15:47<8:55:07, 49.25s/it]                                                      {'loss': 0.6493, 'learning_rate': 0.0006700883540908185, 'epoch': 0.41}
 41%|████      | 450/1102 [6:15:47<8:55:07, 49.25s/it] 41%|████      | 451/1102 [6:16:36<8:54:10, 49.23s/it]                                                      {'loss': 0.7137, 'learning_rate': 0.0006687045523895292, 'epoch': 0.41}
 41%|████      | 451/1102 [6:16:36<8:54:10, 49.23s/it] 41%|████      | 452/1102 [6:17:25<8:53:29, 49.25s/it]                                                      {'loss': 0.6913, 'learning_rate': 0.0006673192909206108, 'epoch': 0.41}
 41%|████      | 452/1102 [6:17:25<8:53:29, 49.25s/it] 41%|████      | 453/1102 [6:18:14<8:50:58, 49.09s/it]                                                      {'loss': 0.6942, 'learning_rate': 0.0006659325816704611, 'epoch': 0.41}
 41%|████      | 453/1102 [6:18:14<8:50:58, 49.09s/it] 41%|████      | 454/1102 [6:19:03<8:50:44, 49.14s/it]                                                      {'loss': 0.7319, 'learning_rate': 0.000664544436638005, 'epoch': 0.41}
 41%|████      | 454/1102 [6:19:03<8:50:44, 49.14s/it] 41%|████▏     | 455/1102 [6:19:52<8:50:20, 49.18s/it]                                                      {'loss': 0.7212, 'learning_rate': 0.000663154867834591, 'epoch': 0.41}
 41%|████▏     | 455/1102 [6:19:52<8:50:20, 49.18s/it] 41%|████▏     | 456/1102 [6:20:42<8:50:50, 49.30s/it]                                                      {'loss': 0.6917, 'learning_rate': 0.0006617638872838873, 'epoch': 0.41}
 41%|████▏     | 456/1102 [6:20:42<8:50:50, 49.30s/it] 41%|████▏     | 457/1102 [6:21:31<8:50:04, 49.31s/it]                                                      {'loss': 0.7042, 'learning_rate': 0.0006603715070217778, 'epoch': 0.41}
 41%|████▏     | 457/1102 [6:21:31<8:50:04, 49.31s/it] 42%|████▏     | 458/1102 [6:22:20<8:49:05, 49.29s/it]                                                      {'loss': 0.6951, 'learning_rate': 0.0006589777390962574, 'epoch': 0.42}
 42%|████▏     | 458/1102 [6:22:20<8:49:05, 49.29s/it] 42%|████▏     | 459/1102 [6:23:10<8:48:50, 49.35s/it]                                                      {'loss': 0.6999, 'learning_rate': 0.0006575825955673289, 'epoch': 0.42}
 42%|████▏     | 459/1102 [6:23:10<8:48:50, 49.35s/it] 42%|████▏     | 460/1102 [6:23:59<8:47:37, 49.31s/it]                                                      {'loss': 0.6759, 'learning_rate': 0.0006561860885068972, 'epoch': 0.42}
 42%|████▏     | 460/1102 [6:23:59<8:47:37, 49.31s/it] 42%|████▏     | 461/1102 [6:24:48<8:46:48, 49.31s/it]                                                      {'loss': 0.7153, 'learning_rate': 0.0006547882299986657, 'epoch': 0.42}
 42%|████▏     | 461/1102 [6:24:48<8:46:48, 49.31s/it] 42%|████▏     | 462/1102 [6:25:37<8:44:58, 49.22s/it]                                                      {'loss': 0.6997, 'learning_rate': 0.0006533890321380319, 'epoch': 0.42}
 42%|████▏     | 462/1102 [6:25:37<8:44:58, 49.22s/it] 42%|████▏     | 463/1102 [6:26:27<8:44:26, 49.24s/it]                                                      {'loss': 0.6889, 'learning_rate': 0.0006519885070319826, 'epoch': 0.42}
 42%|████▏     | 463/1102 [6:26:27<8:44:26, 49.24s/it] 42%|████▏     | 464/1102 [6:27:16<8:44:14, 49.30s/it]                                                      {'loss': 0.7264, 'learning_rate': 0.0006505866667989884, 'epoch': 0.42}
 42%|████▏     | 464/1102 [6:27:16<8:44:14, 49.30s/it] 42%|████▏     | 465/1102 [6:28:06<8:43:56, 49.35s/it]                                                      {'loss': 0.6789, 'learning_rate': 0.0006491835235688998, 'epoch': 0.42}
 42%|████▏     | 465/1102 [6:28:06<8:43:56, 49.35s/it] 42%|████▏     | 466/1102 [6:28:55<8:42:28, 49.29s/it]                                                      {'loss': 0.7162, 'learning_rate': 0.0006477790894828422, 'epoch': 0.42}
 42%|████▏     | 466/1102 [6:28:55<8:42:28, 49.29s/it] 42%|████▏     | 467/1102 [6:29:44<8:41:12, 49.25s/it]                                                      {'loss': 0.7071, 'learning_rate': 0.0006463733766931095, 'epoch': 0.42}
 42%|████▏     | 467/1102 [6:29:44<8:41:12, 49.25s/it] 42%|████▏     | 468/1102 [6:30:33<8:40:40, 49.28s/it]                                                      {'loss': 0.6989, 'learning_rate': 0.0006449663973630613, 'epoch': 0.42}
 42%|████▏     | 468/1102 [6:30:33<8:40:40, 49.28s/it] 43%|████▎     | 469/1102 [6:31:23<8:39:34, 49.25s/it]                                                      {'loss': 0.6893, 'learning_rate': 0.0006435581636670154, 'epoch': 0.43}
 43%|████▎     | 469/1102 [6:31:23<8:39:34, 49.25s/it] 43%|████▎     | 470/1102 [6:32:12<8:39:09, 49.29s/it]                                                      {'loss': 0.6551, 'learning_rate': 0.0006421486877901436, 'epoch': 0.43}
 43%|████▎     | 470/1102 [6:32:12<8:39:09, 49.29s/it] 43%|████▎     | 471/1102 [6:33:01<8:36:48, 49.14s/it]                                                      {'loss': 0.7085, 'learning_rate': 0.000640737981928366, 'epoch': 0.43}
 43%|████▎     | 471/1102 [6:33:01<8:36:48, 49.14s/it] 43%|████▎     | 472/1102 [6:33:50<8:37:31, 49.29s/it]                                                      {'loss': 0.6506, 'learning_rate': 0.000639326058288246, 'epoch': 0.43}
 43%|████▎     | 472/1102 [6:33:50<8:37:31, 49.29s/it] 43%|████▎     | 473/1102 [6:34:40<8:36:47, 49.30s/it]                                                      {'loss': 0.6626, 'learning_rate': 0.0006379129290868837, 'epoch': 0.43}
 43%|████▎     | 473/1102 [6:34:40<8:36:47, 49.30s/it] 43%|████▎     | 474/1102 [6:35:29<8:35:29, 49.25s/it]                                                      {'loss': 0.6943, 'learning_rate': 0.0006364986065518106, 'epoch': 0.43}
 43%|████▎     | 474/1102 [6:35:29<8:35:29, 49.25s/it] 43%|████▎     | 475/1102 [6:36:18<8:34:58, 49.28s/it]                                                      {'loss': 0.6789, 'learning_rate': 0.0006350831029208843, 'epoch': 0.43}
 43%|████▎     | 475/1102 [6:36:18<8:34:58, 49.28s/it] 43%|████▎     | 476/1102 [6:37:06<8:30:50, 48.96s/it]                                                      {'loss': 0.7154, 'learning_rate': 0.0006336664304421817, 'epoch': 0.43}
 43%|████▎     | 476/1102 [6:37:06<8:30:50, 48.96s/it] 43%|████▎     | 477/1102 [6:37:55<8:28:43, 48.84s/it]                                                      {'loss': 0.6563, 'learning_rate': 0.0006322486013738941, 'epoch': 0.43}
 43%|████▎     | 477/1102 [6:37:55<8:28:43, 48.84s/it] 43%|████▎     | 478/1102 [6:38:44<8:28:28, 48.89s/it]                                                      {'loss': 0.6805, 'learning_rate': 0.0006308296279842204, 'epoch': 0.43}
 43%|████▎     | 478/1102 [6:38:44<8:28:28, 48.89s/it] 43%|████▎     | 479/1102 [6:39:33<8:28:49, 49.00s/it]                                                      {'loss': 0.7012, 'learning_rate': 0.0006294095225512603, 'epoch': 0.43}
 43%|████▎     | 479/1102 [6:39:33<8:28:49, 49.00s/it] 44%|████▎     | 480/1102 [6:40:23<8:29:12, 49.12s/it]                                                      {'loss': 0.7057, 'learning_rate': 0.0006279882973629101, 'epoch': 0.44}
 44%|████▎     | 480/1102 [6:40:23<8:29:12, 49.12s/it] 44%|████▎     | 481/1102 [6:41:12<8:28:05, 49.09s/it]                                                      {'loss': 0.6707, 'learning_rate': 0.0006265659647167542, 'epoch': 0.44}
 44%|████▎     | 481/1102 [6:41:12<8:28:05, 49.09s/it] 44%|████▎     | 482/1102 [6:42:01<8:27:50, 49.15s/it]                                                      {'loss': 0.6843, 'learning_rate': 0.00062514253691996, 'epoch': 0.44}
 44%|████▎     | 482/1102 [6:42:01<8:27:50, 49.15s/it] 44%|████▍     | 483/1102 [6:42:50<8:28:00, 49.24s/it]                                                      {'loss': 0.6759, 'learning_rate': 0.0006237180262891708, 'epoch': 0.44}
 44%|████▍     | 483/1102 [6:42:50<8:28:00, 49.24s/it] 44%|████▍     | 484/1102 [6:43:39<8:26:43, 49.20s/it]                                                      {'loss': 0.6377, 'learning_rate': 0.0006222924451504, 'epoch': 0.44}
 44%|████▍     | 484/1102 [6:43:39<8:26:43, 49.20s/it] 44%|████▍     | 485/1102 [6:44:45<9:16:49, 54.15s/it]                                                      {'loss': 0.7149, 'learning_rate': 0.0006208658058389231, 'epoch': 0.44}
 44%|████▍     | 485/1102 [6:44:45<9:16:49, 54.15s/it] 44%|████▍     | 486/1102 [6:45:35<9:01:48, 52.77s/it]                                                      {'loss': 0.7053, 'learning_rate': 0.0006194381206991723, 'epoch': 0.44}
 44%|████▍     | 486/1102 [6:45:35<9:01:48, 52.77s/it] 44%|████▍     | 487/1102 [6:46:24<8:50:45, 51.78s/it]                                                      {'loss': 0.7096, 'learning_rate': 0.000618009402084629, 'epoch': 0.44}
 44%|████▍     | 487/1102 [6:46:24<8:50:45, 51.78s/it] 44%|████▍     | 488/1102 [6:47:14<8:44:38, 51.27s/it]                                                      {'loss': 0.694, 'learning_rate': 0.0006165796623577171, 'epoch': 0.44}
 44%|████▍     | 488/1102 [6:47:14<8:44:38, 51.27s/it] 44%|████▍     | 489/1102 [6:48:32<10:05:06, 59.23s/it]                                                       {'loss': 0.7125, 'learning_rate': 0.000615148913889696, 'epoch': 0.44}
 44%|████▍     | 489/1102 [6:48:32<10:05:06, 59.23s/it] 44%|████▍     | 490/1102 [6:52:13<18:20:22, 107.88s/it]                                                        {'loss': 0.6784, 'learning_rate': 0.0006137171690605533, 'epoch': 0.44}
 44%|████▍     | 490/1102 [6:52:13<18:20:22, 107.88s/it] 45%|████▍     | 491/1102 [6:53:03<15:19:49, 90.33s/it]                                                        {'loss': 0.6602, 'learning_rate': 0.0006122844402588982, 'epoch': 0.45}
 45%|████▍     | 491/1102 [6:53:03<15:19:49, 90.33s/it] 45%|████▍     | 492/1102 [6:53:52<13:13:45, 78.07s/it]                                                       {'loss': 0.671, 'learning_rate': 0.0006108507398818539, 'epoch': 0.45}
 45%|████▍     | 492/1102 [6:53:52<13:13:45, 78.07s/it] 45%|████▍     | 493/1102 [6:54:41<11:44:11, 69.38s/it]                                                       {'loss': 0.7085, 'learning_rate': 0.0006094160803349508, 'epoch': 0.45}
 45%|████▍     | 493/1102 [6:54:41<11:44:11, 69.38s/it] 45%|████▍     | 494/1102 [6:55:34<10:51:53, 64.33s/it]                                                       {'loss': 0.6809, 'learning_rate': 0.0006079804740320181, 'epoch': 0.45}
 45%|████▍     | 494/1102 [6:55:35<10:51:53, 64.33s/it] 45%|████▍     | 495/1102 [7:02:02<27:12:51, 161.40s/it]                                                        {'loss': 0.6161, 'learning_rate': 0.0006065439333950776, 'epoch': 0.45}
 45%|████▍     | 495/1102 [7:02:02<27:12:51, 161.40s/it] 45%|████▌     | 496/1102 [7:03:40<23:59:40, 142.54s/it]                                                        {'loss': 0.8119, 'learning_rate': 0.0006051064708542356, 'epoch': 0.45}
 45%|████▌     | 496/1102 [7:03:40<23:59:40, 142.54s/it] 45%|████▌     | 497/1102 [7:04:29<19:13:14, 114.37s/it]                                                        {'loss': 0.6769, 'learning_rate': 0.0006036680988475755, 'epoch': 0.45}
 45%|████▌     | 497/1102 [7:04:29<19:13:14, 114.37s/it] 45%|████▌     | 498/1102 [7:05:18<15:54:09, 94.78s/it]                                                        {'loss': 0.7003, 'learning_rate': 0.0006022288298210501, 'epoch': 0.45}
 45%|████▌     | 498/1102 [7:05:18<15:54:09, 94.78s/it] 45%|████▌     | 499/1102 [7:06:07<13:34:37, 81.06s/it]                                                       {'loss': 0.6899, 'learning_rate': 0.000600788676228374, 'epoch': 0.45}
 45%|████▌     | 499/1102 [7:06:07<13:34:37, 81.06s/it] 45%|████▌     | 500/1102 [7:06:56<11:56:40, 71.43s/it]                                                       {'loss': 0.7009, 'learning_rate': 0.0005993476505309155, 'epoch': 0.45}
 45%|████▌     | 500/1102 [7:06:56<11:56:40, 71.43s/it] 45%|████▌     | 501/1102 [7:07:45<10:48:23, 64.73s/it]                                                       {'loss': 0.6745, 'learning_rate': 0.0005979057651975892, 'epoch': 0.45}
 45%|████▌     | 501/1102 [7:07:45<10:48:23, 64.73s/it] 46%|████▌     | 502/1102 [7:08:34<9:58:53, 59.89s/it]                                                       {'loss': 0.7315, 'learning_rate': 0.0005964630327047484, 'epoch': 0.46}
 46%|████▌     | 502/1102 [7:08:34<9:58:53, 59.89s/it] 46%|████▌     | 503/1102 [7:09:23<9:25:28, 56.64s/it]                                                      {'loss': 0.6701, 'learning_rate': 0.0005950194655360761, 'epoch': 0.46}
 46%|████▌     | 503/1102 [7:09:23<9:25:28, 56.64s/it] 46%|████▌     | 504/1102 [7:10:12<9:01:07, 54.29s/it]                                                      {'loss': 0.7156, 'learning_rate': 0.0005935750761824776, 'epoch': 0.46}
 46%|████▌     | 504/1102 [7:10:12<9:01:07, 54.29s/it] 46%|████▌     | 505/1102 [7:11:01<8:46:01, 52.87s/it]                                                      {'loss': 0.6618, 'learning_rate': 0.000592129877141973, 'epoch': 0.46}
 46%|████▌     | 505/1102 [7:11:01<8:46:01, 52.87s/it] 46%|████▌     | 506/1102 [7:11:51<8:34:41, 51.81s/it]                                                      {'loss': 0.6777, 'learning_rate': 0.0005906838809195879, 'epoch': 0.46}
 46%|████▌     | 506/1102 [7:11:51<8:34:41, 51.81s/it] 46%|████▌     | 507/1102 [7:12:40<8:25:42, 51.00s/it]                                                      {'loss': 0.6699, 'learning_rate': 0.000589237100027246, 'epoch': 0.46}
 46%|████▌     | 507/1102 [7:12:40<8:25:42, 51.00s/it] 46%|████▌     | 508/1102 [7:13:29<8:18:59, 50.40s/it]                                                      {'loss': 0.6638, 'learning_rate': 0.0005877895469836604, 'epoch': 0.46}
 46%|████▌     | 508/1102 [7:13:29<8:18:59, 50.40s/it] 46%|████▌     | 509/1102 [7:14:18<8:14:41, 50.05s/it]                                                      {'loss': 0.621, 'learning_rate': 0.0005863412343142258, 'epoch': 0.46}
 46%|████▌     | 509/1102 [7:14:18<8:14:41, 50.05s/it] 46%|████▋     | 510/1102 [7:15:07<8:11:05, 49.77s/it]                                                      {'loss': 0.6821, 'learning_rate': 0.0005848921745509094, 'epoch': 0.46}
 46%|████▋     | 510/1102 [7:15:07<8:11:05, 49.77s/it] 46%|████▋     | 511/1102 [7:15:56<8:08:17, 49.57s/it]                                                      {'loss': 0.677, 'learning_rate': 0.0005834423802321431, 'epoch': 0.46}
 46%|████▋     | 511/1102 [7:15:56<8:08:17, 49.57s/it] 46%|████▋     | 512/1102 [7:16:45<8:05:38, 49.39s/it]                                                      {'loss': 0.7177, 'learning_rate': 0.0005819918639027149, 'epoch': 0.46}
 46%|████▋     | 512/1102 [7:16:45<8:05:38, 49.39s/it] 47%|████▋     | 513/1102 [7:17:35<8:05:11, 49.42s/it]                                                      {'loss': 0.6819, 'learning_rate': 0.0005805406381136597, 'epoch': 0.47}
 47%|████▋     | 513/1102 [7:17:35<8:05:11, 49.42s/it] 47%|████▋     | 514/1102 [7:18:24<8:04:19, 49.42s/it]                                                      {'loss': 0.714, 'learning_rate': 0.000579088715422152, 'epoch': 0.47}
 47%|████▋     | 514/1102 [7:18:24<8:04:19, 49.42s/it] 47%|████▋     | 515/1102 [7:19:13<8:02:43, 49.34s/it]                                                      {'loss': 0.7494, 'learning_rate': 0.0005776361083913959, 'epoch': 0.47}
 47%|████▋     | 515/1102 [7:19:13<8:02:43, 49.34s/it] 47%|████▋     | 516/1102 [7:20:03<8:02:18, 49.38s/it]                                                      {'loss': 0.6474, 'learning_rate': 0.0005761828295905168, 'epoch': 0.47}
 47%|████▋     | 516/1102 [7:20:03<8:02:18, 49.38s/it] 47%|████▋     | 517/1102 [7:20:52<8:02:38, 49.50s/it]                                                      {'loss': 0.676, 'learning_rate': 0.0005747288915944533, 'epoch': 0.47}
 47%|████▋     | 517/1102 [7:20:52<8:02:38, 49.50s/it] 47%|████▋     | 518/1102 [7:21:42<8:01:02, 49.42s/it]                                                      {'loss': 0.6902, 'learning_rate': 0.0005732743069838478, 'epoch': 0.47}
 47%|████▋     | 518/1102 [7:21:42<8:01:02, 49.42s/it] 47%|████▋     | 519/1102 [7:22:31<7:59:49, 49.38s/it]                                                      {'loss': 0.6555, 'learning_rate': 0.0005718190883449373, 'epoch': 0.47}
 47%|████▋     | 519/1102 [7:22:31<7:59:49, 49.38s/it] 47%|████▋     | 520/1102 [7:23:20<7:59:21, 49.42s/it]                                                      {'loss': 0.7318, 'learning_rate': 0.0005703632482694453, 'epoch': 0.47}
 47%|████▋     | 520/1102 [7:23:20<7:59:21, 49.42s/it] 47%|████▋     | 521/1102 [7:24:09<7:57:08, 49.27s/it]                                                      {'loss': 0.6906, 'learning_rate': 0.0005689067993544726, 'epoch': 0.47}
 47%|████▋     | 521/1102 [7:24:09<7:57:08, 49.27s/it] 47%|████▋     | 522/1102 [7:24:59<7:57:14, 49.37s/it]                                                      {'loss': 0.6947, 'learning_rate': 0.0005674497542023874, 'epoch': 0.47}
 47%|████▋     | 522/1102 [7:24:59<7:57:14, 49.37s/it] 47%|████▋     | 523/1102 [7:25:48<7:55:44, 49.30s/it]                                                      {'loss': 0.6702, 'learning_rate': 0.0005659921254207182, 'epoch': 0.47}
 47%|████▋     | 523/1102 [7:25:48<7:55:44, 49.30s/it] 48%|████▊     | 524/1102 [7:26:37<7:53:36, 49.16s/it]                                                      {'loss': 0.7318, 'learning_rate': 0.0005645339256220426, 'epoch': 0.48}
 48%|████▊     | 524/1102 [7:26:37<7:53:36, 49.16s/it] 48%|████▊     | 525/1102 [7:27:26<7:52:30, 49.13s/it]                                                      {'loss': 0.717, 'learning_rate': 0.0005630751674238796, 'epoch': 0.48}
 48%|████▊     | 525/1102 [7:27:26<7:52:30, 49.13s/it] 48%|████▊     | 526/1102 [7:28:15<7:50:18, 48.99s/it]                                                      {'loss': 0.7265, 'learning_rate': 0.0005616158634485792, 'epoch': 0.48}
 48%|████▊     | 526/1102 [7:28:15<7:50:18, 48.99s/it] 48%|████▊     | 527/1102 [7:29:04<7:49:42, 49.01s/it]                                                      {'loss': 0.65, 'learning_rate': 0.0005601560263232152, 'epoch': 0.48}
 48%|████▊     | 527/1102 [7:29:04<7:49:42, 49.01s/it] 48%|████▊     | 528/1102 [7:29:53<7:50:27, 49.18s/it]                                                      {'loss': 0.6664, 'learning_rate': 0.0005586956686794734, 'epoch': 0.48}
 48%|████▊     | 528/1102 [7:29:53<7:50:27, 49.18s/it] 48%|████▊     | 529/1102 [7:30:42<7:49:28, 49.16s/it]                                                      {'loss': 0.7032, 'learning_rate': 0.0005572348031535441, 'epoch': 0.48}
 48%|████▊     | 529/1102 [7:30:42<7:49:28, 49.16s/it] 48%|████▊     | 530/1102 [7:31:31<7:48:18, 49.12s/it]                                                      {'loss': 0.6841, 'learning_rate': 0.0005557734423860122, 'epoch': 0.48}
 48%|████▊     | 530/1102 [7:31:31<7:48:18, 49.12s/it] 48%|████▊     | 531/1102 [7:32:21<7:48:41, 49.25s/it]                                                      {'loss': 0.6881, 'learning_rate': 0.0005543115990217477, 'epoch': 0.48}
 48%|████▊     | 531/1102 [7:32:21<7:48:41, 49.25s/it] 48%|████▊     | 532/1102 [7:33:10<7:47:40, 49.23s/it]                                                      {'loss': 0.7184, 'learning_rate': 0.0005528492857097965, 'epoch': 0.48}
 48%|████▊     | 532/1102 [7:33:10<7:47:40, 49.23s/it] 48%|████▊     | 533/1102 [7:33:59<7:46:33, 49.20s/it]                                                      {'loss': 0.6821, 'learning_rate': 0.0005513865151032709, 'epoch': 0.48}
 48%|████▊     | 533/1102 [7:33:59<7:46:33, 49.20s/it] 48%|████▊     | 534/1102 [7:34:49<7:45:50, 49.21s/it]                                                      {'loss': 0.6574, 'learning_rate': 0.0005499232998592399, 'epoch': 0.48}
 48%|████▊     | 534/1102 [7:34:49<7:45:50, 49.21s/it] 49%|████▊     | 535/1102 [7:35:38<7:45:27, 49.26s/it]                                                      {'loss': 0.6787, 'learning_rate': 0.0005484596526386197, 'epoch': 0.49}
 49%|████▊     | 535/1102 [7:35:38<7:45:27, 49.26s/it] 49%|████▊     | 536/1102 [7:36:27<7:43:43, 49.16s/it]                                                      {'loss': 0.7326, 'learning_rate': 0.0005469955861060653, 'epoch': 0.49}
 49%|████▊     | 536/1102 [7:36:27<7:43:43, 49.16s/it] 49%|████▊     | 537/1102 [7:37:16<7:43:23, 49.21s/it]                                                      {'loss': 0.6595, 'learning_rate': 0.0005455311129298585, 'epoch': 0.49}
 49%|████▊     | 537/1102 [7:37:16<7:43:23, 49.21s/it] 49%|████▉     | 538/1102 [7:38:05<7:42:06, 49.16s/it]                                                      {'loss': 0.7178, 'learning_rate': 0.000544066245781801, 'epoch': 0.49}
 49%|████▉     | 538/1102 [7:38:05<7:42:06, 49.16s/it] 49%|████▉     | 539/1102 [7:38:54<7:41:31, 49.18s/it]                                                      {'loss': 0.6633, 'learning_rate': 0.0005426009973371025, 'epoch': 0.49}
 49%|████▉     | 539/1102 [7:38:54<7:41:31, 49.18s/it] 49%|████▉     | 540/1102 [7:39:44<7:42:15, 49.35s/it]                                                      {'loss': 0.6822, 'learning_rate': 0.0005411353802742725, 'epoch': 0.49}
 49%|████▉     | 540/1102 [7:39:44<7:42:15, 49.35s/it] 49%|████▉     | 541/1102 [7:40:34<7:42:55, 49.51s/it]                                                      {'loss': 0.598, 'learning_rate': 0.0005396694072750099, 'epoch': 0.49}
 49%|████▉     | 541/1102 [7:40:34<7:42:55, 49.51s/it] 49%|████▉     | 542/1102 [7:41:22<7:38:12, 49.09s/it]                                                      {'loss': 0.6593, 'learning_rate': 0.0005382030910240935, 'epoch': 0.49}
 49%|████▉     | 542/1102 [7:41:22<7:38:12, 49.09s/it] 49%|████▉     | 543/1102 [7:42:11<7:37:27, 49.10s/it]                                                      {'loss': 0.6801, 'learning_rate': 0.0005367364442092723, 'epoch': 0.49}
 49%|████▉     | 543/1102 [7:42:11<7:37:27, 49.10s/it] 49%|████▉     | 544/1102 [7:43:01<7:37:42, 49.22s/it]                                                      {'loss': 0.6604, 'learning_rate': 0.0005352694795211554, 'epoch': 0.49}
 49%|████▉     | 544/1102 [7:43:01<7:37:42, 49.22s/it] 49%|████▉     | 545/1102 [7:43:50<7:36:58, 49.23s/it]                                                      {'loss': 0.6847, 'learning_rate': 0.0005338022096531028, 'epoch': 0.49}
 49%|████▉     | 545/1102 [7:43:50<7:36:58, 49.23s/it] 50%|████▉     | 546/1102 [7:44:39<7:35:02, 49.10s/it]                                                      {'loss': 0.7314, 'learning_rate': 0.0005323346473011143, 'epoch': 0.5}
 50%|████▉     | 546/1102 [7:44:39<7:35:02, 49.10s/it] 50%|████▉     | 547/1102 [7:45:28<7:33:53, 49.07s/it]                                                      {'loss': 0.6444, 'learning_rate': 0.0005308668051637212, 'epoch': 0.5}
 50%|████▉     | 547/1102 [7:45:28<7:33:53, 49.07s/it] 50%|████▉     | 548/1102 [7:46:18<7:34:53, 49.27s/it]                                                      {'loss': 0.6505, 'learning_rate': 0.000529398695941876, 'epoch': 0.5}
 50%|████▉     | 548/1102 [7:46:18<7:34:53, 49.27s/it] 50%|████▉     | 549/1102 [7:47:07<7:33:15, 49.18s/it]                                                      {'loss': 0.6292, 'learning_rate': 0.0005279303323388413, 'epoch': 0.5}
 50%|████▉     | 549/1102 [7:47:07<7:33:15, 49.18s/it] 50%|████▉     | 550/1102 [7:47:55<7:31:14, 49.05s/it]                                                      {'loss': 0.6803, 'learning_rate': 0.0005264617270600815, 'epoch': 0.5}
 50%|████▉     | 550/1102 [7:47:55<7:31:14, 49.05s/it] 50%|█████     | 551/1102 [7:48:43<7:26:06, 48.58s/it]                                                      {'loss': 0.6862, 'learning_rate': 0.0005249928928131524, 'epoch': 0.5}
 50%|█████     | 551/1102 [7:48:43<7:26:06, 48.58s/it] 50%|█████     | 552/1102 [7:49:32<7:26:21, 48.69s/it]                                                      {'loss': 0.6807, 'learning_rate': 0.0005235238423075899, 'epoch': 0.5}
 50%|█████     | 552/1102 [7:49:32<7:26:21, 48.69s/it] 50%|█████     | 553/1102 [7:50:21<7:27:08, 48.87s/it]                                                      {'loss': 0.6743, 'learning_rate': 0.0005220545882548024, 'epoch': 0.5}
 50%|█████     | 553/1102 [7:50:21<7:27:08, 48.87s/it] 50%|█████     | 554/1102 [7:51:10<7:27:11, 48.96s/it]                                                      {'loss': 0.6943, 'learning_rate': 0.000520585143367959, 'epoch': 0.5}
 50%|█████     | 554/1102 [7:51:10<7:27:11, 48.96s/it] 50%|█████     | 555/1102 [7:51:59<7:27:01, 49.03s/it]                                                      {'loss': 0.6642, 'learning_rate': 0.0005191155203618796, 'epoch': 0.5}
 50%|█████     | 555/1102 [7:51:59<7:27:01, 49.03s/it] 50%|█████     | 556/1102 [7:52:48<7:26:03, 49.02s/it]                                                      {'loss': 0.7138, 'learning_rate': 0.0005176457319529263, 'epoch': 0.5}
 50%|█████     | 556/1102 [7:52:48<7:26:03, 49.02s/it] 51%|█████     | 557/1102 [7:53:38<7:26:23, 49.14s/it]                                                      {'loss': 0.6471, 'learning_rate': 0.0005161757908588916, 'epoch': 0.51}
 51%|█████     | 557/1102 [7:53:38<7:26:23, 49.14s/it] 51%|█████     | 558/1102 [7:54:27<7:26:21, 49.23s/it]                                                      {'loss': 0.7179, 'learning_rate': 0.0005147057097988898, 'epoch': 0.51}
 51%|█████     | 558/1102 [7:54:27<7:26:21, 49.23s/it] 51%|█████     | 559/1102 [7:55:16<7:25:22, 49.21s/it]                                                      {'loss': 0.6602, 'learning_rate': 0.0005132355014932455, 'epoch': 0.51}
 51%|█████     | 559/1102 [7:55:16<7:25:22, 49.21s/it] 51%|█████     | 560/1102 [7:56:06<7:25:30, 49.32s/it]                                                      {'loss': 0.6826, 'learning_rate': 0.0005117651786633849, 'epoch': 0.51}
 51%|█████     | 560/1102 [7:56:06<7:25:30, 49.32s/it] 51%|█████     | 561/1102 [7:56:55<7:23:07, 49.14s/it]                                                      {'loss': 0.6993, 'learning_rate': 0.0005102947540317253, 'epoch': 0.51}
 51%|█████     | 561/1102 [7:56:55<7:23:07, 49.14s/it] 51%|█████     | 562/1102 [7:57:44<7:21:38, 49.07s/it]                                                      {'loss': 0.6848, 'learning_rate': 0.0005088242403215644, 'epoch': 0.51}
 51%|█████     | 562/1102 [7:57:44<7:21:38, 49.07s/it] 51%|█████     | 563/1102 [7:58:33<7:21:29, 49.14s/it]                                                      {'loss': 0.6618, 'learning_rate': 0.0005073536502569708, 'epoch': 0.51}
 51%|█████     | 563/1102 [7:58:33<7:21:29, 49.14s/it] 51%|█████     | 564/1102 [7:59:22<7:20:11, 49.09s/it]                                                      {'loss': 0.6623, 'learning_rate': 0.0005058829965626741, 'epoch': 0.51}
 51%|█████     | 564/1102 [7:59:22<7:20:11, 49.09s/it] 51%|█████▏    | 565/1102 [8:00:11<7:19:58, 49.16s/it]                                                      {'loss': 0.6637, 'learning_rate': 0.0005044122919639541, 'epoch': 0.51}
 51%|█████▏    | 565/1102 [8:00:11<7:19:58, 49.16s/it] 51%|█████▏    | 566/1102 [8:01:00<7:17:58, 49.03s/it]                                                      {'loss': 0.6924, 'learning_rate': 0.0005029415491865311, 'epoch': 0.51}
 51%|█████▏    | 566/1102 [8:01:00<7:17:58, 49.03s/it] 51%|█████▏    | 567/1102 [8:01:49<7:18:33, 49.18s/it]                                                      {'loss': 0.7143, 'learning_rate': 0.0005014707809564561, 'epoch': 0.51}
 51%|█████▏    | 567/1102 [8:01:49<7:18:33, 49.18s/it] 52%|█████▏    | 568/1102 [8:02:39<7:18:29, 49.27s/it]                                                      {'loss': 0.6613, 'learning_rate': 0.0005, 'epoch': 0.52}
 52%|█████▏    | 568/1102 [8:02:39<7:18:29, 49.27s/it] 52%|█████▏    | 569/1102 [8:03:28<7:18:03, 49.31s/it]                                                      {'loss': 0.6884, 'learning_rate': 0.000498529219043544, 'epoch': 0.52}
 52%|█████▏    | 569/1102 [8:03:28<7:18:03, 49.31s/it] 52%|█████▏    | 570/1102 [8:04:17<7:15:55, 49.16s/it]                                                      {'loss': 0.673, 'learning_rate': 0.000497058450813469, 'epoch': 0.52}
 52%|█████▏    | 570/1102 [8:04:17<7:15:55, 49.16s/it] 52%|█████▏    | 571/1102 [8:05:06<7:14:26, 49.09s/it]                                                      {'loss': 0.6482, 'learning_rate': 0.0004955877080360462, 'epoch': 0.52}
 52%|█████▏    | 571/1102 [8:05:06<7:14:26, 49.09s/it] 52%|█████▏    | 572/1102 [8:05:55<7:14:23, 49.18s/it]                                                      {'loss': 0.6868, 'learning_rate': 0.0004941170034373259, 'epoch': 0.52}
 52%|█████▏    | 572/1102 [8:05:55<7:14:23, 49.18s/it] 52%|█████▏    | 573/1102 [8:06:45<7:13:45, 49.20s/it]                                                      {'loss': 0.6411, 'learning_rate': 0.0004926463497430293, 'epoch': 0.52}
 52%|█████▏    | 573/1102 [8:06:45<7:13:45, 49.20s/it] 52%|█████▏    | 574/1102 [8:07:34<7:13:02, 49.21s/it]                                                      {'loss': 0.6642, 'learning_rate': 0.0004911757596784357, 'epoch': 0.52}
 52%|█████▏    | 574/1102 [8:07:34<7:13:02, 49.21s/it] 52%|█████▏    | 575/1102 [8:08:23<7:12:20, 49.22s/it]                                                      {'loss': 0.6598, 'learning_rate': 0.0004897052459682748, 'epoch': 0.52}
 52%|█████▏    | 575/1102 [8:08:23<7:12:20, 49.22s/it] 52%|█████▏    | 576/1102 [8:09:12<7:10:58, 49.16s/it]                                                      {'loss': 0.7146, 'learning_rate': 0.0004882348213366152, 'epoch': 0.52}
 52%|█████▏    | 576/1102 [8:09:12<7:10:58, 49.16s/it] 52%|█████▏    | 577/1102 [8:10:01<7:10:07, 49.16s/it]                                                      {'loss': 0.6819, 'learning_rate': 0.00048676449850675475, 'epoch': 0.52}
 52%|█████▏    | 577/1102 [8:10:01<7:10:07, 49.16s/it] 52%|█████▏    | 578/1102 [8:10:51<7:09:24, 49.17s/it]                                                      {'loss': 0.7004, 'learning_rate': 0.0004852942902011103, 'epoch': 0.52}
 52%|█████▏    | 578/1102 [8:10:51<7:09:24, 49.17s/it] 53%|█████▎    | 579/1102 [8:11:39<7:07:25, 49.04s/it]                                                      {'loss': 0.6716, 'learning_rate': 0.0004838242091411084, 'epoch': 0.53}
 53%|█████▎    | 579/1102 [8:11:39<7:07:25, 49.04s/it] 53%|█████▎    | 580/1102 [8:12:29<7:07:16, 49.11s/it]                                                      {'loss': 0.6735, 'learning_rate': 0.0004823542680470738, 'epoch': 0.53}
 53%|█████▎    | 580/1102 [8:12:29<7:07:16, 49.11s/it] 53%|█████▎    | 581/1102 [8:13:18<7:06:18, 49.09s/it]                                                      {'loss': 0.6515, 'learning_rate': 0.0004808844796381205, 'epoch': 0.53}
 53%|█████▎    | 581/1102 [8:13:18<7:06:18, 49.09s/it] 53%|█████▎    | 582/1102 [8:14:07<7:05:40, 49.12s/it]                                                      {'loss': 0.6839, 'learning_rate': 0.0004794148566320412, 'epoch': 0.53}
 53%|█████▎    | 582/1102 [8:14:07<7:05:40, 49.12s/it] 53%|█████▎    | 583/1102 [8:14:56<7:05:48, 49.23s/it]                                                      {'loss': 0.6674, 'learning_rate': 0.00047794541174519774, 'epoch': 0.53}
 53%|█████▎    | 583/1102 [8:14:56<7:05:48, 49.23s/it] 53%|█████▎    | 584/1102 [8:15:46<7:05:16, 49.26s/it]                                                      {'loss': 0.6653, 'learning_rate': 0.00047647615769241006, 'epoch': 0.53}
 53%|█████▎    | 584/1102 [8:15:46<7:05:16, 49.26s/it] 53%|█████▎    | 585/1102 [8:16:35<7:04:34, 49.27s/it]                                                      {'loss': 0.7081, 'learning_rate': 0.00047500710718684783, 'epoch': 0.53}
 53%|█████▎    | 585/1102 [8:16:35<7:04:34, 49.27s/it] 53%|█████▎    | 586/1102 [8:17:24<7:03:48, 49.28s/it]                                                      {'loss': 0.6453, 'learning_rate': 0.0004735382729399184, 'epoch': 0.53}
 53%|█████▎    | 586/1102 [8:17:24<7:03:48, 49.28s/it] 53%|█████▎    | 587/1102 [8:18:14<7:02:55, 49.27s/it]                                                      {'loss': 0.677, 'learning_rate': 0.0004720696676611588, 'epoch': 0.53}
 53%|█████▎    | 587/1102 [8:18:14<7:02:55, 49.27s/it] 53%|█████▎    | 588/1102 [8:19:02<7:01:14, 49.17s/it]                                                      {'loss': 0.6659, 'learning_rate': 0.0004706013040581242, 'epoch': 0.53}
 53%|█████▎    | 588/1102 [8:19:02<7:01:14, 49.17s/it] 53%|█████▎    | 589/1102 [8:19:52<7:00:18, 49.16s/it]                                                      {'loss': 0.7329, 'learning_rate': 0.0004691331948362789, 'epoch': 0.53}
 53%|█████▎    | 589/1102 [8:19:52<7:00:18, 49.16s/it] 54%|█████▎    | 590/1102 [8:20:41<6:59:15, 49.13s/it]                                                      {'loss': 0.7041, 'learning_rate': 0.00046766535269888575, 'epoch': 0.54}
 54%|█████▎    | 590/1102 [8:20:41<6:59:15, 49.13s/it] 54%|█████▎    | 591/1102 [8:21:30<6:58:36, 49.15s/it]                                                      {'loss': 0.6981, 'learning_rate': 0.00046619779034689737, 'epoch': 0.54}
 54%|█████▎    | 591/1102 [8:21:30<6:58:36, 49.15s/it] 54%|█████▎    | 592/1102 [8:22:19<6:57:38, 49.13s/it]                                                      {'loss': 0.7069, 'learning_rate': 0.00046473052047884444, 'epoch': 0.54}
 54%|█████▎    | 592/1102 [8:22:19<6:57:38, 49.13s/it] 54%|█████▍    | 593/1102 [8:23:08<6:56:02, 49.04s/it]                                                      {'loss': 0.6747, 'learning_rate': 0.0004632635557907277, 'epoch': 0.54}
 54%|█████▍    | 593/1102 [8:23:08<6:56:02, 49.04s/it] 54%|█████▍    | 594/1102 [8:23:56<6:54:08, 48.92s/it]                                                      {'loss': 0.6711, 'learning_rate': 0.00046179690897590653, 'epoch': 0.54}
 54%|█████▍    | 594/1102 [8:23:56<6:54:08, 48.92s/it] 54%|█████▍    | 595/1102 [8:24:45<6:53:07, 48.89s/it]                                                      {'loss': 0.7462, 'learning_rate': 0.00046033059272499024, 'epoch': 0.54}
 54%|█████▍    | 595/1102 [8:24:45<6:53:07, 48.89s/it] 54%|█████▍    | 596/1102 [8:25:34<6:52:46, 48.95s/it]                                                      {'loss': 0.6347, 'learning_rate': 0.00045886461972572773, 'epoch': 0.54}
 54%|█████▍    | 596/1102 [8:25:34<6:52:46, 48.95s/it] 54%|█████▍    | 597/1102 [8:26:23<6:51:58, 48.95s/it]                                                      {'loss': 0.6926, 'learning_rate': 0.00045739900266289756, 'epoch': 0.54}
 54%|█████▍    | 597/1102 [8:26:23<6:51:58, 48.95s/it] 54%|█████▍    | 598/1102 [8:27:12<6:51:22, 48.97s/it]                                                      {'loss': 0.7189, 'learning_rate': 0.0004559337542181993, 'epoch': 0.54}
 54%|█████▍    | 598/1102 [8:27:12<6:51:22, 48.97s/it] 54%|█████▍    | 599/1102 [8:28:02<6:51:47, 49.12s/it]                                                      {'loss': 0.6964, 'learning_rate': 0.0004544688870701415, 'epoch': 0.54}
 54%|█████▍    | 599/1102 [8:28:02<6:51:47, 49.12s/it] 54%|█████▍    | 600/1102 [8:28:50<6:49:35, 48.95s/it]                                                      {'loss': 0.6768, 'learning_rate': 0.00045300441389393493, 'epoch': 0.54}
 54%|█████▍    | 600/1102 [8:28:50<6:49:35, 48.95s/it] 55%|█████▍    | 601/1102 [8:29:39<6:49:01, 48.99s/it]                                                      {'loss': 0.6792, 'learning_rate': 0.00045154034736138033, 'epoch': 0.55}
 55%|█████▍    | 601/1102 [8:29:39<6:49:01, 48.99s/it] 55%|█████▍    | 602/1102 [8:30:28<6:48:22, 49.00s/it]                                                      {'loss': 0.6098, 'learning_rate': 0.0004500767001407604, 'epoch': 0.55}
 55%|█████▍    | 602/1102 [8:30:28<6:48:22, 49.00s/it] 55%|█████▍    | 603/1102 [8:31:17<6:47:27, 48.99s/it]                                                      {'loss': 0.6864, 'learning_rate': 0.00044861348489672916, 'epoch': 0.55}
 55%|█████▍    | 603/1102 [8:31:17<6:47:27, 48.99s/it] 55%|█████▍    | 604/1102 [8:32:07<6:47:11, 49.06s/it]                                                      {'loss': 0.6833, 'learning_rate': 0.0004471507142902036, 'epoch': 0.55}
 55%|█████▍    | 604/1102 [8:32:07<6:47:11, 49.06s/it] 55%|█████▍    | 605/1102 [8:32:56<6:46:28, 49.07s/it]                                                      {'loss': 0.6187, 'learning_rate': 0.00044568840097825225, 'epoch': 0.55}
 55%|█████▍    | 605/1102 [8:32:56<6:46:28, 49.07s/it] 55%|█████▍    | 606/1102 [8:33:45<6:46:17, 49.15s/it]                                                      {'loss': 0.6386, 'learning_rate': 0.0004442265576139878, 'epoch': 0.55}
 55%|█████▍    | 606/1102 [8:33:45<6:46:17, 49.15s/it] 55%|█████▌    | 607/1102 [8:34:34<6:44:55, 49.08s/it]                                                      {'loss': 0.665, 'learning_rate': 0.0004427651968464558, 'epoch': 0.55}
 55%|█████▌    | 607/1102 [8:34:34<6:44:55, 49.08s/it] 55%|█████▌    | 608/1102 [8:35:24<6:45:44, 49.28s/it]                                                      {'loss': 0.69, 'learning_rate': 0.0004413043313205266, 'epoch': 0.55}
 55%|█████▌    | 608/1102 [8:35:24<6:45:44, 49.28s/it] 55%|█████▌    | 609/1102 [8:36:13<6:44:19, 49.21s/it]                                                      {'loss': 0.6628, 'learning_rate': 0.00043984397367678474, 'epoch': 0.55}
 55%|█████▌    | 609/1102 [8:36:13<6:44:19, 49.21s/it] 55%|█████▌    | 610/1102 [8:37:02<6:43:10, 49.17s/it]                                                      {'loss': 0.6535, 'learning_rate': 0.0004383841365514207, 'epoch': 0.55}
 55%|█████▌    | 610/1102 [8:37:02<6:43:10, 49.17s/it] 55%|█████▌    | 611/1102 [8:37:51<6:42:34, 49.19s/it]                                                      {'loss': 0.6831, 'learning_rate': 0.00043692483257612045, 'epoch': 0.55}
 55%|█████▌    | 611/1102 [8:37:51<6:42:34, 49.19s/it] 56%|█████▌    | 612/1102 [8:38:40<6:41:55, 49.22s/it]                                                      {'loss': 0.615, 'learning_rate': 0.00043546607437795743, 'epoch': 0.56}
 56%|█████▌    | 612/1102 [8:38:40<6:41:55, 49.22s/it] 56%|█████▌    | 613/1102 [8:39:29<6:40:29, 49.14s/it]                                                      {'loss': 0.6896, 'learning_rate': 0.0004340078745792818, 'epoch': 0.56}
 56%|█████▌    | 613/1102 [8:39:29<6:40:29, 49.14s/it] 56%|█████▌    | 614/1102 [8:40:19<6:40:14, 49.21s/it]                                                      {'loss': 0.6999, 'learning_rate': 0.0004325502457976126, 'epoch': 0.56}
 56%|█████▌    | 614/1102 [8:40:19<6:40:14, 49.21s/it] 56%|█████▌    | 615/1102 [8:41:08<6:39:04, 49.17s/it]                                                      {'loss': 0.6903, 'learning_rate': 0.0004310932006455276, 'epoch': 0.56}
 56%|█████▌    | 615/1102 [8:41:08<6:39:04, 49.17s/it] 56%|█████▌    | 616/1102 [8:41:57<6:38:24, 49.19s/it]                                                      {'loss': 0.677, 'learning_rate': 0.0004296367517305548, 'epoch': 0.56}
 56%|█████▌    | 616/1102 [8:41:57<6:38:24, 49.19s/it] 56%|█████▌    | 617/1102 [8:42:46<6:37:58, 49.23s/it]                                                      {'loss': 0.6589, 'learning_rate': 0.0004281809116550629, 'epoch': 0.56}
 56%|█████▌    | 617/1102 [8:42:46<6:37:58, 49.23s/it] 56%|█████▌    | 618/1102 [8:43:35<6:35:22, 49.01s/it]                                                      {'loss': 0.7193, 'learning_rate': 0.00042672569301615225, 'epoch': 0.56}
 56%|█████▌    | 618/1102 [8:43:35<6:35:22, 49.01s/it] 56%|█████▌    | 619/1102 [8:44:24<6:34:56, 49.06s/it]                                                      {'loss': 0.7131, 'learning_rate': 0.0004252711084055467, 'epoch': 0.56}
 56%|█████▌    | 619/1102 [8:44:24<6:34:56, 49.06s/it] 56%|█████▋    | 620/1102 [8:45:13<6:34:04, 49.06s/it]                                                      {'loss': 0.6732, 'learning_rate': 0.00042381717040948323, 'epoch': 0.56}
 56%|█████▋    | 620/1102 [8:45:13<6:34:04, 49.06s/it] 56%|█████▋    | 621/1102 [8:46:02<6:33:27, 49.08s/it]                                                      {'loss': 0.6427, 'learning_rate': 0.0004223638916086043, 'epoch': 0.56}
 56%|█████▋    | 621/1102 [8:46:02<6:33:27, 49.08s/it] 56%|█████▋    | 622/1102 [8:46:51<6:31:11, 48.90s/it]                                                      {'loss': 0.7107, 'learning_rate': 0.00042091128457784804, 'epoch': 0.56}
 56%|█████▋    | 622/1102 [8:46:51<6:31:11, 48.90s/it] 57%|█████▋    | 623/1102 [8:47:40<6:32:29, 49.16s/it]                                                      {'loss': 0.73, 'learning_rate': 0.00041945936188634035, 'epoch': 0.57}
 57%|█████▋    | 623/1102 [8:47:40<6:32:29, 49.16s/it] 57%|█████▋    | 624/1102 [8:48:29<6:31:25, 49.13s/it]                                                      {'loss': 0.7071, 'learning_rate': 0.00041800813609728523, 'epoch': 0.57}
 57%|█████▋    | 624/1102 [8:48:29<6:31:25, 49.13s/it] 57%|█████▋    | 625/1102 [8:49:19<6:30:22, 49.10s/it]                                                      {'loss': 0.7131, 'learning_rate': 0.00041655761976785706, 'epoch': 0.57}
 57%|█████▋    | 625/1102 [8:49:19<6:30:22, 49.10s/it] 57%|█████▋    | 626/1102 [8:50:08<6:29:40, 49.12s/it]                                                      {'loss': 0.677, 'learning_rate': 0.00041510782544909076, 'epoch': 0.57}
 57%|█████▋    | 626/1102 [8:50:08<6:29:40, 49.12s/it] 57%|█████▋    | 627/1102 [8:50:57<6:28:56, 49.13s/it]                                                      {'loss': 0.6791, 'learning_rate': 0.0004136587656857744, 'epoch': 0.57}
 57%|█████▋    | 627/1102 [8:50:57<6:28:56, 49.13s/it] 57%|█████▋    | 628/1102 [8:51:46<6:28:59, 49.24s/it]                                                      {'loss': 0.6758, 'learning_rate': 0.0004122104530163397, 'epoch': 0.57}
 57%|█████▋    | 628/1102 [8:51:46<6:28:59, 49.24s/it] 57%|█████▋    | 629/1102 [8:52:36<6:28:26, 49.27s/it]                                                      {'loss': 0.6593, 'learning_rate': 0.00041076289997275415, 'epoch': 0.57}
 57%|█████▋    | 629/1102 [8:52:36<6:28:26, 49.27s/it] 57%|█████▋    | 630/1102 [8:53:25<6:26:55, 49.19s/it]                                                      {'loss': 0.7081, 'learning_rate': 0.000409316119080412, 'epoch': 0.57}
 57%|█████▋    | 630/1102 [8:53:25<6:26:55, 49.19s/it] 57%|█████▋    | 631/1102 [8:54:14<6:27:01, 49.30s/it]                                                      {'loss': 0.7047, 'learning_rate': 0.00040787012285802693, 'epoch': 0.57}
 57%|█████▋    | 631/1102 [8:54:14<6:27:01, 49.30s/it] 57%|█████▋    | 632/1102 [8:55:03<6:25:03, 49.16s/it]                                                      {'loss': 0.7164, 'learning_rate': 0.0004064249238175223, 'epoch': 0.57}
 57%|█████▋    | 632/1102 [8:55:03<6:25:03, 49.16s/it] 57%|█████▋    | 633/1102 [8:55:52<6:24:47, 49.23s/it]                                                      {'loss': 0.6902, 'learning_rate': 0.000404980534463924, 'epoch': 0.57}
 57%|█████▋    | 633/1102 [8:55:52<6:24:47, 49.23s/it] 58%|█████▊    | 634/1102 [8:56:42<6:23:38, 49.19s/it]                                                      {'loss': 0.6867, 'learning_rate': 0.00040353696729525157, 'epoch': 0.58}
 58%|█████▊    | 634/1102 [8:56:42<6:23:38, 49.19s/it] 58%|█████▊    | 635/1102 [8:57:31<6:23:46, 49.31s/it]                                                      {'loss': 0.7117, 'learning_rate': 0.00040209423480241083, 'epoch': 0.58}
 58%|█████▊    | 635/1102 [8:57:31<6:23:46, 49.31s/it] 58%|█████▊    | 636/1102 [8:58:20<6:22:54, 49.30s/it]                                                      {'loss': 0.6685, 'learning_rate': 0.0004006523494690845, 'epoch': 0.58}
 58%|█████▊    | 636/1102 [8:58:20<6:22:54, 49.30s/it] 58%|█████▊    | 637/1102 [8:59:10<6:22:42, 49.38s/it]                                                      {'loss': 0.6588, 'learning_rate': 0.0003992113237716261, 'epoch': 0.58}
 58%|█████▊    | 637/1102 [8:59:10<6:22:42, 49.38s/it] 58%|█████▊    | 638/1102 [8:59:59<6:21:17, 49.30s/it]                                                      {'loss': 0.6765, 'learning_rate': 0.00039777117017894987, 'epoch': 0.58}
 58%|█████▊    | 638/1102 [8:59:59<6:21:17, 49.30s/it] 58%|█████▊    | 639/1102 [9:00:48<6:20:02, 49.25s/it]                                                      {'loss': 0.6955, 'learning_rate': 0.0003963319011524246, 'epoch': 0.58}
 58%|█████▊    | 639/1102 [9:00:48<6:20:02, 49.25s/it] 58%|█████▊    | 640/1102 [9:01:38<6:19:49, 49.33s/it]                                                      {'loss': 0.6538, 'learning_rate': 0.0003948935291457644, 'epoch': 0.58}
 58%|█████▊    | 640/1102 [9:01:38<6:19:49, 49.33s/it] 58%|█████▊    | 641/1102 [9:02:27<6:18:12, 49.22s/it]                                                      {'loss': 0.6992, 'learning_rate': 0.00039345606660492257, 'epoch': 0.58}
 58%|█████▊    | 641/1102 [9:02:27<6:18:12, 49.22s/it] 58%|█████▊    | 642/1102 [9:03:16<6:18:07, 49.32s/it]                                                      {'loss': 0.7052, 'learning_rate': 0.0003920195259679822, 'epoch': 0.58}
 58%|█████▊    | 642/1102 [9:03:16<6:18:07, 49.32s/it] 58%|█████▊    | 643/1102 [9:04:06<6:17:45, 49.38s/it]                                                      {'loss': 0.6461, 'learning_rate': 0.0003905839196650493, 'epoch': 0.58}
 58%|█████▊    | 643/1102 [9:04:06<6:17:45, 49.38s/it] 58%|█████▊    | 644/1102 [9:04:59<6:24:36, 50.39s/it]                                                      {'loss': 0.7087, 'learning_rate': 0.00038914926011814624, 'epoch': 0.58}
 58%|█████▊    | 644/1102 [9:04:59<6:24:36, 50.39s/it] 59%|█████▊    | 645/1102 [9:09:03<13:46:52, 108.56s/it]                                                        {'loss': 0.7539, 'learning_rate': 0.0003877155597411019, 'epoch': 0.59}
 59%|█████▊    | 645/1102 [9:09:03<13:46:52, 108.56s/it] 59%|█████▊    | 646/1102 [9:09:51<11:28:22, 90.58s/it]                                                        {'loss': 0.693, 'learning_rate': 0.00038628283093944686, 'epoch': 0.59}
 59%|█████▊    | 646/1102 [9:09:51<11:28:22, 90.58s/it] 59%|█████▊    | 647/1102 [9:10:41<9:52:29, 78.13s/it]                                                       {'loss': 0.6752, 'learning_rate': 0.0003848510861103042, 'epoch': 0.59}
 59%|█████▊    | 647/1102 [9:10:41<9:52:29, 78.13s/it] 59%|█████▉    | 648/1102 [9:11:30<8:45:04, 69.39s/it]                                                      {'loss': 0.6498, 'learning_rate': 0.00038342033764228304, 'epoch': 0.59}
 59%|█████▉    | 648/1102 [9:11:30<8:45:04, 69.39s/it] 59%|█████▉    | 649/1102 [9:12:19<7:58:35, 63.39s/it]                                                      {'loss': 0.6363, 'learning_rate': 0.000381990597915371, 'epoch': 0.59}
 59%|█████▉    | 649/1102 [9:12:19<7:58:35, 63.39s/it] 59%|█████▉    | 650/1102 [9:13:08<7:25:14, 59.10s/it]                                                      {'loss': 0.673, 'learning_rate': 0.00038056187930082786, 'epoch': 0.59}
 59%|█████▉    | 650/1102 [9:13:08<7:25:14, 59.10s/it] 59%|█████▉    | 651/1102 [9:13:57<7:01:16, 56.04s/it]                                                      {'loss': 0.7094, 'learning_rate': 0.0003791341941610769, 'epoch': 0.59}
 59%|█████▉    | 651/1102 [9:13:57<7:01:16, 56.04s/it] 59%|█████▉    | 652/1102 [9:14:46<6:45:18, 54.04s/it]                                                      {'loss': 0.6901, 'learning_rate': 0.00037770755484960004, 'epoch': 0.59}
 59%|█████▉    | 652/1102 [9:14:46<6:45:18, 54.04s/it] 59%|█████▉    | 653/1102 [9:15:35<6:31:42, 52.34s/it]                                                      {'loss': 0.6509, 'learning_rate': 0.0003762819737108291, 'epoch': 0.59}
 59%|█████▉    | 653/1102 [9:15:35<6:31:42, 52.34s/it] 59%|█████▉    | 654/1102 [9:16:24<6:24:15, 51.46s/it]                                                      {'loss': 0.676, 'learning_rate': 0.0003748574630800401, 'epoch': 0.59}
 59%|█████▉    | 654/1102 [9:16:24<6:24:15, 51.46s/it] 59%|█████▉    | 655/1102 [9:17:13<6:18:46, 50.84s/it]                                                      {'loss': 0.6699, 'learning_rate': 0.0003734340352832457, 'epoch': 0.59}
 59%|█████▉    | 655/1102 [9:17:13<6:18:46, 50.84s/it] 60%|█████▉    | 656/1102 [9:18:02<6:13:48, 50.29s/it]                                                      {'loss': 0.7438, 'learning_rate': 0.00037201170263709, 'epoch': 0.6}
 60%|█████▉    | 656/1102 [9:18:02<6:13:48, 50.29s/it] 60%|█████▉    | 657/1102 [9:18:52<6:10:40, 49.98s/it]                                                      {'loss': 0.6579, 'learning_rate': 0.0003705904774487396, 'epoch': 0.6}
 60%|█████▉    | 657/1102 [9:18:52<6:10:40, 49.98s/it] 60%|█████▉    | 658/1102 [9:19:41<6:08:33, 49.81s/it]                                                      {'loss': 0.6993, 'learning_rate': 0.0003691703720157797, 'epoch': 0.6}
 60%|█████▉    | 658/1102 [9:19:41<6:08:33, 49.81s/it] 60%|█████▉    | 659/1102 [9:20:31<6:06:58, 49.70s/it]                                                      {'loss': 0.7217, 'learning_rate': 0.00036775139862610574, 'epoch': 0.6}
 60%|█████▉    | 659/1102 [9:20:31<6:06:58, 49.70s/it] 60%|█████▉    | 660/1102 [9:21:20<6:05:22, 49.60s/it]                                                      {'loss': 0.6509, 'learning_rate': 0.00036633356955781827, 'epoch': 0.6}
 60%|█████▉    | 660/1102 [9:21:20<6:05:22, 49.60s/it] 60%|█████▉    | 661/1102 [9:22:09<6:02:21, 49.30s/it]                                                      {'loss': 0.6431, 'learning_rate': 0.0003649168970791157, 'epoch': 0.6}
 60%|█████▉    | 661/1102 [9:22:09<6:02:21, 49.30s/it] 60%|██████    | 662/1102 [9:22:58<6:01:15, 49.26s/it]                                                      {'loss': 0.6527, 'learning_rate': 0.0003635013934481895, 'epoch': 0.6}
 60%|██████    | 662/1102 [9:22:58<6:01:15, 49.26s/it] 60%|██████    | 663/1102 [9:23:47<6:00:21, 49.25s/it]                                                      {'loss': 0.6456, 'learning_rate': 0.0003620870709131163, 'epoch': 0.6}
 60%|██████    | 663/1102 [9:23:47<6:00:21, 49.25s/it] 60%|██████    | 664/1102 [9:24:37<6:00:22, 49.37s/it]                                                      {'loss': 0.7262, 'learning_rate': 0.0003606739417117539, 'epoch': 0.6}
 60%|██████    | 664/1102 [9:24:37<6:00:22, 49.37s/it] 60%|██████    | 665/1102 [9:25:26<5:59:24, 49.35s/it]                                                      {'loss': 0.6821, 'learning_rate': 0.0003592620180716338, 'epoch': 0.6}
 60%|██████    | 665/1102 [9:25:26<5:59:24, 49.35s/it] 60%|██████    | 666/1102 [9:26:15<5:58:24, 49.32s/it]                                                      {'loss': 0.6373, 'learning_rate': 0.00035785131220985656, 'epoch': 0.6}
 60%|██████    | 666/1102 [9:26:15<5:58:24, 49.32s/it] 61%|██████    | 667/1102 [9:27:04<5:57:04, 49.25s/it]                                                      {'loss': 0.6721, 'learning_rate': 0.0003564418363329848, 'epoch': 0.61}
 61%|██████    | 667/1102 [9:27:04<5:57:04, 49.25s/it] 61%|██████    | 668/1102 [9:27:54<5:56:45, 49.32s/it]                                                      {'loss': 0.6314, 'learning_rate': 0.0003550336026369388, 'epoch': 0.61}
 61%|██████    | 668/1102 [9:27:54<5:56:45, 49.32s/it] 61%|██████    | 669/1102 [9:28:43<5:56:29, 49.40s/it]                                                      {'loss': 0.7242, 'learning_rate': 0.00035362662330689064, 'epoch': 0.61}
 61%|██████    | 669/1102 [9:28:43<5:56:29, 49.40s/it] 61%|██████    | 670/1102 [9:29:33<5:56:16, 49.48s/it]                                                      {'loss': 0.628, 'learning_rate': 0.00035222091051715797, 'epoch': 0.61}
 61%|██████    | 670/1102 [9:29:33<5:56:16, 49.48s/it] 61%|██████    | 671/1102 [9:30:22<5:54:24, 49.34s/it]                                                      {'loss': 0.6577, 'learning_rate': 0.00035081647643110024, 'epoch': 0.61}
 61%|██████    | 671/1102 [9:30:22<5:54:24, 49.34s/it] 61%|██████    | 672/1102 [9:31:11<5:53:36, 49.34s/it]                                                      {'loss': 0.6766, 'learning_rate': 0.00034941333320101173, 'epoch': 0.61}
 61%|██████    | 672/1102 [9:31:11<5:53:36, 49.34s/it] 61%|██████    | 673/1102 [9:32:01<5:52:49, 49.35s/it]                                                      {'loss': 0.7205, 'learning_rate': 0.0003480114929680176, 'epoch': 0.61}
 61%|██████    | 673/1102 [9:32:01<5:52:49, 49.35s/it] 61%|██████    | 674/1102 [9:32:50<5:52:08, 49.37s/it]                                                      {'loss': 0.6672, 'learning_rate': 0.0003466109678619681, 'epoch': 0.61}
 61%|██████    | 674/1102 [9:32:50<5:52:08, 49.37s/it] 61%|██████▏   | 675/1102 [9:33:40<5:51:35, 49.40s/it]                                                      {'loss': 0.6656, 'learning_rate': 0.0003452117700013345, 'epoch': 0.61}
 61%|██████▏   | 675/1102 [9:33:40<5:51:35, 49.40s/it] 61%|██████▏   | 676/1102 [9:34:29<5:50:27, 49.36s/it]                                                      {'loss': 0.6746, 'learning_rate': 0.00034381391149310294, 'epoch': 0.61}
 61%|██████▏   | 676/1102 [9:34:29<5:50:27, 49.36s/it] 61%|██████▏   | 677/1102 [9:35:18<5:49:07, 49.29s/it]                                                      {'loss': 0.682, 'learning_rate': 0.00034241740443267113, 'epoch': 0.61}
 61%|██████▏   | 677/1102 [9:35:18<5:49:07, 49.29s/it] 62%|██████▏   | 678/1102 [9:36:07<5:47:57, 49.24s/it]                                                      {'loss': 0.6748, 'learning_rate': 0.0003410222609037424, 'epoch': 0.62}
 62%|██████▏   | 678/1102 [9:36:07<5:47:57, 49.24s/it] 62%|██████▏   | 679/1102 [9:36:56<5:47:16, 49.26s/it]                                                      {'loss': 0.6906, 'learning_rate': 0.00033962849297822223, 'epoch': 0.62}
 62%|██████▏   | 679/1102 [9:36:56<5:47:16, 49.26s/it] 62%|██████▏   | 680/1102 [9:37:46<5:47:00, 49.34s/it]                                                      {'loss': 0.6258, 'learning_rate': 0.00033823611271611265, 'epoch': 0.62}
 62%|██████▏   | 680/1102 [9:37:46<5:47:00, 49.34s/it] 62%|██████▏   | 681/1102 [9:38:36<5:47:05, 49.47s/it]                                                      {'loss': 0.686, 'learning_rate': 0.00033684513216540905, 'epoch': 0.62}
 62%|██████▏   | 681/1102 [9:38:36<5:47:05, 49.47s/it] 62%|██████▏   | 682/1102 [9:39:24<5:44:42, 49.24s/it]                                                      {'loss': 0.6823, 'learning_rate': 0.000335455563361995, 'epoch': 0.62}
 62%|██████▏   | 682/1102 [9:39:24<5:44:42, 49.24s/it] 62%|██████▏   | 683/1102 [9:40:14<5:44:47, 49.37s/it]                                                      {'loss': 0.6882, 'learning_rate': 0.0003340674183295389, 'epoch': 0.62}
 62%|██████▏   | 683/1102 [9:40:14<5:44:47, 49.37s/it] 62%|██████▏   | 684/1102 [9:41:03<5:43:48, 49.35s/it]                                                      {'loss': 0.6676, 'learning_rate': 0.00033268070907938914, 'epoch': 0.62}
 62%|██████▏   | 684/1102 [9:41:03<5:43:48, 49.35s/it] 62%|██████▏   | 685/1102 [9:41:52<5:42:28, 49.28s/it]                                                      {'loss': 0.6374, 'learning_rate': 0.00033129544761047094, 'epoch': 0.62}
 62%|██████▏   | 685/1102 [9:41:52<5:42:28, 49.28s/it] 62%|██████▏   | 686/1102 [9:42:42<5:41:23, 49.24s/it]                                                      {'loss': 0.6552, 'learning_rate': 0.0003299116459091816, 'epoch': 0.62}
 62%|██████▏   | 686/1102 [9:42:42<5:41:23, 49.24s/it] 62%|██████▏   | 687/1102 [9:43:31<5:40:59, 49.30s/it]                                                      {'loss': 0.6604, 'learning_rate': 0.00032852931594928804, 'epoch': 0.62}
 62%|██████▏   | 687/1102 [9:43:31<5:40:59, 49.30s/it] 62%|██████▏   | 688/1102 [9:44:20<5:40:14, 49.31s/it]                                                      {'loss': 0.6788, 'learning_rate': 0.00032714846969182176, 'epoch': 0.62}
 62%|██████▏   | 688/1102 [9:44:20<5:40:14, 49.31s/it] 63%|██████▎   | 689/1102 [9:45:09<5:37:58, 49.10s/it]                                                      {'loss': 0.7265, 'learning_rate': 0.0003257691190849769, 'epoch': 0.63}
 63%|██████▎   | 689/1102 [9:45:09<5:37:58, 49.10s/it] 63%|██████▎   | 690/1102 [9:45:54<5:28:52, 47.89s/it]                                                      {'loss': 0.7, 'learning_rate': 0.0003243912760640054, 'epoch': 0.63}
 63%|██████▎   | 690/1102 [9:45:54<5:28:52, 47.89s/it] 63%|██████▎   | 691/1102 [9:46:43<5:30:25, 48.24s/it]                                                      {'loss': 0.6454, 'learning_rate': 0.00032301495255111426, 'epoch': 0.63}
 63%|██████▎   | 691/1102 [9:46:43<5:30:25, 48.24s/it] 63%|██████▎   | 692/1102 [9:47:30<5:26:46, 47.82s/it]                                                      {'loss': 0.6724, 'learning_rate': 0.000321640160455363, 'epoch': 0.63}
 63%|██████▎   | 692/1102 [9:47:30<5:26:46, 47.82s/it] 63%|██████▎   | 693/1102 [9:48:19<5:28:04, 48.13s/it]                                                      {'loss': 0.6273, 'learning_rate': 0.0003202669116725598, 'epoch': 0.63}
 63%|██████▎   | 693/1102 [9:48:19<5:28:04, 48.13s/it] 63%|██████▎   | 694/1102 [9:49:08<5:29:43, 48.49s/it]                                                      {'loss': 0.637, 'learning_rate': 0.00031889521808515885, 'epoch': 0.63}
 63%|██████▎   | 694/1102 [9:49:08<5:29:43, 48.49s/it] 63%|██████▎   | 695/1102 [9:49:57<5:30:25, 48.71s/it]                                                      {'loss': 0.6871, 'learning_rate': 0.00031752509156215736, 'epoch': 0.63}
 63%|██████▎   | 695/1102 [9:49:57<5:30:25, 48.71s/it] 63%|██████▎   | 696/1102 [9:50:47<5:30:35, 48.86s/it]                                                      {'loss': 0.7158, 'learning_rate': 0.00031615654395899373, 'epoch': 0.63}
 63%|██████▎   | 696/1102 [9:50:47<5:30:35, 48.86s/it] 63%|██████▎   | 697/1102 [9:51:36<5:30:25, 48.95s/it]                                                      {'loss': 0.6494, 'learning_rate': 0.0003147895871174432, 'epoch': 0.63}
 63%|██████▎   | 697/1102 [9:51:36<5:30:25, 48.95s/it] 63%|██████▎   | 698/1102 [9:52:25<5:30:12, 49.04s/it]                                                      {'loss': 0.6405, 'learning_rate': 0.00031342423286551753, 'epoch': 0.63}
 63%|██████▎   | 698/1102 [9:52:25<5:30:12, 49.04s/it] 63%|██████▎   | 699/1102 [9:53:14<5:29:09, 49.01s/it]                                                      {'loss': 0.6463, 'learning_rate': 0.0003120604930173608, 'epoch': 0.63}
 63%|██████▎   | 699/1102 [9:53:14<5:29:09, 49.01s/it] 64%|██████▎   | 700/1102 [9:54:03<5:29:00, 49.11s/it]                                                      {'loss': 0.6812, 'learning_rate': 0.00031069837937314844, 'epoch': 0.64}
 64%|██████▎   | 700/1102 [9:54:03<5:29:00, 49.11s/it] 64%|██████▎   | 701/1102 [9:54:52<5:27:29, 49.00s/it]                                                      {'loss': 0.6593, 'learning_rate': 0.00030933790371898416, 'epoch': 0.64}
 64%|██████▎   | 701/1102 [9:54:52<5:27:29, 49.00s/it] 64%|██████▎   | 702/1102 [9:55:41<5:27:23, 49.11s/it]                                                      {'loss': 0.7078, 'learning_rate': 0.0003079790778267994, 'epoch': 0.64}
 64%|██████▎   | 702/1102 [9:55:41<5:27:23, 49.11s/it] 64%|██████▍   | 703/1102 [9:56:30<5:26:25, 49.09s/it]                                                      {'loss': 0.6616, 'learning_rate': 0.00030662191345424923, 'epoch': 0.64}
 64%|██████▍   | 703/1102 [9:56:30<5:26:25, 49.09s/it] 64%|██████▍   | 704/1102 [9:57:20<5:25:37, 49.09s/it]                                                      {'loss': 0.6674, 'learning_rate': 0.0003052664223446131, 'epoch': 0.64}
 64%|██████▍   | 704/1102 [9:57:20<5:25:37, 49.09s/it] 64%|██████▍   | 705/1102 [9:58:09<5:24:55, 49.11s/it]                                                      {'loss': 0.655, 'learning_rate': 0.0003039126162266912, 'epoch': 0.64}
 64%|██████▍   | 705/1102 [9:58:09<5:24:55, 49.11s/it] 64%|██████▍   | 706/1102 [9:58:58<5:23:59, 49.09s/it]                                                      {'loss': 0.6722, 'learning_rate': 0.0003025605068147044, 'epoch': 0.64}
 64%|██████▍   | 706/1102 [9:58:58<5:23:59, 49.09s/it] 64%|██████▍   | 707/1102 [9:59:47<5:23:23, 49.12s/it]                                                      {'loss': 0.6362, 'learning_rate': 0.00030121010580819185, 'epoch': 0.64}
 64%|██████▍   | 707/1102 [9:59:47<5:23:23, 49.12s/it] 64%|██████▍   | 708/1102 [10:00:36<5:22:15, 49.07s/it]                                                       {'loss': 0.6551, 'learning_rate': 0.0002998614248919107, 'epoch': 0.64}
 64%|██████▍   | 708/1102 [10:00:36<5:22:15, 49.07s/it] 64%|██████▍   | 709/1102 [10:01:25<5:21:02, 49.01s/it]                                                       {'loss': 0.6857, 'learning_rate': 0.0002985144757357338, 'epoch': 0.64}
 64%|██████▍   | 709/1102 [10:01:25<5:21:02, 49.01s/it] 64%|██████▍   | 710/1102 [10:02:14<5:20:42, 49.09s/it]                                                       {'loss': 0.6116, 'learning_rate': 0.00029716926999455017, 'epoch': 0.64}
 64%|██████▍   | 710/1102 [10:02:14<5:20:42, 49.09s/it] 65%|██████▍   | 711/1102 [10:03:03<5:19:18, 49.00s/it]                                                       {'loss': 0.6683, 'learning_rate': 0.00029582581930816287, 'epoch': 0.65}
 65%|██████▍   | 711/1102 [10:03:03<5:19:18, 49.00s/it] 65%|██████▍   | 712/1102 [10:03:52<5:18:54, 49.06s/it]                                                       {'loss': 0.7202, 'learning_rate': 0.0002944841353011891, 'epoch': 0.65}
 65%|██████▍   | 712/1102 [10:03:52<5:18:54, 49.06s/it] 65%|██████▍   | 713/1102 [10:04:40<5:16:40, 48.85s/it]                                                       {'loss': 0.6983, 'learning_rate': 0.00029314422958295905, 'epoch': 0.65}
 65%|██████▍   | 713/1102 [10:04:40<5:16:40, 48.85s/it] 65%|██████▍   | 714/1102 [10:05:30<5:16:34, 48.95s/it]                                                       {'loss': 0.6526, 'learning_rate': 0.00029180611374741625, 'epoch': 0.65}
 65%|██████▍   | 714/1102 [10:05:30<5:16:34, 48.95s/it] 65%|██████▍   | 715/1102 [10:06:19<5:15:53, 48.97s/it]                                                       {'loss': 0.7053, 'learning_rate': 0.0002904697993730159, 'epoch': 0.65}
 65%|██████▍   | 715/1102 [10:06:19<5:15:53, 48.97s/it] 65%|██████▍   | 716/1102 [10:07:08<5:15:51, 49.10s/it]                                                       {'loss': 0.6919, 'learning_rate': 0.00028913529802262615, 'epoch': 0.65}
 65%|██████▍   | 716/1102 [10:07:08<5:15:51, 49.10s/it] 65%|██████▌   | 717/1102 [10:07:57<5:14:57, 49.08s/it]                                                       {'loss': 0.7041, 'learning_rate': 0.00028780262124342756, 'epoch': 0.65}
 65%|██████▌   | 717/1102 [10:07:57<5:14:57, 49.08s/it] 65%|██████▌   | 718/1102 [10:08:46<5:14:21, 49.12s/it]                                                       {'loss': 0.6627, 'learning_rate': 0.0002864717805668119, 'epoch': 0.65}
 65%|██████▌   | 718/1102 [10:08:46<5:14:21, 49.12s/it] 65%|██████▌   | 719/1102 [10:09:35<5:13:44, 49.15s/it]                                                       {'loss': 0.6802, 'learning_rate': 0.00028514278750828536, 'epoch': 0.65}
 65%|██████▌   | 719/1102 [10:09:35<5:13:44, 49.15s/it] 65%|██████▌   | 720/1102 [10:10:25<5:14:12, 49.35s/it]                                                       {'loss': 0.6934, 'learning_rate': 0.00028381565356736514, 'epoch': 0.65}
 65%|██████▌   | 720/1102 [10:10:25<5:14:12, 49.35s/it] 65%|██████▌   | 721/1102 [10:11:15<5:13:12, 49.32s/it]                                                       {'loss': 0.6585, 'learning_rate': 0.0002824903902274831, 'epoch': 0.65}
 65%|██████▌   | 721/1102 [10:11:15<5:13:12, 49.32s/it] 66%|██████▌   | 722/1102 [10:12:04<5:12:17, 49.31s/it]                                                       {'loss': 0.6569, 'learning_rate': 0.0002811670089558847, 'epoch': 0.66}
 66%|██████▌   | 722/1102 [10:12:04<5:12:17, 49.31s/it] 66%|██████▌   | 723/1102 [10:12:53<5:10:42, 49.19s/it]                                                       {'loss': 0.6957, 'learning_rate': 0.00027984552120353045, 'epoch': 0.66}
 66%|██████▌   | 723/1102 [10:12:53<5:10:42, 49.19s/it] 66%|██████▌   | 724/1102 [10:13:42<5:09:41, 49.16s/it]                                                       {'loss': 0.6797, 'learning_rate': 0.0002785259384049959, 'epoch': 0.66}
 66%|██████▌   | 724/1102 [10:13:42<5:09:41, 49.16s/it] 66%|██████▌   | 725/1102 [10:14:31<5:09:53, 49.32s/it]                                                       {'loss': 0.6701, 'learning_rate': 0.00027720827197837475, 'epoch': 0.66}
 66%|██████▌   | 725/1102 [10:14:31<5:09:53, 49.32s/it] 66%|██████▌   | 726/1102 [10:15:21<5:09:11, 49.34s/it]                                                       {'loss': 0.6491, 'learning_rate': 0.00027589253332517734, 'epoch': 0.66}
 66%|██████▌   | 726/1102 [10:15:21<5:09:11, 49.34s/it] 66%|██████▌   | 727/1102 [10:16:10<5:08:25, 49.35s/it]                                                       {'loss': 0.6877, 'learning_rate': 0.0002745787338302341, 'epoch': 0.66}
 66%|██████▌   | 727/1102 [10:16:10<5:08:25, 49.35s/it] 66%|██████▌   | 728/1102 [10:16:59<5:06:44, 49.21s/it]                                                       {'loss': 0.7352, 'learning_rate': 0.00027326688486159614, 'epoch': 0.66}
 66%|██████▌   | 728/1102 [10:16:59<5:06:44, 49.21s/it] 66%|██████▌   | 729/1102 [10:17:49<5:06:16, 49.27s/it]                                                       {'loss': 0.6858, 'learning_rate': 0.0002719569977704372, 'epoch': 0.66}
 66%|██████▌   | 729/1102 [10:17:49<5:06:16, 49.27s/it] 66%|██████▌   | 730/1102 [10:18:38<5:05:41, 49.31s/it]                                                       {'loss': 0.6357, 'learning_rate': 0.00027064908389095465, 'epoch': 0.66}
 66%|██████▌   | 730/1102 [10:18:38<5:05:41, 49.31s/it] 66%|██████▋   | 731/1102 [10:19:27<5:04:23, 49.23s/it]                                                       {'loss': 0.661, 'learning_rate': 0.00026934315454027317, 'epoch': 0.66}
 66%|██████▋   | 731/1102 [10:19:27<5:04:23, 49.23s/it] 66%|██████▋   | 732/1102 [10:20:16<5:02:35, 49.07s/it]                                                       {'loss': 0.725, 'learning_rate': 0.00026803922101834455, 'epoch': 0.66}
 66%|██████▋   | 732/1102 [10:20:16<5:02:35, 49.07s/it] 67%|██████▋   | 733/1102 [10:21:05<5:02:02, 49.11s/it]                                                       {'loss': 0.7076, 'learning_rate': 0.00026673729460785175, 'epoch': 0.67}
 67%|██████▋   | 733/1102 [10:21:05<5:02:02, 49.11s/it] 67%|██████▋   | 734/1102 [10:21:54<5:01:25, 49.14s/it]                                                       {'loss': 0.7304, 'learning_rate': 0.00026543738657411033, 'epoch': 0.67}
 67%|██████▋   | 734/1102 [10:21:54<5:01:25, 49.14s/it] 67%|██████▋   | 735/1102 [10:22:43<4:59:33, 48.98s/it]                                                       {'loss': 0.6567, 'learning_rate': 0.00026413950816497146, 'epoch': 0.67}
 67%|██████▋   | 735/1102 [10:22:43<4:59:33, 48.98s/it] 67%|██████▋   | 736/1102 [10:23:32<4:59:25, 49.09s/it]                                                       {'loss': 0.6207, 'learning_rate': 0.00026284367061072376, 'epoch': 0.67}
 67%|██████▋   | 736/1102 [10:23:32<4:59:25, 49.09s/it] 67%|██████▋   | 737/1102 [10:24:21<4:58:56, 49.14s/it]                                                       {'loss': 0.6257, 'learning_rate': 0.0002615498851239978, 'epoch': 0.67}
 67%|██████▋   | 737/1102 [10:24:21<4:58:56, 49.14s/it] 67%|██████▋   | 738/1102 [10:25:11<4:58:16, 49.17s/it]                                                       {'loss': 0.6278, 'learning_rate': 0.00026025816289966704, 'epoch': 0.67}
 67%|██████▋   | 738/1102 [10:25:11<4:58:16, 49.17s/it] 67%|██████▋   | 739/1102 [10:26:00<4:57:55, 49.24s/it]                                                       {'loss': 0.6807, 'learning_rate': 0.00025896851511475184, 'epoch': 0.67}
 67%|██████▋   | 739/1102 [10:26:00<4:57:55, 49.24s/it] 67%|██████▋   | 740/1102 [10:26:49<4:57:14, 49.27s/it]                                                       {'loss': 0.6851, 'learning_rate': 0.0002576809529283241, 'epoch': 0.67}
 67%|██████▋   | 740/1102 [10:26:49<4:57:14, 49.27s/it] 67%|██████▋   | 741/1102 [10:27:39<4:56:28, 49.28s/it]                                                       {'loss': 0.6912, 'learning_rate': 0.000256395487481408, 'epoch': 0.67}
 67%|██████▋   | 741/1102 [10:27:39<4:56:28, 49.28s/it] 67%|██████▋   | 742/1102 [10:28:27<4:54:43, 49.12s/it]                                                       {'loss': 0.7228, 'learning_rate': 0.0002551121298968859, 'epoch': 0.67}
 67%|██████▋   | 742/1102 [10:28:27<4:54:43, 49.12s/it] 67%|██████▋   | 743/1102 [10:29:17<4:54:11, 49.17s/it]                                                       {'loss': 0.6767, 'learning_rate': 0.00025383089127940084, 'epoch': 0.67}
 67%|██████▋   | 743/1102 [10:29:17<4:54:11, 49.17s/it] 68%|██████▊   | 744/1102 [10:30:06<4:54:13, 49.31s/it]                                                       {'loss': 0.6882, 'learning_rate': 0.00025255178271526137, 'epoch': 0.67}
 68%|██████▊   | 744/1102 [10:30:06<4:54:13, 49.31s/it] 68%|██████▊   | 745/1102 [10:30:55<4:51:33, 49.00s/it]                                                       {'loss': 0.6708, 'learning_rate': 0.00025127481527234395, 'epoch': 0.68}
 68%|██████▊   | 745/1102 [10:30:55<4:51:33, 49.00s/it] 68%|██████▊   | 746/1102 [10:31:43<4:50:26, 48.95s/it]                                                       {'loss': 0.6668, 'learning_rate': 0.0002500000000000001, 'epoch': 0.68}
 68%|██████▊   | 746/1102 [10:31:43<4:50:26, 48.95s/it] 68%|██████▊   | 747/1102 [10:32:32<4:49:47, 48.98s/it]                                                       {'loss': 0.6748, 'learning_rate': 0.00024872734792895737, 'epoch': 0.68}
 68%|██████▊   | 747/1102 [10:32:32<4:49:47, 48.98s/it] 68%|██████▊   | 748/1102 [10:33:21<4:49:01, 48.99s/it]                                                       {'loss': 0.7039, 'learning_rate': 0.00024745687007122634, 'epoch': 0.68}
 68%|██████▊   | 748/1102 [10:33:21<4:49:01, 48.99s/it] 68%|██████▊   | 749/1102 [10:34:10<4:48:04, 48.96s/it]                                                       {'loss': 0.6496, 'learning_rate': 0.0002461885774200046, 'epoch': 0.68}
 68%|██████▊   | 749/1102 [10:34:10<4:48:04, 48.96s/it] 68%|██████▊   | 750/1102 [10:35:00<4:47:58, 49.09s/it]                                                       {'loss': 0.6257, 'learning_rate': 0.0002449224809495815, 'epoch': 0.68}
 68%|██████▊   | 750/1102 [10:35:00<4:47:58, 49.09s/it] 68%|██████▊   | 751/1102 [10:35:49<4:46:42, 49.01s/it]                                                       {'loss': 0.6921, 'learning_rate': 0.00024365859161524256, 'epoch': 0.68}
 68%|██████▊   | 751/1102 [10:35:49<4:46:42, 49.01s/it] 68%|██████▊   | 752/1102 [10:36:37<4:44:42, 48.81s/it]                                                       {'loss': 0.734, 'learning_rate': 0.00024239692035317678, 'epoch': 0.68}
 68%|██████▊   | 752/1102 [10:36:37<4:44:42, 48.81s/it] 68%|██████▊   | 753/1102 [10:37:26<4:45:16, 49.04s/it]                                                       {'loss': 0.6822, 'learning_rate': 0.00024113747808037929, 'epoch': 0.68}
 68%|██████▊   | 753/1102 [10:37:26<4:45:16, 49.04s/it] 68%|██████▊   | 754/1102 [10:38:16<4:44:34, 49.07s/it]                                                       {'loss': 0.6335, 'learning_rate': 0.00023988027569455894, 'epoch': 0.68}
 68%|██████▊   | 754/1102 [10:38:16<4:44:34, 49.07s/it] 69%|██████▊   | 755/1102 [10:39:05<4:43:40, 49.05s/it]                                                       {'loss': 0.6732, 'learning_rate': 0.00023862532407404303, 'epoch': 0.68}
 69%|██████▊   | 755/1102 [10:39:05<4:43:40, 49.05s/it] 69%|██████▊   | 756/1102 [10:39:54<4:43:12, 49.11s/it]                                                       {'loss': 0.6873, 'learning_rate': 0.00023737263407768366, 'epoch': 0.69}
 69%|██████▊   | 756/1102 [10:39:54<4:43:12, 49.11s/it] 69%|██████▊   | 757/1102 [10:40:43<4:43:01, 49.22s/it]                                                       {'loss': 0.6626, 'learning_rate': 0.0002361222165447628, 'epoch': 0.69}
 69%|██████▊   | 757/1102 [10:40:43<4:43:01, 49.22s/it] 69%|██████▉   | 758/1102 [10:41:32<4:41:42, 49.13s/it]                                                       {'loss': 0.5951, 'learning_rate': 0.0002348740822949006, 'epoch': 0.69}
 69%|██████▉   | 758/1102 [10:41:32<4:41:42, 49.13s/it] 69%|██████▉   | 759/1102 [10:42:21<4:39:57, 48.97s/it]                                                       {'loss': 0.7259, 'learning_rate': 0.00023362824212795898, 'epoch': 0.69}
 69%|██████▉   | 759/1102 [10:42:21<4:39:57, 48.97s/it] 69%|██████▉   | 760/1102 [10:43:10<4:39:19, 49.00s/it]                                                       {'loss': 0.6568, 'learning_rate': 0.00023238470682395037, 'epoch': 0.69}
 69%|██████▉   | 760/1102 [10:43:10<4:39:19, 49.00s/it] 69%|██████▉   | 761/1102 [10:43:59<4:38:36, 49.02s/it]                                                       {'loss': 0.6423, 'learning_rate': 0.00023114348714294353, 'epoch': 0.69}
 69%|██████▉   | 761/1102 [10:43:59<4:38:36, 49.02s/it] 69%|██████▉   | 762/1102 [10:44:48<4:38:21, 49.12s/it]                                                       {'loss': 0.6225, 'learning_rate': 0.00022990459382497087, 'epoch': 0.69}
 69%|██████▉   | 762/1102 [10:44:48<4:38:21, 49.12s/it] 69%|██████▉   | 763/1102 [10:45:37<4:37:17, 49.08s/it]                                                       {'loss': 0.6532, 'learning_rate': 0.00022866803758993443, 'epoch': 0.69}
 69%|██████▉   | 763/1102 [10:45:37<4:37:17, 49.08s/it] 69%|██████▉   | 764/1102 [10:46:26<4:35:54, 48.98s/it]                                                       {'loss': 0.666, 'learning_rate': 0.0002274338291375147, 'epoch': 0.69}
 69%|██████▉   | 764/1102 [10:46:26<4:35:54, 48.98s/it] 69%|██████▉   | 765/1102 [10:47:15<4:35:22, 49.03s/it]                                                       {'loss': 0.7171, 'learning_rate': 0.00022620197914707718, 'epoch': 0.69}
 69%|██████▉   | 765/1102 [10:47:15<4:35:22, 49.03s/it] 70%|██████▉   | 766/1102 [10:48:04<4:34:28, 49.01s/it]                                                       {'loss': 0.685, 'learning_rate': 0.0002249724982775793, 'epoch': 0.69}
 70%|██████▉   | 766/1102 [10:48:04<4:34:28, 49.01s/it] 70%|██████▉   | 767/1102 [10:48:53<4:33:29, 48.98s/it]                                                       {'loss': 0.6479, 'learning_rate': 0.00022374539716748032, 'epoch': 0.7}
 70%|██████▉   | 767/1102 [10:48:53<4:33:29, 48.98s/it] 70%|██████▉   | 768/1102 [10:49:43<4:33:41, 49.16s/it]                                                       {'loss': 0.6445, 'learning_rate': 0.00022252068643464651, 'epoch': 0.7}
 70%|██████▉   | 768/1102 [10:49:43<4:33:41, 49.16s/it] 70%|██████▉   | 769/1102 [10:50:32<4:32:46, 49.15s/it]                                                       {'loss': 0.7032, 'learning_rate': 0.00022129837667626145, 'epoch': 0.7}
 70%|██████▉   | 769/1102 [10:50:32<4:32:46, 49.15s/it] 70%|██████▉   | 770/1102 [10:51:21<4:31:40, 49.10s/it]                                                       {'loss': 0.6782, 'learning_rate': 0.0002200784784687334, 'epoch': 0.7}
 70%|██████▉   | 770/1102 [10:51:21<4:31:40, 49.10s/it] 70%|██████▉   | 771/1102 [10:52:10<4:30:27, 49.02s/it]                                                       {'loss': 0.694, 'learning_rate': 0.0002188610023676041, 'epoch': 0.7}
 70%|██████▉   | 771/1102 [10:52:10<4:30:27, 49.02s/it] 70%|███████   | 772/1102 [10:52:59<4:29:31, 49.00s/it]                                                       {'loss': 0.6777, 'learning_rate': 0.0002176459589074566, 'epoch': 0.7}
 70%|███████   | 772/1102 [10:52:59<4:29:31, 49.00s/it] 70%|███████   | 773/1102 [10:53:48<4:28:35, 48.98s/it]                                                       {'loss': 0.623, 'learning_rate': 0.0002164333586018259, 'epoch': 0.7}
 70%|███████   | 773/1102 [10:53:48<4:28:35, 48.98s/it] 70%|███████   | 774/1102 [10:54:37<4:29:10, 49.24s/it]                                                       {'loss': 0.6527, 'learning_rate': 0.00021522321194310573, 'epoch': 0.7}
 70%|███████   | 774/1102 [10:54:37<4:29:10, 49.24s/it] 70%|███████   | 775/1102 [10:55:26<4:27:42, 49.12s/it]                                                       {'loss': 0.5781, 'learning_rate': 0.0002140155294024596, 'epoch': 0.7}
 70%|███████   | 775/1102 [10:55:26<4:27:42, 49.12s/it] 70%|███████   | 776/1102 [10:56:15<4:26:42, 49.09s/it]                                                       {'loss': 0.6722, 'learning_rate': 0.00021281032142972934, 'epoch': 0.7}
 70%|███████   | 776/1102 [10:56:15<4:26:42, 49.09s/it] 71%|███████   | 777/1102 [10:57:04<4:26:01, 49.11s/it]                                                       {'loss': 0.6421, 'learning_rate': 0.00021160759845334482, 'epoch': 0.7}
 71%|███████   | 777/1102 [10:57:04<4:26:01, 49.11s/it] 71%|███████   | 778/1102 [10:57:53<4:25:11, 49.11s/it]                                                       {'loss': 0.6519, 'learning_rate': 0.0002104073708802332, 'epoch': 0.71}
 71%|███████   | 778/1102 [10:57:53<4:25:11, 49.11s/it] 71%|███████   | 779/1102 [10:58:43<4:24:59, 49.22s/it]                                                       {'loss': 0.6276, 'learning_rate': 0.00020920964909573064, 'epoch': 0.71}
 71%|███████   | 779/1102 [10:58:43<4:24:59, 49.22s/it] 71%|███████   | 780/1102 [10:59:32<4:23:39, 49.13s/it]                                                       {'loss': 0.7225, 'learning_rate': 0.0002080144434634898, 'epoch': 0.71}
 71%|███████   | 780/1102 [10:59:32<4:23:39, 49.13s/it] 71%|███████   | 781/1102 [11:00:21<4:22:22, 49.04s/it]                                                       {'loss': 0.7034, 'learning_rate': 0.00020682176432539246, 'epoch': 0.71}
 71%|███████   | 781/1102 [11:00:21<4:22:22, 49.04s/it] 71%|███████   | 782/1102 [11:01:10<4:21:27, 49.02s/it]                                                       {'loss': 0.6924, 'learning_rate': 0.00020563162200145879, 'epoch': 0.71}
 71%|███████   | 782/1102 [11:01:10<4:21:27, 49.02s/it] 71%|███████   | 783/1102 [11:01:59<4:20:34, 49.01s/it]                                                       {'loss': 0.6623, 'learning_rate': 0.00020444402678975878, 'epoch': 0.71}
 71%|███████   | 783/1102 [11:01:59<4:20:34, 49.01s/it] 71%|███████   | 784/1102 [11:02:48<4:20:08, 49.08s/it]                                                       {'loss': 0.672, 'learning_rate': 0.00020325898896632178, 'epoch': 0.71}
 71%|███████   | 784/1102 [11:02:48<4:20:08, 49.08s/it] 71%|███████   | 785/1102 [11:03:37<4:19:28, 49.11s/it]                                                       {'loss': 0.6814, 'learning_rate': 0.00020207651878505, 'epoch': 0.71}
 71%|███████   | 785/1102 [11:03:37<4:19:28, 49.11s/it] 71%|███████▏  | 786/1102 [11:04:26<4:18:55, 49.16s/it]                                                       {'loss': 0.6773, 'learning_rate': 0.00020089662647762712, 'epoch': 0.71}
 71%|███████▏  | 786/1102 [11:04:26<4:18:55, 49.16s/it] 71%|███████▏  | 787/1102 [11:05:16<4:18:05, 49.16s/it]                                                       {'loss': 0.6886, 'learning_rate': 0.0001997193222534316, 'epoch': 0.71}
 71%|███████▏  | 787/1102 [11:05:16<4:18:05, 49.16s/it] 72%|███████▏  | 788/1102 [11:06:05<4:17:48, 49.26s/it]                                                       {'loss': 0.6762, 'learning_rate': 0.00019854461629944763, 'epoch': 0.71}
 72%|███████▏  | 788/1102 [11:06:05<4:17:48, 49.26s/it] 72%|███████▏  | 789/1102 [11:06:55<4:17:50, 49.43s/it]                                                       {'loss': 0.6936, 'learning_rate': 0.00019737251878017677, 'epoch': 0.72}
 72%|███████▏  | 789/1102 [11:06:55<4:17:50, 49.43s/it] 72%|███████▏  | 790/1102 [11:07:44<4:16:37, 49.35s/it]                                                       {'loss': 0.6446, 'learning_rate': 0.00019620303983755062, 'epoch': 0.72}
 72%|███████▏  | 790/1102 [11:07:44<4:16:37, 49.35s/it] 72%|███████▏  | 791/1102 [11:08:33<4:15:31, 49.30s/it]                                                       {'loss': 0.6089, 'learning_rate': 0.0001950361895908427, 'epoch': 0.72}
 72%|███████▏  | 791/1102 [11:08:33<4:15:31, 49.30s/it] 72%|███████▏  | 792/1102 [11:09:22<4:14:15, 49.21s/it]                                                       {'loss': 0.6484, 'learning_rate': 0.00019387197813658093, 'epoch': 0.72}
 72%|███████▏  | 792/1102 [11:09:22<4:14:15, 49.21s/it] 72%|███████▏  | 793/1102 [11:10:11<4:12:59, 49.12s/it]                                                       {'loss': 0.7092, 'learning_rate': 0.0001927104155484602, 'epoch': 0.72}
 72%|███████▏  | 793/1102 [11:10:11<4:12:59, 49.12s/it] 72%|███████▏  | 794/1102 [11:11:01<4:12:49, 49.25s/it]                                                       {'loss': 0.6651, 'learning_rate': 0.0001915515118772555, 'epoch': 0.72}
 72%|███████▏  | 794/1102 [11:11:01<4:12:49, 49.25s/it] 72%|███████▏  | 795/1102 [11:11:50<4:11:27, 49.14s/it]                                                       {'loss': 0.7249, 'learning_rate': 0.00019039527715073424, 'epoch': 0.72}
 72%|███████▏  | 795/1102 [11:11:50<4:11:27, 49.14s/it] 72%|███████▏  | 796/1102 [11:12:39<4:10:35, 49.14s/it]                                                       {'loss': 0.7472, 'learning_rate': 0.00018924172137357037, 'epoch': 0.72}
 72%|███████▏  | 796/1102 [11:12:39<4:10:35, 49.14s/it] 72%|███████▏  | 797/1102 [11:13:28<4:10:03, 49.19s/it]                                                       {'loss': 0.672, 'learning_rate': 0.00018809085452725744, 'epoch': 0.72}
 72%|███████▏  | 797/1102 [11:13:28<4:10:03, 49.19s/it] 72%|███████▏  | 798/1102 [11:14:19<4:11:24, 49.62s/it]                                                       {'loss': 0.6468, 'learning_rate': 0.00018694268657002195, 'epoch': 0.72}
 72%|███████▏  | 798/1102 [11:14:19<4:11:24, 49.62s/it] 73%|███████▎  | 799/1102 [11:15:13<4:17:19, 50.95s/it]                                                       {'loss': 0.6967, 'learning_rate': 0.0001857972274367377, 'epoch': 0.72}
 73%|███████▎  | 799/1102 [11:15:13<4:17:19, 50.95s/it] 73%|███████▎  | 800/1102 [11:20:09<10:26:49, 124.53s/it]                                                         {'loss': 0.6704, 'learning_rate': 0.00018465448703883957, 'epoch': 0.73}
 73%|███████▎  | 800/1102 [11:20:09<10:26:49, 124.53s/it] 73%|███████▎  | 801/1102 [11:20:57<8:30:12, 101.70s/it]                                                         {'loss': 0.6632, 'learning_rate': 0.00018351447526423724, 'epoch': 0.73}
 73%|███████▎  | 801/1102 [11:20:57<8:30:12, 101.70s/it] 73%|███████▎  | 802/1102 [11:21:46<7:09:38, 85.93s/it]                                                        {'loss': 0.6134, 'learning_rate': 0.00018237720197723074, 'epoch': 0.73}
 73%|███████▎  | 802/1102 [11:21:46<7:09:38, 85.93s/it] 73%|███████▎  | 803/1102 [11:22:35<6:12:29, 74.75s/it]                                                       {'loss': 0.6976, 'learning_rate': 0.00018124267701842428, 'epoch': 0.73}
 73%|███████▎  | 803/1102 [11:22:35<6:12:29, 74.75s/it] 73%|███████▎  | 804/1102 [11:23:25<5:33:30, 67.15s/it]                                                       {'loss': 0.7288, 'learning_rate': 0.00018011091020464138, 'epoch': 0.73}
 73%|███████▎  | 804/1102 [11:23:25<5:33:30, 67.15s/it] 73%|███████▎  | 805/1102 [11:24:14<5:05:27, 61.71s/it]                                                       {'loss': 0.66, 'learning_rate': 0.00017898191132883966, 'epoch': 0.73}
 73%|███████▎  | 805/1102 [11:24:14<5:05:27, 61.71s/it] 73%|███████▎  | 806/1102 [11:25:03<4:45:47, 57.93s/it]                                                       {'loss': 0.6799, 'learning_rate': 0.00017785569016002685, 'epoch': 0.73}
 73%|███████▎  | 806/1102 [11:25:03<4:45:47, 57.93s/it] 73%|███████▎  | 807/1102 [11:25:52<4:31:59, 55.32s/it]                                                       {'loss': 0.5742, 'learning_rate': 0.00017673225644317486, 'epoch': 0.73}
 73%|███████▎  | 807/1102 [11:25:52<4:31:59, 55.32s/it] 73%|███████▎  | 808/1102 [11:26:40<4:20:14, 53.11s/it]                                                       {'loss': 0.7344, 'learning_rate': 0.00017561161989913698, 'epoch': 0.73}
 73%|███████▎  | 808/1102 [11:26:40<4:20:14, 53.11s/it] 73%|███████▎  | 809/1102 [11:27:29<4:13:42, 51.95s/it]                                                       {'loss': 0.6574, 'learning_rate': 0.00017449379022456296, 'epoch': 0.73}
 73%|███████▎  | 809/1102 [11:27:29<4:13:42, 51.95s/it] 74%|███████▎  | 810/1102 [11:28:18<4:09:00, 51.17s/it]                                                       {'loss': 0.6276, 'learning_rate': 0.00017337877709181526, 'epoch': 0.73}
 74%|███████▎  | 810/1102 [11:28:18<4:09:00, 51.17s/it] 74%|███████▎  | 811/1102 [11:29:08<4:05:39, 50.65s/it]                                                       {'loss': 0.6291, 'learning_rate': 0.00017226659014888546, 'epoch': 0.74}
 74%|███████▎  | 811/1102 [11:29:08<4:05:39, 50.65s/it] 74%|███████▎  | 812/1102 [11:29:57<4:02:53, 50.25s/it]                                                       {'loss': 0.6675, 'learning_rate': 0.0001711572390193102, 'epoch': 0.74}
 74%|███████▎  | 812/1102 [11:29:57<4:02:53, 50.25s/it] 74%|███████▍  | 813/1102 [11:30:47<4:01:15, 50.09s/it]                                                       {'loss': 0.6298, 'learning_rate': 0.00017005073330208882, 'epoch': 0.74}
 74%|███████▍  | 813/1102 [11:30:47<4:01:15, 50.09s/it] 74%|███████▍  | 814/1102 [11:31:34<3:55:22, 49.04s/it]                                                       {'loss': 0.6632, 'learning_rate': 0.0001689470825715998, 'epoch': 0.74}
 74%|███████▍  | 814/1102 [11:31:34<3:55:22, 49.04s/it] 74%|███████▍  | 815/1102 [11:32:23<3:55:05, 49.15s/it]                                                       {'loss': 0.6887, 'learning_rate': 0.00016784629637751813, 'epoch': 0.74}
 74%|███████▍  | 815/1102 [11:32:23<3:55:05, 49.15s/it] 74%|███████▍  | 816/1102 [11:33:12<3:54:39, 49.23s/it]                                                       {'loss': 0.6309, 'learning_rate': 0.00016674838424473172, 'epoch': 0.74}
 74%|███████▍  | 816/1102 [11:33:12<3:54:39, 49.23s/it] 74%|███████▍  | 817/1102 [11:34:01<3:52:55, 49.04s/it]                                                       {'loss': 0.6749, 'learning_rate': 0.00016565335567326111, 'epoch': 0.74}
 74%|███████▍  | 817/1102 [11:34:01<3:52:55, 49.04s/it] 74%|███████▍  | 818/1102 [11:34:50<3:52:20, 49.09s/it]                                                       {'loss': 0.6579, 'learning_rate': 0.00016456122013817475, 'epoch': 0.74}
 74%|███████▍  | 818/1102 [11:34:50<3:52:20, 49.09s/it] 74%|███████▍  | 819/1102 [11:35:39<3:51:17, 49.04s/it]                                                       {'loss': 0.6714, 'learning_rate': 0.00016347198708950884, 'epoch': 0.74}
 74%|███████▍  | 819/1102 [11:35:39<3:51:17, 49.04s/it] 74%|███████▍  | 820/1102 [11:36:28<3:50:36, 49.07s/it]                                                       {'loss': 0.6479, 'learning_rate': 0.00016238566595218473, 'epoch': 0.74}
 74%|███████▍  | 820/1102 [11:36:28<3:50:36, 49.07s/it] 75%|███████▍  | 821/1102 [11:37:18<3:51:20, 49.40s/it]                                                       {'loss': 0.617, 'learning_rate': 0.00016130226612592785, 'epoch': 0.74}
 75%|███████▍  | 821/1102 [11:37:19<3:51:20, 49.40s/it] 75%|███████▍  | 822/1102 [11:40:27<7:05:52, 91.26s/it]                                                       {'loss': 0.6332, 'learning_rate': 0.00016022179698518525, 'epoch': 0.75}
 75%|███████▍  | 822/1102 [11:40:27<7:05:52, 91.26s/it] 75%|███████▍  | 823/1102 [11:41:22<6:12:53, 80.19s/it]                                                       {'loss': 0.6769, 'learning_rate': 0.00015914426787904667, 'epoch': 0.75}
 75%|███████▍  | 823/1102 [11:41:22<6:12:53, 80.19s/it] 75%|███████▍  | 824/1102 [11:42:11<5:28:31, 70.91s/it]                                                       {'loss': 0.7077, 'learning_rate': 0.00015806968813116107, 'epoch': 0.75}
 75%|███████▍  | 824/1102 [11:42:11<5:28:31, 70.91s/it] 75%|███████▍  | 825/1102 [11:43:00<4:57:10, 64.37s/it]                                                       {'loss': 0.6725, 'learning_rate': 0.00015699806703965786, 'epoch': 0.75}
 75%|███████▍  | 825/1102 [11:43:00<4:57:10, 64.37s/it] 75%|███████▍  | 826/1102 [11:43:49<4:34:57, 59.77s/it]                                                       {'loss': 0.6784, 'learning_rate': 0.0001559294138770656, 'epoch': 0.75}
 75%|███████▍  | 826/1102 [11:43:49<4:34:57, 59.77s/it] 75%|███████▌  | 827/1102 [11:44:38<4:19:28, 56.61s/it]                                                       {'loss': 0.6585, 'learning_rate': 0.00015486373789023205, 'epoch': 0.75}
 75%|███████▌  | 827/1102 [11:44:38<4:19:28, 56.61s/it] 75%|███████▌  | 828/1102 [11:45:28<4:08:29, 54.41s/it]                                                       {'loss': 0.6913, 'learning_rate': 0.00015380104830024348, 'epoch': 0.75}
 75%|███████▌  | 828/1102 [11:45:28<4:08:29, 54.41s/it] 75%|███████▌  | 829/1102 [11:46:17<4:00:38, 52.89s/it]                                                       {'loss': 0.5985, 'learning_rate': 0.00015274135430234654, 'epoch': 0.75}
 75%|███████▌  | 829/1102 [11:46:17<4:00:38, 52.89s/it] 75%|███████▌  | 830/1102 [11:47:06<3:54:34, 51.74s/it]                                                       {'loss': 0.6811, 'learning_rate': 0.00015168466506586652, 'epoch': 0.75}
 75%|███████▌  | 830/1102 [11:47:06<3:54:34, 51.74s/it] 75%|███████▌  | 831/1102 [11:47:55<3:50:07, 50.95s/it]                                                       {'loss': 0.6484, 'learning_rate': 0.0001506309897341297, 'epoch': 0.75}
 75%|███████▌  | 831/1102 [11:47:55<3:50:07, 50.95s/it] 75%|███████▌  | 832/1102 [11:48:44<3:46:52, 50.42s/it]                                                       {'loss': 0.6306, 'learning_rate': 0.00014958033742438348, 'epoch': 0.75}
 75%|███████▌  | 832/1102 [11:48:44<3:46:52, 50.42s/it] 76%|███████▌  | 833/1102 [11:49:33<3:43:48, 49.92s/it]                                                       {'loss': 0.6676, 'learning_rate': 0.00014853271722771772, 'epoch': 0.76}
 76%|███████▌  | 833/1102 [11:49:33<3:43:48, 49.92s/it] 76%|███████▌  | 834/1102 [11:50:22<3:41:50, 49.67s/it]                                                       {'loss': 0.6854, 'learning_rate': 0.00014748813820898555, 'epoch': 0.76}
 76%|███████▌  | 834/1102 [11:50:22<3:41:50, 49.67s/it] 76%|███████▌  | 835/1102 [11:51:11<3:40:26, 49.54s/it]                                                       {'loss': 0.6492, 'learning_rate': 0.00014644660940672628, 'epoch': 0.76}
 76%|███████▌  | 835/1102 [11:51:11<3:40:26, 49.54s/it] 76%|███████▌  | 836/1102 [11:52:01<3:39:39, 49.55s/it]                                                       {'loss': 0.6754, 'learning_rate': 0.0001454081398330855, 'epoch': 0.76}
 76%|███████▌  | 836/1102 [11:52:01<3:39:39, 49.55s/it] 76%|███████▌  | 837/1102 [11:52:50<3:38:24, 49.45s/it]                                                       {'loss': 0.6488, 'learning_rate': 0.0001443727384737378, 'epoch': 0.76}
 76%|███████▌  | 837/1102 [11:52:50<3:38:24, 49.45s/it] 76%|███████▌  | 838/1102 [11:53:40<3:37:30, 49.43s/it]                                                       {'loss': 0.6847, 'learning_rate': 0.00014334041428781002, 'epoch': 0.76}
 76%|███████▌  | 838/1102 [11:53:40<3:37:30, 49.43s/it] 76%|███████▌  | 839/1102 [11:54:29<3:36:09, 49.31s/it]                                                       {'loss': 0.7172, 'learning_rate': 0.00014231117620780188, 'epoch': 0.76}
 76%|███████▌  | 839/1102 [11:54:29<3:36:09, 49.31s/it] 76%|███████▌  | 840/1102 [11:55:18<3:35:16, 49.30s/it]                                                       {'loss': 0.6651, 'learning_rate': 0.00014128503313951007, 'epoch': 0.76}
 76%|███████▌  | 840/1102 [11:55:18<3:35:16, 49.30s/it] 76%|███████▋  | 841/1102 [11:56:07<3:33:48, 49.15s/it]                                                       {'loss': 0.6575, 'learning_rate': 0.00014026199396195078, 'epoch': 0.76}
 76%|███████▋  | 841/1102 [11:56:07<3:33:48, 49.15s/it] 76%|███████▋  | 842/1102 [11:56:56<3:32:51, 49.12s/it]                                                       {'loss': 0.6762, 'learning_rate': 0.0001392420675272828, 'epoch': 0.76}
 76%|███████▋  | 842/1102 [11:56:56<3:32:51, 49.12s/it] 76%|███████▋  | 843/1102 [11:57:45<3:32:19, 49.19s/it]                                                       {'loss': 0.7123, 'learning_rate': 0.00013822526266073044, 'epoch': 0.76}
 76%|███████▋  | 843/1102 [11:57:45<3:32:19, 49.19s/it] 77%|███████▋  | 844/1102 [11:58:34<3:31:50, 49.26s/it]                                                       {'loss': 0.7012, 'learning_rate': 0.00013721158816050873, 'epoch': 0.77}
 77%|███████▋  | 844/1102 [11:58:34<3:31:50, 49.26s/it] 77%|███████▋  | 845/1102 [11:59:24<3:31:23, 49.35s/it]                                                       {'loss': 0.6811, 'learning_rate': 0.0001362010527977453, 'epoch': 0.77}
 77%|███████▋  | 845/1102 [11:59:24<3:31:23, 49.35s/it] 77%|███████▋  | 846/1102 [12:00:13<3:30:05, 49.24s/it]                                                       {'loss': 0.7343, 'learning_rate': 0.00013519366531640587, 'epoch': 0.77}
 77%|███████▋  | 846/1102 [12:00:13<3:30:05, 49.24s/it] 77%|███████▋  | 847/1102 [12:01:02<3:29:18, 49.25s/it]                                                       {'loss': 0.688, 'learning_rate': 0.00013418943443321808, 'epoch': 0.77}
 77%|███████▋  | 847/1102 [12:01:02<3:29:18, 49.25s/it] 77%|███████▋  | 848/1102 [12:01:52<3:28:28, 49.25s/it]                                                       {'loss': 0.6553, 'learning_rate': 0.00013318836883759633, 'epoch': 0.77}
 77%|███████▋  | 848/1102 [12:01:52<3:28:28, 49.25s/it] 77%|███████▋  | 849/1102 [12:02:41<3:27:36, 49.23s/it]                                                       {'loss': 0.7042, 'learning_rate': 0.00013219047719156574, 'epoch': 0.77}
 77%|███████▋  | 849/1102 [12:02:41<3:27:36, 49.23s/it] 77%|███████▋  | 850/1102 [12:03:30<3:27:25, 49.39s/it]                                                       {'loss': 0.633, 'learning_rate': 0.00013119576812968892, 'epoch': 0.77}
 77%|███████▋  | 850/1102 [12:03:30<3:27:25, 49.39s/it] 77%|███████▋  | 851/1102 [12:04:19<3:26:00, 49.25s/it]                                                       {'loss': 0.7076, 'learning_rate': 0.00013020425025898923, 'epoch': 0.77}
 77%|███████▋  | 851/1102 [12:04:19<3:26:00, 49.25s/it] 77%|███████▋  | 852/1102 [12:05:09<3:25:03, 49.22s/it]                                                       {'loss': 0.6896, 'learning_rate': 0.00012921593215887777, 'epoch': 0.77}
 77%|███████▋  | 852/1102 [12:05:09<3:25:03, 49.22s/it] 77%|███████▋  | 853/1102 [12:05:57<3:23:24, 49.01s/it]                                                       {'loss': 0.6491, 'learning_rate': 0.00012823082238107858, 'epoch': 0.77}
 77%|███████▋  | 853/1102 [12:05:57<3:23:24, 49.01s/it] 77%|███████▋  | 854/1102 [12:06:46<3:22:48, 49.06s/it]                                                       {'loss': 0.6488, 'learning_rate': 0.0001272489294495548, 'epoch': 0.77}
 77%|███████▋  | 854/1102 [12:06:46<3:22:48, 49.06s/it] 78%|███████▊  | 855/1102 [12:07:36<3:22:24, 49.17s/it]                                                       {'loss': 0.7039, 'learning_rate': 0.0001262702618604342, 'epoch': 0.78}
 78%|███████▊  | 855/1102 [12:07:36<3:22:24, 49.17s/it] 78%|███████▊  | 856/1102 [12:08:25<3:21:48, 49.22s/it]                                                       {'loss': 0.6421, 'learning_rate': 0.0001252948280819375, 'epoch': 0.78}
 78%|███████▊  | 856/1102 [12:08:25<3:21:48, 49.22s/it] 78%|███████▊  | 857/1102 [12:09:14<3:21:14, 49.29s/it]                                                       {'loss': 0.628, 'learning_rate': 0.0001243226365543026, 'epoch': 0.78}
 78%|███████▊  | 857/1102 [12:09:14<3:21:14, 49.29s/it] 78%|███████▊  | 858/1102 [12:10:04<3:20:29, 49.30s/it]                                                       {'loss': 0.6856, 'learning_rate': 0.0001233536956897136, 'epoch': 0.78}
 78%|███████▊  | 858/1102 [12:10:04<3:20:29, 49.30s/it] 78%|███████▊  | 859/1102 [12:10:52<3:18:46, 49.08s/it]                                                       {'loss': 0.6941, 'learning_rate': 0.00012238801387222715, 'epoch': 0.78}
 78%|███████▊  | 859/1102 [12:10:52<3:18:46, 49.08s/it] 78%|███████▊  | 860/1102 [12:11:42<3:18:27, 49.20s/it]                                                       {'loss': 0.6617, 'learning_rate': 0.00012142559945769993, 'epoch': 0.78}
 78%|███████▊  | 860/1102 [12:11:42<3:18:27, 49.20s/it] 78%|███████▊  | 861/1102 [12:12:31<3:17:10, 49.09s/it]                                                       {'loss': 0.6963, 'learning_rate': 0.00012046646077371615, 'epoch': 0.78}
 78%|███████▊  | 861/1102 [12:12:31<3:17:10, 49.09s/it] 78%|███████▊  | 862/1102 [12:13:20<3:16:30, 49.13s/it]                                                       {'loss': 0.6148, 'learning_rate': 0.00011951060611951614, 'epoch': 0.78}
 78%|███████▊  | 862/1102 [12:13:20<3:16:30, 49.13s/it] 78%|███████▊  | 863/1102 [12:14:09<3:15:45, 49.14s/it]                                                       {'loss': 0.6841, 'learning_rate': 0.00011855804376592411, 'epoch': 0.78}
 78%|███████▊  | 863/1102 [12:14:09<3:15:45, 49.14s/it] 78%|███████▊  | 864/1102 [12:15:02<3:19:04, 50.19s/it]                                                       {'loss': 0.6616, 'learning_rate': 0.00011760878195527641, 'epoch': 0.78}
 78%|███████▊  | 864/1102 [12:15:02<3:19:04, 50.19s/it] 78%|███████▊  | 865/1102 [12:16:40<4:15:02, 64.57s/it]                                                       {'loss': 0.6842, 'learning_rate': 0.00011666282890135083, 'epoch': 0.78}
 78%|███████▊  | 865/1102 [12:16:40<4:15:02, 64.57s/it] 79%|███████▊  | 866/1102 [12:17:30<3:56:29, 60.13s/it]                                                       {'loss': 0.6023, 'learning_rate': 0.00011572019278929458, 'epoch': 0.79}
 79%|███████▊  | 866/1102 [12:17:30<3:56:29, 60.13s/it] 79%|███████▊  | 867/1102 [12:18:19<3:42:36, 56.84s/it]                                                       {'loss': 0.6509, 'learning_rate': 0.0001147808817755544, 'epoch': 0.79}
 79%|███████▊  | 867/1102 [12:18:19<3:42:36, 56.84s/it] 79%|███████▉  | 868/1102 [12:19:08<3:32:26, 54.47s/it]                                                       {'loss': 0.652, 'learning_rate': 0.00011384490398780561, 'epoch': 0.79}
 79%|███████▉  | 868/1102 [12:19:08<3:32:26, 54.47s/it] 79%|███████▉  | 869/1102 [12:19:57<3:25:24, 52.90s/it]                                                       {'loss': 0.6861, 'learning_rate': 0.0001129122675248816, 'epoch': 0.79}
 79%|███████▉  | 869/1102 [12:19:57<3:25:24, 52.90s/it] 79%|███████▉  | 870/1102 [12:20:46<3:19:42, 51.65s/it]                                                       {'loss': 0.6563, 'learning_rate': 0.00011198298045670402, 'epoch': 0.79}
 79%|███████▉  | 870/1102 [12:20:46<3:19:42, 51.65s/it] 79%|███████▉  | 871/1102 [12:21:35<3:16:04, 50.93s/it]                                                       {'loss': 0.6298, 'learning_rate': 0.00011105705082421302, 'epoch': 0.79}
 79%|███████▉  | 871/1102 [12:21:35<3:16:04, 50.93s/it] 79%|███████▉  | 872/1102 [12:22:24<3:13:25, 50.46s/it]                                                       {'loss': 0.6792, 'learning_rate': 0.00011013448663929704, 'epoch': 0.79}
 79%|███████▉  | 872/1102 [12:22:24<3:13:25, 50.46s/it] 79%|███████▉  | 873/1102 [12:23:13<3:11:05, 50.07s/it]                                                       {'loss': 0.7313, 'learning_rate': 0.00010921529588472445, 'epoch': 0.79}
 79%|███████▉  | 873/1102 [12:23:13<3:11:05, 50.07s/it] 79%|███████▉  | 874/1102 [12:24:02<3:09:07, 49.77s/it]                                                       {'loss': 0.6862, 'learning_rate': 0.00010829948651407373, 'epoch': 0.79}
 79%|███████▉  | 874/1102 [12:24:02<3:09:07, 49.77s/it] 79%|███████▉  | 875/1102 [12:24:52<3:07:32, 49.57s/it]                                                       {'loss': 0.5968, 'learning_rate': 0.00010738706645166507, 'epoch': 0.79}
 79%|███████▉  | 875/1102 [12:24:52<3:07:32, 49.57s/it] 79%|███████▉  | 876/1102 [12:25:40<3:05:23, 49.22s/it]                                                       {'loss': 0.7193, 'learning_rate': 0.00010647804359249141, 'epoch': 0.79}
 79%|███████▉  | 876/1102 [12:25:40<3:05:23, 49.22s/it] 80%|███████▉  | 877/1102 [12:26:29<3:04:08, 49.10s/it]                                                       {'loss': 0.6653, 'learning_rate': 0.00010557242580215066, 'epoch': 0.8}
 80%|███████▉  | 877/1102 [12:26:29<3:04:08, 49.10s/it] 80%|███████▉  | 878/1102 [12:27:18<3:03:53, 49.26s/it]                                                       {'loss': 0.6415, 'learning_rate': 0.00010467022091677691, 'epoch': 0.8}
 80%|███████▉  | 878/1102 [12:27:18<3:03:53, 49.26s/it] 80%|███████▉  | 879/1102 [12:28:08<3:03:06, 49.27s/it]                                                       {'loss': 0.6883, 'learning_rate': 0.0001037714367429734, 'epoch': 0.8}
 80%|███████▉  | 879/1102 [12:28:08<3:03:06, 49.27s/it] 80%|███████▉  | 880/1102 [12:28:57<3:02:10, 49.24s/it]                                                       {'loss': 0.6568, 'learning_rate': 0.00010287608105774454, 'epoch': 0.8}
 80%|███████▉  | 880/1102 [12:28:57<3:02:10, 49.24s/it] 80%|███████▉  | 881/1102 [12:29:46<3:00:49, 49.09s/it]                                                       {'loss': 0.6516, 'learning_rate': 0.0001019841616084286, 'epoch': 0.8}
 80%|███████▉  | 881/1102 [12:29:46<3:00:49, 49.09s/it] 80%|████████  | 882/1102 [12:30:35<3:00:16, 49.17s/it]                                                       {'loss': 0.6913, 'learning_rate': 0.00010109568611263092, 'epoch': 0.8}
 80%|████████  | 882/1102 [12:30:35<3:00:16, 49.17s/it] 80%|████████  | 883/1102 [12:31:24<2:59:20, 49.14s/it]                                                       {'loss': 0.6965, 'learning_rate': 0.00010021066225815689, 'epoch': 0.8}
 80%|████████  | 883/1102 [12:31:24<2:59:20, 49.14s/it] 80%|████████  | 884/1102 [12:32:12<2:57:30, 48.85s/it]                                                       {'loss': 0.7026, 'learning_rate': 9.932909770294541e-05, 'epoch': 0.8}
 80%|████████  | 884/1102 [12:32:12<2:57:30, 48.85s/it] 80%|████████  | 885/1102 [12:33:02<2:57:29, 49.08s/it]                                                       {'loss': 0.646, 'learning_rate': 9.845100007500291e-05, 'epoch': 0.8}
 80%|████████  | 885/1102 [12:33:02<2:57:29, 49.08s/it] 80%|████████  | 886/1102 [12:33:51<2:57:15, 49.24s/it]                                                       {'loss': 0.6871, 'learning_rate': 9.757637697233723e-05, 'epoch': 0.8}
 80%|████████  | 886/1102 [12:33:51<2:57:15, 49.24s/it] 80%|████████  | 887/1102 [12:34:41<2:56:39, 49.30s/it]                                                       {'loss': 0.6411, 'learning_rate': 9.670523596289137e-05, 'epoch': 0.8}
 80%|████████  | 887/1102 [12:34:41<2:56:39, 49.30s/it] 81%|████████  | 888/1102 [12:35:30<2:55:08, 49.10s/it]                                                       {'loss': 0.6501, 'learning_rate': 9.583758458447928e-05, 'epoch': 0.81}
 81%|████████  | 888/1102 [12:35:30<2:55:08, 49.10s/it] 81%|████████  | 889/1102 [12:36:19<2:54:29, 49.15s/it]                                                       {'loss': 0.6679, 'learning_rate': 9.497343034471895e-05, 'epoch': 0.81}
 81%|████████  | 889/1102 [12:36:19<2:54:29, 49.15s/it] 81%|████████  | 890/1102 [12:37:08<2:53:56, 49.23s/it]                                                       {'loss': 0.6137, 'learning_rate': 9.41127807209688e-05, 'epoch': 0.81}
 81%|████████  | 890/1102 [12:37:08<2:53:56, 49.23s/it] 81%|████████  | 891/1102 [12:37:57<2:53:08, 49.23s/it]                                                       {'loss': 0.7205, 'learning_rate': 9.325564316026235e-05, 'epoch': 0.81}
 81%|████████  | 891/1102 [12:37:57<2:53:08, 49.23s/it] 81%|████████  | 892/1102 [12:38:47<2:52:26, 49.27s/it]                                                       {'loss': 0.6718, 'learning_rate': 9.240202507924412e-05, 'epoch': 0.81}
 81%|████████  | 892/1102 [12:38:47<2:52:26, 49.27s/it] 81%|████████  | 893/1102 [12:39:35<2:51:01, 49.10s/it]                                                       {'loss': 0.7008, 'learning_rate': 9.155193386410465e-05, 'epoch': 0.81}
 81%|████████  | 893/1102 [12:39:35<2:51:01, 49.10s/it] 81%|████████  | 894/1102 [12:40:25<2:50:21, 49.14s/it]                                                       {'loss': 0.6841, 'learning_rate': 9.070537687051816e-05, 'epoch': 0.81}
 81%|████████  | 894/1102 [12:40:25<2:50:21, 49.14s/it] 81%|████████  | 895/1102 [12:41:14<2:49:23, 49.10s/it]                                                       {'loss': 0.6735, 'learning_rate': 8.986236142357706e-05, 'epoch': 0.81}
 81%|████████  | 895/1102 [12:41:14<2:49:23, 49.10s/it] 81%|████████▏ | 896/1102 [12:42:03<2:48:38, 49.12s/it]                                                       {'loss': 0.6595, 'learning_rate': 8.902289481772997e-05, 'epoch': 0.81}
 81%|████████▏ | 896/1102 [12:42:03<2:48:38, 49.12s/it] 81%|████████▏ | 897/1102 [12:42:52<2:47:40, 49.07s/it]                                                       {'loss': 0.6631, 'learning_rate': 8.818698431671773e-05, 'epoch': 0.81}
 81%|████████▏ | 897/1102 [12:42:52<2:47:40, 49.07s/it] 81%|████████▏ | 898/1102 [12:43:41<2:47:10, 49.17s/it]                                                       {'loss': 0.6375, 'learning_rate': 8.735463715351138e-05, 'epoch': 0.81}
 81%|████████▏ | 898/1102 [12:43:41<2:47:10, 49.17s/it] 82%|████████▏ | 899/1102 [12:44:31<2:46:37, 49.25s/it]                                                       {'loss': 0.6755, 'learning_rate': 8.652586053024835e-05, 'epoch': 0.82}
 82%|████████▏ | 899/1102 [12:44:31<2:46:37, 49.25s/it] 82%|████████▏ | 900/1102 [12:45:20<2:45:35, 49.18s/it]                                                       {'loss': 0.6801, 'learning_rate': 8.570066161817174e-05, 'epoch': 0.82}
 82%|████████▏ | 900/1102 [12:45:20<2:45:35, 49.18s/it] 82%|████████▏ | 901/1102 [12:46:09<2:44:38, 49.14s/it]                                                       {'loss': 0.675, 'learning_rate': 8.487904755756676e-05, 'epoch': 0.82}
 82%|████████▏ | 901/1102 [12:46:09<2:44:38, 49.14s/it] 82%|████████▏ | 902/1102 [12:46:58<2:44:22, 49.31s/it]                                                       {'loss': 0.7061, 'learning_rate': 8.406102545769989e-05, 'epoch': 0.82}
 82%|████████▏ | 902/1102 [12:46:58<2:44:22, 49.31s/it] 82%|████████▏ | 903/1102 [12:47:48<2:43:21, 49.25s/it]                                                       {'loss': 0.6753, 'learning_rate': 8.324660239675697e-05, 'epoch': 0.82}
 82%|████████▏ | 903/1102 [12:47:48<2:43:21, 49.25s/it] 82%|████████▏ | 904/1102 [12:48:37<2:42:33, 49.26s/it]                                                       {'loss': 0.661, 'learning_rate': 8.243578542178227e-05, 'epoch': 0.82}
 82%|████████▏ | 904/1102 [12:48:37<2:42:33, 49.26s/it] 82%|████████▏ | 905/1102 [12:49:26<2:41:29, 49.19s/it]                                                       {'loss': 0.6604, 'learning_rate': 8.16285815486168e-05, 'epoch': 0.82}
 82%|████████▏ | 905/1102 [12:49:26<2:41:29, 49.19s/it] 82%|████████▏ | 906/1102 [12:50:15<2:40:58, 49.28s/it]                                                       {'loss': 0.6334, 'learning_rate': 8.082499776183883e-05, 'epoch': 0.82}
 82%|████████▏ | 906/1102 [12:50:15<2:40:58, 49.28s/it] 82%|████████▏ | 907/1102 [12:51:05<2:40:20, 49.34s/it]                                                       {'loss': 0.674, 'learning_rate': 8.002504101470203e-05, 'epoch': 0.82}
 82%|████████▏ | 907/1102 [12:51:05<2:40:20, 49.34s/it] 82%|████████▏ | 908/1102 [12:51:54<2:39:33, 49.35s/it]                                                       {'loss': 0.6888, 'learning_rate': 7.92287182290764e-05, 'epoch': 0.82}
 82%|████████▏ | 908/1102 [12:51:54<2:39:33, 49.35s/it] 82%|████████▏ | 909/1102 [12:52:43<2:38:35, 49.30s/it]                                                       {'loss': 0.6848, 'learning_rate': 7.843603629538803e-05, 'epoch': 0.82}
 82%|████████▏ | 909/1102 [12:52:43<2:38:35, 49.30s/it] 83%|████████▎ | 910/1102 [12:53:32<2:37:15, 49.14s/it]                                                       {'loss': 0.6501, 'learning_rate': 7.764700207255904e-05, 'epoch': 0.83}
 83%|████████▎ | 910/1102 [12:53:32<2:37:15, 49.14s/it] 83%|████████▎ | 911/1102 [12:54:22<2:36:39, 49.21s/it]                                                       {'loss': 0.6947, 'learning_rate': 7.686162238794897e-05, 'epoch': 0.83}
 83%|████████▎ | 911/1102 [12:54:22<2:36:39, 49.21s/it] 83%|████████▎ | 912/1102 [12:55:11<2:35:57, 49.25s/it]                                                       {'loss': 0.6444, 'learning_rate': 7.607990403729526e-05, 'epoch': 0.83}
 83%|████████▎ | 912/1102 [12:55:11<2:35:57, 49.25s/it] 83%|████████▎ | 913/1102 [12:56:00<2:34:56, 49.19s/it]                                                       {'loss': 0.7136, 'learning_rate': 7.530185378465459e-05, 'epoch': 0.83}
 83%|████████▎ | 913/1102 [12:56:00<2:34:56, 49.19s/it] 83%|████████▎ | 914/1102 [12:56:49<2:34:06, 49.18s/it]                                                       {'loss': 0.6664, 'learning_rate': 7.452747836234392e-05, 'epoch': 0.83}
 83%|████████▎ | 914/1102 [12:56:49<2:34:06, 49.18s/it] 83%|████████▎ | 915/1102 [12:57:38<2:33:05, 49.12s/it]                                                       {'loss': 0.6936, 'learning_rate': 7.375678447088347e-05, 'epoch': 0.83}
 83%|████████▎ | 915/1102 [12:57:38<2:33:05, 49.12s/it] 83%|████████▎ | 916/1102 [12:58:27<2:32:10, 49.09s/it]                                                       {'loss': 0.642, 'learning_rate': 7.298977877893686e-05, 'epoch': 0.83}
 83%|████████▎ | 916/1102 [12:58:27<2:32:10, 49.09s/it] 83%|████████▎ | 917/1102 [12:59:16<2:31:01, 48.98s/it]                                                       {'loss': 0.711, 'learning_rate': 7.222646792325515e-05, 'epoch': 0.83}
 83%|████████▎ | 917/1102 [12:59:16<2:31:01, 48.98s/it] 83%|████████▎ | 918/1102 [13:00:05<2:30:16, 49.01s/it]                                                       {'loss': 0.7041, 'learning_rate': 7.146685850861851e-05, 'epoch': 0.83}
 83%|████████▎ | 918/1102 [13:00:05<2:30:16, 49.01s/it] 83%|████████▎ | 919/1102 [13:00:55<2:30:04, 49.21s/it]                                                       {'loss': 0.6625, 'learning_rate': 7.071095710777925e-05, 'epoch': 0.83}
 83%|████████▎ | 919/1102 [13:00:55<2:30:04, 49.21s/it] 83%|████████▎ | 920/1102 [13:01:44<2:29:14, 49.20s/it]                                                       {'loss': 0.6741, 'learning_rate': 6.995877026140468e-05, 'epoch': 0.83}
 83%|████████▎ | 920/1102 [13:01:44<2:29:14, 49.20s/it] 84%|████████▎ | 921/1102 [13:02:33<2:28:24, 49.20s/it]                                                       {'loss': 0.6483, 'learning_rate': 6.921030447802146e-05, 'epoch': 0.84}
 84%|████████▎ | 921/1102 [13:02:33<2:28:24, 49.20s/it] 84%|████████▎ | 922/1102 [13:03:22<2:27:30, 49.17s/it]                                                       {'loss': 0.6713, 'learning_rate': 6.846556623395794e-05, 'epoch': 0.84}
 84%|████████▎ | 922/1102 [13:03:22<2:27:30, 49.17s/it] 84%|████████▍ | 923/1102 [13:04:11<2:26:44, 49.19s/it]                                                       {'loss': 0.6364, 'learning_rate': 6.772456197328918e-05, 'epoch': 0.84}
 84%|████████▍ | 923/1102 [13:04:11<2:26:44, 49.19s/it] 84%|████████▍ | 924/1102 [13:05:00<2:25:36, 49.08s/it]                                                       {'loss': 0.6289, 'learning_rate': 6.698729810778065e-05, 'epoch': 0.84}
 84%|████████▍ | 924/1102 [13:05:00<2:25:36, 49.08s/it] 84%|████████▍ | 925/1102 [13:05:49<2:24:56, 49.13s/it]                                                       {'loss': 0.6931, 'learning_rate': 6.625378101683316e-05, 'epoch': 0.84}
 84%|████████▍ | 925/1102 [13:05:49<2:24:56, 49.13s/it] 84%|████████▍ | 926/1102 [13:06:39<2:24:34, 49.29s/it]                                                       {'loss': 0.6798, 'learning_rate': 6.552401704742678e-05, 'epoch': 0.84}
 84%|████████▍ | 926/1102 [13:06:39<2:24:34, 49.29s/it] 84%|████████▍ | 927/1102 [13:07:28<2:23:29, 49.20s/it]                                                       {'loss': 0.6489, 'learning_rate': 6.479801251406747e-05, 'epoch': 0.84}
 84%|████████▍ | 927/1102 [13:07:28<2:23:29, 49.20s/it] 84%|████████▍ | 928/1102 [13:08:17<2:22:15, 49.05s/it]                                                       {'loss': 0.6709, 'learning_rate': 6.407577369873069e-05, 'epoch': 0.84}
 84%|████████▍ | 928/1102 [13:08:17<2:22:15, 49.05s/it] 84%|████████▍ | 929/1102 [13:09:06<2:21:23, 49.04s/it]                                                       {'loss': 0.708, 'learning_rate': 6.335730685080838e-05, 'epoch': 0.84}
 84%|████████▍ | 929/1102 [13:09:06<2:21:23, 49.04s/it] 84%|████████▍ | 930/1102 [13:09:55<2:20:36, 49.05s/it]                                                       {'loss': 0.7306, 'learning_rate': 6.264261818705419e-05, 'epoch': 0.84}
 84%|████████▍ | 930/1102 [13:09:55<2:20:36, 49.05s/it] 84%|████████▍ | 931/1102 [13:10:44<2:19:46, 49.04s/it]                                                       {'loss': 0.6756, 'learning_rate': 6.193171389152996e-05, 'epoch': 0.84}
 84%|████████▍ | 931/1102 [13:10:44<2:19:46, 49.04s/it] 85%|████████▍ | 932/1102 [13:11:33<2:19:10, 49.12s/it]                                                       {'loss': 0.6574, 'learning_rate': 6.122460011555187e-05, 'epoch': 0.85}
 85%|████████▍ | 932/1102 [13:11:33<2:19:10, 49.12s/it] 85%|████████▍ | 933/1102 [13:12:22<2:18:20, 49.11s/it]                                                       {'loss': 0.6586, 'learning_rate': 6.052128297763804e-05, 'epoch': 0.85}
 85%|████████▍ | 933/1102 [13:12:22<2:18:20, 49.11s/it] 85%|████████▍ | 934/1102 [13:13:11<2:17:28, 49.10s/it]                                                       {'loss': 0.6641, 'learning_rate': 5.982176856345445e-05, 'epoch': 0.85}
 85%|████████▍ | 934/1102 [13:13:11<2:17:28, 49.10s/it] 85%|████████▍ | 935/1102 [13:14:01<2:17:00, 49.22s/it]                                                       {'loss': 0.6302, 'learning_rate': 5.9126062925762836e-05, 'epoch': 0.85}
 85%|████████▍ | 935/1102 [13:14:01<2:17:00, 49.22s/it] 85%|████████▍ | 936/1102 [13:14:50<2:16:02, 49.17s/it]                                                       {'loss': 0.6739, 'learning_rate': 5.8434172084369076e-05, 'epoch': 0.85}
 85%|████████▍ | 936/1102 [13:14:50<2:16:02, 49.17s/it] 85%|████████▌ | 937/1102 [13:15:39<2:15:13, 49.17s/it]                                                       {'loss': 0.5791, 'learning_rate': 5.774610202606939e-05, 'epoch': 0.85}
 85%|████████▌ | 937/1102 [13:15:39<2:15:13, 49.17s/it] 85%|████████▌ | 938/1102 [13:16:28<2:14:14, 49.11s/it]                                                       {'loss': 0.6966, 'learning_rate': 5.706185870460018e-05, 'epoch': 0.85}
 85%|████████▌ | 938/1102 [13:16:28<2:14:14, 49.11s/it] 85%|████████▌ | 939/1102 [13:17:17<2:13:01, 48.96s/it]                                                       {'loss': 0.6786, 'learning_rate': 5.638144804058559e-05, 'epoch': 0.85}
 85%|████████▌ | 939/1102 [13:17:17<2:13:01, 48.96s/it] 85%|████████▌ | 940/1102 [13:18:04<2:10:50, 48.46s/it]                                                       {'loss': 0.7137, 'learning_rate': 5.5704875921486656e-05, 'epoch': 0.85}
 85%|████████▌ | 940/1102 [13:18:04<2:10:50, 48.46s/it] 85%|████████▌ | 941/1102 [13:18:53<2:10:19, 48.57s/it]                                                       {'loss': 0.655, 'learning_rate': 5.503214820154978e-05, 'epoch': 0.85}
 85%|████████▌ | 941/1102 [13:18:53<2:10:19, 48.57s/it] 85%|████████▌ | 942/1102 [13:19:42<2:09:49, 48.68s/it]                                                       {'loss': 0.6539, 'learning_rate': 5.436327070175728e-05, 'epoch': 0.85}
 85%|████████▌ | 942/1102 [13:19:42<2:09:49, 48.68s/it] 86%|████████▌ | 943/1102 [13:20:31<2:09:23, 48.83s/it]                                                       {'loss': 0.6422, 'learning_rate': 5.369824920977567e-05, 'epoch': 0.86}
 86%|████████▌ | 943/1102 [13:20:31<2:09:23, 48.83s/it] 86%|████████▌ | 944/1102 [13:21:20<2:08:35, 48.83s/it]                                                       {'loss': 0.6673, 'learning_rate': 5.3037089479906375e-05, 'epoch': 0.86}
 86%|████████▌ | 944/1102 [13:21:20<2:08:35, 48.83s/it] 86%|████████▌ | 945/1102 [13:22:09<2:07:53, 48.88s/it]                                                       {'loss': 0.6829, 'learning_rate': 5.237979723303582e-05, 'epoch': 0.86}
 86%|████████▌ | 945/1102 [13:22:09<2:07:53, 48.88s/it] 86%|████████▌ | 946/1102 [13:22:58<2:07:31, 49.05s/it]                                                       {'loss': 0.7102, 'learning_rate': 5.172637815658582e-05, 'epoch': 0.86}
 86%|████████▌ | 946/1102 [13:22:58<2:07:31, 49.05s/it] 86%|████████▌ | 947/1102 [13:23:47<2:06:56, 49.14s/it]                                                       {'loss': 0.6762, 'learning_rate': 5.1076837904464105e-05, 'epoch': 0.86}
 86%|████████▌ | 947/1102 [13:23:47<2:06:56, 49.14s/it] 86%|████████▌ | 948/1102 [13:24:36<2:05:37, 48.94s/it]                                                       {'loss': 0.719, 'learning_rate': 5.0431182097016304e-05, 'epoch': 0.86}
 86%|████████▌ | 948/1102 [13:24:36<2:05:37, 48.94s/it] 86%|████████▌ | 949/1102 [13:25:25<2:05:08, 49.08s/it]                                                       {'loss': 0.669, 'learning_rate': 4.9789416320976114e-05, 'epoch': 0.86}
 86%|████████▌ | 949/1102 [13:25:25<2:05:08, 49.08s/it] 86%|████████▌ | 950/1102 [13:26:14<2:04:22, 49.10s/it]                                                       {'loss': 0.6195, 'learning_rate': 4.91515461294178e-05, 'epoch': 0.86}
 86%|████████▌ | 950/1102 [13:26:14<2:04:22, 49.10s/it] 86%|████████▋ | 951/1102 [13:27:04<2:03:53, 49.23s/it]                                                       {'loss': 0.6231, 'learning_rate': 4.851757704170795e-05, 'epoch': 0.86}
 86%|████████▋ | 951/1102 [13:27:04<2:03:53, 49.23s/it] 86%|████████▋ | 952/1102 [13:27:54<2:03:22, 49.35s/it]                                                       {'loss': 0.6308, 'learning_rate': 4.788751454345763e-05, 'epoch': 0.86}
 86%|████████▋ | 952/1102 [13:27:54<2:03:22, 49.35s/it] 86%|████████▋ | 953/1102 [13:28:42<2:02:08, 49.19s/it]                                                       {'loss': 0.6826, 'learning_rate': 4.726136408647463e-05, 'epoch': 0.86}
 86%|████████▋ | 953/1102 [13:28:42<2:02:08, 49.19s/it] 87%|████████▋ | 954/1102 [13:29:31<2:01:09, 49.12s/it]                                                       {'loss': 0.6867, 'learning_rate': 4.663913108871726e-05, 'epoch': 0.87}
 87%|████████▋ | 954/1102 [13:29:31<2:01:09, 49.12s/it] 87%|████████▋ | 955/1102 [13:30:21<2:00:21, 49.12s/it]                                                       {'loss': 0.6688, 'learning_rate': 4.60208209342462e-05, 'epoch': 0.87}
 87%|████████▋ | 955/1102 [13:30:21<2:00:21, 49.12s/it] 87%|████████▋ | 956/1102 [13:31:10<1:59:55, 49.28s/it]                                                       {'loss': 0.6194, 'learning_rate': 4.5406438973178864e-05, 'epoch': 0.87}
 87%|████████▋ | 956/1102 [13:31:10<1:59:55, 49.28s/it] 87%|████████▋ | 957/1102 [13:31:59<1:58:55, 49.21s/it]                                                       {'loss': 0.6777, 'learning_rate': 4.479599052164268e-05, 'epoch': 0.87}
 87%|████████▋ | 957/1102 [13:31:59<1:58:55, 49.21s/it] 87%|████████▋ | 958/1102 [13:32:49<1:58:19, 49.30s/it]                                                       {'loss': 0.6814, 'learning_rate': 4.418948086172914e-05, 'epoch': 0.87}
 87%|████████▋ | 958/1102 [13:32:49<1:58:19, 49.30s/it] 87%|████████▋ | 959/1102 [13:33:38<1:57:21, 49.24s/it]                                                       {'loss': 0.6801, 'learning_rate': 4.35869152414482e-05, 'epoch': 0.87}
 87%|████████▋ | 959/1102 [13:33:38<1:57:21, 49.24s/it] 87%|████████▋ | 960/1102 [13:34:26<1:56:03, 49.04s/it]                                                       {'loss': 0.7012, 'learning_rate': 4.298829887468275e-05, 'epoch': 0.87}
 87%|████████▋ | 960/1102 [13:34:26<1:56:03, 49.04s/it] 87%|████████▋ | 961/1102 [13:35:16<1:55:39, 49.22s/it]                                                       {'loss': 0.6564, 'learning_rate': 4.239363694114367e-05, 'epoch': 0.87}
 87%|████████▋ | 961/1102 [13:35:16<1:55:39, 49.22s/it] 87%|████████▋ | 962/1102 [13:36:05<1:54:57, 49.27s/it]                                                       {'loss': 0.6642, 'learning_rate': 4.180293458632489e-05, 'epoch': 0.87}
 87%|████████▋ | 962/1102 [13:36:05<1:54:57, 49.27s/it] 87%|████████▋ | 963/1102 [13:36:55<1:54:12, 49.30s/it]                                                       {'loss': 0.7059, 'learning_rate': 4.121619692145878e-05, 'epoch': 0.87}
 87%|████████▋ | 963/1102 [13:36:55<1:54:12, 49.30s/it] 87%|████████▋ | 964/1102 [13:37:44<1:53:05, 49.17s/it]                                                       {'loss': 0.6415, 'learning_rate': 4.0633429023472004e-05, 'epoch': 0.87}
 87%|████████▋ | 964/1102 [13:37:44<1:53:05, 49.17s/it] 88%|████████▊ | 965/1102 [13:38:33<1:52:11, 49.14s/it]                                                       {'loss': 0.656, 'learning_rate': 4.005463593494163e-05, 'epoch': 0.88}
 88%|████████▊ | 965/1102 [13:38:33<1:52:11, 49.14s/it] 88%|████████▊ | 966/1102 [13:39:22<1:51:38, 49.25s/it]                                                       {'loss': 0.6451, 'learning_rate': 3.947982266405159e-05, 'epoch': 0.88}
 88%|████████▊ | 966/1102 [13:39:22<1:51:38, 49.25s/it] 88%|████████▊ | 967/1102 [13:40:12<1:51:03, 49.36s/it]                                                       {'loss': 0.6619, 'learning_rate': 3.8908994184549126e-05, 'epoch': 0.88}
 88%|████████▊ | 967/1102 [13:40:12<1:51:03, 49.36s/it] 88%|████████▊ | 968/1102 [13:41:01<1:49:58, 49.24s/it]                                                       {'loss': 0.6471, 'learning_rate': 3.834215543570191e-05, 'epoch': 0.88}
 88%|████████▊ | 968/1102 [13:41:01<1:49:58, 49.24s/it] 88%|████████▊ | 969/1102 [13:41:50<1:49:18, 49.31s/it]                                                       {'loss': 0.6435, 'learning_rate': 3.777931132225526e-05, 'epoch': 0.88}
 88%|████████▊ | 969/1102 [13:41:50<1:49:18, 49.31s/it] 88%|████████▊ | 970/1102 [13:42:40<1:48:34, 49.35s/it]                                                       {'loss': 0.6628, 'learning_rate': 3.72204667143895e-05, 'epoch': 0.88}
 88%|████████▊ | 970/1102 [13:42:40<1:48:34, 49.35s/it] 88%|████████▊ | 971/1102 [13:43:29<1:47:38, 49.30s/it]                                                       {'loss': 0.7088, 'learning_rate': 3.666562644767823e-05, 'epoch': 0.88}
 88%|████████▊ | 971/1102 [13:43:29<1:47:38, 49.30s/it] 88%|████████▊ | 972/1102 [13:44:19<1:47:01, 49.40s/it]                                                       {'loss': 0.6558, 'learning_rate': 3.611479532304618e-05, 'epoch': 0.88}
 88%|████████▊ | 972/1102 [13:44:19<1:47:01, 49.40s/it] 88%|████████▊ | 973/1102 [13:45:09<1:46:47, 49.67s/it]                                                       {'loss': 0.6865, 'learning_rate': 3.556797810672785e-05, 'epoch': 0.88}
 88%|████████▊ | 973/1102 [13:45:09<1:46:47, 49.67s/it] 88%|████████▊ | 974/1102 [13:46:03<1:48:52, 51.04s/it]                                                       {'loss': 0.6638, 'learning_rate': 3.502517953022599e-05, 'epoch': 0.88}
 88%|████████▊ | 974/1102 [13:46:03<1:48:52, 51.04s/it] 88%|████████▊ | 975/1102 [13:47:09<1:57:25, 55.48s/it]                                                       {'loss': 0.6278, 'learning_rate': 3.448640429027111e-05, 'epoch': 0.88}
 88%|████████▊ | 975/1102 [13:47:09<1:57:25, 55.48s/it] 89%|████████▊ | 976/1102 [13:47:58<1:52:28, 53.56s/it]                                                       {'loss': 0.6634, 'learning_rate': 3.3951657048780226e-05, 'epoch': 0.89}
 89%|████████▊ | 976/1102 [13:47:58<1:52:28, 53.56s/it] 89%|████████▊ | 977/1102 [13:48:47<1:48:39, 52.15s/it]                                                       {'loss': 0.6673, 'learning_rate': 3.3420942432817124e-05, 'epoch': 0.89}
 89%|████████▊ | 977/1102 [13:48:47<1:48:39, 52.15s/it] 89%|████████▊ | 978/1102 [13:49:36<1:45:46, 51.18s/it]                                                       {'loss': 0.683, 'learning_rate': 3.2894265034552004e-05, 'epoch': 0.89}
 89%|████████▊ | 978/1102 [13:49:36<1:45:46, 51.18s/it] 89%|████████▉ | 979/1102 [13:50:25<1:43:36, 50.54s/it]                                                       {'loss': 0.6169, 'learning_rate': 3.237162941122185e-05, 'epoch': 0.89}
 89%|████████▉ | 979/1102 [13:50:25<1:43:36, 50.54s/it] 89%|████████▉ | 980/1102 [13:51:14<1:42:06, 50.21s/it]                                                       {'loss': 0.6526, 'learning_rate': 3.1853040085090766e-05, 'epoch': 0.89}
 89%|████████▉ | 980/1102 [13:51:14<1:42:06, 50.21s/it] 89%|████████▉ | 981/1102 [13:52:03<1:40:32, 49.86s/it]                                                       {'loss': 0.7248, 'learning_rate': 3.133850154341139e-05, 'epoch': 0.89}
 89%|████████▉ | 981/1102 [13:52:03<1:40:32, 49.86s/it] 89%|████████▉ | 982/1102 [13:52:52<1:39:16, 49.64s/it]                                                       {'loss': 0.6421, 'learning_rate': 3.0828018238385266e-05, 'epoch': 0.89}
 89%|████████▉ | 982/1102 [13:52:52<1:39:16, 49.64s/it] 89%|████████▉ | 983/1102 [13:53:42<1:38:16, 49.55s/it]                                                       {'loss': 0.6776, 'learning_rate': 3.032159458712508e-05, 'epoch': 0.89}
 89%|████████▉ | 983/1102 [13:53:42<1:38:16, 49.55s/it] 89%|████████▉ | 984/1102 [13:54:31<1:37:05, 49.37s/it]                                                       {'loss': 0.6451, 'learning_rate': 2.981923497161615e-05, 'epoch': 0.89}
 89%|████████▉ | 984/1102 [13:54:31<1:37:05, 49.37s/it] 89%|████████▉ | 985/1102 [13:55:20<1:36:13, 49.34s/it]                                                       {'loss': 0.6682, 'learning_rate': 2.9320943738678107e-05, 'epoch': 0.89}
 89%|████████▉ | 985/1102 [13:55:20<1:36:13, 49.34s/it] 89%|████████▉ | 986/1102 [13:56:09<1:35:27, 49.37s/it]                                                       {'loss': 0.5964, 'learning_rate': 2.8826725199928237e-05, 'epoch': 0.89}
 89%|████████▉ | 986/1102 [13:56:09<1:35:27, 49.37s/it] 90%|████████▉ | 987/1102 [13:56:58<1:34:24, 49.26s/it]                                                       {'loss': 0.6979, 'learning_rate': 2.833658363174302e-05, 'epoch': 0.9}
 90%|████████▉ | 987/1102 [13:56:58<1:34:24, 49.26s/it] 90%|████████▉ | 988/1102 [13:57:48<1:33:33, 49.25s/it]                                                       {'loss': 0.6848, 'learning_rate': 2.785052327522214e-05, 'epoch': 0.9}
 90%|████████▉ | 988/1102 [13:57:48<1:33:33, 49.25s/it] 90%|████████▉ | 989/1102 [13:58:37<1:32:34, 49.16s/it]                                                       {'loss': 0.6493, 'learning_rate': 2.73685483361511e-05, 'epoch': 0.9}
 90%|████████▉ | 989/1102 [13:58:37<1:32:34, 49.16s/it] 90%|████████▉ | 990/1102 [13:59:26<1:31:39, 49.10s/it]                                                       {'loss': 0.6934, 'learning_rate': 2.689066298496523e-05, 'epoch': 0.9}
 90%|████████▉ | 990/1102 [13:59:26<1:31:39, 49.10s/it] 90%|████████▉ | 991/1102 [14:00:15<1:31:00, 49.20s/it]                                                       {'loss': 0.5944, 'learning_rate': 2.6416871356713223e-05, 'epoch': 0.9}
 90%|████████▉ | 991/1102 [14:00:15<1:31:00, 49.20s/it] 90%|█████████ | 992/1102 [14:01:04<1:29:59, 49.09s/it]                                                       {'loss': 0.7102, 'learning_rate': 2.594717755102205e-05, 'epoch': 0.9}
 90%|█████████ | 992/1102 [14:01:04<1:29:59, 49.09s/it] 90%|█████████ | 993/1102 [14:01:53<1:29:17, 49.15s/it]                                                       {'loss': 0.6987, 'learning_rate': 2.548158563206038e-05, 'epoch': 0.9}
 90%|█████████ | 993/1102 [14:01:53<1:29:17, 49.15s/it] 90%|█████████ | 994/1102 [14:02:43<1:28:39, 49.25s/it]                                                       {'loss': 0.6366, 'learning_rate': 2.50200996285046e-05, 'epoch': 0.9}
 90%|█████████ | 994/1102 [14:02:43<1:28:39, 49.25s/it] 90%|█████████ | 995/1102 [14:03:36<1:30:08, 50.55s/it]                                                       {'loss': 0.6478, 'learning_rate': 2.4562723533503083e-05, 'epoch': 0.9}
 90%|█████████ | 995/1102 [14:03:36<1:30:08, 50.55s/it] 90%|█████████ | 996/1102 [14:09:28<4:09:09, 141.03s/it]                                                        {'loss': 0.6588, 'learning_rate': 2.4109461304642254e-05, 'epoch': 0.9}
 90%|█████████ | 996/1102 [14:09:28<4:09:09, 141.03s/it] 90%|█████████ | 997/1102 [14:10:18<3:18:35, 113.48s/it]                                                        {'loss': 0.6477, 'learning_rate': 2.366031686391168e-05, 'epoch': 0.9}
 90%|█████████ | 997/1102 [14:10:18<3:18:35, 113.48s/it] 91%|█████████ | 998/1102 [14:11:08<2:43:53, 94.55s/it]                                                        {'loss': 0.6623, 'learning_rate': 2.3215294097670923e-05, 'epoch': 0.91}
 91%|█████████ | 998/1102 [14:11:09<2:43:53, 94.55s/it] 91%|█████████ | 999/1102 [14:13:00<2:51:27, 99.88s/it]                                                       {'loss': 0.6737, 'learning_rate': 2.2774396856615088e-05, 'epoch': 0.91}
 91%|█████████ | 999/1102 [14:13:00<2:51:27, 99.88s/it] 91%|█████████ | 1000/1102 [14:13:50<2:24:01, 84.72s/it]                                                        {'loss': 0.6506, 'learning_rate': 2.233762895574226e-05, 'epoch': 0.91}
 91%|█████████ | 1000/1102 [14:13:50<2:24:01, 84.72s/it] 91%|█████████ | 1001/1102 [14:14:39<2:04:39, 74.06s/it]                                                        {'loss': 0.6919, 'learning_rate': 2.1904994174319904e-05, 'epoch': 0.91}
 91%|█████████ | 1001/1102 [14:14:39<2:04:39, 74.06s/it] 91%|█████████ | 1002/1102 [14:15:28<1:51:08, 66.69s/it]                                                        {'loss': 0.7091, 'learning_rate': 2.1476496255852684e-05, 'epoch': 0.91}
 91%|█████████ | 1002/1102 [14:15:28<1:51:08, 66.69s/it] 91%|█████████ | 1003/1102 [14:16:18<1:41:26, 61.48s/it]                                                        {'loss': 0.6782, 'learning_rate': 2.10521389080493e-05, 'epoch': 0.91}
 91%|█████████ | 1003/1102 [14:16:18<1:41:26, 61.48s/it] 91%|█████████ | 1004/1102 [14:17:07<1:34:21, 57.77s/it]                                                        {'loss': 0.6749, 'learning_rate': 2.0631925802791606e-05, 'epoch': 0.91}
 91%|█████████ | 1004/1102 [14:17:07<1:34:21, 57.77s/it] 91%|█████████ | 1005/1102 [14:17:56<1:29:16, 55.23s/it]                                                        {'loss': 0.6735, 'learning_rate': 2.021586057610153e-05, 'epoch': 0.91}
 91%|█████████ | 1005/1102 [14:17:56<1:29:16, 55.23s/it] 91%|█████████▏| 1006/1102 [14:18:45<1:25:18, 53.32s/it]                                                        {'loss': 0.7035, 'learning_rate': 1.9803946828110375e-05, 'epoch': 0.91}
 91%|█████████▏| 1006/1102 [14:18:45<1:25:18, 53.32s/it] 91%|█████████▏| 1007/1102 [14:19:34<1:22:22, 52.03s/it]                                                        {'loss': 0.6246, 'learning_rate': 1.9396188123027737e-05, 'epoch': 0.91}
 91%|█████████▏| 1007/1102 [14:19:34<1:22:22, 52.03s/it] 91%|█████████▏| 1008/1102 [14:20:23<1:20:13, 51.21s/it]                                                        {'loss': 0.6352, 'learning_rate': 1.8992587989110133e-05, 'epoch': 0.91}
 91%|█████████▏| 1008/1102 [14:20:23<1:20:13, 51.21s/it] 92%|█████████▏| 1009/1102 [14:21:12<1:18:20, 50.55s/it]                                                        {'loss': 0.6565, 'learning_rate': 1.8593149918630925e-05, 'epoch': 0.92}
 92%|█████████▏| 1009/1102 [14:21:12<1:18:20, 50.55s/it] 92%|█████████▏| 1010/1102 [14:22:02<1:16:57, 50.19s/it]                                                        {'loss': 0.6929, 'learning_rate': 1.8197877367849947e-05, 'epoch': 0.92}
 92%|█████████▏| 1010/1102 [14:22:02<1:16:57, 50.19s/it] 92%|█████████▏| 1011/1102 [14:22:51<1:15:53, 50.04s/it]                                                        {'loss': 0.6575, 'learning_rate': 1.780677375698364e-05, 'epoch': 0.92}
 92%|█████████▏| 1011/1102 [14:22:51<1:15:53, 50.04s/it] 92%|█████████▏| 1012/1102 [14:23:41<1:14:52, 49.91s/it]                                                        {'loss': 0.629, 'learning_rate': 1.7419842470175196e-05, 'epoch': 0.92}
 92%|█████████▏| 1012/1102 [14:23:41<1:14:52, 49.91s/it] 92%|█████████▏| 1013/1102 [14:24:30<1:13:34, 49.60s/it]                                                        {'loss': 0.6715, 'learning_rate': 1.70370868554659e-05, 'epoch': 0.92}
 92%|█████████▏| 1013/1102 [14:24:30<1:13:34, 49.60s/it] 92%|█████████▏| 1014/1102 [14:25:19<1:12:26, 49.39s/it]                                                        {'loss': 0.6503, 'learning_rate': 1.6658510224765333e-05, 'epoch': 0.92}
 92%|█████████▏| 1014/1102 [14:25:19<1:12:26, 49.39s/it] 92%|█████████▏| 1015/1102 [14:26:08<1:11:38, 49.41s/it]                                                        {'loss': 0.6646, 'learning_rate': 1.6284115853823444e-05, 'epoch': 0.92}
 92%|█████████▏| 1015/1102 [14:26:08<1:11:38, 49.41s/it] 92%|█████████▏| 1016/1102 [14:26:57<1:10:33, 49.23s/it]                                                        {'loss': 0.6803, 'learning_rate': 1.5913906982201743e-05, 'epoch': 0.92}
 92%|█████████▏| 1016/1102 [14:26:57<1:10:33, 49.23s/it] 92%|█████████▏| 1017/1102 [14:27:46<1:09:44, 49.23s/it]                                                        {'loss': 0.6371, 'learning_rate': 1.5547886813245537e-05, 'epoch': 0.92}
 92%|█████████▏| 1017/1102 [14:27:46<1:09:44, 49.23s/it] 92%|█████████▏| 1018/1102 [14:28:35<1:08:50, 49.17s/it]                                                        {'loss': 0.6697, 'learning_rate': 1.5186058514055912e-05, 'epoch': 0.92}
 92%|█████████▏| 1018/1102 [14:28:35<1:08:50, 49.17s/it] 92%|█████████▏| 1019/1102 [14:29:25<1:08:04, 49.22s/it]                                                        {'loss': 0.6732, 'learning_rate': 1.482842521546285e-05, 'epoch': 0.92}
 92%|█████████▏| 1019/1102 [14:29:25<1:08:04, 49.22s/it] 93%|█████████▎| 1020/1102 [14:30:14<1:07:19, 49.26s/it]                                                        {'loss': 0.6977, 'learning_rate': 1.447499001199748e-05, 'epoch': 0.93}
 93%|█████████▎| 1020/1102 [14:30:14<1:07:19, 49.26s/it] 93%|█████████▎| 1021/1102 [14:31:03<1:06:31, 49.28s/it]                                                        {'loss': 0.6216, 'learning_rate': 1.4125755961865827e-05, 'epoch': 0.93}
 93%|█████████▎| 1021/1102 [14:31:03<1:06:31, 49.28s/it] 93%|█████████▎| 1022/1102 [14:31:54<1:06:25, 49.82s/it]                                                        {'loss': 0.6574, 'learning_rate': 1.3780726086922102e-05, 'epoch': 0.93}
 93%|█████████▎| 1022/1102 [14:31:54<1:06:25, 49.82s/it] 93%|█████████▎| 1023/1102 [14:36:49<2:42:14, 123.23s/it]                                                         {'loss': 0.6671, 'learning_rate': 1.3439903372642614e-05, 'epoch': 0.93}
 93%|█████████▎| 1023/1102 [14:36:49<2:42:14, 123.23s/it] 93%|█████████▎| 1024/1102 [14:43:00<4:17:05, 197.76s/it]                                                         {'loss': 0.6469, 'learning_rate': 1.3103290768099797e-05, 'epoch': 0.93}
 93%|█████████▎| 1024/1102 [14:43:01<4:17:05, 197.76s/it] 93%|█████████▎| 1025/1102 [14:43:52<3:17:18, 153.74s/it]                                                         {'loss': 0.6222, 'learning_rate': 1.2770891185937105e-05, 'epoch': 0.93}
 93%|█████████▎| 1025/1102 [14:43:52<3:17:18, 153.74s/it] 93%|█████████▎| 1026/1102 [14:45:03<2:43:23, 129.00s/it]                                                         {'loss': 0.6932, 'learning_rate': 1.2442707502343331e-05, 'epoch': 0.93}
 93%|█████████▎| 1026/1102 [14:45:03<2:43:23, 129.00s/it] 93%|█████████▎| 1027/1102 [14:45:52<2:11:21, 105.08s/it]                                                         {'loss': 0.6715, 'learning_rate': 1.2118742557027885e-05, 'epoch': 0.93}
 93%|█████████▎| 1027/1102 [14:45:52<2:11:21, 105.08s/it] 93%|█████████▎| 1028/1102 [14:46:41<1:48:46, 88.19s/it]                                                         {'loss': 0.6178, 'learning_rate': 1.1798999153196433e-05, 'epoch': 0.93}
 93%|█████████▎| 1028/1102 [14:46:41<1:48:46, 88.19s/it] 93%|█████████▎| 1029/1102 [14:47:30<1:33:14, 76.64s/it]                                                        {'loss': 0.6692, 'learning_rate': 1.1483480057526363e-05, 'epoch': 0.93}
 93%|█████████▎| 1029/1102 [14:47:30<1:33:14, 76.64s/it] 93%|█████████▎| 1030/1102 [14:48:20<1:22:03, 68.38s/it]                                                        {'loss': 0.6683, 'learning_rate': 1.1172188000142803e-05, 'epoch': 0.93}
 93%|█████████▎| 1030/1102 [14:48:20<1:22:03, 68.38s/it] 94%|█████████▎| 1031/1102 [14:49:09<1:14:18, 62.79s/it]                                                        {'loss': 0.6849, 'learning_rate': 1.0865125674595466e-05, 'epoch': 0.94}
 94%|█████████▎| 1031/1102 [14:49:09<1:14:18, 62.79s/it] 94%|█████████▎| 1032/1102 [14:49:59<1:08:32, 58.76s/it]                                                        {'loss': 0.6789, 'learning_rate': 1.0562295737834737e-05, 'epoch': 0.94}
 94%|█████████▎| 1032/1102 [14:49:59<1:08:32, 58.76s/it] 94%|█████████▎| 1033/1102 [14:50:48<1:04:23, 56.00s/it]                                                        {'loss': 0.6468, 'learning_rate': 1.0263700810189069e-05, 'epoch': 0.94}
 94%|█████████▎| 1033/1102 [14:50:48<1:04:23, 56.00s/it] 94%|█████████▍| 1034/1102 [14:51:37<1:01:06, 53.93s/it]                                                        {'loss': 0.6385, 'learning_rate': 9.969343475342285e-06, 'epoch': 0.94}
 94%|█████████▍| 1034/1102 [14:51:37<1:01:06, 53.93s/it] 94%|█████████▍| 1035/1102 [14:52:26<58:26, 52.33s/it]                                                        {'loss': 0.6486, 'learning_rate': 9.679226280310981e-06, 'epoch': 0.94}
 94%|█████████▍| 1035/1102 [14:52:26<58:26, 52.33s/it] 94%|█████████▍| 1036/1102 [14:53:15<56:36, 51.47s/it]                                                      {'loss': 0.6536, 'learning_rate': 9.393351735422773e-06, 'epoch': 0.94}
 94%|█████████▍| 1036/1102 [14:53:15<56:36, 51.47s/it] 94%|█████████▍| 1037/1102 [14:54:04<54:56, 50.71s/it]                                                      {'loss': 0.6515, 'learning_rate': 9.111722314294356e-06, 'epoch': 0.94}
 94%|█████████▍| 1037/1102 [14:54:04<54:56, 50.71s/it] 94%|█████████▍| 1038/1102 [14:54:54<53:37, 50.27s/it]                                                      {'loss': 0.68, 'learning_rate': 8.834340453810374e-06, 'epoch': 0.94}
 94%|█████████▍| 1038/1102 [14:54:54<53:37, 50.27s/it] 94%|█████████▍| 1039/1102 [14:55:43<52:22, 49.88s/it]                                                      {'loss': 0.6682, 'learning_rate': 8.561208554101863e-06, 'epoch': 0.94}
 94%|█████████▍| 1039/1102 [14:55:43<52:22, 49.88s/it] 94%|█████████▍| 1040/1102 [14:56:32<51:22, 49.72s/it]                                                      {'loss': 0.677, 'learning_rate': 8.292328978526108e-06, 'epoch': 0.94}
 94%|█████████▍| 1040/1102 [14:56:32<51:22, 49.72s/it] 94%|█████████▍| 1041/1102 [14:57:21<50:22, 49.55s/it]                                                      {'loss': 0.6774, 'learning_rate': 8.027704053645612e-06, 'epoch': 0.94}
 94%|█████████▍| 1041/1102 [14:57:21<50:22, 49.55s/it] 95%|█████████▍| 1042/1102 [14:58:10<49:26, 49.45s/it]                                                      {'loss': 0.7102, 'learning_rate': 7.767336069208319e-06, 'epoch': 0.95}
 95%|█████████▍| 1042/1102 [14:58:10<49:26, 49.45s/it] 95%|█████████▍| 1043/1102 [14:59:00<48:33, 49.39s/it]                                                      {'loss': 0.6345, 'learning_rate': 7.511227278127697e-06, 'epoch': 0.95}
 95%|█████████▍| 1043/1102 [14:59:00<48:33, 49.39s/it] 95%|█████████▍| 1044/1102 [14:59:49<47:46, 49.42s/it]                                                      {'loss': 0.6356, 'learning_rate': 7.259379896463248e-06, 'epoch': 0.95}
 95%|█████████▍| 1044/1102 [14:59:49<47:46, 49.42s/it] 95%|█████████▍| 1045/1102 [15:00:38<46:53, 49.35s/it]                                                      {'loss': 0.6811, 'learning_rate': 7.0117961034011915e-06, 'epoch': 0.95}
 95%|█████████▍| 1045/1102 [15:00:38<46:53, 49.35s/it] 95%|█████████▍| 1046/1102 [15:01:27<45:59, 49.28s/it]                                                      {'loss': 0.6803, 'learning_rate': 6.768478041236037e-06, 'epoch': 0.95}
 95%|█████████▍| 1046/1102 [15:01:27<45:59, 49.28s/it] 95%|█████████▌| 1047/1102 [15:02:17<45:14, 49.36s/it]                                                      {'loss': 0.6785, 'learning_rate': 6.529427815351374e-06, 'epoch': 0.95}
 95%|█████████▌| 1047/1102 [15:02:17<45:14, 49.36s/it] 95%|█████████▌| 1048/1102 [15:03:06<44:28, 49.41s/it]                                                      {'loss': 0.6839, 'learning_rate': 6.294647494202444e-06, 'epoch': 0.95}
 95%|█████████▌| 1048/1102 [15:03:06<44:28, 49.41s/it] 95%|█████████▌| 1049/1102 [15:04:01<45:02, 50.99s/it]                                                      {'loss': 0.6395, 'learning_rate': 6.064139109297484e-06, 'epoch': 0.95}
 95%|█████████▌| 1049/1102 [15:04:01<45:02, 50.99s/it] 95%|█████████▌| 1050/1102 [15:07:30<1:25:20, 98.48s/it]                                                        {'loss': 0.6525, 'learning_rate': 5.837904655180748e-06, 'epoch': 0.95}
 95%|█████████▌| 1050/1102 [15:07:30<1:25:20, 98.48s/it] 95%|█████████▌| 1051/1102 [15:08:20<1:11:13, 83.79s/it]                                                        {'loss': 0.6072, 'learning_rate': 5.615946089414737e-06, 'epoch': 0.95}
 95%|█████████▌| 1051/1102 [15:08:20<1:11:13, 83.79s/it] 95%|█████████▌| 1052/1102 [15:09:09<1:01:05, 73.31s/it]                                                        {'loss': 0.7001, 'learning_rate': 5.398265332563934e-06, 'epoch': 0.95}
 95%|█████████▌| 1052/1102 [15:09:09<1:01:05, 73.31s/it] 96%|█████████▌| 1053/1102 [15:09:58<53:54, 66.01s/it]                                                        {'loss': 0.6589, 'learning_rate': 5.184864268177325e-06, 'epoch': 0.96}
 96%|█████████▌| 1053/1102 [15:09:58<53:54, 66.01s/it] 96%|█████████▌| 1054/1102 [15:10:47<48:48, 61.00s/it]                                                      {'loss': 0.7014, 'learning_rate': 4.975744742772848e-06, 'epoch': 0.96}
 96%|█████████▌| 1054/1102 [15:10:47<48:48, 61.00s/it] 96%|█████████▌| 1055/1102 [15:11:36<45:00, 57.47s/it]                                                      {'loss': 0.6328, 'learning_rate': 4.770908565820964e-06, 'epoch': 0.96}
 96%|█████████▌| 1055/1102 [15:11:36<45:00, 57.47s/it] 96%|█████████▌| 1056/1102 [15:12:25<42:09, 55.00s/it]                                                      {'loss': 0.6141, 'learning_rate': 4.570357509729228e-06, 'epoch': 0.96}
 96%|█████████▌| 1056/1102 [15:12:25<42:09, 55.00s/it] 96%|█████████▌| 1057/1102 [15:13:15<39:56, 53.26s/it]                                                      {'loss': 0.6433, 'learning_rate': 4.3740933098269095e-06, 'epoch': 0.96}
 96%|█████████▌| 1057/1102 [15:13:15<39:56, 53.26s/it] 96%|█████████▌| 1058/1102 [15:14:04<38:07, 51.99s/it]                                                      {'loss': 0.6384, 'learning_rate': 4.182117664349783e-06, 'epoch': 0.96}
 96%|█████████▌| 1058/1102 [15:14:04<38:07, 51.99s/it] 96%|█████████▌| 1059/1102 [15:14:53<36:36, 51.08s/it]                                                      {'loss': 0.6457, 'learning_rate': 3.99443223442586e-06, 'epoch': 0.96}
 96%|█████████▌| 1059/1102 [15:14:53<36:36, 51.08s/it] 96%|█████████▌| 1060/1102 [15:15:42<35:21, 50.51s/it]                                                      {'loss': 0.6818, 'learning_rate': 3.811038644060516e-06, 'epoch': 0.96}
 96%|█████████▌| 1060/1102 [15:15:42<35:21, 50.51s/it] 96%|█████████▋| 1061/1102 [15:16:31<34:13, 50.08s/it]                                                      {'loss': 0.6799, 'learning_rate': 3.6319384801227763e-06, 'epoch': 0.96}
 96%|█████████▋| 1061/1102 [15:16:31<34:13, 50.08s/it] 96%|█████████▋| 1062/1102 [15:17:20<33:10, 49.77s/it]                                                      {'loss': 0.6573, 'learning_rate': 3.4571332923314935e-06, 'epoch': 0.96}
 96%|█████████▋| 1062/1102 [15:17:20<33:10, 49.77s/it] 96%|█████████▋| 1063/1102 [15:18:09<32:13, 49.58s/it]                                                      {'loss': 0.6398, 'learning_rate': 3.2866245932418603e-06, 'epoch': 0.96}
 96%|█████████▋| 1063/1102 [15:18:09<32:13, 49.58s/it] 97%|█████████▋| 1064/1102 [15:18:59<31:23, 49.58s/it]                                                      {'loss': 0.6672, 'learning_rate': 3.1204138582324736e-06, 'epoch': 0.97}
 97%|█████████▋| 1064/1102 [15:18:59<31:23, 49.58s/it] 97%|█████████▋| 1065/1102 [15:19:48<30:31, 49.51s/it]                                                      {'loss': 0.6346, 'learning_rate': 2.9585025254924568e-06, 'epoch': 0.97}
 97%|█████████▋| 1065/1102 [15:19:48<30:31, 49.51s/it] 97%|█████████▋| 1066/1102 [15:20:37<29:41, 49.49s/it]                                                      {'loss': 0.6368, 'learning_rate': 2.800891996009025e-06, 'epoch': 0.97}
 97%|█████████▋| 1066/1102 [15:20:37<29:41, 49.49s/it] 97%|█████████▋| 1067/1102 [15:21:27<28:51, 49.47s/it]                                                      {'loss': 0.6391, 'learning_rate': 2.647583633555384e-06, 'epoch': 0.97}
 97%|█████████▋| 1067/1102 [15:21:27<28:51, 49.47s/it] 97%|█████████▋| 1068/1102 [15:22:16<27:56, 49.30s/it]                                                      {'loss': 0.6651, 'learning_rate': 2.498578764678849e-06, 'epoch': 0.97}
 97%|█████████▋| 1068/1102 [15:22:16<27:56, 49.30s/it] 97%|█████████▋| 1069/1102 [15:23:05<27:08, 49.34s/it]                                                      {'loss': 0.6611, 'learning_rate': 2.3538786786896915e-06, 'epoch': 0.97}
 97%|█████████▋| 1069/1102 [15:23:05<27:08, 49.34s/it] 97%|█████████▋| 1070/1102 [15:23:54<26:16, 49.26s/it]                                                      {'loss': 0.6712, 'learning_rate': 2.2134846276494205e-06, 'epoch': 0.97}
 97%|█████████▋| 1070/1102 [15:23:54<26:16, 49.26s/it] 97%|█████████▋| 1071/1102 [15:24:43<25:24, 49.19s/it]                                                      {'loss': 0.6681, 'learning_rate': 2.0773978263605164e-06, 'epoch': 0.97}
 97%|█████████▋| 1071/1102 [15:24:43<25:24, 49.19s/it] 97%|█████████▋| 1072/1102 [15:25:32<24:33, 49.12s/it]                                                      {'loss': 0.6905, 'learning_rate': 1.9456194523554403e-06, 'epoch': 0.97}
 97%|█████████▋| 1072/1102 [15:25:32<24:33, 49.12s/it] 97%|█████████▋| 1073/1102 [15:26:22<23:46, 49.19s/it]                                                      {'loss': 0.6559, 'learning_rate': 1.8181506458869733e-06, 'epoch': 0.97}
 97%|█████████▋| 1073/1102 [15:26:22<23:46, 49.19s/it] 97%|█████████▋| 1074/1102 [15:27:10<22:53, 49.04s/it]                                                      {'loss': 0.6707, 'learning_rate': 1.6949925099176699e-06, 'epoch': 0.97}
 97%|█████████▋| 1074/1102 [15:27:10<22:53, 49.04s/it] 98%|█████████▊| 1075/1102 [15:27:59<22:05, 49.08s/it]                                                      {'loss': 0.7317, 'learning_rate': 1.5761461101110318e-06, 'epoch': 0.98}
 98%|█████████▊| 1075/1102 [15:27:59<22:05, 49.08s/it] 98%|█████████▊| 1076/1102 [15:28:49<21:15, 49.07s/it]                                                      {'loss': 0.6828, 'learning_rate': 1.4616124748217385e-06, 'epoch': 0.98}
 98%|█████████▊| 1076/1102 [15:28:49<21:15, 49.07s/it] 98%|█████████▊| 1077/1102 [15:29:37<20:23, 48.93s/it]                                                      {'loss': 0.656, 'learning_rate': 1.351392595087042e-06, 'epoch': 0.98}
 98%|█████████▊| 1077/1102 [15:29:37<20:23, 48.93s/it] 98%|█████████▊| 1078/1102 [15:30:27<19:38, 49.11s/it]                                                      {'loss': 0.6692, 'learning_rate': 1.245487424618108e-06, 'epoch': 0.98}
 98%|█████████▊| 1078/1102 [15:30:27<19:38, 49.11s/it] 98%|█████████▊| 1079/1102 [15:31:15<18:47, 49.02s/it]                                                      {'loss': 0.7318, 'learning_rate': 1.1438978797916889e-06, 'epoch': 0.98}
 98%|█████████▊| 1079/1102 [15:31:15<18:47, 49.02s/it] 98%|█████████▊| 1080/1102 [15:32:05<18:02, 49.21s/it]                                                      {'loss': 0.6726, 'learning_rate': 1.0466248396424072e-06, 'epoch': 0.98}
 98%|█████████▊| 1080/1102 [15:32:05<18:02, 49.21s/it] 98%|█████████▊| 1081/1102 [15:32:54<17:12, 49.15s/it]                                                      {'loss': 0.6666, 'learning_rate': 9.536691458548741e-07, 'epoch': 0.98}
 98%|█████████▊| 1081/1102 [15:32:54<17:12, 49.15s/it] 98%|█████████▊| 1082/1102 [15:33:43<16:23, 49.18s/it]                                                      {'loss': 0.6502, 'learning_rate': 8.650316027566385e-07, 'epoch': 0.98}
 98%|█████████▊| 1082/1102 [15:33:43<16:23, 49.18s/it] 98%|█████████▊| 1083/1102 [15:34:33<15:35, 49.26s/it]                                                      {'loss': 0.6948, 'learning_rate': 7.807129773110821e-07, 'epoch': 0.98}
 98%|█████████▊| 1083/1102 [15:34:33<15:35, 49.26s/it] 98%|█████████▊| 1084/1102 [15:35:22<14:46, 49.23s/it]                                                      {'loss': 0.6903, 'learning_rate': 7.007139991108136e-07, 'epoch': 0.98}
 98%|█████████▊| 1084/1102 [15:35:22<14:46, 49.23s/it] 98%|█████████▊| 1085/1102 [15:36:12<13:58, 49.34s/it]                                                      {'loss': 0.7248, 'learning_rate': 6.250353603714509e-07, 'epoch': 0.98}
 98%|█████████▊| 1085/1102 [15:36:12<13:58, 49.34s/it] 99%|█████████▊| 1086/1102 [15:37:00<13:06, 49.19s/it]                                                      {'loss': 0.636, 'learning_rate': 5.536777159254602e-07, 'epoch': 0.99}
 99%|█████████▊| 1086/1102 [15:37:00<13:06, 49.19s/it] 99%|█████████▊| 1087/1102 [15:37:49<12:15, 49.01s/it]                                                      {'loss': 0.7028, 'learning_rate': 4.866416832167153e-07, 'epoch': 0.99}
 99%|█████████▊| 1087/1102 [15:37:49<12:15, 49.01s/it] 99%|█████████▊| 1088/1102 [15:38:38<11:27, 49.10s/it]                                                      {'loss': 0.6584, 'learning_rate': 4.239278422948911e-07, 'epoch': 0.99}
 99%|█████████▊| 1088/1102 [15:38:38<11:27, 49.10s/it] 99%|█████████▉| 1089/1102 [15:39:27<10:37, 49.07s/it]                                                      {'loss': 0.682, 'learning_rate': 3.655367358106343e-07, 'epoch': 0.99}
 99%|█████████▉| 1089/1102 [15:39:27<10:37, 49.07s/it] 99%|█████████▉| 1090/1102 [15:40:17<09:51, 49.29s/it]                                                      {'loss': 0.6262, 'learning_rate': 3.114688690109002e-07, 'epoch': 0.99}
 99%|█████████▉| 1090/1102 [15:40:17<09:51, 49.29s/it] 99%|█████████▉| 1091/1102 [15:41:08<09:08, 49.89s/it]                                                      {'loss': 0.6496, 'learning_rate': 2.617247097342901e-07, 'epoch': 0.99}
 99%|█████████▉| 1091/1102 [15:41:08<09:08, 49.89s/it] 99%|█████████▉| 1092/1102 [15:42:18<09:17, 55.71s/it]                                                      {'loss': 0.6755, 'learning_rate': 2.1630468840738715e-07, 'epoch': 0.99}
 99%|█████████▉| 1092/1102 [15:42:18<09:17, 55.71s/it] 99%|█████████▉| 1093/1102 [15:43:41<09:36, 64.04s/it]                                                      {'loss': 0.6675, 'learning_rate': 1.7520919804075996e-07, 'epoch': 0.99}
 99%|█████████▉| 1093/1102 [15:43:41<09:36, 64.04s/it] 99%|█████████▉| 1094/1102 [15:44:31<07:57, 59.66s/it]                                                      {'loss': 0.654, 'learning_rate': 1.3843859422574267e-07, 'epoch': 0.99}
 99%|█████████▉| 1094/1102 [15:44:31<07:57, 59.66s/it] 99%|█████████▉| 1095/1102 [15:45:28<06:52, 58.90s/it]                                                      {'loss': 0.6791, 'learning_rate': 1.0599319513115991e-07, 'epoch': 0.99}
 99%|█████████▉| 1095/1102 [15:45:28<06:52, 58.90s/it] 99%|█████████▉| 1096/1102 [15:54:14<19:54, 199.02s/it]                                                       {'loss': 0.6354, 'learning_rate': 7.78732815007177e-08, 'epoch': 0.99}
 99%|█████████▉| 1096/1102 [15:54:14<19:54, 199.02s/it]100%|█████████▉| 1097/1102 [15:55:02<12:49, 153.87s/it]                                                       {'loss': 0.6268, 'learning_rate': 5.40790966505611e-08, 'epoch': 1.0}
100%|█████████▉| 1097/1102 [15:55:02<12:49, 153.87s/it]100%|█████████▉| 1098/1102 [15:55:52<08:10, 122.53s/it]                                                       {'loss': 0.6458, 'learning_rate': 3.4610846467109106e-08, 'epoch': 1.0}
100%|█████████▉| 1098/1102 [15:55:52<08:10, 122.53s/it]100%|█████████▉| 1099/1102 [15:56:41<05:01, 100.62s/it]                                                       {'loss': 0.6447, 'learning_rate': 1.9468699405444934e-08, 'epoch': 1.0}
100%|█████████▉| 1099/1102 [15:56:41<05:01, 100.62s/it]100%|█████████▉| 1100/1102 [15:57:30<02:50, 85.02s/it]                                                       {'loss': 0.6782, 'learning_rate': 8.652786487484132e-09, 'epoch': 1.0}
100%|█████████▉| 1100/1102 [15:57:30<02:50, 85.02s/it]100%|█████████▉| 1101/1102 [15:58:18<01:14, 74.05s/it]                                                      {'loss': 0.721, 'learning_rate': 2.163201301308426e-09, 'epoch': 1.0}
100%|█████████▉| 1101/1102 [15:58:18<01:14, 74.05s/it]100%|██████████| 1102/1102 [15:59:08<00:00, 66.71s/it]                                                      {'loss': 0.6564, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 1102/1102 [15:59:08<00:00, 66.71s/it]                                                      {'train_runtime': 57548.6021, 'train_samples_per_second': 4.826, 'train_steps_per_second': 0.019, 'train_loss': 0.717554172240671, 'epoch': 1.0}
100%|██████████| 1102/1102 [15:59:08<00:00, 66.71s/it]100%|██████████| 1102/1102 [15:59:08<00:00, 52.22s/it]
[2024-11-03 02:02:15,324] [INFO] [launch.py:351:main] Process 8742 exits successfully.
[2024-11-03 02:02:16,325] [INFO] [launch.py:351:main] Process 8737 exits successfully.
[2024-11-03 02:02:17,327] [INFO] [launch.py:351:main] Process 8738 exits successfully.
[2024-11-03 02:02:17,327] [INFO] [launch.py:351:main] Process 8736 exits successfully.
[2024-11-03 02:02:18,329] [INFO] [launch.py:351:main] Process 8740 exits successfully.
[2024-11-03 02:02:20,331] [INFO] [launch.py:351:main] Process 8739 exits successfully.
[2024-11-03 02:02:20,331] [INFO] [launch.py:351:main] Process 8741 exits successfully.
